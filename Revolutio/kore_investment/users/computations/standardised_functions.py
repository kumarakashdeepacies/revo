import ast
from ast import literal_eval
import base64
import datetime as dt
from datetime import date, datetime, timedelta
from email import encoders
from email.mime.base import MIMEBase
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from html.parser import HTMLParser
from io import StringIO
import json
import logging
import os
import pickle
import random
import re
import smtplib
import string
import time

from O365 import Account
from cryptography.fernet import Fernet
from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import dateutil.parser as dp
from dateutil.relativedelta import relativedelta
import dateutil.rrule as dr
from django.contrib import messages
import numpy as np
import pandas as pd
import pyarrow as pa
from rq_scheduler import Scheduler

from config.settings.base import (
    MEDIA_ROOT,
    PASSCODE_KEY,
    PLATFORM_FILE_PATH,
    engine,
    redis_instance,
    redis_instance_scheduler,
)
from kore_investment.users.computation_studio_lib import Credit_Card_Validator, SFTPconnectors
from kore_investment.users.computations import (
    Computation_master_file,
    Data_replica_utilities,
    data_to_pdf_converter,
)
from kore_investment.users.computations.Data_fetching_functions import data_chunking
from kore_investment.users.computations.db_centralised_function import (
    app_engine_generator,
    current_app_db_extractor,
    data_handling,
    db_engine_extractor,
    db_name_extractor,
    read_data_func,
    update_data_func,
)
from kore_investment.users.computations.file_storage import (
    computation_storage,
    filemanager_diskstorage,
    flush_diskstorage,
    read_computation_from_storage,
    read_diskstorage,
    to_diskstorage,
)
from kore_investment.users.computations.multi_select_handler import (
    multi_select_id_to_value_converter,
    multi_select_value_converter,
)
from kore_investment.utils.utilities import tenant_schema_from_request

from . import dynamic_model_create, emailBox_functions, search_filter


def datetime_handler(x, date_format="iso"):
    if isinstance(x, (dt.date)):
        if date_format == "iso":
            return x.isoformat()
        else:
            return x.strftime("%Y-%m-%d")
    elif isinstance(x, (dt.datetime)):
        if date_format == "iso":
            return x.isoformat()
        else:
            return x.strftime("%Y-%m-%d %H:%M:%S")
    elif isinstance(x, (dt.time)):
        if date_format == "iso":
            return x.isoformat()
        else:
            return x.strftime("%H:%M:%S")
    else:
        return x
    raise TypeError("Unknown type")


class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.datetime64):
            return str(obj)
        elif isinstance(obj, date):
            return obj.strftime("%Y-%m-%d")
        elif isinstance(obj, datetime):
            return obj.strftime("%Y-%m-%d %H:%M:%S")
        else:
            return super().default(obj)


def application_order_func(operation, request, data="", app_code=""):
    appCode = app_code
    if operation == "initial_fetch":
        data = {}
        data1 = {}
        data = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Application",
                    "Columns": ["process_group_names", "navbar_order"],
                },
                "condition": [
                    {
                        "column_name": "application_code",
                        "condition": "Equal to",
                        "input_value": appCode,
                        "and_or": "",
                    }
                ],
            },
        )
        sub = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "NavigationSideBar",
                    "Columns": ["item_name", "item_group_name"],
                },
                "condition": [],
            },
        )
        data = data.to_dict("records")
        sub_process_dict = {}
        for i in json.loads(data[0]["process_group_names"]):
            x = sub["item_group_name"] == f"{i}"

            sub_process = sub.loc[x,]
            sub_process_dict[i] = sub_process["item_name"].tolist()
        data1["process_group_names"] = json.loads(data[0]["process_group_names"])
        data1["sub_process"] = sub_process_dict
        try:
            data1["navbar_order"] = data[0]["navbar_order"]
        except Exception as e:
            logging.warning(f"Following exception occured - {e}")
            data1["navbar_order"] = ""
        pr = {}
        data1["sub_process"] = {}
        for i in json.loads(data1["navbar_order"]):
            for j in json.loads(data1["navbar_order"])[i]:
                pr[i] = j
                data1["sub_process"][i] = []
                for k in json.loads(data1["navbar_order"])[i][j]:
                    data1["sub_process"][i].append([k, json.loads(data1["navbar_order"])[i][j][k]])

        data1["process_group_names"] = {}
        data1["process_group_names"] = pr

        return data1
    elif operation == "update":
        update_data_func(
            request,
            config_dict={
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Application",
                    "Columns": [
                        {
                            "column_name": "navbar_order",
                            "input_value": data,
                            "separator": "",
                        },
                    ],
                },
                "condition": [
                    {
                        "column_name": "application_code",
                        "condition": "Equal to",
                        "input_value": appCode,
                        "and_or": "",
                    }
                ],
            },
        )
        return True


def list_view_tab(user_name, screen_path, row_data, request):
    data = {}

    # json to be retrieved from row passed as an argument in the function
    try:
        list_view_tab_body_content = json.loads(row_data["tab_body_content"])
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        list_view_tab_body_content = {
            "Category_attributes": {
                "Mandatory": {"Table_name": "CountryMaster", "DroppedFields": []},
                "Optional": {"Template_choice": "list_view_template_1.html"},
                "Default": {"Template_choice": "list_view_template_1.html"},
            },
            "Tab_Constraint": [],
            "Category_sub_elements": [
                {
                    "Category_sub_element_name": "Data_table",
                    "Required": "Yes",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "CountryMaster"},
                        {
                            "attr": "Upload",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Multi_edit",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Save template",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Expand",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
                {
                    "Category_sub_element_name": "Plot_chart",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "DEPENDENT_VALUE"},
                        {
                            "attr": "Plot_chart",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
                {
                    "Category_sub_element_name": "Set_alert",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "DEPENDENT_VALUE"},
                        {
                            "attr": "Set_alert",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
                {
                    "Category_sub_element_name": "Filter",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "DEPENDENT_VALUE"},
                        {
                            "attr": "Filter",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
            ],
        }

    # abbreviation for list_view_tab_body_content
    ltbc = list_view_tab_body_content
    list_view_table_name = ltbc["Category_attributes"]["Mandatory"]["Table_name"]
    if "table_header_data" in ltbc:
        list_table_header_config = ltbc["table_header_data"]
    else:
        list_table_header_config = {}
    sql_table_name = "users_" + list_view_table_name.lower()
    actual_model_name = dynamic_model_create.get_model_class(list_view_table_name, request)
    verbose_column_name_dictf = {
        field.name: field.verbose_name for field in actual_model_name.concrete_fields
    }
    verbose_column_name_dictf_title = {
        field.name: field.verbose_name.title() for field in actual_model_name.concrete_fields
    }
    file_list = []
    for field in actual_model_name.concrete_fields:
        if field.internal_type in ["FileField", "VideoField", "ImageField"]:
            file_list.append(field.verbose_name.title())
        else:
            continue

    content1 = []

    if len(content1) == 0:
        tabledata = "empty"
    else:
        tabledata = "filled"

    headers11 = []
    content11 = []

    # json to be retrieved from row passed as an argument in the function
    try:
        list_view_tab_body_content = json.loads(row_data["tab_body_content"])
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        list_view_tab_body_content = {
            "Category_attributes": {
                "Mandatory": {"Table_name": "CountryMaster", "DroppedFields": []},
                "Optional": {"Template_choice": "list_view_template_1.html"},
                "Default": {"Template_choice": "list_view_template_1.html"},
            },
            "Category_sub_elements": [
                {
                    "Category_sub_element_name": "Data_table",
                    "Required": "Yes",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "CountryMaster"},
                        {
                            "attr": "Upload",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Multi_edit",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Save template",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Expand",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
                {
                    "Category_sub_element_name": "Plot_chart",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "DEPENDENT_VALUE"},
                        {
                            "attr": "Plot_chart",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
                {
                    "Category_sub_element_name": "Set_alert",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "DEPENDENT_VALUE"},
                        {
                            "attr": "Set_alert",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
                {
                    "Category_sub_element_name": "Filter",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "DEPENDENT_VALUE"},
                        {
                            "attr": "Filter",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
            ],
        }

    # abbreviation for list_view_tab_body_content
    ltbc = list_view_tab_body_content
    data["card_header_configs"] = ltbc["Category_attributes"]["Mandatory"].get("card_header_configs")
    list_view_table_name = ltbc["Category_attributes"]["Mandatory"]["Table_name"]
    if "table_header_data" in ltbc:
        list_table_header_config = ltbc["table_header_data"]
    else:
        list_table_header_config = {}
    for k, v in list_table_header_config.items():
        nwe = []
        for i in v:
            nwe.append(verbose_column_name_dictf[i])
        list_table_header_config[k] = nwe
    sql_table_name = "users_" + list_view_table_name.lower()
    if ltbc.get("mulview_comp_element_id"):
        comp_element_id = ltbc["mulview_comp_element_id"]
    else:
        comp_element_id = ""
    if ltbc.get("customView"):
        customViewColumn = ltbc.get("customView")
    else:
        customViewColumn = []
    customViewColumnNotVerbose = []
    if len(customViewColumn) > 0:

        custom_view_field_name = {
            field.verbose_name.title(): field.name for field in actual_model_name.concrete_fields
        }

        custom_view_index = []
        index = 0
        for i in custom_view_field_name:
            index = index + 1
            for j in customViewColumn:
                if j == i:
                    custom_view_index.append(index)
                    customViewColumnNotVerbose.append(custom_view_field_name[i])
                else:
                    pass

        data["custom_view_index"] = custom_view_index
        data["custom_view_cols"] = customViewColumnNotVerbose
    else:
        data["custom_view_index"] = []
        data["custom_view_columns"] = []
    if ltbc.get("reportingView"):
        report_view_template = ltbc["reportingView"]["Template_choice"]
        report_view_column = ltbc["reportingView"]["reportingViewColumns"]
    else:
        report_view_template = ""
        report_view_column = []
    data["reportingViewTableName"] = list_view_table_name
    if (
        report_view_template == "Reporting View"
        or report_view_template == "List View With History"
        or report_view_template == "Scenario"
        or report_view_template == "Multi Dropdown View"
    ):
        data["reportingViewTemplate"] = report_view_template
    if report_view_template == "Approval Template" and report_view_column != []:
        data["reportingViewTemplate"] = report_view_template
    if report_view_template == "Multi Dropdown View":
        if ltbc.get("mulview_def_cols"):
            data["reportingViewColumnsValue"] = ltbc["mulview_def_cols"]
            data["default_view_name"] = ltbc["mulview_def"]
    if report_view_template == "Scenario":
        data["reportingViewColumnsValue"] = []
    if (
        report_view_template == "Reporting View"
        or report_view_template == "List View With History"
        or report_view_template == "Approval Template"
    ) and report_view_column:

        data["reportingViewColumns"] = []
        data["reportingViewColumnsValue"] = []
        if "reportingShowLatest" in ltbc["reportingView"]:
            data["reportingShowLatest"] = ltbc["reportingView"]["reportingShowLatest"]
        if "basicfilter_config" in ltbc["reportingView"]:
            data["basicfilter_config"] = ltbc["reportingView"]["basicfilter_config"]
            basic_filter = json.loads(data["basicfilter_config"])
        else:
            pass

        report_view_field_name = {
            field.verbose_name: field.name for field in actual_model_name.concrete_fields
        }
        report_view_verbose_name = {
            field.name: field.verbose_name for field in actual_model_name.concrete_fields
        }
        data["reportViewVerboseColumn"] = []

        for i in report_view_column:
            j = report_view_verbose_name[i]
            data["reportingViewColumns"].append(i)
            data["reportViewVerboseColumn"].append(j)
            data["reportingViewColumnsValue"].append([])
    data["createViewName"] = ltbc.get("createViewName")

    t = data["createViewName"][0]
    columnMulti = "tab_header_name"
    if t.startswith("whiteSpacewrap"):
        columnMulti = "element_id"

    multi_select_field_dict = {}
    is_multi_select_field = False
    for field in actual_model_name.concrete_fields:
        if field.get_internal_type() == "MultiselectField":
            is_multi_select_field = True
            temp_mul_config = json.loads(field.mulsel_config)
            for attri, conf_val in temp_mul_config.items():
                if (
                    attri == "value"
                    or attri == "masterColumn"
                    or attri == "master"
                    or attri == "add"
                    or attri == "def_MulVal"
                    or attri == "checkBox"
                    or attri == "condition"
                ):
                    if attri in multi_select_field_dict:
                        multi_select_field_dict[attri].append(conf_val[0])
                    else:
                        multi_select_field_dict[attri] = conf_val
                elif attri == "plusBtn" or attri == "popUpOption":
                    if attri in multi_select_field_dict:
                        multi_select_field_dict[attri].update(conf_val)
                    else:
                        multi_select_field_dict[attri] = conf_val
                else:
                    multi_select_field_dict[attri] = conf_val

    if is_multi_select_field:
        data["configCreateView"] = {}
        datas = {}

        datas["masterTable"] = multi_select_field_dict["value"]
        datas["masterColumn"] = multi_select_field_dict["masterColumn"]
        datas["tableColumn"] = multi_select_field_dict["char_column"]
        datas["master"] = multi_select_field_dict["master"]
        datas["add"] = multi_select_field_dict["add"]
        datas["checkBox"] = multi_select_field_dict["checkBox"]
        data["columnNameMultis"] = []
        data["columnNameMultisVerb"] = []
        data["masterColumnName"] = []
        data["masterColVerboseName"] = []
        data["masterColName"] = []
        data["len"] = []
        data["checkbox"] = []
        data["columnValMultis"] = []
        data["columnNameMultis"] = []
        for k in range(len(datas["masterTable"])):
            b = datas["masterTable"][k].lower()
            datas["add"][k].insert(0, datas["masterColumn"][k])
            datas["add"][k].append("id")
            if datas["masterColumn"][k]:
                modelName = dynamic_model_create.get_model_class(datas["masterTable"][k], request)

                verbose_column_name_dict = {
                    field.name: field.verbose_name.title() for field in actual_model_name.concrete_fields
                }

                verbose_column_name_dict_master = {
                    field.name: field.verbose_name.title() for field in modelName.concrete_fields
                }
                data["columnNameMultisVerb"].append([])
                for i in datas["add"][k]:
                    if i not in ["Default Value", "id", "Id"]:
                        data["columnNameMultisVerb"][-1].append(verbose_column_name_dict_master.get(i))

                if "Default Value" in datas["add"][k]:
                    data["columnNameMultisVerb"][-1].append("Default Value")
                data["columnNameMultisVerb"][-1].append("id")
                data["masterColumnName"].append(datas["masterColumn"][k])
                data["masterColVerboseName"].append(verbose_column_name_dict.get(datas["master"][k]))
                data["masterColName"].append(datas["master"][k])
                data["masterTableName"] = datas["masterTable"]
                data["checkbox"].append(datas["checkBox"][k])
                if len(datas["checkBox"]) > 0:
                    if datas["checkBox"][k] == 1:
                        data["len"].append(len(datas["add"][k]) + 1)
                    else:
                        data["len"].append(len(datas["add"][k]))
                else:
                    data["len"].append(len(datas["add"][k]))
                data["templateMultiSelect"] = "Multi Select"
                data["editTemplateName"] = "Default"

            else:
                data["editTemplateName"] = "Default"

    if "null" not in data["createViewName"][0]:
        configVal = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "TabScreens",
                    "Columns": ["tab_header_name", "tab_body_content"],
                },
                "condition": [
                    {
                        "column_name": "tab_type",
                        "condition": "Equal to",
                        "input_value": "create_view",
                        "and_or": "AND",
                    },
                    {
                        "column_name": columnMulti,
                        "condition": "Equal to",
                        "input_value": t,
                        "and_or": "",
                    },
                ],
            },
        )
        if len(configVal) > 0:
            a = configVal["tab_body_content"].iloc[0]
            b = configVal["tab_header_name"].iloc[0]

            tempSelect = json.loads(a)
            if not tempSelect["Category_attributes"]["Template"]["Template_choice"]:
                tempSelect["Category_attributes"]["Template"]["Template_choice"] = "Default"
            else:
                pass
            if (
                "Constraint" in tempSelect["Category_attributes"]["Template"]["Template_choice"]
                and list_view_table_name
                == tempSelect["Category_sub_elements"][0]["Category_sub_element_attributes"][0]["value"][0]
            ):
                data["configCreateView"] = tempSelect
                datas = {}
                verboseList = {
                    field.name: field.verbose_name.title() for field in actual_model_name.concrete_fields
                }

                for i in range(len(data["configCreateView"])):
                    data["tab_name"] = b

                    data["selected_tables"] = data["configCreateView"]["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][4]["selected_tables"]
                    data["constraint_holder"] = data["configCreateView"]["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][4]["constraint_holder"]
                    data["selectedConstraint_fields"] = data["configCreateView"]["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][4]["selectedConstraint_fields"]
                    data["remove_additional_column"] = data["configCreateView"]["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][4]["remove_additional_column"]
                    data["verbose_list"] = verboseList

                data["editTemplateName"] = "Constraint"
            elif (
                "Parent child relationship mapping"
                in tempSelect["Category_attributes"]["Template"]["Template_choice"]
            ):
                data["configCreateView"] = tempSelect
                fields = tempSelect["Category_sub_elements"][0]["Category_sub_element_attributes"][1]["value"]
                for i in range(len(fields)):
                    key = list(fields[i].keys())[0]
                    attributes = list(fields[i][key][0].keys())
                    if "jsattr" in attributes:
                        ###chid is where the dropdown would be ; parent is the column from which data will be filled ; table name will be same for both
                        linked_child_column = key
                        linked_parent_column = fields[0][key][0]["jsattr"][0]["finaljsattr"][2][0]["value"]

                datas = {}
                data["editTemplateName"] = "Parent child relationship mapping"

            elif "Flow Definition" in tempSelect["Category_attributes"]["Template"]["Template_choice"]:
                verbose_column_name_dict = {
                    field.name: field.verbose_name.title() for field in actual_model_name.concrete_fields
                }
                data["configCreateView"] = tempSelect
                dataf = {}
                dataf["mastertableflow"] = data["configCreateView"]["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][6]["mastertableflow"]
                dataf["masterColumnflow"] = data["configCreateView"]["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][6]["masterColumnflow"]
                mastertable = dataf["mastertableflow"]
                mastercolumn = dataf["masterColumnflow"]

                master_data_flow = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": mastertable,
                            "Agg_Type": "DISTINCT",
                            "Columns": [mastercolumn],
                        },
                        "condition": [],
                    },
                )
                master_data_flow = list(master_data_flow[mastercolumn])

                data["flowcolumn"] = data["configCreateView"]["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][6]["flowcolumn"]
                data["mastertableflow"] = data["configCreateView"]["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][6]["mastertableflow"]
                data["masterColumnflow"] = data["configCreateView"]["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][6]["masterColumnflow"]
                data["editTemplateName"] = "Flow Definition"
                data["master_data_flow"] = json.dumps(master_data_flow)
                data["flowcolumnverbose"] = verbose_column_name_dict[data["flowcolumn"]]
            elif "Model Definition" in tempSelect["Category_attributes"]["Template"]["Template_choice"]:
                data["configCreateView"] = tempSelect
                master_data_template = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "modelmaster_workflow_template",
                            "Agg_Type": "DISTINCT",
                            "Columns": ["template_name"],
                        },
                        "condition": [],
                    },
                )
                master_data_template = list(master_data_template["template_name"])
                data["master_data_template"] = json.dumps(master_data_template)
                data["editTemplateName"] = "Model Definition"
                users_template = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "user",
                            "Agg_Type": "DISTINCT",
                            "Columns": ["username"],
                        },
                        "condition": [],
                    },
                )
                users_template = list(users_template["username"])
                data["users_template"] = json.dumps(users_template)
            else:
                data["editTemplateName"] = "Default"
        else:
            data["editTemplateName"] = "Default"
    else:
        data["editTemplateName"] = "Default"

    if ltbc["Category_attributes"]["Mandatory"].get("JSAttributes"):
        data["JSAttributes"] = ltbc["Category_attributes"]["Mandatory"]["JSAttributes"]
    else:
        data["JSAttributes"] = ""

    list_view_template_choice = ltbc["Category_attributes"]["Optional"]["Template_choice"]

    appReferFields = []
    appReferFieldsVerb = []
    appReferTemplate = ""
    appreferTable = ""
    if ltbc["reportingView"].get("Template_choice"):
        appReferTemplate = ltbc["reportingView"]["Template_choice"]
    if ltbc["Category_attributes"]["Mandatory"].get("appReferFields"):
        appReferFields = ltbc["Category_attributes"]["Mandatory"]["appReferFields"]
    if ltbc["Category_attributes"]["Mandatory"].get("appreferTable"):
        appreferTable = ltbc["Category_attributes"]["Mandatory"]["appreferTable"]

    if appreferTable:
        actual_model_name_app = dynamic_model_create.get_model_class(appreferTable, request)
        verbcolList = {
            field.name: field.verbose_name.title() for field in actual_model_name_app.concrete_fields
        }
        for col_ in appReferFields:
            appReferFieldsVerb.append(verbcolList[col_])

    allowEditColAlign = 0
    allowEditColConfig = []
    if ltbc["Category_attributes"]["Mandatory"].get("allowEditColAlign"):
        if ltbc["Category_attributes"]["Mandatory"]["allowEditColAlign"]:
            allowEditColAlign = 1
    if ltbc["Category_attributes"]["Mandatory"].get("allowEditColConfig"):
        allowEditColConfig = ltbc["Category_attributes"]["Mandatory"]["allowEditColConfig"]
    ## write code to handle Optional and Default later

    ##create a list to store the html code of every sub_element and its attributes

    for sub_element in ltbc["Category_sub_elements"]:
        if sub_element["Category_sub_element_name"] == "Data_table":
            """extract table name for datatable from Category_sub_element_attributes
            Since its a list view in this case, we have have the table name from mandatory
            attributes.
            """

            for sub_element_attr in sub_element["Category_sub_element_attributes"]:
                if sub_element_attr["attr"] == "Upload" and sub_element_attr["value"] == "Yes":
                    pass
                if sub_element_attr["attr"] == "Multi_edit" and sub_element_attr["value"] == "Yes":
                    pass
        if sub_element["Category_sub_element_name"] == "Plot_chart":
            for sub_element_attr in sub_element["Category_sub_element_attributes"]:
                if sub_element_attr["attr"] == "Plot_chart" and sub_element_attr["value"] == "Yes":
                    pass
        if sub_element["Category_sub_element_name"] == "Set_alert":
            for sub_element_attr in sub_element["Category_sub_element_attributes"]:
                if sub_element_attr["attr"] == "Set_alert" and sub_element_attr["value"] == "Yes":
                    pass
        if sub_element["Category_sub_element_name"] == "Filter":
            for sub_element_attr in sub_element["Category_sub_element_attributes"]:
                if sub_element_attr["attr"] == "Filter" and sub_element_attr["value"] == "Yes":
                    pass

    ##filter code
    (
        table_name,
        label_columns,
        search_filters,
        form_fields,
        form_fields1,
        form_fields2,
    ) = search_filter.ViewFilter(actual_model_name, request=request, original_verbose_name=True)
    data["table_name"] = table_name
    data["table_data"] = tabledata
    data["search_filters"] = search_filters
    data["form_fields"] = form_fields
    data["form_fields1"] = form_fields1
    data["label_columns"] = label_columns
    data["headers"] = headers11
    data["alertdata"] = content11
    renamed_columns_list = {}
    if ltbc["Category_attributes"]["Mandatory"].get("listViewColumnRenamed") is not None:
        if (
            ltbc["Category_attributes"]["Mandatory"]["listViewColumnRenamed"].get(list_view_table_name)
            is not None
        ):
            listViewColumnRenamed = ltbc["Category_attributes"]["Mandatory"]["listViewColumnRenamed"].get(
                list_view_table_name
            )
            verbcolList = {field.name: field.verbose_name for field in actual_model_name.concrete_fields}
            if listViewColumnRenamed.get("json_model_name") is not None:
                if listViewColumnRenamed["json_model_name"] != "":
                    actual_model_name1 = dynamic_model_create.get_model_class(
                        listViewColumnRenamed["json_model_name"], request
                    )
                    verbcolList1 = {
                        field.name: field.verbose_name for field in actual_model_name1.concrete_fields
                    }
                    for j in listViewColumnRenamed["config"]:
                        if j["selected_column"] in verbcolList1:
                            renamed_columns_list[verbcolList1[j["selected_column"]]] = j[
                                "renamed_column_name"
                            ]
            for j in listViewColumnRenamed["config"]:
                if j["selected_column"] in verbcolList:
                    renamed_columns_list[verbcolList[j["selected_column"]]] = j["renamed_column_name"]
                elif j["selected_column"] in [
                    "Edit",
                    "Delete",
                    "Temporary delete",
                    "View",
                    "Approve",
                    "Delegate Approval",
                    "Reject",
                    "Send to previous approver",
                    "PDF Action Button",
                    "Actions",
                ]:
                    renamed_columns_list[j["selected_column"]] = j["renamed_column_name"]
    ##load column names
    view_name1 = ""
    group_by_trigger = False
    if ltbc["Category_attributes"]["Mandatory"].get("GroupByConfigs") is not None:
        group_by = ltbc["Category_attributes"]["Mandatory"].get("GroupByConfigs")
        if group_by.get(list_view_table_name) is not None:
            if group_by.get(list_view_table_name)["group_by_switch"] is False:
                group_by_trigger = True
        if ltbc.get("mulview_def") is not None:
            view_name1 = ltbc.get("mulview_def")
            if group_by.get(view_name1) is not None:
                if group_by.get(view_name1)["group_by_switch"] is False:
                    group_by_trigger = True
    if group_by_trigger:
        finalColumnListDatatableFormat = []
        if "view_name1" in locals() and view_name1:
            if group_by.get(view_name1) is not None:
                group_by = group_by.get(view_name1)
            else:
                group_by = group_by.get(list_view_table_name)
        else:
            group_by = group_by.get(list_view_table_name)
        actual_model_name = dynamic_model_create.get_model_class(list_view_table_name, request)
        fetch_columns_list_field_name = [*group_by["levels"], *group_by["selected_columns"]]
        verbcolList = {field.name: field.verbose_name for field in actual_model_name.concrete_fields}
        verbcolList_json_model_name = {}
        else_tag = False
        if "data-json-table" in group_by and list_view_table_name == "ApprovalTable":
            if group_by["data-json-table"] != "":
                json_model_name = group_by["data-json-table"]
                json_model_name = dynamic_model_create.get_model_class(json_model_name, request)
                verbcolList_json_model_name = {
                    field.name: field.verbose_name for field in json_model_name.concrete_fields
                }
                for i in fetch_columns_list_field_name:
                    if i.split("__-")[0] in verbcolList_json_model_name:
                        finalColumnListDatatableFormat.append(
                            {"data": verbcolList_json_model_name[i.split("__-")[0]]}
                        )
                    else:
                        finalColumnListDatatableFormat.append({"data": verbcolList[i.split("__-")[0]]})
            else:
                else_tag = True
        else:
            else_tag = True
        if else_tag:
            for i in fetch_columns_list_field_name:
                if i in verbcolList_json_model_name:
                    finalColumnListDatatableFormat.append({"data": verbcolList_json_model_name[i]})
                else:
                    finalColumnListDatatableFormat.append({"data": verbcolList[i]})
    else:
        finalColumnListDatatableFormat = sendColumnNamesDatatablesListViewAjaxCall(actual_model_name)
        if ltbc["Category_attributes"]["Mandatory"].get("listViewEmbededComputation") is not None:
            finalColumnListDatatableFormat.append({"data": "Execute Computation"})
        if ltbc["Category_attributes"]["Mandatory"].get("listViewEmbededComputationMultiple") is not None:
            listViewEmbededComputationMultiple = ltbc["Category_attributes"]["Mandatory"].get(
                "listViewEmbededComputationMultiple"
            )
            list_a = []
            for i in listViewEmbededComputationMultiple:
                local_data = i.get(list_view_table_name)
                if local_data is not None:
                    list_a.append(local_data)
            if list_a != []:
                finalColumnListDatatableFormat.append({"data": "Execute Computation"})
        action_button_config = ltbc["Category_attributes"]["Mandatory"].get("configActionButtons")
        action_button_group_together = ltbc["Category_attributes"]["Mandatory"].get(
            "actionButtonsGroupTogether"
        )
        approval_table = False
        if 'approvaltable' in (table_name.split('_')):
            approval_table = True
        if action_button_config is not None:
            action_button_config_model = action_button_config.get(list_view_table_name)
        else:
            action_button_config_model = None
        if action_button_group_together is not None:
            if action_button_group_together is False:
                for j in range(len(ltbc["Category_sub_elements"])):
                    if ltbc["Category_sub_elements"][j]["Category_sub_element_name"] == "Action":
                        for i in ltbc["Category_sub_elements"][j]["Category_sub_element_attributes"]:
                            if i["attr"] == "SelectAll_Action" and i["value"] == "Yes":
                                if action_button_config_model is not None:
                                    function_check = button_styling(action_button_config_model, "Edit")
                                    if function_check is not None:
                                        finalColumnListDatatableFormat.insert(
                                            0, {"data": function_check["columnTextHeader"]}
                                        )
                                    else:
                                        finalColumnListDatatableFormat.insert(0, {"data": "Edit"})
                                    function_check = button_styling(action_button_config_model, "Delete")
                                    if function_check is not None:
                                        finalColumnListDatatableFormat.insert(
                                            1, {"data": function_check["columnTextHeader"]}
                                        )
                                    else:
                                        finalColumnListDatatableFormat.insert(1, {"data": "Delete"})
                                    function_check = button_styling(
                                        action_button_config_model, "Temporary delete"
                                    )
                                    if function_check is not None:
                                        finalColumnListDatatableFormat.insert(
                                            2, {"data": function_check["columnTextHeader"]}
                                        )
                                    else:
                                        finalColumnListDatatableFormat.insert(2, {"data": "Temporary delete"})
                                    function_check = button_styling(action_button_config_model, "View")
                                    if function_check is not None:
                                        finalColumnListDatatableFormat.insert(
                                            3, {"data": function_check["columnTextHeader"]}
                                        )
                                    else:
                                        finalColumnListDatatableFormat.insert(3, {"data": "View"})
                                else:
                                    finalColumnListDatatableFormat.insert(0, {"data": "Edit"})
                                    finalColumnListDatatableFormat.insert(1, {"data": "Delete"})
                                    finalColumnListDatatableFormat.insert(2, {"data": "Temporary delete"})
                                    finalColumnListDatatableFormat.insert(3, {"data": "View"})
                                    if approval_table:
                                        finalColumnListDatatableFormat.insert(4, {"data": "Approval Wall"})
                                        finalColumnListDatatableFormat.insert(5, {"data": "Comments"})
                                        finalColumnListDatatableFormat.insert(6, {"data": "Approve"})
                                        finalColumnListDatatableFormat.insert(7, {"data": "Delegate approval"})
                                        finalColumnListDatatableFormat.insert(8, {"data": "Reject record"})
                                        finalColumnListDatatableFormat.insert(9, {"data": "Resend record"})
                            else:
                                if i["attr"] == "Edit Record" and i["value"] == "Yes":
                                    if action_button_config_model is not None:
                                        function_check = button_styling(action_button_config_model, "Edit")
                                        if function_check is not None:
                                            finalColumnListDatatableFormat.insert(
                                                0, {"data": function_check["columnTextHeader"]}
                                            )
                                        else:
                                            finalColumnListDatatableFormat.insert(0, {"data": "Edit"})
                                    else:
                                        finalColumnListDatatableFormat.insert(0, {"data": "Edit"})
                                if i["attr"] == "Delete Record" and i["value"] == "Yes":
                                    if i.get("delete_type"):
                                        if (
                                            i["delete_type"]["per_delete"] == "Yes"
                                            and i["delete_type"]["temp_delete"] == "No"
                                        ):
                                            if action_button_config_model is not None:
                                                function_check = button_styling(
                                                    action_button_config_model, "Delete"
                                                )
                                                if function_check is not None:
                                                    finalColumnListDatatableFormat.insert(
                                                        1, {"data": function_check["columnTextHeader"]}
                                                    )
                                                else:
                                                    finalColumnListDatatableFormat.insert(
                                                        1, {"data": "Delete"}
                                                    )
                                            else:
                                                finalColumnListDatatableFormat.insert(1, {"data": "Delete"})
                                        elif (
                                            i["delete_type"]["per_delete"] == "No"
                                            and i["delete_type"]["temp_delete"] == "Yes"
                                        ):
                                            if action_button_config_model is not None:
                                                function_check = button_styling(
                                                    action_button_config_model, "Temporary delete"
                                                )
                                                if function_check is not None:
                                                    finalColumnListDatatableFormat.insert(
                                                        1, {"data": function_check["columnTextHeader"]}
                                                    )
                                                else:
                                                    finalColumnListDatatableFormat.insert(
                                                        1, {"data": "Temporary delete"}
                                                    )
                                            else:
                                                finalColumnListDatatableFormat.insert(
                                                    1, {"data": "Temporary delete"}
                                                )
                                        elif (
                                            i["delete_type"]["per_delete"] == "Yes"
                                            and i["delete_type"]["temp_delete"] == "Yes"
                                        ):
                                            if action_button_config_model is not None:
                                                function_check = button_styling(
                                                    action_button_config_model, "Temporary delete"
                                                )
                                                if function_check is not None:
                                                    finalColumnListDatatableFormat.insert(
                                                        1, {"data": function_check["columnTextHeader"]}
                                                    )
                                                else:
                                                    finalColumnListDatatableFormat.insert(
                                                        1, {"data": "Temporary delete"}
                                                    )
                                                function_check = button_styling(
                                                    action_button_config_model, "Delete"
                                                )
                                                if function_check is not None:
                                                    finalColumnListDatatableFormat.insert(
                                                        2, {"data": function_check["columnTextHeader"]}
                                                    )
                                                else:
                                                    finalColumnListDatatableFormat.insert(
                                                        2, {"data": "Delete"}
                                                    )
                                            else:
                                                finalColumnListDatatableFormat.insert(1, {"data": "Delete"})
                                                finalColumnListDatatableFormat.insert(
                                                    2, {"data": "Temporary delete"}
                                                )

                                    else:
                                        if action_button_config_model is not None:
                                            function_check = button_styling(
                                                action_button_config_model, "Delete"
                                            )
                                            if function_check is not None:
                                                finalColumnListDatatableFormat.insert(
                                                    1, {"data": function_check["columnTextHeader"]}
                                                )
                                            else:
                                                finalColumnListDatatableFormat.insert(1, {"data": "Delete"})
                                        else:
                                            finalColumnListDatatableFormat.insert(1, {"data": "Delete"})
                                if i["attr"] == "View Record" and i["value"] == "Yes":
                                    if action_button_config_model is not None:
                                        function_check = button_styling(action_button_config_model, "View")
                                        if function_check is not None:
                                            finalColumnListDatatableFormat.insert(
                                                2, {"data": function_check["columnTextHeader"]}
                                            )
                                        else:
                                            finalColumnListDatatableFormat.insert(2, {"data": "View"})
                                    else:
                                        finalColumnListDatatableFormat.insert(2, {"data": "View"})
                                if approval_table:
                                    if i["attr"] == "Approval Wall" and i["value"] == "Yes":
                                        finalColumnListDatatableFormat.insert(4, {"data": "Approval Wall"})
                                    if i["attr"] == "Enable Comments" and i["value"] == "Yes":
                                        finalColumnListDatatableFormat.insert(5, {"data": "Comments"})	
                                    if i["attr"] == "Approve" and i["value"] == "Yes":
                                        finalColumnListDatatableFormat.insert(6, {"data": "Approve"})	
                                    if i["attr"] == "Delegate Approval" and i["value"] == "Yes":
                                        finalColumnListDatatableFormat.insert(7, {"data": "Delegate approval"})	
                                    if i["attr"] == "Reject" and i["value"] == "Yes":
                                        finalColumnListDatatableFormat.insert(8, {"data": "Reject record"})	
                                    if i["attr"] == "Send to previous approver" and i["value"] == "Yes":
                                        finalColumnListDatatableFormat.insert(9, {"data": "Resend record"})	
                finalColumnListDatatableFormat.insert(0, {"data": "Select"})
            else:
                configureActionColumn = ltbc["Category_attributes"]["Mandatory"].get("configureActionColumn")
                else_condition = False
                if configureActionColumn is not None:
                    if configureActionColumn.get(list_view_table_name) is not None:
                        configureActionColumnModel = configureActionColumn.get(list_view_table_name)
                        finalColumnListDatatableFormat.insert(
                            0, {"data": configureActionColumnModel["columnHeader"]}
                        )
                    else:
                        else_condition = True
                else:
                    else_condition = True
                if else_condition:
                    finalColumnListDatatableFormat.insert(0, {"data": "Actions"})
        else:
            finalColumnListDatatableFormat.insert(0, {"data": "Actions"})

    droppedFields = ltbc["Category_attributes"]["Mandatory"]["DroppedFields"]
    if isinstance(droppedFields, dict):
        if (len(droppedFields)) == 0:
            droppedFields = []
        else:
            droppedFields = droppedFields[list_view_table_name]
    droppedFields2 = []
    droppedFields3 = []
    for i in droppedFields:
        droppedFields2.append(verbose_column_name_dictf_title[i])
        droppedFields3.append(verbose_column_name_dictf[i])
    if len(droppedFields) > 0:
        if group_by_trigger:
            fields_to_be_displayed = [
                i
                for i in finalColumnListDatatableFormat
                if (i["data"].title() not in droppedFields2 and i["data"] not in droppedFields3)
            ]
        else:
            if action_button_config_model is not None:
                if action_button_config_model.get("columnOrder") is not None:
                    newTableList = []
                    for i in action_button_config_model:
                        for j in action_button_config_model["columnOrder"]:
                            if i == j:
                                index = action_button_config_model["columnOrder"].index(j)
                                action_button_config_model["columnOrder"].remove(j)
                                action_button_config_model["columnOrder"].insert(
                                    index, action_button_config_model[i]["column-header"]
                                )
                    for k in action_button_config_model["columnOrder"]:
                        if k in verbose_column_name_dictf:
                            newTableList.append({"data": verbose_column_name_dictf[k]})
                        else:
                            newTableList.append({"data": k})
                    fields_to_be_displayed = [
                        i
                        for i in newTableList
                        if (i["data"].title() not in droppedFields2 and i["data"] not in droppedFields3)
                    ]
                else:
                    fields_to_be_displayed = [
                        i
                        for i in finalColumnListDatatableFormat
                        if (i["data"].title() not in droppedFields2 and i["data"] not in droppedFields3)
                    ]
            else:
                fields_to_be_displayed = [
                    i
                    for i in finalColumnListDatatableFormat
                    if (i["data"].title() not in droppedFields2 and i["data"] not in droppedFields3)
                ]
    else:
        if group_by_trigger:
            fields_to_be_displayed = finalColumnListDatatableFormat
        else:
            if action_button_config_model is not None:
                if action_button_config_model.get("columnOrder") is not None:
                    newTableList = []
                    for i in action_button_config_model:
                        for j in action_button_config_model["columnOrder"]:
                            if i == j:
                                index = action_button_config_model["columnOrder"].index(j)
                                action_button_config_model["columnOrder"].remove(j)
                                action_button_config_model["columnOrder"].insert(
                                    index, action_button_config_model[i]["column-header"]
                                )
                    for k in action_button_config_model["columnOrder"]:
                        if k in verbose_column_name_dictf:
                            newTableList.append({"data": verbose_column_name_dictf[k]})
                        else:
                            newTableList.append({"data": k})
                    fields_to_be_displayed = newTableList
                else:
                    fields_to_be_displayed = finalColumnListDatatableFormat
            else:
                fields_to_be_displayed = finalColumnListDatatableFormat
    fields_to_be_displayedNames = [i["data"] for i in fields_to_be_displayed]
    if not group_by_trigger:
        if appReferTemplate == "Approval Template" and appReferFieldsVerb:
            for count, i in enumerate(appReferFieldsVerb):
                fields_to_be_displayed.insert(count + 1, {"data": i})
    finalColumnListDatatableFormat1 = json.dumps(fields_to_be_displayed)

    if comp_element_id:
        cols_db = json.loads(
            read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "computation_model_configuration",
                        "Columns": ["element_config"],
                    },
                    "condition": [
                        {
                            "column_name": "model_name",
                            "condition": "Equal to",
                            "input_value": comp_element_id,
                            "and_or": "",
                        },
                    ],
                },
            ).iloc[0, 0]
        )

        cols_from_db = cols_db["inputs"]["Columns"]
        values_dict_comp = {
            field.name: field.verbose_name.title() for field in actual_model_name.concrete_fields
        }
        cosl_2 = []
        for i in cols_from_db:
            cosl_2.append(values_dict_comp[i])
        finalColumnListDatatableFormat1_copy = json.loads(finalColumnListDatatableFormat1)
        finalColumnListDatatableFormat1 = json.loads(finalColumnListDatatableFormat1)
        for kk in finalColumnListDatatableFormat1:
            if kk["data"] not in cosl_2:
                finalColumnListDatatableFormat1_copy.remove(kk)
        finalColumnListDatatableFormat1 = json.dumps(finalColumnListDatatableFormat1_copy)

    ##load data list view
    columnCombine = [
        {"verboseName": field.verbose_name, "originalName": field.name}
        for field in actual_model_name.concrete_fields
        if field.verbose_name.title() in fields_to_be_displayedNames
    ]
    table_headers = {
        i.name: i.verbose_name
        for i in actual_model_name.concrete_fields
        if i.verbose_name.title() in fields_to_be_displayedNames
    }

    rest_cols = []
    app_cols = []
    for i in allowEditColConfig:
        for indx, j in enumerate(json.loads(finalColumnListDatatableFormat1)):
            if verbose_column_name_dictf_title.get(i["column"]):
                if j["data"].title() == verbose_column_name_dictf_title[i["column"]]:
                    i["target"] = indx
                    app_cols.append(indx)
            else:
                if j["data"].title() == appReferFieldsVerb[appReferFields.index(i["column"])]:
                    i["target"] = indx
                else:
                    continue

    for indx, j in enumerate(json.loads(finalColumnListDatatableFormat1)):
        if indx not in app_cols:
            rest_cols.append(indx)
    data["table_headers"] = table_headers
    data["element_id"] = row_data["element_id"]
    data["tab_type"] = row_data["tab_type"]
    data["tab_header_name"] = row_data["tab_header_name"]
    data["list_view_column_names"] = finalColumnListDatatableFormat1
    data["renamed_columns_list"] = renamed_columns_list
    data["list_view_verbose_original_column_names"] = columnCombine
    data["model_name"] = list_view_table_name
    data["list_view_html_json"] = ltbc["Category_sub_elements"]
    data["list_table_header_config"] = list_table_header_config
    data["list_view_template_directory_to_file"] = "list_view_templates/" + list_view_template_choice
    data["file_list"] = file_list
    data["allowEditColAlign"] = allowEditColAlign
    data["allowEditColConfig"] = allowEditColConfig
    data["rest_cols"] = rest_cols
    return data


# !
def alertfunction(condition, columnname, inputval, sql_table_name, variable):
    table_content = pd.read_sql_query(f"select * from {sql_table_name}", con=engine)
    cond = condition
    columnname = columnname
    inputval = inputval
    string_limit = alert_check_condition(cond, columnname, inputval)
    result = table_content[pd.eval(string_limit)]
    if result.empty:
        variable["status"] = "notbreached"
    else:
        variable["status"] = "breached"

    return variable


def ocr_tab(front_end_name, row_data, request):
    data = {}
    data["element_id"] = row_data["element_id"]
    data["tab_type"] = row_data["tab_type"]
    data["tab_header_name"] = row_data["tab_header_name"]
    try:
        ocr_tab_body_content = json.loads(row_data["tab_body_content"])
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        ocr_tab_body_content = {
            "tablename": "",
            "columns": [],
            "percentval": 0,
            "operationtype": "single_image",
        }

    data["tablename"] = ocr_tab_body_content["tablename"]
    temp_list = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "ocr_template",
                "Columns": ["template_name"],
            },
            "condition": [
                {
                    "column_name": "table_name",
                    "condition": "Equal to",
                    "input_value": ocr_tab_body_content["tablename"],
                    "and_or": "",
                }
            ],
        },
    ).template_name.to_list()
    data["template_list"] = temp_list
    data["tablename"] = ocr_tab_body_content["tablename"]
    data["region_of_interest"] = ocr_tab_body_content["columns"]
    data["operation_type"] = ocr_tab_body_content["operationtype"]
    return data


def computation_tab(front_end_name, row_data, request):
    data = {}
    data["element_id"] = row_data["element_id"]
    computation_tab_element_id = row_data["element_id"]
    data["tab_type"] = row_data["tab_type"]
    data["tab_header_name"] = row_data["tab_header_name"]
    try:
        computation_tab_body_content = json.loads(row_data["tab_body_content"])
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        computation_tab_body_content = {"model": ""}
    model_name = computation_tab_body_content["model"]
    data["model_name"] = model_name
    data["button_config"] = computation_tab_body_content.get("button_config")
    if computation_tab_body_content.get("previous_run"):
        data["previous_run"] = computation_tab_body_content["previous_run"]
    else:
        data["previous_run"] = "yes"
    if computation_tab_body_content.get("global_variable_configs"):
        data["global_variable_configs"] = computation_tab_body_content.get("global_variable_configs")
    else:
        data["global_variable_configs"] = {}
    mandatory_list = []
    flowchart_elements = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_flowchart",
                "Columns": ["flowchart_elements"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": model_name,
                    "and_or": "",
                }
            ],
        },
    )

    flowchart_elements = flowchart_elements.iloc[0, 0]
    flowchart_elements = json.loads(flowchart_elements)
    if len(flowchart_elements) > 0:
        html = ""
        for el in flowchart_elements:
            if el["text"] == "Global Variable":
                elementid = el["element_id"]
                element_config = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "computation_model_configuration",
                            "Columns": ["element_config"],
                        },
                        "condition": [
                            {
                                "column_name": "model_name",
                                "condition": "Equal to",
                                "input_value": model_name,
                                "and_or": "and",
                            },
                            {
                                "column_name": "element_id",
                                "condition": "Equal to",
                                "input_value": elementid,
                                "and_or": "",
                            },
                        ],
                    },
                )

                if len(element_config) > 0:
                    elecon_dict = element_config.iloc[0, 0]
                    config_dict = json.loads(elecon_dict)
                    variable_list = config_dict["inputs"]["variables"]
                    defaultVal_list = []
                    for i in variable_list:
                        if i["dataType"] == "dropdown":
                            defaultVal_list.append(i["defaultValue"])
                    variable_list = [
                        g_var
                        for g_var in variable_list
                        if g_var["dataType"]
                        in [
                            "text",
                            "number",
                            "date",
                            "datetime-local",
                            "file",
                            "dropdown",
                            "dropdown-multiple",
                        ]
                    ]
                    dropdown_variables = [
                        g_var
                        for g_var in variable_list
                        if g_var["dataType"] in ['dropdown']
                    ]
                    gdependent_columns_dict = parse_gdropdown_Dependencies(dropdown_variables)
                    col_string = ""
                    layout_column_string = ""
                    for val, variable in enumerate(variable_list):
                        if variable.get("mandatory") == "Mandatory":
                            mandatory_list.append(variable.get("varName").strip())
                    for ind, i in enumerate(variable_list):
                        if i["dataType"] == "text":
                            validations = i.get("validations")
                            custom_message = i.get("custom_message")
                            if i.get("mandatory") == "Mandatory":
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="">{i['varName']} <span class="asteriskField">*</span></label>
                                    <div class="">
                                        <input type="text" placeholder='{i['varName']}' data-var_name='{i['varName']}' data-elementid='{elementid}' data-id='{data["element_id"]}' name=gVar_{i['varName']}_{elementid} maxlength="100" data-val='{json.dumps(validations)}' data-custom_message={json.dumps(custom_message)} class=" mandatory validation textinput textInput form-control"  data-mandatory_list="{(mandatory_list)}" required="" >
                                    </div>
                                </div>
                                """
                            else:
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="">{i['varName']}</label>
                                    <div class="">
                                        <input type="text" placeholder='{i['varName']}' name=gVar_{i['varName']}_{elementid} data-val='{json.dumps(validations)}' data-id='{data["element_id"]}' data-custom_message={json.dumps(custom_message)} maxlength="100" class="validation textinput textInput form-control" required="" >
                                    </div>
                                </div>
                                """
                        elif i["dataType"] == "number":
                            validations = i.get("validations")
                            custom_message = i.get("custom_message")
                            if i.get("mandatory") == "Mandatory":
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="">{i['varName']} <span class="asteriskField">*</span></label>
                                    <div class="">
                                        <input type="number" placeholder='{i['varName']}' data-var_name='{i['varName']}' data-elementid='{elementid}' data-id='{data["element_id"]}' data-val='{json.dumps(validations)}' data-custom_message={json.dumps(custom_message)} data-id='{data["element_id"]}' name=gVar_{i['varName']}_{elementid} step='any' class="mandatory validation numberinput form-control" data-mandatory_list="{(mandatory_list)}" required="" >
                                    </div>
                                </div>
                                """
                            else:
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="">{i['varName']}</label>
                                    <div class="">
                                        <input type="number" placeholder='{i['varName']}' data-val='{json.dumps(validations)}' data-elementid='{elementid}'  data-id='{data["element_id"]}' data-custom_message={json.dumps(custom_message)} name=gVar_{i['varName']}_{elementid} step='any' class="validation numberinput form-control" required="" >
                                    </div>
                                </div>
                                """
                        elif i["dataType"] == "date":
                            validations = i.get("validations")
                            custom_message = i.get("custom_message")
                            if i.get("mandatory") == "Mandatory":
                                col_string = (
                                    f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="">{i['varName']} <span class="asteriskField">*</span></label>
                                    <div class="input-group date">
                                        <input type="date"  placeholder="YYYY-MM-DD" data-elementid='{elementid}' data-val='{json.dumps(validations)}' data-custom_message={json.dumps(custom_message)} data-id='{data["element_id"]}' data-var_name='{i['varName']}' name=gVar_{i['varName']}_{elementid} class="mandatory validation form-control" data-mandatory_list="{(mandatory_list)}" required="" """
                                    + """>
                                    </div>
                                </div>
                                """
                                )
                            else:
                                col_string = (
                                    f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="">{i['varName']}</label>
                                    <div class="input-group date">
                                        <input type="date" placeholder="YYYY-MM-DD" name=gVar_{i['varName']}_{elementid} data-elementid='{elementid}'  data-id='{data["element_id"]}' data-val='{json.dumps(validations)}' data-custom_message={json.dumps(custom_message)} class="validation form-control" required="" """
                                    + """>
                                    </div>
                                </div>
                                """
                                )
                        elif i["dataType"] == "datetime-local":
                            validations = i.get("validations")
                            custom_message = i.get("custom_message")
                            if i.get("mandatory") == "Mandatory":
                                col_string = (
                                    f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="">{i['varName']} <span class="asteriskField">*</span></label>
                                    <div class="input-group date">
                                        <input type="datetime-local" data-var_name='{i['varName']}' placeholder="YYYY-MM-DD HH:MM" data-id='{data["element_id"]}' data-val='{json.dumps(validations)}' data-custom_message={json.dumps(custom_message)} data-elementid='{elementid}' name=gVar_{i['varName']}_{elementid} class="mandatory validation form-control" data-mandatory_list="{(mandatory_list)}" required="" """
                                    + """>
                                    </div>
                                </div>
                                """
                                )
                            else:
                                col_string = (
                                    f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="">{i['varName']}</label>
                                    <div class="input-group date">
                                        <input type="datetime-local" placeholder="YYYY-MM-DD HH:MM" data-elementid='{elementid}'  data-id='{data["element_id"]}' data-val='{json.dumps(validations)}' data-custom_message={json.dumps(custom_message)} name=gVar_{i['varName']}_{elementid} class="validation form-control" required="" """
                                    + """>
                                    </div>
                                </div>
                                """
                                )
                        elif i["dataType"] == "file":
                            if i.get("mandatory") == "Mandatory":
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="gVarNameLabel">{i['varName']} <span class="asteriskField">*</span></label>
                                    <form method="post" class="gVarFileInput" name="gVar_{i['varName']}_{elementid}" enctype="multipart/form-data">
                                        <div class="custom-file">
                                            <input type="file" name="gVarFileRM" class="mandatory custom-file-input" data-var_name='{i['varName']}' accept=".csv,.json,.parquet" data-mandatory_list="{(mandatory_list)}" data-id='{data["element_id"]}' data-elementid="{elementid}" >
                                            <label class="custom-file-label">Choose file</label>
                                        </div>
                                        <input type="hidden" name="engine_parameter" value='{i["engine_parameter"]}'>
                                    </form>
                                </div>
                                """
                            else:
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="gVarNameLabel">{i['varName']}</label>
                                    <form method="post" class="gVarFileInput" name="gVar_{i['varName']}_{elementid}"  enctype="multipart/form-data">
                                        <div class="custom-file">
                                            <input type="file" name="gVarFileRM" class="custom-file-input" accept=".csv,.json,.parquet">
                                            <label class="custom-file-label">Choose file</label>
                                        </div>
                                        <input type="hidden" name="engine_parameter" value='{i["engine_parameter"]}'>
                                    </form>
                                </div>
                                """
                        elif i["dataType"] == "dropdown":
                            process_level_filters = "no"
                            if data["global_variable_configs"].get(i["varName"]):
                                process_level_filters = "yes"
                            dependencies = i.get("dependencies",[])
                            multi_dependencies = i.get("multi_dependencies",[])
                            if i.get("mandatory") == "Mandatory":
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="gVarNameLabel">{i['varName']} <span class="asteriskField">*</span></label>
                                    <form method="post" class="gVarDropDown" column='{i['columnName']}' has_process_level_filters={process_level_filters} gdependent_columns_dict='{json.dumps(gdependent_columns_dict)}' dependencies='{json.dumps(dependencies)}' multi_dependencies='{json.dumps(multi_dependencies)}' name="gVar_{i['varName']}_{elementid}">
                                        <div class="custom-file">
                                            <select onchange="populateCascades.call(this,'{i['varName']}','{i['columnName']}')"  class="mandatory dropdown_box select2 form-control" data-var_name='{i['varName']}' name="dropdown_defaultValue" data-elementid="{elementid}" data-id='{data["element_id"]}' data-mandatory_list="{(mandatory_list)}">
                                            <option value="" selected disabled> Select Default Value </option>
                                            </select>
                                        </div>
                                    </form>
                                </div>
                                """
                            else:
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="gVarNameLabel">{i['varName']}</label>
                                    <form method="post" class="gVarDropDown" column='{i['columnName']}' has_process_level_filters={process_level_filters} gdependent_columns_dict='{json.dumps(gdependent_columns_dict)}' dependencies='{json.dumps(dependencies)}' multi_dependencies='{json.dumps(multi_dependencies)}' name="gVar_{i['varName']}_{elementid}">
                                        <div class="custom-file">
                                            <select onchange="populateCascades.call(this,'{i['varName']}','{i['columnName']}')" class="dropdown_box select2 form-control" name="dropdown_defaultValue">
                                            <option value="" selected disabled> Select Default Value </option>
                                            </select>
                                        </div>
                                    </form>
                                </div>
                                """
                        elif i["dataType"] == "dropdown-multiple":
                            if i.get("mandatory") == "Mandatory":
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="gVarNameLabel">{i['varName']}<span class="asteriskField">*</span></label>
                                    <form method="post" class="gVarDropDown" name="gVar_{i['varName']}_{elementid}">
                                        <div class="custom-file">
                                            <select class="mandatory dropdown_box select2 form-control" data-var_name='{i['varName']}' name="dropdown_defaultValue" data-mandatory_list="{(mandatory_list)}" data-id='{data["element_id"]}' data-elementid="{elementid}" multiple>
                                            </select>
                                        </div>
                                    </form>
                                </div>
                                """
                            else:
                                col_string = f"""
                                <div class="form-group col-md-3">
                                    <label for="gVar_{i['varName']}_{elementid}" class="gVarNameLabel">{i['varName']}</label>
                                    <form method="post" class="gVarDropDown" name="gVar_{i['varName']}_{elementid}">
                                        <div class="custom-file">
                                            <select class="dropdown_box select2 form-control" name="dropdown_defaultValue" multiple>
                                            </select>
                                        </div>
                                    </form>
                                </div>
                                """
                        else:
                            col_string = ""
                        layout_column_string += col_string
                        if (ind + 1) % 4 == 0:
                            r = f'<div class="form-row" data-parent_element_id="{elementid}">'
                            r += layout_column_string
                            r += "</div>"
                            layout_column_string = ""
                            html += r
                        else:
                            if (len(variable_list) - (ind + 1)) == 0:
                                r = f'<div class="form-row"  data-parent_element_id="{elementid}">'
                                r += layout_column_string
                                r += "</div>"
                                layout_column_string = ""
                                html += r
            # Interest Rate Products
            elif el["text"] == "Interest Rate Products":
                elementid = el["element_id"]
                element_config = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "computation_model_configuration",
                            "Columns": ["element_config"],
                        },
                        "condition": [
                            {
                                "column_name": "model_name",
                                "condition": "Equal to",
                                "input_value": model_name,
                                "and_or": "and",
                            },
                            {
                                "column_name": "element_id",
                                "condition": "Equal to",
                                "input_value": elementid,
                                "and_or": "",
                            },
                        ],
                    },
                )
                if len(element_config) > 0:
                    elecon_dict = element_config.iloc[0, 0]
                    config_dict = json.loads(elecon_dict)
                    global_function = config_dict["globalVar"]
                    if global_function:
                        product_category = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Category_Master",
                                    "Columns": ["id"],
                                },
                                "condition": [
                                    {
                                        "column_name": "product_category",
                                        "condition": "Equal to",
                                        "input_value": "Financial_Instruments_Interest_Rate_Products",
                                        "and_or": "",
                                    }
                                ],
                            },
                        )

                        if product_category.iloc[0, 0]:
                            product_category = product_category.iloc[0, 0]
                        else:
                            product_category = "0"
                        products_data = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Product_Master",
                                    "Columns": ["id", "product_variant_name"],
                                },
                                "condition": [
                                    {
                                        "column_name": "product_category",
                                        "condition": "Equal to",
                                        "input_value": str(product_category),
                                        "and_or": "",
                                    }
                                ],
                            },
                        )

                        products_list = products_data.product_variant_name.tolist()
                        products_data = products_data.set_index("id").to_dict()
                        products_to_model_data = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Product_to_Model_mapping",
                                    "Columns": ["id", "product_variant_name", "model_code"],
                                },
                                "condition": [],
                            },
                        ).set_index("id")
                        products_to_model_data["product_variant_name"] = products_to_model_data[
                            "product_variant_name"
                        ].replace(products_data["product_variant_name"])
                        model_data = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Model_Repository",
                                    "Columns": ["id", "model_code", "model_name"],
                                },
                                "condition": [],
                            },
                        ).set_index("id")
                        model_mapper = model_data["model_code"].to_dict()
                        products_to_model_data["model_code"] = products_to_model_data["model_code"].replace(
                            model_mapper
                        )
                        products_to_model_data.rename(
                            columns={"product_variant_name": "product_variant"}, inplace=True
                        )
                        products_to_model_data = products_to_model_data.set_index("product_variant")[
                            "model_code"
                        ].to_dict()

                        int_html = f"<section class='globalFunction' data-element_name='{el['text']}' data-element_id='{elementid}'>"
                        select_operation = f"""
                        <div class="form-group col-md-3 col-sm-6">
                            <label for="Choose_Operation">{el['text']}</label>
                            <select class="select2 form-control" name="Choose Operation" id="select_intRatesCF_val_{computation_tab_element_id}" required>
                                <option value="" disabled selected> Select Operation</option>"""
                        for i in products_list:
                            select_operation += f"""<option data-model_code='{products_to_model_data[i]}' value='{i}'>{i}</option>"""

                        select_operation += """</select>
                        </div>
                        """
                        select_configuration = f"""
                        <hr>
                        <section class="form-row mx-2" id="finInstrumentsCF_configure_container_{computation_tab_element_id}">

                        </section>
                        <hr>
                        """
                        select_output = f"""
                        <div class="form-group mx-2" id = "finInstrumentsCF_checkbox_{computation_tab_element_id}">
                            <label>Output:</label>
                            <div class="custom-control custom-checkbox">
                                <input type="checkbox" name="ComputedValue" class="checkboxinput custom-control-input" id="cftable1_{computation_tab_element_id}" value="Cashflows">
                                <label for="cftable1_{computation_tab_element_id}" class="custom-control-label">
                                Cashflow Table
                                </label>
                            </div>
                            <div class="custom-control custom-checkbox">
                                <input type="checkbox" name="ComputedValue" class="checkboxinput custom-control-input" id="cftable2_{computation_tab_element_id}" value="Valuation">
                                <label for="cftable2_{computation_tab_element_id}" class="custom-control-label">
                                    Valuation Result
                                </label>
                            </div>
                            <div class="custom-control custom-checkbox">
                                <input type="checkbox" name="ComputedValue" class="checkboxinput custom-control-input" id="cftable3_{computation_tab_element_id}" value="Sensitivity_Analysis">
                                <label for="cftable3_{computation_tab_element_id}" class="custom-control-label">
                                    Sensitivity Measure
                                </label>
                            </div>
                        </div>
                        """
                        select_valuation_method = f"""
                        <div class="form-group finInstrumentsCF_input" id = "finInstrumentsCF_valuation_method_{computation_tab_element_id}">
                            <label >Valuation Methodology: </label>
                            <div class='custom-control custom-radio'>
                                <input type="radio" id = "risk_based_valuation_{computation_tab_element_id}" class="custom-control-input finInstrumentsCF_valuation_method_button_{computation_tab_element_id}" name="valuation_choice" value="risk_based_valuation">
                                <label for="risk_based_valuation_{computation_tab_element_id}" class="custom-control-label var(--font-color)">Risk Based Valuation</label >
                            </div>
                            <div class='custom-control custom-radio'>
                                <input type="radio" id="mtm_valuation_{computation_tab_element_id}" class="custom-control-input finInstrumentsCF_valuation_method_button_{computation_tab_element_id}" name="valuation_choice" value="mtm_valuation">
                                <label for="mtm_valuation_{computation_tab_element_id}" class="custom-control-label var(--font-color)">Mark to Market</label >
                            </div>
                        </div>
                        """
                        script = f"""

                        <script>
                            $('#finInstrumentsCF_configure_container_{computation_tab_element_id}').empty();
                            $('#select_intRatesCF_val_{computation_tab_element_id}').off("select2:select").on('select2:select',function()"""
                        script += (
                            """{
                                $.ajax({
                                    url: '/users/computationModule/',
                                    data: {
                                        'product_type':$('#select_intRatesCF_val_"""
                            + f"""{computation_tab_element_id}').val(),"""
                            + """'model_code':$('#select_intRatesCF_val_"""
                            + f"""{computation_tab_element_id} option:selected').attr('data-model_code'),"""
                            + """       'operation': 'fetch_product_attributes_intRates',
                                    },
                                    type: "POST",
                                    dataType: "json",
                                    success: function (data) {
                                        """
                            + f"""$('#finInstrumentsCF_configure_container_{computation_tab_element_id}').empty()"""
                            + """
                                        var string = ``
                                        for(i in data.attribute_dict){
                                            if (data.attribute_dict[i]['field_type']=='IntegerField'){
                                                string+=`<div class="form-group col-3" >
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="numberinput form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="number" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='BigIntegerField'){
                                                string+=`<div class="form-group col-3" >
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="numberinput form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="number" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='FloatField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="numberinput form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="number" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='CharField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="textInput textinput form-control"  id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="text" required>
                                                        </div>`
                                            } else if (data.attribute_dict[i]['field_type']=='DateField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="date" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='SelectField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <select class="select2 form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ required>`

                                                            for(j in data.attribute_dict[i]['options']){
                                                                string+=`<option>${data.attribute_dict[i]['options'][j]}</option>`
                                                            }
                                                string+=`</select></div>`
                                            }
                                        }"""
                        )
                        script += f""" $('#finInstrumentsCF_configure_container_{computation_tab_element_id}').append(string);"""
                        script += (
                            f""" $('#finInstrumentsCF_configure_container_{computation_tab_element_id}')"""
                            + """.find('select.select2').each(function(){
                            parent = $(this).parent()
                            $(this).select2({dropdownParent:parent})
                        });"""
                        )

                        script += """},
                                    error: function(){
                                        Swal.fire({icon: 'error',text: 'Error while fetching attributes for the selected product variant.'});
                                    }
                                });
                                });
                        </script>
                        """
                        int_html += select_operation
                        int_html += select_configuration
                        int_html += select_output
                        int_html += select_valuation_method
                        int_html += script
                        int_html += "</section>"
                        html += int_html

            elif el["text"] == "Equities":
                elementid = el["element_id"]
                element_config = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "computation_model_configuration",
                            "Columns": ["element_config"],
                        },
                        "condition": [
                            {
                                "column_name": "model_name",
                                "condition": "Equal to",
                                "input_value": model_name,
                                "and_or": "and",
                            },
                            {
                                "column_name": "element_id",
                                "condition": "Equal to",
                                "input_value": elementid,
                                "and_or": "",
                            },
                        ],
                    },
                )
                if len(element_config) > 0:
                    elecon_dict = element_config.iloc[0, 0]
                    config_dict = json.loads(elecon_dict)
                    global_function = config_dict["globalVar"]
                    if global_function:
                        product_category = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Category_Master",
                                    "Columns": ["id"],
                                },
                                "condition": [
                                    {
                                        "column_name": "product_category",
                                        "condition": "Equal to",
                                        "input_value": "Financial_Instruments_Equities",
                                        "and_or": "",
                                    }
                                ],
                            },
                        )
                        if product_category.iloc[0, 0]:
                            product_category = str(product_category.iloc[0, 0])
                        else:
                            product_category = "0"
                        products_data = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Product_Master",
                                    "Columns": ["id", "product_variant_name"],
                                },
                                "condition": [
                                    {
                                        "column_name": "product_category",
                                        "condition": "Equal to",
                                        "input_value": product_category,
                                        "and_or": "",
                                    }
                                ],
                            },
                        )
                        products_list = products_data.product_variant_name.tolist()
                        products_data = products_data.set_index("id").to_dict()
                        products_to_model_data = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Product_to_Model_mapping",
                                    "Columns": ["id", "product_variant", "model_code"],
                                },
                                "condition": [],
                            },
                        ).set_index("id")

                        products_to_model_data["product_variant"] = products_to_model_data[
                            "product_variant"
                        ].replace(products_data["product_variant_name"])
                        model_data = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Model_Repository",
                                    "Columns": ["id", "model_code", "model_name"],
                                },
                                "condition": [],
                            },
                        ).set_index("id")
                        model_mapper = model_data["model_code"].to_dict()
                        products_to_model_data["model_code"] = products_to_model_data["model_code"].replace(
                            model_mapper
                        )
                        products_to_model_data = products_to_model_data.set_index("product_variant")[
                            "model_code"
                        ].to_dict()

                        int_html = f"<section class='globalFunction' data-element_name='{el['text']}' data-element_id='{elementid}'>"
                        select_operation = f"""
                        <div class="form-group col-md-3 col-sm-6">
                            <label for="Choose_Operation">{el['text']}</label>
                            <select class="select2 form-control" name="Choose Operation" id="select_equitiesCF_val_{computation_tab_element_id}" required>
                                <option value="" disabled selected> Select Operation</option>"""
                        for i in products_list:
                            select_operation += f"""<option data-model_code='{products_to_model_data[i]}' value='{i}'>{i}</option>"""

                        select_operation += """</select>
                        </div>
                        """
                        select_configuration = f"""
                        <hr>
                        <section class="form-row mx-2" id="finInstrumentsCF_configure_container_{computation_tab_element_id}">

                        </section>
                        <hr>
                        """
                        select_output = f"""
                        <div class="form-group mx-2" id = "finInstrumentsCF_checkbox_{computation_tab_element_id}">
                            <label>Output:</label>
                            <div class="custom-control custom-checkbox">
                                <input type="checkbox" name="ComputedValue" class="checkboxinput custom-control-input" id="cftable1_{computation_tab_element_id}" value="Cashflows">
                                <label for="cftable1_{computation_tab_element_id}" class="custom-control-label">
                                Cashflow Table
                                </label>
                            </div>
                            <div class="custom-control custom-checkbox">
                                <input type="checkbox" name="ComputedValue" class="checkboxinput custom-control-input" id="cftable2_{computation_tab_element_id}" value="Valuation">
                                <label for="cftable2_{computation_tab_element_id}" class="custom-control-label">
                                    Valuation Result
                                </label>
                            </div>
                            <div class="custom-control custom-checkbox">
                                <input type="checkbox" name="ComputedValue" class="checkboxinput custom-control-input" id="cftable3_{computation_tab_element_id}" value="Sensitivity_Analysis">
                                <label for="cftable3_{computation_tab_element_id}" class="custom-control-label">
                                    Sensitivity Measure
                                </label>
                            </div>
                        </div>
                        """
                        select_valuation_method = f"""
                        <div class="form-group finInstrumentsCF_input" id = "finInstrumentsCF_valuation_method_{computation_tab_element_id}">
                            <label >Valuation Methodology: </label>
                            <div class='custom-control custom-radio'>
                                <input type="radio" id = "risk_based_valuation_{computation_tab_element_id}" class="custom-control-input finInstrumentsCF_valuation_method_button_{computation_tab_element_id}" name="valuation_choice" value="risk_based_valuation">
                                <label for="risk_based_valuation_{computation_tab_element_id}" class="custom-control-label var(--font-color)">Risk Based Valuation</label >
                            </div>
                            <div class='custom-control custom-radio'>
                                <input type="radio" id="mtm_valuation_{computation_tab_element_id}" class="custom-control-input finInstrumentsCF_valuation_method_button_{computation_tab_element_id}" name="valuation_choice" value="mtm_valuation">
                                <label for="mtm_valuation_{computation_tab_element_id}" class="custom-control-label var(--font-color)">Mark to Market</label >
                            </div>
                        </div>
                        """
                        script = f"""

                        <script>
                            $('#finInstrumentsCF_configure_container_{computation_tab_element_id}').empty();
                            $('#select_equitiesCF_val_{computation_tab_element_id}').off("select2:select").on('select2:select',function()"""
                        script += (
                            """{
                                $.ajax({
                                    url: '/users/computationModule/',
                                    data: {
                                        'product_type':$('#select_equitiesCF_val_"""
                            + f"""{computation_tab_element_id}').val(),"""
                            + """'model_code':$('#select_equitiesCF_val_"""
                            + f"""{computation_tab_element_id} option:selected').attr('data-model_code'),"""
                            + """       'operation': 'fetch_product_attributes_intRates',
                                    },
                                    type: "POST",
                                    dataType: "json",
                                    success: function (data) {
                                        """
                            + f"""$('#finInstrumentsCF_configure_container_{computation_tab_element_id}').empty()"""
                            + """
                                        var string = ``
                                        for(i in data.attribute_dict){
                                            if (data.attribute_dict[i]['field_type']=='IntegerField'){
                                                string+=`<div class="form-group col-3" >
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="numberinput form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="number" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='BigIntegerField'){
                                                string+=`<div class="form-group col-3" >
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="numberinput form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="number" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='FloatField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="numberinput form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="number" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='CharField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="textInput textinput form-control"  id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="text" required>
                                                        </div>`
                                            } else if (data.attribute_dict[i]['field_type']=='DateField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="date" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='SelectField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <select class="select2 form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ required>`

                                                            for(j in data.attribute_dict[i]['options']){
                                                                string+=`<option>${data.attribute_dict[i]['options'][j]}</option>`
                                                            }
                                                string+=`</select></div>`
                                            }
                                        }"""
                        )
                        script += f""" $('#finInstrumentsCF_configure_container_{computation_tab_element_id}').append(string);"""
                        script += (
                            f""" $('#finInstrumentsCF_configure_container_{computation_tab_element_id}')"""
                            + """.find('select.select2').each(function(){
                            parent = $(this).parent()
                        $(this).select2({dropdownParent:parent})
                        });"""
                        )

                        script += """},
                                    error: function(){
                                        Swal.fire({icon: 'error',text: 'Error while fetching attributes for the selected product variant.'});
                                    }
                                });
                                });
                        </script>
                        """
                        int_html += select_operation
                        int_html += select_configuration
                        int_html += select_output
                        int_html += select_valuation_method
                        int_html += script
                        int_html += "</section>"
                        html += int_html

            elif el["text"] == "Mutual Fund":
                elementid = el["element_id"]
                element_config = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "computation_model_configuration",
                            "Columns": ["element_config"],
                        },
                        "condition": [
                            {
                                "column_name": "model_name",
                                "condition": "Equal to",
                                "input_value": model_name,
                                "and_or": "and",
                            },
                            {
                                "column_name": "element_id",
                                "condition": "Equal to",
                                "input_value": elementid,
                                "and_or": "",
                            },
                        ],
                    },
                )
                if len(element_config) > 0:
                    elecon_dict = element_config.iloc[0, 0]
                    config_dict = json.loads(elecon_dict)
                    global_function = config_dict["globalVar"]
                    if global_function:
                        product_category = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Category_Master",
                                    "Columns": ["id"],
                                },
                                "condition": [
                                    {
                                        "column_name": "product_category",
                                        "condition": "Equal to",
                                        "input_value": "Financial_Instruments_Mutual_Fund",
                                        "and_or": "",
                                    }
                                ],
                            },
                        )

                        if product_category.iloc[0, 0]:
                            product_category = product_category.iloc[0, 0]
                        else:
                            product_category = "0"
                        products_data = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Product_Master",
                                    "Columns": ["id", "product_variant_name"],
                                },
                                "condition": [
                                    {
                                        "column_name": "product_category",
                                        "condition": "Equal to",
                                        "input_value": product_category,
                                        "and_or": "",
                                    }
                                ],
                            },
                        )
                        products_list = products_data.product_variant_name.tolist()
                        products_data = products_data.set_index("id").to_dict()
                        products_to_model_data = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Product_to_Model_mapping",
                                    "Columns": ["id", "product_variant_name"],
                                },
                                "condition": [],
                            },
                        ).set_index("id")

                        products_to_model_data["product_variant"] = products_to_model_data[
                            "product_variant"
                        ].replace(products_data["product_variant_name"])
                        model_data = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Model_Repository",
                                    "Columns": ["id", "model_code", "model_name"],
                                },
                                "condition": [],
                            },
                        ).set_index("id")
                        model_mapper = model_data["model_code"].to_dict()
                        products_to_model_data["model_code"] = products_to_model_data["model_code"].replace(
                            model_mapper
                        )
                        products_to_model_data = products_to_model_data.set_index("product_variant")[
                            "model_code"
                        ].to_dict()

                        int_html = f"<section class='globalFunction' data-element_name='{el['text']}' data-element_id='{elementid}'>"
                        select_operation = f"""
                        <div class="form-group col-md-3 col-sm-6">
                            <label for="Choose_Operation">{el['text']}</label>
                            <select class="select2 form-control" name="Choose Operation" id="select_mfCF_val_{computation_tab_element_id}" required>
                                <option value="" disabled selected> Select Operation</option>"""
                        for i in products_list:
                            select_operation += f"""<option data-model_code='{products_to_model_data[i]}' value='{i}'>{i}</option>"""

                        select_operation += """</select>
                        </div>
                        """
                        select_configuration = f"""
                        <hr>
                        <section class="form-row mx-2" id="finInstrumentsCF_configure_container_{computation_tab_element_id}">

                        </section>
                        <hr>
                        """
                        select_output = f"""
                        <div class="form-group mx-2" id = "finInstrumentsCF_checkbox_{computation_tab_element_id}">
                            <label>Output:</label>
                            <div class="custom-control custom-checkbox">
                                <input type="checkbox" name="ComputedValue" class="checkboxinput custom-control-input" id="cftable1_{computation_tab_element_id}" value="Cashflows">
                                <label for="cftable1_{computation_tab_element_id}" class="custom-control-label">
                                Cashflow Table
                                </label>
                            </div>
                            <div class="custom-control custom-checkbox">
                                <input type="checkbox" name="ComputedValue" class="checkboxinput custom-control-input" id="cftable2_{computation_tab_element_id}" value="Valuation">
                                <label for="cftable2_{computation_tab_element_id}" class="custom-control-label">
                                    Valuation Result
                                </label>
                            </div>
                            <div class="custom-control custom-checkbox">
                                <input type="checkbox" name="ComputedValue" class="checkboxinput custom-control-input" id="cftable3_{computation_tab_element_id}" value="Sensitivity_Analysis">
                                <label for="cftable3_{computation_tab_element_id}" class="custom-control-label">
                                    Sensitivity Measure
                                </label>
                            </div>
                        </div>
                        """
                        select_valuation_method = f"""
                        <div class="form-group finInstrumentsCF_input" id = "finInstrumentsCF_valuation_method_{computation_tab_element_id}">
                            <label >Valuation Methodology: </label>
                            <div class='custom-control custom-radio'>
                                <input type="radio" id = "risk_based_valuation_{computation_tab_element_id}" class="custom-control-input finInstrumentsCF_valuation_method_button_{computation_tab_element_id}" name="valuation_choice" value="risk_based_valuation">
                                <label for="risk_based_valuation_{computation_tab_element_id}" class="custom-control-label var(--font-color)">Risk Based Valuation</label >
                            </div>
                            <div class='custom-control custom-radio'>
                                <input type="radio" id="mtm_valuation_{computation_tab_element_id}" class="custom-control-input finInstrumentsCF_valuation_method_button_{computation_tab_element_id}" name="valuation_choice" value="mtm_valuation">
                                <label for="mtm_valuation_{computation_tab_element_id}" class="custom-control-label var(--font-color)">Mark to Market</label >
                            </div>
                        </div>
                        """
                        script = f"""

                        <script>
                            $('#finInstrumentsCF_configure_container_{computation_tab_element_id}').empty();
                            $('#select_mfCF_val_{computation_tab_element_id}').off("select2:select").on('select2:select',function()"""
                        script += (
                            """{
                                $.ajax({
                                    url: '/users/computationModule/',
                                    data: {
                                        'product_type':$('#select_mfCF_val_"""
                            + f"""{computation_tab_element_id}').val(),"""
                            + """'model_code':$('#select_mfCF_val_"""
                            + f"""{computation_tab_element_id} option:selected').attr('data-model_code'),"""
                            + """       'operation': 'fetch_product_attributes_intRates',
                                    },
                                    type: "POST",
                                    dataType: "json",
                                    success: function (data) {
                                        """
                            + f"""$('#finInstrumentsCF_configure_container_{computation_tab_element_id}').empty()"""
                            + """
                                        var string = ``
                                        for(i in data.attribute_dict){
                                            if (data.attribute_dict[i]['field_type']=='IntegerField'){
                                                string+=`<div class="form-group col-3" >
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="numberinput form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="number" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='BigIntegerField'){
                                                string+=`<div class="form-group col-3" >
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="numberinput form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="number" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='FloatField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="numberinput form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="number" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='CharField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="textInput textinput form-control"  id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="text" required>
                                                        </div>`
                                            } else if (data.attribute_dict[i]['field_type']=='DateField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <input class="form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ type="date" required>
                                                        </div>`

                                            } else if (data.attribute_dict[i]['field_type']=='SelectField'){
                                                string+=`<div class="form-group col-3">
                                                            <label>${data.attribute_dict[i]['field_name']}</label>
                                                            <select class="select2 form-control" id=${data.attribute_dict[i]['id']}"""
                            + f"_{computation_tab_element_id}"
                            + """ required>`

                                                            for(j in data.attribute_dict[i]['options']){
                                                                string+=`<option>${data.attribute_dict[i]['options'][j]}</option>`
                                                            }
                                                string+=`</select></div>`
                                            }
                                        }"""
                        )
                        script += f""" $('#finInstrumentsCF_configure_container_{computation_tab_element_id}').append(string);"""
                        script += (
                            f""" $('#finInstrumentsCF_configure_container_{computation_tab_element_id}')"""
                            + """.find('select.select2').each(function(){
                            parent = $(this).parent()
                        $(this).select2({dropdownParent:parent})
                        });"""
                        )

                        script += """},
                                    error: function(){
                                        Swal.fire({icon: 'error',text: 'Error while fetching attributes for the selected product variant.'});
                                    }
                                });
                                });
                        </script>
                        """
                        int_html += select_operation
                        int_html += select_configuration
                        int_html += select_output
                        int_html += select_valuation_method
                        int_html += script
                        int_html += "</section>"
                        html += int_html
        data["form_computation"] = html
        if len(mandatory_list) > 0:
            data["mandatory list"] = mandatory_list
        else:
            data["mandatory list"] = []
    return data

def parse_gdropdown_Dependencies(dropdown_variables):
    dependent_columns_dict = {}

    for dropdown_var_config in dropdown_variables:
        for dropdown_var in dropdown_var_config.get("dependencies",[]):
            dependencies = dependent_columns_dict.get(dropdown_var,[])
            if dependencies:
                dependencies.append(dropdown_var_config["varName"])
            else:
                dependent_columns_dict[dropdown_var] = [dropdown_var_config["varName"]]
    
    return dependent_columns_dict


def report_view_tab(reportJson, request, row_data):
    curr_app_code, db_connection_name = current_app_db_extractor(request)
    data = {}
    base_table = reportJson["Report_Base_Table_Name"]
    report_table = reportJson["Report_Table_Name"]
    base_table_model_name = dynamic_model_create.get_model_class(base_table, request)
    report_table_model_name = dynamic_model_create.get_model_class(report_table, request)

    input_pk = base_table_model_name.pk.name
    base_pk = reportJson["Report_base_column"]
    colAll = [field.name for field in base_table_model_name.concrete_fields]
    base_table_data = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": base_table,
                "Columns": colAll,
            },
            "condition": [],
        },
    )
    base_col_list = [input_pk] + [
        i["field name"] for i in reportJson["Report_Table_Structure"] if i["parent table"] == base_table
    ]
    base_table_data = base_table_data.loc[:, base_col_list]

    # Add direct relational columns for other tables
    rel_fields_dict = {
        i["parent table"]: [i["field name"]]
        for i in reportJson["Report_Table_Structure"]
        if i["aggregation"] == "Direct relation" and i["parent table"] != base_table
    }
    for tablename, field in rel_fields_dict.items():
        colAll = [field.name for field in tablename.concrete_fields]
        rel_field_data = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": tablename,
                    "Columns": colAll,
                },
                "condition": [],
            },
        )
        cols = [base_pk] + field
        base_table_data = base_table_data.merge(
            rel_field_data[cols], right_on=base_pk, left_on="id", how="left"
        )
        if f"{base_pk}_x" in base_table_data.columns:
            base_table_data.rename(columns={f"{base_pk}_x": base_pk}, inplace=True)
        if f"{base_pk}_y" in base_table_data.columns:
            base_table_data.drop(columns=[f"{base_pk}_y"], inplace=True)

    # Add aggregation columns
    aggr_fields_list = [
        {i["parent table"]: {i["field name"]: i["aggregation"]}}
        for i in reportJson["Report_Table_Structure"]
        if len(i["parent table"]) > 0 and len(i["aggregation"]) > 0 and i["aggregation"] != "Direct relation"
    ]

    for i in aggr_fields_list:
        for tablename, field in i.items():
            colAll = [field.name for field in tablename.concrete_fields]
            aggr_field_data = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": tablename,
                        "Columns": colAll,
                    },
                    "condition": [],
                },
            )
            agg_column = list(field.keys())[0]
            cols = [base_pk] + list(field.keys())
            aggr_field_data = aggr_field_data[cols]
            aggregation = list(field.values())[0]
            if aggregation == "Sum":
                aggr_field_data_final = aggr_field_data.groupby(base_pk)[agg_column].sum().reset_index()
            if aggregation == "Average":
                aggr_field_data_final = aggr_field_data.groupby(base_pk)[agg_column].mean().reset_index()
            if aggregation == "Count":
                aggr_field_data_final = aggr_field_data.groupby(base_pk)[agg_column].count().reset_index()
            base_table_data = base_table_data.merge(
                aggr_field_data_final, right_on=base_pk, left_on="id", how="left"
            )
            if f"{base_pk}_x" in base_table_data.columns:
                base_table_data.rename(columns={f"{base_pk}_x": base_pk}, inplace=True)
            if f"{base_pk}_y" in base_table_data.columns:
                base_table_data.drop(columns=[f"{base_pk}_y"], inplace=True)
    computed_fields_list = [
        {
            "field name": i["field name"],
            "operation": i["operation"],
            "operation_columns": i["data elements"],
        }
        for i in reportJson["Report_Table_Structure"]
        if i["field data type"]
        in [
            "IntegerField (Integer numbers)",
            "BigIntegerField (Big Integer numbers)",
            "FloatField (Integer or decimal numbers)",
        ]
        and len(i["parent table"]) == 0
        and len(i["operation"]) > 0
    ]

    for i in computed_fields_list:
        computed_column = base_table_data[i["operation_columns"][0]]
        for j in range(1, len(i["operation_columns"])):
            if i["operation"] == "Add":
                computed_column = computed_column + base_table_data[i["operation_columns"][j]]
            if i["operation"] == "Subtract":
                computed_column = computed_column - base_table_data[i["operation_columns"][j]]
            if i["operation"] == "Multiply":
                computed_column = computed_column * base_table_data[i["operation_columns"][j]]
            if i["operation"] == "Divide":
                computed_column = computed_column / base_table_data[i["operation_columns"][j]]
        base_table_data[i["field name"]] = computed_column.round(4)

    content1 = []

    if len(content1) == 0:
        tabledata = "empty"
    else:
        tabledata = "filled"

    headers11 = []
    content11 = []

    base_table_data["created_by"] = request.user.username
    base_table_data["modified_by"] = request.user.username
    base_table_data["created_date"] = pd.to_datetime(datetime.now())
    base_table_data["modified_date"] = pd.to_datetime(datetime.now())
    base_table_data.drop(columns=input_pk, inplace=True)

    report_sql_tablename = "users_" + report_table.lower()

    data_handling(request, base_table_data, report_table)
    base_table_display = get_data_from_cache(report_sql_tablename, request, report_table)

    report_headers = {i.name: i.verbose_name.title() for i in report_table_model_name.concrete_fields}
    base_table_display.rename(columns=report_headers, inplace=True)
    report_content = base_table_display.to_dict("records")
    for i in report_content:
        for key, value in i.items():
            if isinstance(value, (dt.date, dt.datetime)):
                i[key] = value.isoformat()
    (
        table_name1,
        label_columns1,
        search_filters1,
        form_fields11,
        form_fields111,
        form_fieldsnew,
    ) = search_filter.ViewFilter(report_table_model_name, request=request)

    data["element_id"] = row_data["element_id"]
    data["tab_type"] = row_data["tab_type"]
    data["tab_header_name"] = row_data["tab_header_name"]
    data["model_name"] = report_table
    data["report_headers"] = base_table_display.columns.tolist()
    data["report_content"] = report_content
    data["report_subelements"] = reportJson["Report_SubElements"]
    data["table_name"] = table_name1
    data["label_columns"] = label_columns1
    data["search_filters"] = search_filters1
    data["form_fields"] = form_fields11
    data["form_fields1"] = form_fields111
    data["headers"] = headers11
    data["alertdata"] = content11
    data["table_data"] = tabledata
    return data


def alert_check_condition(op_cond, op_col, op_limit):
    if op_cond == "Starts with":
        s = f"(table_content['{op_col}'].str.startswith((int({op_limit}) if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}')))"
    elif op_cond == "Ends with":
        s = f"(table_content['{op_col}'].str.endswith((int({op_limit}) if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}')))"
    elif op_cond == "Contains":
        s = f"(table_content[table_content['{op_col}'].str.contains((int({op_limit}) if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}')))"
    elif op_cond == "Equal to":
        s = f"(table_content['{op_col}'] == (float('{op_limit}') if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}'))"
    elif op_cond == "Not Starts with":
        s = f"(~table_content['{op_col}'].str.startswith((int({op_limit}) if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}')))"
    elif op_cond == "Not Ends with":
        s = f"(~table_content['{op_col}'].str.endswith((int({op_limit}) if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}')))"
    elif op_cond == "Not Contains":
        s = f"(~table_content['{op_col}'].str.contains((int({op_limit}) if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}')))"
    elif op_cond == "Not Equal to":
        s = f"(table_content['{op_col}'] != (float({op_limit}) if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}'))"
    elif op_cond == "Greater than":
        s = f"(table_content['{op_col}'] > (float({op_limit}) if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}'))"
    elif op_cond == "Smaller than":
        s = f"(table_content['{op_col}'] < (float({op_limit}) if table_content['{op_col}'].dtypes in ['float64','int64'] else '{op_limit}'))"
    return s


def custom_validation_condition_test(data_csv, condition_list, request, messages_list=""):
    # List of DataTypes Columns
    IntegerField_list = condition_list["IntegerField_list"]
    FloatField_list = condition_list["FloatField_list"]
    DateTimeField_list = condition_list["DateTimeField_list"]
    DateField_list = condition_list["DateField_list"]
    TimeField_list = condition_list["TimeField_list"]
    BooleanField_list = condition_list["BooleanField_list"]
    date_type = DateTimeField_list + TimeField_list + DateField_list
    bool_type = BooleanField_list

    # Required config
    property_custom_dict = condition_list["property_custom_dict"]

    # Extract Data
    column_name = property_custom_dict["column_name"]
    input_value = property_custom_dict["input_value"]
    condition_name = property_custom_dict["condition_name"]
    master_table_name = property_custom_dict["master_table_name"]
    values_list = []

    if master_table_name:
        values_list = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": master_table_name,
                    "Agg_Type": "DISTINCT",
                    "Columns": [input_value],
                },
                "condition": [],
            },
        )
        if len(values_list) > 0:
            values_list = values_list[input_value].dropna().tolist()
        else:
            values_list = []

    final_string = ""

    if condition_name == "Greater than":
        if column_name in IntegerField_list:
            if not input_value:
                input_value = "NULL"
                final_string = f'self.data_csv["{column_name}"].isna()'
            else:
                check_value = float(input_value)
                final_string = (
                    f'pd.to_numeric(self.data_csv["{column_name}"], errors="coerce",).ge({check_value})'
                )

        elif column_name in FloatField_list:
            if not input_value:
                input_value = "NULL"
                final_string = f'self.data_csv["{column_name}"].isna()'
            else:
                check_value = float(input_value)
                final_string = (
                    f'pd.to_numeric(self.data_csv["{column_name}"], errors="coerce",).ge({check_value})'
                )

        elif column_name in date_type:
            if column_name in DateTimeField_list:
                try:
                    date_convert = datetime.strptime({input_value}, "%Y-%m-%dT%H:%M")
                    date_convert = f"""datetime.strptime("{input_value}", "%Y-%m-%dT%H:%M")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = str(pd.NaT)

                if str(date_convert) != str(pd.NaT):
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d %H:%M:%S", errors="coerce", dayfirst=True,).ge({date_convert})'
                    input_value = str(datetime.strptime({input_value}, "%Y-%m-%dT%H:%M"))
                else:
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d %H:%M:%S", errors="coerce", dayfirst=True,).ge({date_convert})'
                    input_value = "NULL"

            elif column_name in DateField_list:
                try:
                    date_convert = datetime.strptime(input_value, "%Y-%m-%d")
                    date_convert = f"""datetime.strptime("{input_value}", "%Y-%m-%d")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = pd.NaT

                if str(date_convert) != str(pd.NaT):
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d", errors="coerce", dayfirst=True).ge({date_convert})'
                    input_value = str(datetime.strptime(input_value, "%Y-%m-%d").date())
                else:
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d", errors="coerce", dayfirst=True).ge({date_convert})'
                    input_value = "NULL"
            else:

                try:
                    date_convert = datetime.strptime(input_value, "%H:%M:%S")
                    date_convert = f"""datetime.strptime("{input_value}", "%H:%M:%S")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = pd.NaT

                if str(date_convert) != str(pd.NaT):
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%H:%M:%S", errors="coerce", dayfirst=True).ge({date_convert})'

                    input_value = str(datetime.strptime(input_value, "%H:%M:%S").time())
                else:
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%H:%M:%S", errors="coerce", dayfirst=True).ge({date_convert})'
                    input_value = "NULL"
        messages_list = f"""Column {column_name} should be greater than {input_value}"""

    if condition_name == "Smaller than":
        if column_name in IntegerField_list:
            if not input_value:
                check_value = "NULL"
                final_string = f'self.data_csv["{column_name}"].isna()'
            else:
                check_value = float(input_value)
                final_string = (
                    f'pd.to_numeric(self.data_csv["{column_name}"], errors="coerce",).le({check_value})'
                )
        elif column_name in FloatField_list:
            if not input_value:
                check_value = "NULL"
                final_string = f'self.data_csv["{column_name}"].isna()'
            else:
                check_value = float(input_value)
                final_string = (
                    f'pd.to_numeric(self.data_csv["{column_name}"], errors="coerce",).le({check_value})'
                )
        elif column_name in date_type:
            if column_name in DateTimeField_list:
                try:
                    date_convert = datetime.strptime({input_value}, "%Y-%m-%dT%H:%M")
                    date_convert = f"""datetime.strptime("{input_value}", "%Y-%m-%dT%H:%M")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = str(pd.NaT)

                if str(date_convert) != str(pd.NaT):
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%dT%H:%M", errors="coerce", dayfirst=True,).le({date_convert})'
                    input_value = str(datetime.strptime({input_value}, "%Y-%m-%dT%H:%M"))
                else:
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%dT%H:%M", errors="coerce", dayfirst=True,).le({date_convert})'
                    input_value = "NULL"

            elif column_name in DateField_list:
                try:
                    date_convert = datetime.strptime(input_value, "%Y-%m-%d")
                    date_convert = f"""datetime.strptime("{input_value}", "%Y-%m-%d")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = pd.NaT

                if str(date_convert) != str(pd.NaT):
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d", errors="coerce", dayfirst=True).le({date_convert})'
                    input_value = str(datetime.strptime(input_value, "%Y-%m-%d").date())
                else:
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d", errors="coerce", dayfirst=True).le({date_convert})'
                    input_value = "NULL"
            else:
                try:
                    date_convert = datetime.strptime(input_value, "%H:%M:%S")
                    date_convert = f"""datetime.strptime("{input_value}", "%H:%M:%S")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = pd.NaT

                if str(date_convert) != str(pd.NaT):
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%H:%M:%S", errors="coerce", dayfirst=True,).le({date_convert})'

                    input_value = str(datetime.strptime(input_value, "%H:%M:%S").time())
                else:
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%H:%M:%S", errors="coerce", dayfirst=True,).le({date_convert})'
                    input_value = "NULL"

        messages_list = f"""Column {column_name} should be smaller than {input_value}"""

    if condition_name == "Equal to":
        if column_name in IntegerField_list:
            if not input_value:
                input_value = "NULL"
                final_string = f'self.data_csv["{column_name}"].isna()'
            else:
                check_value = int(float(input_value))
                final_string = f'self.data_csv["{column_name}"].astype("Int64").eq({check_value})'
        elif column_name in FloatField_list:
            if not input_value:
                input_value = "NULL"
                final_string = f'self.data_csv["{column_name}"].isna()'
            else:
                check_value = float(input_value)
                final_string = f'self.data_csv["{column_name}"].astype("float").eq({check_value})'
        elif column_name in date_type:
            date_convert = ""
            if column_name in DateTimeField_list:
                try:
                    date_convert = datetime.strptime(input_value, "%Y-%m-%dT%H:%M")
                    date_convert = f"""datetime.strptime("{input_value}", "%Y-%m-%dT%H:%M")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = str(pd.NaT)

                if date_convert == str(pd.NaT):
                    input_value = "NULL"
                    final_string = f'self.data_csv["{column_name}"].isna()'
                else:
                    input_value = str(datetime.strptime(input_value, "%Y-%m-%dT%H:%M"))
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d %H:%M:%S", errors="coerce", dayfirst=True).eq({date_convert})'

            elif column_name in DateField_list:
                try:
                    date_convert = datetime.strptime(input_value, "%Y-%m-%d")
                    date_convert = f"""datetime.strptime("{input_value}", "%Y-%m-%d")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = str(pd.NaT)

                if date_convert == str(pd.NaT):
                    input_value = "NULL"
                    final_string = f'self.data_csv["{column_name}"].isna()'
                else:
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d", errors="coerce", dayfirst=True).eq({date_convert})'
                    input_value = str(datetime.strptime(input_value, "%Y-%m-%d").date())

            else:
                try:
                    date_convert = datetime.strptime(input_value, "%H:%M:%S")
                    date_convert = f"""datetime.strptime("{input_value}", "%H:%M:%S")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = str(pd.NaT)

                if date_convert == str(pd.NaT):
                    input_value = "NULL"
                    final_string = f'self.data_csv["{column_name}"].isna()'
                else:
                    input_value = str(datetime.strptime(input_value, "%H:%M:%S").time())
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%H:%M:%S", errors="coerce", dayfirst=True).eq({date_convert})'

        elif column_name in bool_type:
            if input_value in ["True", 1, "1"]:
                final_string = f'self.data_csv["{column_name}"].astype("str").eq("1")'
            else:
                final_string = f'self.data_csv["{column_name}"].astype("str").eq("0")'
        else:
            if input_value and input_value != "NULL":
                final_string = f'self.data_csv["{column_name}"].astype("str").eq("{input_value}")'
            else:
                final_string = f'self.data_csv["{column_name}"].isna()'
                input_value = "NULL"

        messages_list = f"""Column {column_name} should equal to {input_value}"""

    if condition_name == "Not Equal to":
        if column_name in IntegerField_list:
            if not input_value:
                final_string = f'self.data_csv["{column_name}"].notnull()'
                input_value = "NULL"
            else:
                check_value = int(float(input_value))
                final_string = f'pd.to_numeric(self.data_csv["{column_name}"].fillna({check_value + 1}), errors="coerce",).ne({check_value})'
        elif column_name in FloatField_list:
            if not input_value:
                final_string = f'self.data_csv["{column_name}"].notnull()'
                input_value = "NULL"
            else:
                check_value = float(input_value)
                final_string = f'pd.to_numeric(self.data_csv["{column_name}"].fillna({check_value + 1}), errors="coerce",).ne({check_value})'
        elif column_name in date_type:
            date_convert = ""
            if column_name in DateTimeField_list:
                try:
                    date_convert = datetime.strptime(input_value, "%Y-%m-%dT%H:%M")
                    date_convert = f"""datetime.strptime("{input_value}", "%Y-%m-%dT%H:%M")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = str(pd.NaT)

                if date_convert == str(pd.NaT):
                    input_value = "NULL"
                    final_string = f'self.data_csv["{column_name}"].notnull()'
                else:
                    input_value = str(datetime.strptime(input_value, "%Y-%m-%dT%H:%M"))
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d %H:%M:%S", errors="coerce", dayfirst=True).ne({date_convert})'

            elif column_name in DateField_list:
                try:
                    date_convert = datetime.strptime(input_value, "%Y-%m-%d")
                    date_convert = f"""datetime.strptime("{input_value}", "%Y-%m-%d")"""

                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = str(pd.NaT)

                if date_convert == str(pd.NaT):
                    input_value = "NULL"
                    final_string = f'self.data_csv["{column_name}"].notnull()'
                else:
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%Y-%m-%d", errors="coerce", dayfirst=True).ne({date_convert})'
                    input_value = str(datetime.strptime(input_value, "%Y-%m-%d").date())

            else:
                try:
                    date_convert = datetime.strptime(input_value, "%H:%M:%S")
                    date_convert = f"""datetime.strptime("{input_value}", "%H:%M:%S")"""
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    date_convert = str(pd.NaT)

                if date_convert == str(pd.NaT):
                    input_value = "NULL"
                    final_string = f'self.data_csv["{column_name}"].notnull()'
                else:
                    input_value = str(datetime.strptime(input_value, "%H:%M:%S").time())
                    final_string = f'pd.to_datetime(self.data_csv["{column_name}"], format="%H:%M:%S", errors="coerce", dayfirst=True).ne({date_convert})'

        elif column_name in bool_type:
            if input_value in ["True", 1, "1"]:
                final_string = f'self.data_csv["{column_name}"].astype("str").ne("1")'
            else:
                final_string = f'self.data_csv["{column_name}"].astype("str").ne("0")'
        else:
            if input_value and input_value != "NULL":
                final_string = f'self.data_csv["{column_name}"].astype("str").ne("{input_value}")'
            else:
                final_string = f'self.data_csv["{column_name}"].notnull()'
                input_value = "NULL"
        messages_list = f"""Column {column_name} should not equal to {input_value}"""

    if condition_name == "Starts with":
        final_string = f'self.data_csv["{column_name}"].str.startswith("{input_value}").fillna(True)'
        messages_list = f"""Column {column_name} should start with {input_value}"""

    if condition_name == "Not Starts with":
        final_string = f'~self.data_csv["{column_name}"].str.startswith("{input_value}").fillna(False)'
        messages_list = f"""Column {column_name} should not start with {input_value}"""

    if condition_name == "Ends with":
        final_string = f'self.data_csv["{column_name}"].str.endswith("{input_value}").fillna(True)'
        messages_list = f"""Column {column_name} should end with {input_value}"""

    if condition_name == "Not Ends with":
        final_string = f'~self.data_csv["{column_name}"].str.endswith("{input_value}").fillna(False)'
        messages_list = f"""Column {column_name} should not end with {input_value}"""

    if condition_name == "Contains":
        final_string = f'self.data_csv["{column_name}"].str.contains("{input_value}").fillna(True)'
        messages_list = f"""Column {column_name} should contain {input_value}"""

    if condition_name == "Not Contains":
        final_string = f'~self.data_csv["{column_name}"].str.contains("{input_value}").fillna(False)'
        messages_list = f"""Column {column_name} should not contain {input_value}"""

    if condition_name == "IN":
        if input_value:
            if "," in input_value:
                input_value = list(input_value.split(","))
                check_input = []
                for x in input_value:
                    if x:
                        check_input.append(x)
                    else:
                        check_input.append(str(np.nan))
            else:
                if column_name in date_type:
                    if column_name in DateTimeField_list:
                        try:
                            check_input = datetime.strptime(input_value, "%Y-%m-%dT%H:%M")
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                            check_input = str(pd.NaT)
                    elif column_name in DateField_list:
                        try:
                            check_input = datetime.strptime(input_value, "%Y-%m-%d")
                            check_input = str(check_input.date())
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                            check_input = str(pd.NaT)

                    else:
                        try:
                            check_input = datetime.strptime(input_value, "%H:%M:%S")
                            check_input = str(check_input.time())
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                            check_input = str(pd.NaT)
                else:
                    check_input = str(input_value)
        else:
            check_input = str(np.nan)
        if type(input_value) == list:
            final_string = f'self.data_csv["{column_name}"].astype("str").str.contains("|".join({check_input}), case=True, regex=True)'
        else:
            final_string = f'self.data_csv["{column_name}"].astype("str").str.contains("{check_input}", case=True, regex=True, na=True)'

        messages_list = f"""Column {column_name} should be in {input_value}"""

    if condition_name == "NOT IN":
        if input_value:
            if "," in input_value:
                input_value = list(input_value.split(","))
                check_input = []
                for x in input_value:
                    if x:
                        check_input.append(x)
                    else:
                        check_input.append(str(np.nan))
            else:
                if column_name in date_type:
                    if column_name in DateTimeField_list:
                        try:
                            check_input = datetime.strptime(input_value, "%Y-%m-%dT%H:%M")
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                            check_input = str(pd.NaT)
                    elif column_name in DateField_list:
                        try:
                            check_input = datetime.strptime(input_value, "%Y-%m-%d")
                            check_input = str(check_input.date())
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                            check_input = str(pd.NaT)
                    else:
                        try:
                            check_input = datetime.strptime(input_value, "%H:%M:%S")
                            check_input = str(check_input.time())
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                            check_input = str(pd.NaT)
                else:
                    check_input = str(input_value)
        else:
            check_input = str(np.nan)
        if type(input_value) == list:
            final_string = f'~self.data_csv["{column_name}"].astype("str").str.contains("|".join({check_input}), case=True, regex=True)'
        else:
            final_string = f'~self.data_csv["{column_name}"].astype("str").str.contains("{check_input}", case=True, regex=True, na=False)'
        messages_list = f"""Column {column_name} should not be in {input_value}"""

    if condition_name == "Isin":
        if column_name in DateTimeField_list:
            date_convert = []
            for i in values_list:
                date_convert.append(i.strftime("%Y-%m-%d %H:%M:%S"))

            final_string = f'self.data_csv["{column_name}"].astype("str").isin({date_convert})'

        elif column_name in DateField_list:
            date_convert = []
            for i in values_list:
                date_convert.append(i.strftime("%Y-%m-%d"))

            final_string = f'self.data_csv["{column_name}"].astype("str").isin({date_convert})'
        elif column_name in TimeField_list:
            date_convert = []
            for i in values_list:
                date_convert.append(i.strftime("%H:%M:%S"))

            final_string = f'self.data_csv["{column_name}"].astype("str").isin({date_convert})'
        else:
            final_string = f'self.data_csv["{column_name}"].isin({values_list})'
        messages_list = (
            f"""Column {column_name} should be a value in {input_value} of {master_table_name} table"""
        )
    return final_string, messages_list


def StandardJSFunc(reference_table_name, parent_column, child_column, value, request):
    data_list = []

    rawData = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": reference_table_name,
                "Columns": [child_column],
            },
            "condition": [
                {
                    "column_name": "primary_key",
                    "condition": "Equal to",
                    "input_value": value,
                    "and_or": "",
                }
            ],
        },
    )
    rawData1 = rawData.to_dict("records")
    data_list += rawData1

    return data_list


def data_connector(reportJson, request, row_data):
    data = {}
    data["element_id"] = row_data["element_id"]
    data["tab_type"] = row_data["tab_type"]
    data["tab_header_name"] = row_data["tab_header_name"]
    try:
        list_view_tab_body_content = reportJson
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        list_view_tab_body_content = {
            "Category_attributes": {
                "Mandatory": {"Table_name": "CountryMaster"},
                "Connector": {"Template_choice": "Upload functionality"},
            },
            "Category_sub_elements": [
                {
                    "Category_sub_element_name": "Upload",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "CountryMaster"},
                        {
                            "attr": "Apply Datestamp on Uploaded Records",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Last upload date",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
            ],
        }
    ltbc = list_view_tab_body_content
    list_view_table_name = ltbc["Category_attributes"]["Mandatory"]["Table_name"]
    list_view_template_choice = ltbc["Category_attributes"]["Connector"]["Template_choice"]

    data["data_connector"] = list_view_template_choice
    data["filename"] = list_view_table_name
    if list_view_template_choice == "Upload functionality":
        if ltbc["Category_sub_elements"][0]["Category_sub_element_name"] == "Upload":
            for i in range(1, 7):
                if ltbc["Category_sub_elements"][1]["Category_sub_element_attributes"][i]["value"] == "Yes":
                    data[ltbc["Category_sub_elements"][1]["Category_sub_element_attributes"][i]["attr"]] = (
                        "Yes"
                    )
                else:
                    data[ltbc["Category_sub_elements"][1]["Category_sub_element_attributes"][i]["attr"]] = (
                        "No"
                    )
    data["form_US"] = (
        f"""
        <div id="doe_sheet_selection{row_data["element_id"]}"  style='display: none;margin-top:5px'>
          <select   id='doe_sheet_value_{row_data["element_id"]}' class=' select2  ' name= 'dateOfExtractionSheet'  data-date-sheet-extraction='date_extract_sheet_{row_data["element_id"]}'>
            <option value='' selected disabled>Select Sheet Name</option>
            </select>
        </div>"""
        + f"""
        <div id="doe_field_selection{row_data["element_id"]}" style="display: none;margin-top: 10px;">
        <select   id='doe_field_value_{row_data["element_id"]}' class=' select2 ' name= 'dateOfExtractionColumn'  data-date-field-extraction='date_extract_field_{row_data["element_id"]}'>
        <option value='' selected disabled>Select Date Field</option>
        </select>
        <input type="hidden"  id='doe_field_type_{row_data["element_id"]}' name="dateExtractionType" value=""/>
        </div>
        """
        + "<input type='date' class='form-control datepickerinput form-control' placeholder= 'DD-MM-YYYY', css_class ='dateUS', name= 'dateOfExtraction' class='input-group date' "
        + f"""data-date-extraction='date_extract_{row_data["element_id"]}' style='display: none;margin-top:10px'"""
        + ">"
    )
    return data


def get_data_from_cache(
    sql_table_name, request, actual_table_name="", db_connection_name="", user_db_engine=["", {}], db_type=""
):
    override = False
    if db_type != "":
        override = True

    rawData = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": actual_table_name,
                "Columns": ["*"],
            },
            "condition": [],
        },
        engine2=user_db_engine,
        db_type=db_type,
        engine_override=override,
    )

    return rawData


def button_styling(styling_dict, button_identifier):
    if styling_dict is not None and styling_dict.get(button_identifier) is not None:
        Button = styling_dict.get(button_identifier)
        hoverColorOption = ""
        hoverBgColoroption = ""
        if Button["column-header"] != "":
            columnTextHeader = Button["column-header"]
        else:
            columnTextHeader = ""
        if Button["text"] != "":
            changeText = Button["text"]
        else:
            changeText = ""
        if button_identifier == "Edit":
            if Button["data-icon"] != "":
                if Button["icon-color"] != "#ffffff":
                    iconAppend = f"<i name='actions' value='update' class='{Button['data-icon']}' style='color:{Button['icon-color']}'></i>"
                else:
                    iconAppend = f"<i name='actions' value='update' class='{Button['data-icon']}'></i>"
            else:
                iconAppend = ""
        elif button_identifier == "Delete":
            if Button["data-icon"] != "":
                if Button["icon-color"] != "#ffffff":
                    iconAppend = f"<i name='actions' value='delete per' class='{Button['data-icon']}' style='color:{Button['icon-color']}'></i>"
                else:
                    iconAppend = f"<i name='actions' value='delete per' class='{Button['data-icon']}'></i>"
            else:
                iconAppend = ""
        elif button_identifier == "Temporary delete":
            if Button["data-icon"] != "":
                if Button["icon-color"] != "#ffffff":
                    iconAppend = f"<i name='actions' value='delete temp' class='{Button['data-icon']}' style='color:{Button['icon-color']}'></i>"
                else:
                    iconAppend = f"<i name='actions' value='delete temp' class='{Button['data-icon']}'></i>"
            else:
                iconAppend = ""
        elif button_identifier == "View":
            if Button["data-icon"] != "":
                if Button["icon-color"] != "#ffffff":
                    iconAppend = f"<i name='actions' value='detail' class='{Button['data-icon']}' style='color:{Button['icon-color']}'></i>"
                else:
                    iconAppend = f"<i name='actions' value='detail' class='{Button['data-icon']}'></i>"
            else:
                iconAppend = ""
        else:
            if Button["data-icon"] != "":
                if Button["icon-color"] != "#ffffff":
                    iconAppend = (
                        f"<i  class='{Button['data-icon']}' style='color:{Button['icon-color']}'></i>"
                    )
                else:
                    iconAppend = f"<i  class='{Button['data-icon']}'></i>"
            else:
                iconAppend = ""

        if Button["hoveractions"] == "Color":
            hoverColorOption = f"this.style.backgroundColor='{Button['hover-color']}'"
            hoverBgColoroption = f"this.style.backgroundColor='{Button['rgba']}'"
        elif Button["hoveractions"] == "Gradient":
            hoverColorOption = f"this.style.backgroundImage='{Button['type-gradient']}({Button['gradient-color-1']},{Button['gradient-color-2']})'"
            hoverBgColoroption = "this.style.backgroundImage=''"
        elif Button["hoveractions"] == "textsize":
            hoverColorOption = f"this.style.fontSize='{Button['hover-text-size']}'"
            if Button["font-size"] != "none":
                hoverBgColoroption = f"this.style.fontSize='{Button['font-size']}'"
            else:
                hoverBgColoroption = "this.style.fontSize=''"
        else:
            hoverColorOption = "''"
            hoverBgColoroption = "''"
        styling = f"'color:{Button['color']};background-color:{Button['rgba']};border-style:{Button['border-style']};border-width:{Button['border-width']}{Button['border-measure']};border-color:{Button['border-color']};font-size:{Button['font-size']};'"
        onMouseOver = hoverColorOption
        onMouseOut = hoverBgColoroption
        iconAppend
        changeText
        dict_a = {
            "styling": styling,
            "onMouseOver": onMouseOver,
            "onMouseOut": onMouseOut,
            "iconAppend": iconAppend,
            "changeText": changeText,
            "columnTextHeader": columnTextHeader,
        }
        return dict_a
    else:
        return None


def pdf_action_button(styling_dict, element_id, model_name, app_table_cols, app_table_sep):
    if styling_dict is not None and styling_dict.get(model_name) is not None:
        styling_dict = styling_dict.get(model_name)
        styling_dict["app_table_cols"] = app_table_cols
        styling_dict["app_table_sep"] = app_table_sep
        if styling_dict["pdf_action_button"] is True:
            styling = f"`&nbsp;<a data-toggle='tooltip' title='Extract PDF' data-elementid='{element_id}' data-table_model_name='{model_name}' value='pdf'><i name='actions' value='pdf' class='fas fa-file-pdf ihover javaSC thin-icon' style='font-size:15px;' data-list='{json.dumps(styling_dict)}'></i></a>&nbsp;`"
            dict_a = {"styling": styling}
        else:
            dict_a = {"styling": ""}
    else:
        dict_a = {"styling": ""}
    return dict_a


def Serversidetable(elementTabID, model_name, request, view_name="", request2={}):
    multiple_attr = False
    multiple_table_len = 0
    approval_table = False
    tab_content = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["tab_body_content"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": str(elementTabID),
                    "and_or": "",
                }
            ],
        },
    )

    actual_model_name = dynamic_model_create.get_model_class(model_name, request)
    EXPOSURE_TABLE = []
    curr_app_code, db_connection_name = current_app_db_extractor(request)
    if len(request2) == 0:
        level_button_access = get_button_access(request, curr_app_code, elementTabID, request2=request2)
    else:
        level_button_access = []
    ed_disabled = "pointer-events: none;" if "ListView - Edit Record" not in level_button_access else ""
    de_disabled = "pointer-events: none;" if "ListView - Delete Record" not in level_button_access else ""
    ve_disabled = "pointer-events: none;" if "ListView - View Record" not in level_button_access else ""
    if tab_content.get("tab_body_content").empty is False:
        tab_info = json.loads(tab_content["tab_body_content"].iloc[0])
        if tab_info.get("Category_attributes"):
            if tab_info["Category_attributes"]["Mandatory"].get("Table_name") == "ApprovalTable":
                approval_table = True
            if tab_info["Category_attributes"]["Mandatory"].get("Table_name").lower().startswith("["):
                multiple_table_len = len(
                    json.loads(tab_info["Category_attributes"]["Mandatory"].get("Table_name"))
                )

        if view_name:
            tab_info = tab_info[view_name]

        if tab_info.get("Category_sub_elements"):
            for j in range(len(tab_info.get("Category_sub_elements"))):
                if tab_info["Category_sub_elements"][j]["Category_sub_element_name"] == "Data_table":
                    for i in tab_info["Category_sub_elements"][j]["Category_sub_element_attributes"]:
                        if (
                            i["attr"] == "Delete Multiple(Permanent)"
                            or i["attr"] == "Delete Multiple(Temporary)"
                            or i["attr"] == "Approve Multiple"
                            or i["attr"] == "Reject Multiple"
                        ) and i["value"] == "Yes":
                            multiple_attr = True

        config = False
        if tab_info.get("Category_attributes"):
            tab_info = tab_info
            comp_element_id = ""
        else:
            if view_name:
                tab_info = tab_info[view_name]
                if tab_info.get("mulview_comp"):
                    comp_element_id = tab_info["mulview_comp"].get(view_name)
                else:
                    comp_element_id = ""
            else:
                for key, value in tab_info.items():
                    tab_info = tab_info[value["mulview_def"]]
                    if tab_info.get("mulview_comp"):
                        comp_element_id = tab_info["mulview_comp"].get(value["mulview_def"])
                    else:
                        comp_element_id = ""
                    break
        action_button_config = tab_info["Category_attributes"]["Mandatory"].get("configActionButtons")
        action_button_group_together = tab_info["Category_attributes"]["Mandatory"].get(
            "actionButtonsGroupTogether"
        )
        group_by_trigger = False
        if tab_info["Category_attributes"]["Mandatory"].get("GroupByConfigs") is not None:
            group_by = tab_info["Category_attributes"]["Mandatory"].get("GroupByConfigs")
            if group_by.get(model_name) is not None:
                if group_by.get(model_name)["group_by_switch"] is False:
                    group_by_trigger = True
        if action_button_config is not None:
            action_button_config_model = action_button_config.get(model_name)
        else:
            action_button_config_model = None
        if tab_info.get("Category_attributes").get("Mandatory").get("approversDispFieldsListView"):
            app_table_cols = tab_info["Category_attributes"]["Mandatory"].get("approversDispFieldsListView")
        else:
            app_table_cols = ["username", "first_name", "last_name"]

        if tab_info.get("Category_attributes").get("Mandatory").get("approversDispFormatListView"):
            app_table_sep = tab_info["Category_attributes"]["Mandatory"].get("approversDispFormatListView")
            if app_table_sep == "space_sep":
                app_table_sep = " "
            else:
                app_table_sep = ", "
        else:
            app_table_sep = " "
        if not group_by_trigger:
            if action_button_group_together is not None:
                if action_button_group_together is False:
                    for j in range(len(tab_info["Category_sub_elements"])):
                        if tab_info["Category_sub_elements"][j]["Category_sub_element_name"] == "Action":
                            config = True
                            list_view_col_names = {}
                            list_view_col_names["data_name"] = "Select"
                            list_view_col_names["column_name"] = "Select"
                            list_view_col_names["default"] = "<td>"
                            list_view_col_names[
                                "default"
                            ] += f"""<input class="multiple_select_checkbox form-check-input" type="checkbox" value=""style="display:none; cursor: pointer; margin: 0rem 0.2rem 0.1rem 0.1rem; " onchange="checkforselection(elementTabID='{elementTabID}', obj = this)">
                            <script>
                                $(`#multiple_select_checkbox_SelectAll_div{elementTabID}`).css('display', 'none');
                            </script>
                            <style>
                                .multiple_select_checkbox {{
                                    position: relative;
                                    cursor: pointer;
                                    accent-color: var(--primary-color,var(--primary,darkgoldenrod));
                                    transform: scale(1.05);
                                }}
                                .multiple_select_checkbox::before {{
                                    content: '';
                                    position: absolute;
                                    left: 1.2px;
                                    top: 1.2px;
                                    width: 11px;
                                    height: 11px;
                                    border: 0px solid #838383;
                                    border-radius: 0.8px;
                                    background-color: transparent;
                                }}
                                .multiple_select_checkbox:hover::before {{
                                    background-color: #f8f9fa;
                                }}
                                .multiple_select_checkbox:checked::before {{
                                    accent-color: var(--primary-color,var(--primary,darkgoldenrod));
                                }}
                                .multiple_select_checkbox:checked:hover::before {{
                                    background-color: transparent;
                                }}
                            </style>"""
                            list_view_col_names["default"] += "</td>"
                            list_view_col_names["order"] = 1
                            list_view_col_names["searchable"] = False
                            EXPOSURE_TABLE.append(list_view_col_names)
                            for i in tab_info["Category_sub_elements"][j]["Category_sub_element_attributes"]:
                                if not comp_element_id:
                                    if i["attr"] == "SelectAll_Action" and i["value"] == "Yes":
                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Edit"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(
                                                action_button_config_model, "Edit"
                                            )
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><button name="actions" value="update" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                            else:
                                                list_view_col_names["column_name"] = "Edit"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                        else:
                                            list_view_col_names["column_name"] = "Edit"
                                            list_view_col_names[
                                                "default"
                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Delete"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(
                                                action_button_config_model, "Delete"
                                            )
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><button name="actions" value="delete per" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Delete"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "Delete"
                                            list_view_col_names[
                                                "default"
                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Temporary delete"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(
                                                action_button_config_model, "Temporary delete"
                                            )
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><button name="actions" value="delete temp" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Delete record temporary"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "Delete record temporary"
                                            list_view_col_names[
                                                "default"
                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "View"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(
                                                action_button_config_model, "View"
                                            )
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><button name="actions" value="detail" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "View"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "View"
                                            list_view_col_names[
                                                "default"
                                            ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Approval Wall"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(action_button_config_model, "Approval Wall")
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approval Wall" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approval_wall"><i name="actions" value="approval_wall" class="fa fa-timeline ihover javaSC thin-icon" style="font-size: 15px;transform:rotate(90deg);"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Approval Wall"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approval Wall" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approval_wall"><i name="actions" value="approval_wall" class="fa fa-timeline ihover javaSC thin-icon" style="font-size: 15px;transform:rotate(90deg);"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "Approval Wall"
                                            list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approval Wall" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approval_wall"><i name="actions" value="approval_wall" class="fa fa-timeline ihover javaSC thin-icon" style="font-size: 15px;transform:rotate(90deg);"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Comments"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(action_button_config_model, "Comments")
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Comments" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="comments"><i name="actions" value="comments" class="fa fa-comment-dots ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Comments"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Comments" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="comments"><i name="actions" value="comments" class="fa fa-comment-dots ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "Comments"
                                            list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Comments" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="comments"><i name="actions" value="comments" class="fa fa-comment-dots ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Approve"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(action_button_config_model, "Approve")
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Approve"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "Approve"
                                            list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Reject record"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(action_button_config_model, "Reject Record")
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Reject record"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "Reject record"
                                            list_view_col_names[
                                                "default"
                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Reject record"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(action_button_config_model, "Reject Record")
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Reject record"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "Reject record"
                                            list_view_col_names[
                                                "default"
                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)                                        

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Delegate approval"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(action_button_config_model, "Delegate approval")
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Delegate approval"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "Delegate approval"
                                            list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)

                                        list_view_col_names = {}
                                        list_view_col_names["data_name"] = "Resend record"
                                        list_view_col_names["default"] = "<td>"
                                        if action_button_config_model is not None:
                                            function_check = button_styling(action_button_config_model, "Resend Record")
                                            if function_check is not None:
                                                list_view_col_names["column_name"] = function_check[
                                                    "columnTextHeader"
                                                ]
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Resend record"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names["column_name"] = "Resend record"
                                            list_view_col_names[
                                                "default"
                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                        list_view_col_names["default"] += "</td>"
                                        list_view_col_names["order"] = 1
                                        list_view_col_names["searchable"] = False
                                        EXPOSURE_TABLE.append(list_view_col_names)
                                        break
                                    else:
                                        if i["attr"] == "Edit Record" and i["value"] == "Yes":
                                            list_view_col_names = {}
                                            list_view_col_names["data_name"] = "Edit"
                                            list_view_col_names["default"] = "<td>"
                                            if action_button_config_model is not None:
                                                function_check = button_styling(
                                                    action_button_config_model, "Edit"
                                                )
                                                if function_check is not None:
                                                    list_view_col_names["column_name"] = function_check[
                                                        "columnTextHeader"
                                                    ]
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><button name="actions" value="update" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                                else:
                                                    list_view_col_names["column_name"] = "Edit"
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                            else:
                                                list_view_col_names["column_name"] = "Edit"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                            list_view_col_names["default"] += "</td>"
                                            list_view_col_names["order"] = 1
                                            list_view_col_names["searchable"] = False
                                            EXPOSURE_TABLE.append(list_view_col_names)
                                        if i["attr"] == "Delete Record" and i["value"] == "Yes":
                                            if i.get("delete_type"):
                                                if (
                                                    i["delete_type"]["per_delete"] == "Yes"
                                                    and i["delete_type"]["temp_delete"] == "No"
                                                ):
                                                    list_view_col_names = {}
                                                    list_view_col_names["data_name"] = "Delete"
                                                    list_view_col_names["default"] = "<td>"
                                                    if action_button_config_model is not None:
                                                        function_check = button_styling(
                                                            action_button_config_model, "Delete"
                                                        )
                                                        if function_check is not None:
                                                            list_view_col_names["column_name"] = (
                                                                function_check["columnTextHeader"]
                                                            )
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><button name="actions" value="delete per" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                                        else:
                                                            list_view_col_names["column_name"] = "Delete"
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    else:
                                                        list_view_col_names["column_name"] = "Delete"
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    list_view_col_names["default"] += "</td>"
                                                    list_view_col_names["order"] = 1
                                                    list_view_col_names["searchable"] = False
                                                    EXPOSURE_TABLE.append(list_view_col_names)
                                                elif (
                                                    i["delete_type"]["per_delete"] == "No"
                                                    and i["delete_type"]["temp_delete"] == "Yes"
                                                ):
                                                    list_view_col_names = {}
                                                    list_view_col_names["data_name"] = "Temporary delete"
                                                    list_view_col_names["default"] = "<td>"
                                                    if action_button_config_model is not None:
                                                        function_check = button_styling(
                                                            action_button_config_model, "Temporary delete"
                                                        )
                                                        if function_check is not None:
                                                            list_view_col_names["column_name"] = (
                                                                function_check["columnTextHeader"]
                                                            )
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><button name="actions" value="delete temp" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                                        else:
                                                            list_view_col_names["column_name"] = (
                                                                "Temporary delete"
                                                            )
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    else:
                                                        list_view_col_names["column_name"] = (
                                                            "Temporary delete"
                                                        )
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    list_view_col_names["default"] += "</td>"
                                                    list_view_col_names["order"] = 1
                                                    list_view_col_names["searchable"] = False
                                                    EXPOSURE_TABLE.append(list_view_col_names)
                                                elif (
                                                    i["delete_type"]["per_delete"] == "Yes"
                                                    and i["delete_type"]["temp_delete"] == "Yes"
                                                ):
                                                    list_view_col_names = {}
                                                    list_view_col_names["data_name"] = "Delete"
                                                    list_view_col_names["default"] = "<td>"
                                                    if action_button_config_model is not None:
                                                        function_check = button_styling(
                                                            action_button_config_model, "Delete"
                                                        )
                                                        if function_check is not None:
                                                            list_view_col_names["column_name"] = (
                                                                function_check["columnTextHeader"]
                                                            )
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><button name="actions" value="delete per" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                                        else:
                                                            list_view_col_names["column_name"] = "Delete"
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    else:
                                                        list_view_col_names["column_name"] = "Delete"
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    list_view_col_names["default"] += "</td>"
                                                    list_view_col_names["order"] = 1
                                                    list_view_col_names["searchable"] = False
                                                    EXPOSURE_TABLE.append(list_view_col_names)

                                                    list_view_col_names = {}
                                                    list_view_col_names["data_name"] = "Temporary delete"
                                                    list_view_col_names["default"] = "<td>"
                                                    if action_button_config_model is not None:
                                                        function_check = button_styling(
                                                            action_button_config_model, "Temporary delete"
                                                        )
                                                        if function_check is not None:
                                                            list_view_col_names["column_name"] = (
                                                                function_check["columnTextHeader"]
                                                            )
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><button name="actions" value="delete temp" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                                        else:
                                                            list_view_col_names["column_name"] = (
                                                                "Temporary delete"
                                                            )
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    else:
                                                        list_view_col_names["column_name"] = (
                                                            "Temporary delete"
                                                        )
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    list_view_col_names["default"] += "</td>"
                                                    list_view_col_names["order"] = 1
                                                    list_view_col_names["searchable"] = False
                                                    EXPOSURE_TABLE.append(list_view_col_names)
                                            else:
                                                list_view_col_names = {}
                                                list_view_col_names["data_name"] = "Delete"
                                                list_view_col_names["default"] = "<td>"
                                                if action_button_config_model is not None:
                                                    function_check = button_styling(
                                                        action_button_config_model, "Delete"
                                                    )
                                                    if function_check is not None:
                                                        list_view_col_names["column_name"] = function_check[
                                                            "columnTextHeader"
                                                        ]
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><button name="actions" value="delete per" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                                    else:
                                                        list_view_col_names["column_name"] = "Delete"
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                else:
                                                    list_view_col_names["column_name"] = "Delete"
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                list_view_col_names["default"] += "</td>"
                                                list_view_col_names["order"] = 1
                                                list_view_col_names["searchable"] = False
                                                EXPOSURE_TABLE.append(list_view_col_names)

                                        if i["attr"] == "View Record" and i["value"] == "Yes":
                                            list_view_col_names = {}
                                            list_view_col_names["data_name"] = "View"
                                            list_view_col_names["default"] = "<td>"
                                            if action_button_config_model is not None:
                                                function_check = button_styling(
                                                    action_button_config_model, "View"
                                                )
                                                if function_check is not None:
                                                    list_view_col_names["column_name"] = function_check[
                                                        "columnTextHeader"
                                                    ]
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><button name="actions" value="detail" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                                else:
                                                    list_view_col_names["column_name"] = "View"
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "View"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                                            list_view_col_names["default"] += "</td>"
                                            list_view_col_names["order"] = 1
                                            list_view_col_names["searchable"] = False
                                            EXPOSURE_TABLE.append(list_view_col_names)

                                        if i["attr"] == "Approval Wall" and i["value"] == "Yes":
                                            list_view_col_names = {}
                                            list_view_col_names["data_name"] = "Approval Wall"
                                            list_view_col_names["default"] = "<td>"
                                            if action_button_config_model is not None:
                                                function_check = button_styling(action_button_config_model, "Approval Wall")
                                                if function_check is not None:
                                                    list_view_col_names["column_name"] = function_check[
                                                        "columnTextHeader"
                                                    ]
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Approval Wall" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approval_wall"><i name="actions" value="approval_wall" class="fa fa-timeline ihover javaSC thin-icon" style="font-size: 15px;transform:rotate(90deg);"></i></a>&nbsp;'
                                                else:
                                                    list_view_col_names["column_name"] = "Approval Wall"
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Approval Wall" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approval_wall"><i name="actions" value="approval_wall" class="fa fa-timeline ihover javaSC thin-icon" style="font-size: 15px;transform:rotate(90deg);"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Approval Wall"
                                                list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Approval Wall" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approval_wall"><i name="actions" value="approval_wall" class="fa fa-timeline ihover javaSC thin-icon" style="font-size: 15px;transform:rotate(90deg);"></i></a>&nbsp;'
                                            list_view_col_names["default"] += "</td>"
                                            list_view_col_names["order"] = 1
                                            list_view_col_names["searchable"] = False
                                            EXPOSURE_TABLE.append(list_view_col_names)
                                        
                                        if i["attr"] == "Enable Comments" and i["value"] == "Yes":
                                            list_view_col_names = {}
                                            list_view_col_names["data_name"] = "Comments"
                                            list_view_col_names["default"] = "<td>"
                                            if action_button_config_model is not None:
                                                function_check = button_styling(action_button_config_model, "Comments")
                                                if function_check is not None:
                                                    list_view_col_names["column_name"] = function_check[
                                                        "columnTextHeader"
                                                    ]
                                                    list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Comments" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="comments"><i name="actions" value="comments" class="fa fa-comment-dots ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                                else:
                                                    list_view_col_names["column_name"] = "Comments"
                                                    list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Comments" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="comments"><i name="actions" value="comments" class="fa fa-comment-dots ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Comments"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Comments" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="comments"><i name="actions" value="comments" class="fa fa-comment-dots ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                            list_view_col_names["default"] += "</td>"
                                            list_view_col_names["order"] = 1
                                            list_view_col_names["searchable"] = False
                                            EXPOSURE_TABLE.append(list_view_col_names)

                                        if i["attr"] == "Approve" and i["value"] == "Yes":
                                            list_view_col_names = {}
                                            list_view_col_names["data_name"] = "Approve"
                                            list_view_col_names["default"] = "<td>"
                                            if action_button_config_model is not None:
                                                function_check = button_styling(action_button_config_model, "Approve")
                                                if function_check is not None:
                                                    list_view_col_names["column_name"] = function_check[
                                                        "columnTextHeader"
                                                    ]
                                                    list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                                else:
                                                    list_view_col_names["column_name"] = "Approve"
                                                    list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Approve"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                            list_view_col_names["default"] += "</td>"
                                            list_view_col_names["order"] = 1
                                            list_view_col_names["searchable"] = False
                                            EXPOSURE_TABLE.append(list_view_col_names)

                                        if i["attr"] == "Delegate Approval" and i["value"] == "Yes":
                                            list_view_col_names = {}
                                            list_view_col_names["data_name"] = "Delegate approval"
                                            list_view_col_names["default"] = "<td>"
                                            if action_button_config_model is not None:
                                                function_check = button_styling(action_button_config_model, "Delegate approval")
                                                if function_check is not None:
                                                    list_view_col_names["column_name"] = function_check[
                                                        "columnTextHeader"
                                                    ]
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                                else:
                                                    list_view_col_names["column_name"] = "Delegate approval"
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Delegate approval"
                                                list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            list_view_col_names["default"] += "</td>"
                                            list_view_col_names["order"] = 1
                                            list_view_col_names["searchable"] = False
                                            EXPOSURE_TABLE.append(list_view_col_names)

                                        if i["attr"] == "Reject" and i["value"] == "Yes":
                                            list_view_col_names = {}
                                            list_view_col_names["data_name"] = "Reject record"
                                            list_view_col_names["default"] = "<td>"
                                            if action_button_config_model is not None:
                                                function_check = button_styling(action_button_config_model, "Reject Record")
                                                if function_check is not None:
                                                    list_view_col_names["column_name"] = function_check[
                                                        "columnTextHeader"
                                                    ]
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                                else:
                                                    list_view_col_names["column_name"] = "Reject record"
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Reject record"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            list_view_col_names["default"] += "</td>"
                                            list_view_col_names["order"] = 1
                                            list_view_col_names["searchable"] = False
                                            EXPOSURE_TABLE.append(list_view_col_names)
                                        
                                        if i["attr"] == "Send to previous approver" and i["value"] == "Yes":
                                            list_view_col_names = {}
                                            list_view_col_names["data_name"] = "Resend record"
                                            list_view_col_names["default"] = "<td>"
                                            if action_button_config_model is not None:
                                                function_check = button_styling(action_button_config_model, "Resend Record")
                                                if function_check is not None:
                                                    list_view_col_names["column_name"] = function_check[
                                                        "columnTextHeader"
                                                    ]
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                                else:
                                                    list_view_col_names["column_name"] = "Resend record"
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            else:
                                                list_view_col_names["column_name"] = "Resend record"
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            list_view_col_names["default"] += "</td>"
                                            list_view_col_names["order"] = 1
                                            list_view_col_names["searchable"] = False
                                            EXPOSURE_TABLE.append(list_view_col_names)
                    if not config:
                        if not comp_element_id:
                            list_view_col_names = {}
                            list_view_col_names["data_name"] = "View"
                            list_view_col_names["default"] = "<td>"
                            if action_button_config_model is not None:
                                function_check = button_styling(action_button_config_model, "View")
                                if function_check is not None:
                                    list_view_col_names["column_name"] = function_check["columnTextHeader"]
                                    list_view_col_names[
                                        "default"
                                    ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><button name="actions" value="detail" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                else:
                                    list_view_col_names["column_name"] = "View"
                                    list_view_col_names[
                                        "default"
                                    ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                            else:
                                list_view_col_names["column_name"] = "View"
                                list_view_col_names[
                                    "default"
                                ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                            list_view_col_names["default"] += "</td>"
                            list_view_col_names["order"] = 1
                            list_view_col_names["searchable"] = False
                            EXPOSURE_TABLE.append(list_view_col_names)

                            list_view_col_names = {}
                            list_view_col_names["data_name"] = "Temporary delete"
                            list_view_col_names["default"] = "<td>"
                            if action_button_config_model is not None:
                                function_check = button_styling(
                                    action_button_config_model, "Temporary delete"
                                )
                                if function_check is not None:
                                    list_view_col_names["column_name"] = function_check["columnTextHeader"]
                                    list_view_col_names[
                                        "default"
                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><button name="actions" value="delete temp" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                else:
                                    list_view_col_names["column_name"] = "Temporary delete"
                                    list_view_col_names[
                                        "default"
                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                            else:
                                list_view_col_names["column_name"] = "Temporary delete"
                                list_view_col_names[
                                    "default"
                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                            list_view_col_names["default"] += "</td>"
                            list_view_col_names["order"] = 1
                            list_view_col_names["searchable"] = False
                            EXPOSURE_TABLE.append(list_view_col_names)

                            list_view_col_names = {}
                            list_view_col_names["data_name"] = "Delete"
                            list_view_col_names["default"] = "<td>"
                            if action_button_config_model is not None:
                                function_check = button_styling(action_button_config_model, "Delete")
                                if function_check is not None:
                                    list_view_col_names["column_name"] = function_check["columnTextHeader"]
                                    list_view_col_names[
                                        "default"
                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><button name="actions" value="delete per" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;'
                                else:
                                    list_view_col_names["column_name"] = "Delete"
                                    list_view_col_names[
                                        "default"
                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                            else:
                                list_view_col_names["column_name"] = "Delete"
                                list_view_col_names[
                                    "default"
                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                            list_view_col_names["default"] += "</td>"
                            list_view_col_names["order"] = 1
                            list_view_col_names["searchable"] = False
                            EXPOSURE_TABLE.append(list_view_col_names)

                            list_view_col_names = {}
                            list_view_col_names["data_name"] = "Edit"
                            list_view_col_names["default"] = "<td>"
                            if action_button_config_model is not None:
                                function_check = button_styling(action_button_config_model, "Edit")
                                if function_check is not None:
                                    list_view_col_names["column_name"] = function_check["columnTextHeader"]
                                    list_view_col_names[
                                        "default"
                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><button name="actions" value="update" style ={function_check["styling"]} onMouseOver={function_check["onMouseOver"]} onMouseOut={function_check["onMouseOut"]}>{function_check["iconAppend"]} {function_check["changeText"]}</button></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                else:
                                    list_view_col_names["column_name"] = "Edit"
                                    list_view_col_names[
                                        "default"
                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                            else:
                                list_view_col_names["column_name"] = "Edit"
                                list_view_col_names[
                                    "default"
                                ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                            list_view_col_names["default"] += "</td>"
                            list_view_col_names["order"] = 1
                            list_view_col_names["searchable"] = False
                            EXPOSURE_TABLE.append(list_view_col_names)

                else:
                    configureActionColumn = tab_info["Category_attributes"]["Mandatory"].get(
                        "configureActionColumn"
                    )
                    else_condition = False
                    if configureActionColumn is not None:
                        if configureActionColumn.get(model_name) is not None:
                            configureActionColumnModel = configureActionColumn.get(model_name)
                            list_view_col_names = {}
                            list_view_col_names["data_name"] = "Actions"
                            list_view_col_names["column_name"] = configureActionColumnModel["columnHeader"]
                            if configureActionColumnModel["elipsesTrigger"] is True:
                                list_view_col_names["default"] = ""
                                for j in range(len(tab_info["Category_sub_elements"])):
                                    if (
                                        tab_info["Category_sub_elements"][j]["Category_sub_element_name"]
                                        == "Action"
                                    ):
                                        config = True
                                        list_view_col_names["default"] = "<td>"
                                        list_view_col_names["default"] = (
                                            '<a data-toggle="dropdown" aria-expanded="false" data-list=""><i class="fa fa-ellipsis-v ihover javaSC thin-icon" style="font-size: 15px;" aria-hidden="true"></i></a><div class="dropdown-menu dropdown-menu-lg dropdown-menu-left" style="height: fit-content; min-width: 4em; border-radius: 1rem; overflow-y: auto; position: absolute; will-change: transform; margin: 0px !important; padding-top: 0px !important; top: 0px; left: 0px; transform: translate3d(22px, 30px, 0px);" x-placement="bottom-start"> <div class="apps-dropdownItems"><ul class="sortable-order col pt-2 text-center" style="list-style: none;">'
                                        )
                                        if multiple_attr:
                                            if approval_table:
                                                list_view_col_names[
                                                    "default"
                                                ] += f"""<script>$(document).ready(function() {{disable_checkboxes_conditions(elementTabID='{elementTabID}');}});</script>"""
                                            if multiple_table_len > 0:
                                                for number in range(1, multiple_table_len + 1):
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f"""<script>$(`#multiple_select_checkbox_SelectAll_div{elementTabID}__tab__{number}`).css('display', 'none');</script>"""

                                            list_view_col_names[
                                                "default"
                                            ] += f"""<input class="multiple_select_checkbox form-check-input" type="checkbox" value=""style="display:none; cursor: pointer; margin: 0rem 0.2rem 0.1rem 0.1rem; " onchange="checkforselection(elementTabID='{elementTabID}', obj = this)">
                                                <script>
                                                    $(`#multiple_select_checkbox_SelectAll_div{elementTabID}`).css('display', 'none');
                                                </script>
                                                <style>
                                                    .multiple_select_checkbox {{
                                                        position: relative;
                                                        cursor: pointer;
                                                        accent-color: var(--primary-color);
                                                        transform: scale(1.05);
                                                    }}
                                                    .multiple_select_checkbox::before {{
                                                        content: '';
                                                        position: absolute;
                                                        left: 1.2px;
                                                        top: 1.2px;
                                                        width: 11px;
                                                        height: 11px;
                                                        border: 0px solid #838383;
                                                        border-radius: 0.8px;
                                                        background-color: transparent;
                                                    }}
                                                    .multiple_select_checkbox:hover::before {{
                                                        background-color: #f8f9fa;
                                                    }}
                                                    .multiple_select_checkbox:checked::before {{
                                                        accent-color: var(--primary-color);
                                                    }}
                                                    .multiple_select_checkbox:checked:hover::before {{
                                                        background-color: transparent;
                                                    }}
                                                </style>"""
                                        for i in tab_info["Category_sub_elements"][j][
                                            "Category_sub_element_attributes"
                                        ]:
                                            if not comp_element_id:
                                                if i["attr"] == "SelectAll_Action" and i["value"] == "Yes":
                                                    list_view_col_names["default"] = (
                                                        f'<td><a data-toggle="dropdown" aria-expanded="false" data-list=""><i class="fa fa-ellipsis-v ihover javaSC thin-icon" style="font-size: 15px;" aria-hidden="true"></i></a><div class="dropdown-menu dropdown-menu-lg dropdown-menu-left" style="height: fit-content; min-width: 4em; border-radius: 1rem; overflow-y: auto; position: absolute; will-change: transform; margin: 0px !important; padding-top: 0px !important; top: 0px; left: 0px; transform: translate3d(22px, 30px, 0px);" x-placement="bottom-start"> <div class="apps-dropdownItems"><ul class="sortable-order col pt-2 text-center" style="list-style: none;"><a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approve"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;"></ul></div></div></td>'
                                                    )
                                                    break
                                                else:
                                                    if i["attr"] == "Edit Record" and i["value"] == "Yes":
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                                    if i["attr"] == "Delete Record" and i["value"] == "Yes":
                                                        if i.get("delete_type"):
                                                            if (
                                                                i["delete_type"]["per_delete"] == "Yes"
                                                                and i["delete_type"]["temp_delete"] == "No"
                                                            ):
                                                                list_view_col_names[
                                                                    "default"
                                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                            elif (
                                                                i["delete_type"]["per_delete"] == "No"
                                                                and i["delete_type"]["temp_delete"] == "Yes"
                                                            ):
                                                                list_view_col_names[
                                                                    "default"
                                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                            elif (
                                                                i["delete_type"]["per_delete"] == "Yes"
                                                                and i["delete_type"]["temp_delete"] == "Yes"
                                                            ):
                                                                list_view_col_names[
                                                                    "default"
                                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                        else:
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    if i["attr"] == "View Record" and i["value"] == "Yes":
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                                                    if i["attr"] == "Approve" and i["value"] == "Yes":
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approve"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                                    if (
                                                        i["attr"] == "Delegate Approval"
                                                        and i["value"] == "Yes"
                                                    ):
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                                    if i["attr"] == "Reject" and i["value"] == "Yes":
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                                    if (
                                                        i["attr"] == "Send to previous approver"
                                                        and i["value"] == "Yes"
                                                    ):
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                                    if (
                                                        i["attr"] == "PDF Action Button"
                                                        and i["value"] == "Yes"
                                                    ):
                                                        list_view_col_names["default"] += pdf_action_button(
                                                            tab_info["Category_attributes"]["Mandatory"].get(
                                                                "pdfActionColumn"
                                                            ),
                                                            elementTabID,
                                                            model_name,
                                                            app_table_cols,
                                                            app_table_sep,
                                                        )["styling"].replace("`", "")
                                        list_view_col_names["default"] += "</ul></div></div>"
                                        list_view_col_names["default"] += "</td>"
                                if not config:
                                    if not comp_element_id:
                                        list_view_col_names["default"] = (
                                            f'<td><a data-toggle="dropdown" aria-expanded="false" data-list=""><i class="fa fa-ellipsis-v ihover javaSC thin-icon" style="font-size: 15px;" aria-hidden="true"></i></a><div class="dropdown-menu dropdown-menu-lg dropdown-menu-left" style="height: fit-content; min-width: 4em; border-radius: 1rem; overflow-y: auto; position: absolute; will-change: transform; margin: 0px !important; padding-top: 0px !important; top: 0px; left: 0px; transform: translate3d(22px, 30px, 0px);" x-placement="bottom-start"> <div class="apps-dropdownItems"><ul class="sortable-order col pt-2 text-center" style="list-style: none;"><a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete"><i name="actions" value="delete" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approve"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;"></ul></div></div></td>'
                                        )
                                list_view_col_names["order"] = 1
                                list_view_col_names["searchable"] = False
                                EXPOSURE_TABLE.append(list_view_col_names)
                            else:
                                list_view_col_names["default"] = ""
                                for j in range(len(tab_info["Category_sub_elements"])):
                                    if (
                                        tab_info["Category_sub_elements"][j]["Category_sub_element_name"]
                                        == "Action"
                                    ):
                                        config = True
                                        list_view_col_names["default"] = "<td>"
                                        if multiple_attr:
                                            if approval_table:
                                                list_view_col_names[
                                                    "default"
                                                ] += f"""<script>$(document).ready(function() {{disable_checkboxes_conditions(elementTabID='{elementTabID}');}});</script>"""
                                            if multiple_table_len > 0:
                                                for number in range(1, multiple_table_len + 1):
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f"""<script>$(`#multiple_select_checkbox_SelectAll_div{elementTabID}__tab__{number}`).css('display', 'none');</script>"""

                                            list_view_col_names[
                                                "default"
                                            ] += f"""<input class="multiple_select_checkbox form-check-input" type="checkbox" value=""style="display:none; cursor: pointer; margin: 0rem 0.2rem 0.1rem 0.1rem; " onchange="checkforselection(elementTabID='{elementTabID}', obj = this)">
                                                <script>
                                                    $(`#multiple_select_checkbox_SelectAll_div{elementTabID}`).css('display', 'none');
                                                </script>
                                                <style>
                                                    .multiple_select_checkbox {{
                                                        position: relative;
                                                        cursor: pointer;
                                                        accent-color: var(--primary-color);
                                                        transform: scale(1.05);
                                                    }}
                                                    .multiple_select_checkbox::before {{
                                                        content: '';
                                                        position: absolute;
                                                        left: 1.2px;
                                                        top: 1.2px;
                                                        width: 11px;
                                                        height: 11px;
                                                        border: 0px solid #838383;
                                                        border-radius: 0.8px;
                                                        background-color: transparent;
                                                    }}
                                                    .multiple_select_checkbox:hover::before {{
                                                        background-color: #f8f9fa;
                                                    }}
                                                    .multiple_select_checkbox:checked::before {{
                                                        accent-color: var(--primary-color);
                                                    }}
                                                    .multiple_select_checkbox:checked:hover::before {{
                                                        background-color: transparent;
                                                    }}
                                                </style>"""
                                        for i in tab_info["Category_sub_elements"][j][
                                            "Category_sub_element_attributes"
                                        ]:
                                            if not comp_element_id:
                                                if i["attr"] == "SelectAll_Action" and i["value"] == "Yes":
                                                    list_view_col_names["default"] = (
                                                        f'<td><a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approve"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;"></td>'
                                                    )
                                                    break
                                                else:
                                                    if i["attr"] == "Edit Record" and i["value"] == "Yes":
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                                    if i["attr"] == "Delete Record" and i["value"] == "Yes":
                                                        if i.get("delete_type"):
                                                            if (
                                                                i["delete_type"]["per_delete"] == "Yes"
                                                                and i["delete_type"]["temp_delete"] == "No"
                                                            ):
                                                                list_view_col_names[
                                                                    "default"
                                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                            elif (
                                                                i["delete_type"]["per_delete"] == "No"
                                                                and i["delete_type"]["temp_delete"] == "Yes"
                                                            ):
                                                                list_view_col_names[
                                                                    "default"
                                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                            elif (
                                                                i["delete_type"]["per_delete"] == "Yes"
                                                                and i["delete_type"]["temp_delete"] == "Yes"
                                                            ):
                                                                list_view_col_names[
                                                                    "default"
                                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                        else:
                                                            list_view_col_names[
                                                                "default"
                                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    if i["attr"] == "View Record" and i["value"] == "Yes":
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                                                    if i["attr"] == "Approve" and i["value"] == "Yes":
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                                    if (
                                                        i["attr"] == "Delegate Approval"
                                                        and i["value"] == "Yes"
                                                    ):
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                                    if i["attr"] == "Reject" and i["value"] == "Yes":
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                                    if (
                                                        i["attr"] == "Send to previous approver"
                                                        and i["value"] == "Yes"
                                                    ):
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                                    if (
                                                        i["attr"] == "PDF Action Button"
                                                        and i["value"] == "Yes"
                                                    ):
                                                        list_view_col_names["default"] += pdf_action_button(
                                                            tab_info["Category_attributes"]["Mandatory"].get(
                                                                "pdfActionColumn"
                                                            ),
                                                            elementTabID,
                                                            model_name,
                                                            app_table_cols,
                                                            app_table_sep,
                                                        )["styling"].replace("`", "")
                                        list_view_col_names["default"] += "</td>"
                                if not config:
                                    if not comp_element_id:
                                        list_view_col_names["default"] = (
                                            f'<td><a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete"><i name="actions" value="delete" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approve"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;"></td>'
                                        )
                                list_view_col_names["order"] = 1
                                list_view_col_names["searchable"] = False
                                EXPOSURE_TABLE.append(list_view_col_names)
                        else:
                            else_condition = True
                    else:
                        else_condition = True
                    if else_condition:
                        list_view_col_names = {}
                        list_view_col_names["data_name"] = "Actions"
                        list_view_col_names["column_name"] = "Actions"
                        list_view_col_names["default"] = ""
                        for j in range(len(tab_info["Category_sub_elements"])):
                            if tab_info["Category_sub_elements"][j]["Category_sub_element_name"] == "Action":
                                config = True
                                list_view_col_names["default"] = "<td>"
                                if multiple_attr:
                                    if approval_table:
                                        list_view_col_names[
                                            "default"
                                        ] += f"""<script>$(document).ready(function() {{disable_checkboxes_conditions(elementTabID='{elementTabID}');}});</script>"""
                                    if multiple_table_len > 0:
                                        for number in range(1, multiple_table_len + 1):
                                            list_view_col_names[
                                                "default"
                                            ] += f"""<script>$(`#multiple_select_checkbox_SelectAll_div{elementTabID}__tab__{number}`).css('display', 'none');</script>"""

                                    list_view_col_names[
                                        "default"
                                    ] += f"""<input class="multiple_select_checkbox form-check-input" type="checkbox" value=""style="display:none; cursor: pointer; margin: 0rem 0.2rem 0.1rem 0.1rem; " onchange="checkforselection(elementTabID='{elementTabID}', obj = this)">
                                        <script>
                                            $(`#multiple_select_checkbox_SelectAll_div{elementTabID}`).css('display', 'none');
                                        </script>
                                        <style>
                                            .multiple_select_checkbox {{
                                                position: relative;
                                                cursor: pointer;
                                                accent-color: var(--primary-color);
                                                transform: scale(1.05);
                                            }}
                                            .multiple_select_checkbox::before {{
                                                content: '';
                                                position: absolute;
                                                left: 1.2px;
                                                top: 1.2px;
                                                width: 11px;
                                                height: 11px;
                                                border: 0px solid #838383;
                                                border-radius: 0.8px;
                                                background-color: transparent;
                                            }}
                                            .multiple_select_checkbox:hover::before {{
                                                background-color: #f8f9fa;
                                            }}
                                            .multiple_select_checkbox:checked::before {{
                                                accent-color: var(--primary-color);
                                            }}
                                            .multiple_select_checkbox:checked:hover::before {{
                                                background-color: transparent;
                                            }}
                                        </style>"""
                                for i in tab_info["Category_sub_elements"][j][
                                    "Category_sub_element_attributes"
                                ]:
                                    if not comp_element_id:
                                        if i["attr"] == "SelectAll_Action" and i["value"] == "Yes":
                                            list_view_col_names["default"] = (
                                                f'<td><a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approve"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a></td>'
                                            )
                                            break
                                        else:
                                            if i["attr"] == "Edit Record" and i["value"] == "Yes":
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                            if i["attr"] == "Delete Record" and i["value"] == "Yes":
                                                if i.get("delete_type"):
                                                    if (
                                                        i["delete_type"]["per_delete"] == "Yes"
                                                        and i["delete_type"]["temp_delete"] == "No"
                                                    ):
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    elif (
                                                        i["delete_type"]["per_delete"] == "No"
                                                        and i["delete_type"]["temp_delete"] == "Yes"
                                                    ):
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                    elif (
                                                        i["delete_type"]["per_delete"] == "Yes"
                                                        and i["delete_type"]["temp_delete"] == "Yes"
                                                    ):
                                                        list_view_col_names[
                                                            "default"
                                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                                else:
                                                    list_view_col_names[
                                                        "default"
                                                    ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                            if i["attr"] == "View Record" and i["value"] == "Yes":
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                                            if i["attr"] == "Approve" and i["value"] == "Yes":
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                            if i["attr"] == "Delegate Approval" and i["value"] == "Yes":
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            if i["attr"] == "Reject" and i["value"] == "Yes":
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'

                                            if i["attr"] == "Approval Wall" and i["value"] == "Yes":
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Approval Wall" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approval_wall"><i name="actions" value="approval_wall" class="fa fa-timeline ihover javaSC thin-icon" style="font-size: 15px;transform:rotate(90deg);"></i></a>&nbsp;'

                                            if i["attr"] == "Enable Comments" and i["value"] == "Yes":
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Comments" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="comments"><i name="actions" value="comments" class="fa fa-comment-dots ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'

                                            if (
                                                i["attr"] == "Send to previous approver"
                                                and i["value"] == "Yes"
                                            ):
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                            if i["attr"] == "PDF Action Button" and i["value"] == "Yes":
                                                list_view_col_names["default"] += pdf_action_button(
                                                    tab_info["Category_attributes"]["Mandatory"].get(
                                                        "pdfActionColumn"
                                                    ),
                                                    elementTabID,
                                                    model_name,
                                                    app_table_cols,
                                                    app_table_sep,
                                                )["styling"].replace("`", "")
                                list_view_col_names["default"] += "</td>"
                        if not config:
                            if not comp_element_id:
                                list_view_col_names["default"] = (
                                    f'<td><a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete"><i name="actions" value="delete" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;"></td>'
                                )
                        list_view_col_names["order"] = 1
                        list_view_col_names["searchable"] = False
                        EXPOSURE_TABLE.append(list_view_col_names)
            else:
                list_view_col_names = {}
                list_view_col_names["data_name"] = "Actions"
                list_view_col_names["column_name"] = "Actions"
                list_view_col_names["default"] = ""
                for j in range(len(tab_info["Category_sub_elements"])):
                    if tab_info["Category_sub_elements"][j]["Category_sub_element_name"] == "Action":
                        config = True
                        list_view_col_names["default"] = "<td>"
                        if multiple_attr:
                            if approval_table:
                                list_view_col_names[
                                    "default"
                                ] += f"""<script>$(document).ready(function() {{disable_checkboxes_conditions(elementTabID='{elementTabID}');}});</script>"""
                            if multiple_table_len > 0:
                                for number in range(1, multiple_table_len + 1):
                                    list_view_col_names[
                                        "default"
                                    ] += f"""<script>$(`#multiple_select_checkbox_SelectAll_div{elementTabID}__tab__{number}`).css('display', 'none');</script>"""

                            list_view_col_names[
                                "default"
                            ] += f"""<input class="multiple_select_checkbox form-check-input" type="checkbox" value=""style="display:none; cursor: pointer; margin: 0rem 0.2rem 0.1rem 0.1rem; " onchange="checkforselection(elementTabID='{elementTabID}', obj = this)">
                                <script>
                                    $(`#multiple_select_checkbox_SelectAll_div{elementTabID}`).css('display', 'none');
                                </script>
                                <style>
                                    .multiple_select_checkbox {{
                                        position: relative;
                                        cursor: pointer;
                                        accent-color: var(--primary-color);
                                        transform: scale(1.05);
                                    }}
                                    .multiple_select_checkbox::before {{
                                        content: '';
                                        position: absolute;
                                        left: 1.2px;
                                        top: 1.2px;
                                        width: 11px;
                                        height: 11px;
                                        border: 0px solid #838383;
                                        border-radius: 0.8px;
                                        background-color: transparent;
                                    }}
                                    .multiple_select_checkbox:hover::before {{
                                        background-color: #f8f9fa;
                                    }}
                                    .multiple_select_checkbox:checked::before {{
                                        accent-color: var(--primary-color);
                                    }}
                                    .multiple_select_checkbox:checked:hover::before {{
                                        background-color: transparent;
                                    }}
                                </style>"""
                        for i in tab_info["Category_sub_elements"][j]["Category_sub_element_attributes"]:
                            if not comp_element_id:
                                if i["attr"] == "SelectAll_Action" and i["value"] == "Yes":
                                    list_view_col_names["default"] = (
                                        f'<td><a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approve"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;"></td>'
                                    )
                                    break
                                else:
                                    if i["attr"] == "Edit Record" and i["value"] == "Yes":
                                        list_view_col_names[
                                            "default"
                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;">'
                                    if i["attr"] == "Delete Record" and i["value"] == "Yes":
                                        if i.get("delete_type"):
                                            if (
                                                i["delete_type"]["per_delete"] == "Yes"
                                                and i["delete_type"]["temp_delete"] == "No"
                                            ):
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                            elif (
                                                i["delete_type"]["per_delete"] == "No"
                                                and i["delete_type"]["temp_delete"] == "Yes"
                                            ):
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                            elif (
                                                i["delete_type"]["per_delete"] == "Yes"
                                                and i["delete_type"]["temp_delete"] == "Yes"
                                            ):
                                                list_view_col_names[
                                                    "default"
                                                ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;&nbsp;<a data-toggle="tooltip" title="Delete record temporary" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete temp"><i name="actions" value="delete temp" class="far fa-times-circle ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                        else:
                                            list_view_col_names[
                                                "default"
                                            ] += f'&nbsp;<a data-toggle="tooltip" title="Delete record permanently" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete per"><i name="actions" value="delete per" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;'
                                    if i["attr"] == "View Record" and i["value"] == "Yes":
                                        list_view_col_names[
                                            "default"
                                        ] += f'&nbsp;<a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;'
                                    if i["attr"] == "Approve" and i["value"] == "Yes":
                                        list_view_col_names[
                                            "default"
                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                    if i["attr"] == "Delegate Approval" and i["value"] == "Yes":
                                        list_view_col_names[
                                            "default"
                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Delegate Approval" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delegate_approval"><i name="actions" value="delegate_approval" class="fa fa-sitemap ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                    if i["attr"] == "Reject" and i["value"] == "Yes":
                                        list_view_col_names[
                                            "default"
                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size: 15px;"></i></a>&nbsp;'
                                    if i["attr"] == "Send to previous approver" and i["value"] == "Yes":
                                        list_view_col_names[
                                            "default"
                                        ] += f'&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;'
                                    if i["attr"] == "PDF Action Button" and i["value"] == "Yes":
                                        list_view_col_names["default"] += pdf_action_button(
                                            tab_info["Category_attributes"]["Mandatory"].get(
                                                "pdfActionColumn"
                                            ),
                                            elementTabID,
                                            model_name,
                                            app_table_cols,
                                            app_table_sep,
                                        )["styling"].replace("`", "")
                        list_view_col_names["default"] += "</td>"
                if not config:
                    if not comp_element_id:
                        list_view_col_names["default"] = (
                            f'<td><a data-toggle="tooltip" title="View record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="detail"><i name="actions" value="detail" class="fa fa-search ihover javaSC thin-icon" style="font-size: 15px;{ve_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Edit record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="update"><i name="actions" value="update" class="fa fa-edit ihover javaSC thin-icon" style="font-size:15px;{ed_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Delete record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="delete"><i name="actions" value="delete" class="far fa-trash-alt ihover javaSC thin-icontrash" style="font-size: 15px;{de_disabled}"></i></a>&nbsp;<a data-toggle="tooltip" title="Approve record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="approve"><i name="actions" value="approve" class="far fa-check-circle ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Reject record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="reject"><i name="actions" value="reject" class="fas fa-times ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<a data-toggle="tooltip" title="Resend record" data-elementID="{elementTabID}" data-table_model_name="{model_name}" value="resend"><i name="actions" value="resend" class="fas fa-undo ihover javaSC thin-icon" style="font-size:15px;"></i></a>&nbsp;<input class="multi_column_edit_checkbox form-check-input" type="checkbox" value=""style="display:none;"></td>'
                        )
                list_view_col_names["order"] = 1
                list_view_col_names["searchable"] = False
                EXPOSURE_TABLE.append(list_view_col_names)
    fn_to_verbose = {}
    for field in actual_model_name.concrete_fields:
        list_view_col_names = {}
        list_view_col_names["data_name"] = field.name
        list_view_col_names["column_name"] = field.verbose_name
        list_view_col_names["default"] = ""
        list_view_col_names["order"] = 1
        list_view_col_names["searchable"] = True
        EXPOSURE_TABLE.append(list_view_col_names)
        fn_to_verbose[field.name] = field.verbose_name
    if tab_content.get("tab_body_content").empty is False:
        tab_info = json.loads(tab_content["tab_body_content"].iloc[0])
        if tab_info.get("Category_attributes"):
            if (
                tab_info["Category_attributes"]["Mandatory"].get("listViewEmbededComputationMultiple")
                is not None
            ):
                listViewEmbededComputationMultiple = tab_info["Category_attributes"]["Mandatory"].get(
                    "listViewEmbededComputationMultiple"
                )
                list_a = []
                for i in listViewEmbededComputationMultiple:
                    data = i.get(model_name)
                    if data is not None:
                        list_a.append(data)
                if list_a != []:
                    list_view_col_names = {}
                    list_view_col_names["data_name"] = "Execute Computation"
                    list_view_col_names["column_name"] = "Execute Computation"
                    list_view_col_names["default"] = "<td>"
                    list_view_col_names[
                        "default"
                    ] += "<select class='select2 form-control listviewembededcomputation'><option value='' disabled selected>Models</option>"
                    for i in list_a:
                        for j in i:
                            list_view_col_names["default"] += f"<option value='{j}'>{j}</option>"
                    list_view_col_names["default"] += "</select>"
                    for itmss in list_a:
                        for k, v in itmss.items():
                            new_val = []
                            for model_name, model_config in v.items():
                                for i in model_config:
                                    n_Va = []
                                    if isinstance(i, list):
                                        for j in i:
                                            n_Va.append(fn_to_verbose[j])
                                        new_val.append(n_Va)
                                    else:
                                        new_val.append(i)
                        itmss[k][model_name] = new_val
                    list_view_col_names[
                        "default"
                    ] += f"<button class='listviewcomputationbutton' style='color:var(--primary-color);background-color:var(--font-hover-color);border:none;' data-list='{json.dumps(list_a)}' onclick='listViewRunComputationMultiple(this)'><i class='fa fa-play'></i></button>"
                    list_view_col_names["default"] += "</td>"
                    list_view_col_names["order"] = 1
                    list_view_col_names["searchable"] = False
                    EXPOSURE_TABLE.append(list_view_col_names)
            if tab_info["Category_attributes"]["Mandatory"].get("listViewEmbededComputation") is not None:
                list_view_col_names = {}
                list_view_col_names["data_name"] = "Execute Computation"
                list_view_col_names["column_name"] = "Execute Computation"
                list_view_col_names["default"] = "<td>"
                listViewEmbededComputation = tab_info["Category_attributes"]["Mandatory"].get(
                    "listViewEmbededComputation"
                )
                list_view_col_names[
                    "default"
                ] += "<select class='select2 form-control listviewembededcomputation'><option value='' disabled selected>Models</option>"
                for i in listViewEmbededComputation:
                    list_view_col_names["default"] += f"<option value='{i}'>{i}</option>"
                for k, v in listViewEmbededComputation.items():
                    new_val = []
                    for model_name, model_config in v.items():
                        for i in model_config:
                            n_Va = []
                            if isinstance(i, list):
                                for j in i:
                                    n_Va.append(fn_to_verbose[j])
                                new_val.append(n_Va)
                            else:
                                new_val.append(i)
                    listViewEmbededComputation[k][model_name] = new_val
                list_view_col_names["default"] += "</select>"
                list_view_col_names[
                    "default"
                ] += f"<button class='listviewcomputationbutton' style='color:var(--primary-color);background-color:var(--font-hover-color);border:none;' data-list='{json.dumps(listViewEmbededComputation)}' onclick='listViewRunComputation(this)'><i class='fa fa-play'></i></button>"
                list_view_col_names["default"] += "</td>"
                list_view_col_names["order"] = 1
                list_view_col_names["searchable"] = False
                EXPOSURE_TABLE.append(list_view_col_names)
    return EXPOSURE_TABLE


def send_email(from_email, to_list, subject, content):
    credentials = (
        "b99d0515-5aef-411a-af5f-fdab0a2d6206",
        "_cU62ve6R6a0~351WvI_g0wkQW9O01x3.W",
    )
    account = Account(
        credentials,
        auth_flow_type="credentials",
        tenant_id="4bf6db98-c05a-4a1e-ac6a-340dcfa47097",
    )
    if account.authenticate():
        m = account.mailbox(resource=f"{from_email}")
        m = account.new_message(resource=f"{from_email}")
        m.to.add(to_list)
        m.subject = f"{subject}"
        m.body = f"{content}"
        m.send()
    return None


def read_csv_func(data):
    try:
        results = pa.csv.read_csv(data)
        results = results.to_pandas()
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        results = pd.read_csv(data)
    return results


def condition_validator(condition_list, data):
    list_condition_satisfied = True
    string_dict = {
        "Starts with": "data['{column_name}'].startswith('{value}')",
        "Ends with": "data['{column_name}'].endswith('{value}')",
        "Contains": "data['{column_name}'].str.contains('{value}')",
        "Not Starts with": "~data['{column_name}'].startswith('{value}')",
        "Not Ends with": "~data['{column_name}'].endswith('{value}')",
        "Not Contains": "~data['{column_name}'].str.contains('{value}')",
        "Equal to": "data['{column_name}'].str.fullmatch('{value}')",
        "Not Equal to": "~data['{column_name}'].str.fullmatch('{value}')",
        "Greater than": "data['{column_name}'] > '{value}'",
        "Smaller than": "data['{column_name}'] < '{value}'",
    }
    int_dict = {
        "Equal to": "data['{column_name}'] == {value}",
        "Not Equal to": "data['{column_name}'] != {value}",
        "Greater than": "data['{column_name}'] > {value}",
        "Smaller than": "data['{column_name}'] < {value}",
    }
    date_dict = {
        "Equal to AND": "data['{column_name}'] == '{value}'",
        "Not Equal to AND": "data['{column_name}'] != '{value}'",
        "Greater than AND": "data['{column_name}'] > '{value}'",
        "Smaller than AND": "data['{column_name}'] < '{value}'",
        "Equal to OR": "data['{column_name}'] == '{value}'",
        "Not Equal to OR": "data['{column_name}'] != '{value}'",
        "Greater than OR": "data['{column_name}'] > '{value}'",
        "Smaller than OR": "data['{column_name}'] < '{value}'",
    }
    date_special_case = []
    data = pd.DataFrame(data).T
    for index, ind_cond_dict in enumerate(condition_list):
        column_name = ind_cond_dict["column_name"]
        condition_name = ind_cond_dict["condition"]
        value = ind_cond_dict["input_value"]
        if type(value) == str:
            if value not in ["True", "False"]:
                try:
                    date_v = datetime.strptime(value, "%Y-%m-%d").date()

                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    ind_condition_satisfied = pd.eval(
                        string_dict[condition_name].format(column_name=column_name, value=value)
                    )
                    if not ind_condition_satisfied.iloc[0]:
                        list_condition_satisfied = False
                        break
                else:
                    if condition_name in date_dict.keys():
                        value = datetime.strftime(date_v, "%Y-%m-%d")
                        date_condition_part = pd.eval(
                            date_dict[condition_name].format(column_name=column_name, value=value)
                        )
                        date_special_case.append((column_name, date_condition_part, condition_name))
                    elif date_special_case and (column_name in (i[0] for i in date_special_case)):
                        date_condition_part = pd.eval(
                            string_dict[condition_name].format(column_name=column_name, value=value)
                        )
                        date_special_case.append((column_name, date_condition_part, condition_name))
                    else:
                        ind_condition_satisfied = pd.eval(
                            string_dict[condition_name].format(column_name=column_name, value=value)
                        )
                        if not ind_condition_satisfied.iloc[0]:
                            list_condition_satisfied = False
                            break
            else:
                value = int(literal_eval(value))
                ind_condition_satisfied = pd.eval(
                    int_dict[condition_name].format(column_name=column_name, value=value)
                )
                if not ind_condition_satisfied.iloc[0]:
                    list_condition_satisfied = False
                    break
        elif (type(value) == int) or (type(value) == float):
            ind_condition_satisfied = pd.eval(
                int_dict[condition_name].format(column_name=column_name, value=value)
            )
            if not ind_condition_satisfied.iloc[0]:
                list_condition_satisfied = False
                break
        else:
            continue

    if date_special_case:
        columns_cond = {(i[0], i[2]) for i in date_special_case}
        for col_name, cond in columns_cond:
            if cond.endswith("OR"):
                date_sp_condition = any([j[1] for j in date_special_case if j[0] == col_name])
                if not date_sp_condition:
                    list_condition_satisfied = False
                    break
            elif cond.endswith("AND"):
                date_sp_condition = all([j[1] for j in date_special_case if j[0] == col_name])
                if not date_sp_condition:
                    list_condition_satisfied = False
                    break
            else:
                continue
        date_special_case.clear()
    return list_condition_satisfied


def condition_validator_filter(condition_list, data, request, actual_model_name="", multi_select_filter={}):
    data_df = data
    model_type_dict = {field.name: field.get_internal_type() for field in actual_model_name.concrete_fields}
    string_dict = {
        "Starts with": "data_df['{column_name}'].str.startswith('{value}',na=False)",
        "Ends with": "data_df['{column_name}'].str.endswith('{value}',na=False)",
        "Contains": "data_df['{column_name}'].str.contains('{value}',na=False)",
        "Not Starts with": "~data_df['{column_name}'].str.startswith('{value}',na=False)",
        "Not Ends with": "data_df['{column_name}'].str.endswith('{value}',na=False)",
        "Not Contains": "~data_df['{column_name}'].str.contains('{value}',na=False)",
        "Equal to": "data_df['{column_name}'] == '{value}'",
        "Not Equal to": "data_df['{column_name}'] != '{value}'",
        "IN": "data_df['{column_name}'].fillna('NULL').astype('str').isin({value})",
        "NOT IN": "~data_df['{column_name}'].fillna('NULL').astype('str').isin({value})",
    }
    multi_select_string_dict = {
        "Equal to": "data_df['{column_name}'].fillna('NULL').str.contains('|'.join(['{value}']))",
        "IN": "data_df['{column_name}'].fillna('NULL').str.contains('|'.join(['{value}']))",
        "NOT IN": "~data_df['{column_name}'].fillna('NULL').str.contains('|'.join(['{value}']))",
    }
    int_dict = {
        "Equal to": "data_df['{column_name}'] == {value}",
        "Not Equal to": "data_df['{column_name}'] != {value}",
        "Greater than": "data_df['{column_name}'] > {value}",
        "Smaller than": "data_df['{column_name}'] < {value}",
        "IN": "data_df['{column_name}'].isin({value})",
        "NOT IN": "~data_df['{column_name}'].isin({value})",
    }
    float_dict = {
        "Equal to": "data_df['{column_name}'] == {value}",
        "Not Equal to": "data_df['{column_name}'] != {value}",
        "Greater than": "data_df['{column_name}'] > {value}",
        "Smaller than": "data_df['{column_name}'] < {value}",
        "IN": "data_df['{column_name}'].isin({value})",
        "NOT IN": "~data_df['{column_name}'].isin({value})",
    }
    bool_dict = {
        "Equal to": "data_df['{column_name}'] == {value}",
        "Not Equal to": "data_df['{column_name}'] != {value}",
    }
    datetime_dict = {
        "Equal to": "data_df['{column_name}'] == {value}",
        "Not Equal to": "data_df['{column_name}'] != {value}",
        "Greater than": "data_df['{column_name}'] > {value}",
        "Smaller than": "data_df['{column_name}'] < {value}",
        "IN": "data_df['{column_name}'].astype('str').isin({value})",
        "NOT IN": "~data_df['{column_name}'].astype('str').isin({value})",
    }
    date_dict = {
        "Equal to": "pd.to_datetime(data_df['{column_name}'], format='%Y-%m-%d') == {value}",
        "Not Equal to": "pd.to_datetime(data_df['{column_name}'], format='%Y-%m-%d') != {value}",
        "Greater than": "pd.to_datetime(data_df['{column_name}'], format='%Y-%m-%d') > {value}",
        "Smaller than": "pd.to_datetime(data_df['{column_name}'], format='%Y-%m-%d') < {value}",
        "IN": "data_df['{column_name}'].astype('str').isin({value})",
        "NOT IN": "~data_df['{column_name}'].astype('str').isin({value})",
    }
    time_dict = {
        "Equal to": "pd.to_datetime(data_df['{column_name}'], format='%H:%M:%S') == {value}",
        "Not Equal to": "pd.to_datetime(data_df['{column_name}'], format='%H:%M:%S') != {value}",
        "Greater than": "pd.to_datetime(data_df['{column_name}'], format='%H:%M:%S') > {value}",
        "Smaller than": "pd.to_datetime(data_df['{column_name}'], format='%H:%M:%S') < {value}",
        "IN": "data_df['{column_name}'].astype('str').isin({value})",
        "NOT IN": "~data_df['{column_name}'].astype('str').isin({value})",
    }

    if data_df.shape[0] > 0:
        for index, ind_cond_dict in enumerate(condition_list):
            column_name = ind_cond_dict["column_name"]
            if column_name in data.columns:
                col_type = data_df.dtypes[column_name]
                condition_name = ind_cond_dict["condition"]
                value = ind_cond_dict["input_value"]
                if ind_cond_dict.get("current_value"):
                    curr_val = ind_cond_dict["current_value"]
                else:
                    curr_val = ""

                if curr_val != "":
                    if curr_val == "curr_date":
                        curr_val = date.today().strftime("%Y-%m-%dT%H:%M")
                    elif curr_val == "curr_user":
                        curr_val = request.user.username
                    value = curr_val

                if value in [None, "None"]:
                    if model_type_dict[column_name] == "DateTimeField":
                        value = str(pd.NaT)
                    elif model_type_dict[column_name] == "DateField":
                        value = "None"
                    else:
                        value = str(np.nan)
                else:
                    if col_type in ["int64"]:
                        value = int(ind_cond_dict["input_value"])
                    elif col_type in ["float64"] and model_type_dict[column_name] != "ForeignKey":
                        value = float(ind_cond_dict["input_value"])
                    else:
                        if curr_val:
                            value = curr_val
                        else:
                            value = ind_cond_dict["input_value"]

                if str(value) in ["NaT", "nan", "None"]:
                    if condition_name == "Equal to":
                        ind_condition_satisfied_pd = pd.eval(
                            f"data_df['{column_name}'].isna()",
                            target=data_df,
                        )
                        if ind_condition_satisfied_pd.any():
                            data_df = data_df.loc[ind_condition_satisfied_pd]
                        else:
                            data_df = pd.DataFrame(columns=data.columns)
                    elif condition_name == "Not Equal to":
                        ind_condition_satisfied_pd = pd.eval(
                            f"data_df['{column_name}'].notnull()",
                            target=data_df,
                        )
                        if ind_condition_satisfied_pd.any():
                            data_df = data_df.loc[ind_condition_satisfied_pd]
                        else:
                            data_df = pd.DataFrame(columns=data.columns)
                elif model_type_dict[column_name] not in ["IntegerField", "BigIntegerField", "FloatField"]:
                    if model_type_dict[column_name] != "BooleanField":
                        if model_type_dict[column_name] in ["DateTimeField", "DateField", "TimeField"]:

                            if model_type_dict[column_name] == "DateTimeField":
                                condition_string = ""
                                if condition_name in ["IN", "NOT IN"]:
                                    value = list(value)

                                    condition_string = datetime_dict[condition_name].format(
                                        column_name=column_name, value=value
                                    )
                                else:
                                    condition_string = datetime_dict[condition_name].format(
                                        column_name=column_name,
                                        value=f'pd.to_datetime(datetime.strptime("{value}", "%Y-%m-%dT%H:%M"))',
                                    )

                                ind_condition_satisfied_pd = pd.eval(
                                    condition_string,
                                    target=data_df,
                                )
                                if ind_condition_satisfied_pd.any():
                                    data_df = data_df.loc[ind_condition_satisfied_pd]
                                else:
                                    data_df = pd.DataFrame(columns=data.columns)
                            elif model_type_dict[column_name] == "DateField":
                                condition_string = ""

                                if condition_name in ["IN", "NOT IN"]:
                                    value = list(value)

                                    condition_string = date_dict[condition_name].format(
                                        column_name=column_name, value=value
                                    )
                                else:
                                    condition_string = date_dict[condition_name].format(
                                        column_name=column_name,
                                        value=f'pd.to_datetime(datetime.strptime("{value}", "%Y-%m-%d"))',
                                    )

                                ind_condition_satisfied_pd = pd.eval(
                                    condition_string,
                                    target=data_df,
                                )

                                if ind_condition_satisfied_pd.any():
                                    data_df = data_df.loc[ind_condition_satisfied_pd]
                                else:
                                    data_df = pd.DataFrame(columns=data.columns)
                            elif model_type_dict[column_name] == "TimeField":
                                condition_string = ""
                                if condition_name in ["IN", "NOT IN"]:
                                    value = list(value)
                                    condition_string = time_dict[condition_name].format(
                                        column_name=column_name, value=value
                                    )
                                else:
                                    condition_string = time_dict[condition_name].format(
                                        column_name=column_name,
                                        value=f'datetime.strptime("{value}", "%H:%M:%S")',
                                    )

                                ind_condition_satisfied_pd = pd.eval(
                                    condition_string,
                                    target=data_df,
                                )

                                if ind_condition_satisfied_pd.any():
                                    data_df = data_df.loc[ind_condition_satisfied_pd]
                                else:
                                    data_df = pd.DataFrame(columns=data.columns)

                        else:
                            if condition_name in ["IN", "NOT IN"]:
                                if not multi_select_filter:
                                    value = list(value)
                                if model_type_dict[column_name] == "ForeignKey":
                                    new_value = []
                                    for num in value:
                                        if num != "NULL":
                                            new_value.append(f"{float(num)}")
                                        else:
                                            new_value.append(num)
                                    value = new_value

                                condition_string = string_dict[condition_name].format(
                                    column_name=column_name, value=value
                                )

                            else:
                                condition_string = string_dict[condition_name].format(
                                    column_name=column_name, value=str(value)
                                )

                            if multi_select_filter and column_name in multi_select_filter:
                                ind_condition_satisfied_pd = pd.eval(
                                    multi_select_string_dict[condition_name].format(
                                        column_name=column_name, value=value
                                    ),
                                    target=data_df,
                                )
                            else:
                                ind_condition_satisfied_pd = pd.eval(
                                    string_dict[condition_name].format(column_name=column_name, value=value),
                                    target=data_df,
                                )

                            if ind_condition_satisfied_pd.any():
                                data_df = data_df.loc[ind_condition_satisfied_pd]
                            else:
                                data_df = pd.DataFrame(columns=data.columns)
                    else:
                        bool_val = int(literal_eval(value))
                        ind_condition_satisfied_pd = pd.eval(
                            bool_dict[condition_name].format(column_name=column_name, value=bool_val),
                            target=data_df,
                        )
                        if ind_condition_satisfied_pd.any():
                            data_df = data_df.loc[ind_condition_satisfied_pd]
                        else:
                            data_df = pd.DataFrame(columns=data.columns)

                elif model_type_dict[column_name] not in ["IntegerField"] or model_type_dict[
                    column_name
                ] not in ["BigIntegerField"]:
                    condition_string = ""
                    if condition_name in ["IN", "NOT IN"]:
                        value = list(value)
                        condition_string = int_dict[condition_name].format(
                            column_name=column_name, value=value
                        )
                    else:
                        condition_string = int_dict[condition_name].format(
                            column_name=column_name, value=float(value)
                        )
                    ind_condition_satisfied_pd = pd.eval(
                        condition_string,
                        target=data_df,
                    )
                    if ind_condition_satisfied_pd.any():
                        data_df = data_df.loc[ind_condition_satisfied_pd]
                    else:
                        data_df = pd.DataFrame(columns=data.columns)

                elif model_type_dict[column_name] not in ["FloatField"]:
                    condition_string = ""
                    if condition_name in ["IN", "NOT IN"]:
                        value = list(value)
                        condition_string = float_dict[condition_name].format(
                            column_name=column_name, value=value
                        )
                    else:
                        condition_string = float_dict[condition_name].format(
                            column_name=column_name, value=float(value)
                        )
                    ind_condition_satisfied_pd = pd.eval(
                        condition_string,
                        target=data_df,
                    )
                    if ind_condition_satisfied_pd.any():
                        data_df = data_df.loc[ind_condition_satisfied_pd]
                    else:
                        data_df = pd.DataFrame(columns=data.columns)
                else:
                    continue
    return data_df


def run_process_model_run_handler(
    request,
    flowchart_elements,
    model_name,
    global_dict,
    global_element_id,
    run=0,
    last_run_element=None,
    scenario_name=None,
    scenario_id=None,
    scenario_config=None,
    data_csv=None,
    data_id="comp",
    output_elements=[],
    default="no",
    embedded_compute_table_name=None,
    upload_then_compute=False,
    upload_import_ele=None,
    in_memory_execution=True,
):
    if isinstance(request, dict):

        class AttrDict:
            def __init__(self, i_dict):
                for key, value in i_dict.items():
                    if key not in ["password", "last_login", "date_joined"]:
                        setattr(self, key, value)
                if i_dict.get("username"):
                    setattr(self, "is_anonymous", False)
                else:
                    setattr(self, "is_anonymous", True)

            def get_host(self):
                return self.host

        request["user"] = AttrDict(request["user"])
        request = AttrDict(request)
    tenant = tenant_schema_from_request(request)
    model_run_identifier = random_no_generator(4)
    request_user = request.user.username
    curr_app_code, db_connection_name = current_app_db_extractor(request, tenant=tenant)
    element_flow_dict = {}
    if "saveFav" in flowchart_elements[-1]["element_id"]:
        last_element_id = flowchart_elements[-2]["element_id"]
    else:
        last_element_id = flowchart_elements[-1]["element_id"]
    context = {}
    element_message = "Success"

    if data_id == "comp":
        conf_table = "computation_model_configuration"
    else:
        conf_table = "data_management_computed_fields_config"
    inter_output_export_message_list = []
    extra_config = []

    flow_control_element = "###"
    flow_control_parent_element = "###"

    if len(global_dict) > 0:
        if global_dict["inputs"].get("variables"):
            variableList = global_dict["inputs"].get("variables")
            if len(variableList) > 0:
                for i, v in enumerate(variableList):
                    if v["dataType"] == "date-autonow":
                        global_dict["inputs"]["variables"][i]["defaultValue"] = str(
                            datetime.now().strftime("%Y-%m-%d")
                        )
                    elif v["dataType"] == "datetime-local-autonow":
                        global_dict["inputs"]["variables"][i]["defaultValue"] = str(
                            datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        )
                    elif v["dataType"] == "current_user":
                        global_dict["inputs"]["variables"][i]["defaultValue"] = str(request_user)
                    elif v["dataType"] == "dynamic-date":
                        vartype = v["option"]
                        if vartype == "n_day_ago":
                            default_value = datetime.now() - relativedelta(days=int(v["nDays"]))
                            default_value = default_value.date()
                        elif vartype == "n_month_ago":
                            default_value = datetime.now() - relativedelta(months=int(v["nDays"]))
                            default_value = default_value.date()
                        elif vartype == "today":
                            default_value = datetime.now().date()
                        elif vartype == "yesterday":
                            default_value = datetime.now() - relativedelta(days=1)
                            default_value = default_value.date()
                        elif vartype == "last_week":
                            default_value = datetime.now() - relativedelta(days=7)
                            default_value = default_value.date()
                        elif vartype == "last_month":
                            default_value = datetime.now() - relativedelta(months=1)
                            default_value = default_value.date()
                        elif vartype == "last_year":
                            default_value = datetime.now() - relativedelta(years=1)
                            default_value = default_value.date()
                        else:
                            default_value = ""
                        global_dict["inputs"]["variables"][i]["defaultValue"] = str(default_value)
                    elif v["dataType"] == "dynamic-datetime":
                        vartype = v["option"]
                        if vartype == "n_day_ago":
                            default_value = datetime.now() - relativedelta(days=int(v["nDays"]))
                            default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                        elif vartype == "n_month_ago":
                            default_value = datetime.now() - relativedelta(months=int(v["nDays"]))
                            default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                        elif vartype == "n_min_ago":
                            default_value = datetime.now() - relativedelta(minutes=int(v["nDays"]))
                            default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                        elif vartype == "n_hour_ago":
                            default_value = datetime.now() - relativedelta(hours=int(v["nDays"]))
                            default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                        elif vartype == "now":
                            default_value = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        else:
                            default_value = ""
                        global_dict["inputs"]["variables"][i]["defaultValue"] = default_value
                    elif v["dataType"] == "text" or v["dataType"] == "number":
                        if v.get("defaultValueConfigs"):
                            if v["defaultValueConfigs"]["defaultvalue_filters"] and v["defaultValueConfigs"]["defaultvalue_table"] and v["defaultValueConfigs"]["defaultvalue_column"]:
                                default_value = (
                                    read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": v["defaultValueConfigs"]["defaultvalue_table"],
                                                "Columns": [v["defaultValueConfigs"]["defaultvalue_column"]],
                                            },
                                            "condition": v["defaultValueConfigs"]["defaultvalue_filters"],
                                        },
                                    )[v["defaultValueConfigs"]["defaultvalue_column"]]
                                    .fillna("NULL")
                                    .tolist()
                                )
                                if len(default_value)>0:
                                    global_dict["inputs"]["variables"][i]["defaultValue"] = default_value[0]

        if global_dict["inputs"].get("multi_run_vars"):
            multi_run_vars = global_dict["inputs"].get("multi_run_vars")
        else:
            multi_run_vars = []

        if global_dict["inputs"].get("mapper_variables"):
            variableMapperList = global_dict["inputs"].get("mapper_variables")
            if len(variableMapperList) > 0:
                mapper_lister = []
                globalMapperDict = {}
                global_mapper_config = global_dict["inputs"]["mapperConfig"]
                table_name = global_mapper_config["mapperTable"]
                column_name = global_mapper_config["mapperColumn"]
                defaultVal = global_mapper_config["globalDefaultVal"]

                for mapp_vars in global_dict["inputs"]["variables"]:
                    if mapp_vars["varName"] == global_mapper_config["globalMapperName"]:
                        if mapp_vars["varName"] in multi_run_vars:
                            defaultVal = mapp_vars["defaultValue"][run]
                        elif mapp_vars["dataType"] == "dropdown-multiple":
                            defaultVal = mapp_vars["defaultValue"][0]
                        else:
                            defaultVal = mapp_vars["defaultValue"]

                actual_model_name = dynamic_model_create.get_model_class(table_name, request)

                columns_list = [field.name for field in actual_model_name.concrete_fields]
                test_data = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": table_name,
                            "Columns": columns_list,
                        },
                        "condition": [
                            {
                                "column_name": column_name,
                                "condition": "Equal to",
                                "input_value": defaultVal,
                                "and_or": "",
                            }
                        ],
                    },
                )
                for g_map_vars in global_mapper_config["NewVariablesGlobal"]:
                    globalMapperDict = {
                        "varName": g_map_vars["varName"],
                        "defaultValue": str(test_data[g_map_vars["associatedColumn"]].values[-1]),
                        "dataType": g_map_vars["dataType"],
                    }
                    mapper_lister.append(globalMapperDict)
                global_dict["inputs"]["mapper_variables"] = mapper_lister
    element_config_data = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": conf_table,
                "Columns": ["element_config", "element_id", "element_name"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": model_name,
                    "and_or": "",
                }
            ],
        },
    )
    for index, i in enumerate(flowchart_elements):
        if (i["parent"] != "#") | (i["child"] != "#"):
            ele = {"function": i["text"], "parent": i["parent"], "child": i["child"]}
            elementid = i["element_id"]
            element_config = element_config_data[element_config_data["element_id"] == elementid]
            elecon_dict = element_config.element_config.iloc[0]
            element_name = element_config.element_name.iloc[0]
            ele["element_name"] = element_name
            config_dict = json.loads(elecon_dict)
            if i["text"] == "Basic Aggregates":
                if not config_dict["inputs"].get("agg_config"):
                    config_dict_new = {
                        "function": "Elementary Statistics",
                        "inputs": {
                            "data": config_dict["inputs"]["data"],
                            "Type": config_dict["inputs"]["Type"],
                            "Groupby_column": config_dict["inputs"]["Groupby_column"],
                            "agg_config": [
                                {
                                    "Value_column": config_dict["inputs"]["Value_column"],
                                    "Sum_product_column": config_dict["inputs"]["Sum_product_column"],
                                    "Aggregate": config_dict["inputs"]["Aggregate"],
                                    "new_column_name": config_dict["inputs"]["new_column_name"],
                                    "Weights": config_dict["inputs"]["Weights"],
                                    "Conditional": config_dict["inputs"]["Conditional"],
                                }
                            ],
                        },
                        "outputs": config_dict["outputs"],
                    }
                    config_dict = config_dict_new.copy()

            if len(global_dict) > 0:
                if i["text"] == "Import Data":
                    data_source = config_dict["inputs"]["Data_source"]
                    if data_source == "Database":
                        condition_list = config_dict["condition"]
                        if config_dict.get("adv_condition"):
                            adv_condition_list = config_dict["adv_condition"]
                        else:
                            adv_condition_list = []
                        table__ = "users_" + config_dict["inputs"]["Table"].lower()
                        condition_ = []
                        if len(condition_list) > 0:
                            for li in condition_list:
                                if li.get("table") not in [None]:
                                    if li["table"] == table__:
                                        li["and_or"] = "AND"
                                        condition_.append(li)
                            if len(condition_) > 0:
                                condition_[len(condition_) - 1]["and_or"] = ""
                                condition_list = condition_
                        for cond in condition_list:
                            if cond["globalVariable"] != "":
                                for g in global_dict["inputs"]["variables"]:
                                    if cond["globalVariable"] == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            cond["input_value"] = g["defaultValue"][run]
                                        else:
                                            cond["input_value"] = g["defaultValue"]
                                for g in global_dict["inputs"]["mapper_variables"]:
                                    if cond["globalVariable"] == g["varName"]:
                                        cond["input_value"] = g["defaultValue"]
                        config_dict["condition"] = condition_list
                        for cond in adv_condition_list:
                            if cond["globalVariable"] != "":
                                for g in global_dict["inputs"]["variables"]:
                                    if cond["globalVariable"] == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            cond["input_value"] = g["defaultValue"][run]
                                        else:
                                            cond["input_value"] = g["defaultValue"]
                                for g in global_dict["inputs"]["mapper_variables"]:
                                    if cond["globalVariable"] == g["varName"]:
                                        cond["input_value"] = g["defaultValue"]
                        config_dict["adv_condition"] = adv_condition_list
                    elif data_source == "CSV":
                        import_data_csv_global = config_dict["inputs"]["global_var"]
                        if import_data_csv_global != "":
                            csv_global_data = global_element_id + import_data_csv_global
                        else:
                            csv_global_data = f"{elementid}"
                    elif data_source == "JSON":
                        import_data_csv_global_json = config_dict["inputs"]["global_var"]
                        if import_data_csv_global_json != "":
                            json_global_data = global_element_id + import_data_csv_global_json
                        else:
                            if redis_instance.exists(elementid) == 1:
                                json_global_data = pickle.loads(redis_instance.get(elementid))
                    elif data_source == "Parquet":
                        import_data_csv_global_pq = config_dict["inputs"]["global_var"]
                        if import_data_csv_global_pq != "":
                            pq_global_data = global_element_id + import_data_csv_global_pq
                        else:
                            if redis_instance.exists(elementid) == 1:
                                pq_global_data = pickle.loads(redis_instance.get(elementid))
                    elif data_source == "XML":
                        if redis_instance.exists(elementid) == 1:
                            pq_global_data = pickle.loads(redis_instance.get(elementid))
                        else:
                            pass
                    elif data_source == "Model_output":
                        config_dict["current_global_dict"] = global_dict["inputs"]["variables"]
                        config_dict["current_run"] = run
                        condition_list = config_dict["inputs"]["condition"]
                        for cond in condition_list:
                            if cond["globalVariable"] != "":
                                for g in global_dict["inputs"]["variables"]:
                                    if cond["globalVariable"] == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            cond["input_value"] = g["defaultValue"][run]
                                        else:
                                            cond["input_value"] = g["defaultValue"]
                                for g in global_dict["inputs"]["mapper_variables"]:
                                    if cond["globalVariable"] == g["varName"]:
                                        cond["input_value"] = g["defaultValue"]
                        config_dict["inputs"]["condition"] = condition_list

                    elif data_source == "Redis":
                        redis_element_id = config_dict["inputs"]["RedisTable"]
                        import_data_csv_global_rd = config_dict["inputs"]["global_var"]
                        if import_data_csv_global_rd != "":
                            red_data = global_element_id + import_data_csv_global_rd
                        else:
                            if redis_instance.exists(redis_element_id) == 1:
                                red_data = pickle.loads(redis_instance.get(redis_element_id))

                elif i["text"] == "Data Transformation":
                    final_config = config_dict["inputs"]["final_config"]
                    if final_config["groupby"] != "":
                        groupby_config = final_config["groupby"]
                        option = groupby_config["inputs"]["option"]
                        option_config = groupby_config["inputs"]["option_config"]
                        if option == "where":
                            condition_list = option_config["condition"]
                            for cond in condition_list:
                                if cond["globalVariable"]:
                                    for g in global_dict["inputs"]["variables"]:
                                        if cond["globalVariable"] == g["varName"]:
                                            if g["varName"] in multi_run_vars:
                                                cond["input_value"] = g["defaultValue"][run]
                                            else:
                                                cond["input_value"] = g["defaultValue"]
                                    for g in global_dict["inputs"]["mapper_variables"]:
                                        if cond["globalVariable"] == g["varName"]:
                                            cond["input_value"] = g["defaultValue"]
                            groupby_config["inputs"]["option_config"]["condition"] = condition_list
                        elif option == "addCondColumn":
                            condition_list = option_config["condition"]["condition"]
                            for cond in condition_list:
                                if cond["globalVariable"]:
                                    for g in global_dict["inputs"]["variables"]:
                                        if cond["globalVariable"] == g["varName"]:
                                            if g["varName"] in multi_run_vars:
                                                cond["condition_value"] = g["defaultValue"][run]
                                            else:
                                                cond["condition_value"] = g["defaultValue"]
                                    for g in global_dict["inputs"]["mapper_variables"]:
                                        if cond["globalVariable"] == g["varName"]:
                                            cond["condition_value"] = g["defaultValue"]

                                if cond["repr_value"]["global_var"]:
                                    for g in global_dict["inputs"]["variables"]:
                                        if cond["repr_value"]["global_var"] == g["varName"]:
                                            if g["varName"] in multi_run_vars:
                                                cond["repr_value"]["repr_value"] = g["defaultValue"][run]
                                            else:
                                                cond["repr_value"]["repr_value"] = g["defaultValue"]
                                    for g in global_dict["inputs"]["mapper_variables"]:
                                        if cond["repr_value"]["global_var"] == g["varName"]:
                                            cond["repr_value"]["repr_value"] = g["defaultValue"]
                            groupby_config["inputs"]["option_config"]["condition"][
                                "condition"
                            ] = condition_list
                        else:
                            pass

                elif i["text"] == "Conditional Aggregates":
                    if not config_dict["inputs"].get("agg_config"):
                        config_dict_new = {
                            "function": "Elementary Statistics",
                            "inputs": {
                                "data": config_dict["inputs"]["data"],
                                "Type": config_dict["inputs"]["Type"],
                                "Groupby_column": config_dict["inputs"]["Groupby_column"],
                                "agg_config": [
                                    {
                                        "Value_column": config_dict["inputs"]["Value_column"],
                                        "Sum_product_column": config_dict["inputs"]["Sum_product_column"],
                                        "Aggregate": config_dict["inputs"]["Aggregate"],
                                        "new_column_name": config_dict["inputs"]["new_column_name"],
                                        "Weights": config_dict["inputs"]["Weights"],
                                        "Conditional": config_dict["inputs"]["Conditional"],
                                    }
                                ],
                            },
                            "outputs": config_dict["outputs"],
                        }
                        config_dict = config_dict_new.copy()
                    agg_config = config_dict["inputs"]["agg_config"]
                    for agg_ind, agg in enumerate(agg_config):
                        aggregate = agg["Aggregate"]
                        if aggregate in ["Averageif", "Sumif", "Countif", "Productif"]:
                            condition_list = agg["Conditional"]["If_condition"]
                            for cond in condition_list:
                                if cond["globalVariable"] != "":
                                    for g in global_dict["inputs"]["variables"]:
                                        if cond["globalVariable"] == g["varName"]:
                                            if g["varName"] in multi_run_vars:
                                                cond["input_value"] = g["defaultValue"][run]
                                            else:
                                                cond["input_value"] = g["defaultValue"]
                                    for g in global_dict["inputs"]["mapper_variables"]:
                                        if cond["globalVariable"] == g["varName"]:
                                            cond["input_value"] = g["defaultValue"]
                            config_dict["inputs"]["agg_config"][agg_ind]["Conditional"][
                                "If_condition"
                            ] = condition_list

                elif i["text"] == "Portfolio Liquidity Configuration":
                    liquidity_global_var = config_dict["inputs"]["liquidity"]["global_var"]
                    if liquidity_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if liquidity_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["liquidity"]["liquidity_val"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["liquidity"]["liquidity_val"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if liquidity_global_var == g["varName"]:
                                config_dict["inputs"]["liquidity"]["liquidity_val"] = g["defaultValue"]

                    val_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if val_date_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"]

                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_date_global_var == g["varName"]:
                                config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"]

                elif i["text"] == "Portfolio Limit Utilisation":
                    val_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if val_date_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"]

                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_date_global_var == g["varName"]:
                                config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"]

                    if config_dict["inputs"]["limits"]["source"] == "manual_entry_PLU":
                        for key, value in config_dict["inputs"]["limits"]["manual_limits"].items():
                            value_global_var = value["value"]["global_var"]
                            if value_global_var != "":
                                for g in global_dict["inputs"]["variables"]:
                                    if value_global_var == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            value["value"]["input_value"] = g["defaultValue"][run]
                                        else:
                                            value["value"]["input_value"] = g["defaultValue"]
                                for g in global_dict["inputs"]["mapper_variables"]:
                                    if val_date_global_var == g["varName"]:
                                        value["value"]["input_value"] = g["defaultValue"]

                elif i["text"] == "Expected Return":
                    val_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if val_date_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_date_global_var == g["varName"]:
                                config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"]

                elif i["text"] == "Portfolio Allocation":
                    investment_global_var = config_dict["inputs"]["investment"]["global_var"]
                    if investment_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if investment_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["investment"]["investment_val"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["investment"]["investment_val"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if investment_global_var == g["varName"]:
                                config_dict["inputs"]["investment"]["investment_val"] = g["defaultValue"]

                    val_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if val_date_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_date_global_var == g["varName"]:
                                config_dict["inputs"]["valuation_date"]["val_date"] = g["defaultValue"]

                elif i["text"] == "Portfolio Attribution":
                    run_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if run_date_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if run_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["run_date"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["valuation_date"]["run_date"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if run_date_global_var == g["varName"]:
                                config_dict["inputs"]["valuation_date"]["run_date"] = g["defaultValue"]

                    pool_name_global_var = config_dict["inputs"]["pool_name"]["global_var"]
                    if pool_name_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if pool_name_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["pool_name"]["pool_name"] = g["defaultValue"][run]
                                else:
                                    config_dict["inputs"]["pool_name"]["pool_name"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if pool_name_global_var == g["varName"]:
                                config_dict["inputs"]["pool_name"]["pool_name"] = g["defaultValue"]

                    scenario_name_global_var = config_dict["inputs"]["scenario_name"]["global_var"]
                    if scenario_name_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if scenario_name_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["scenario_name"]["scenario_name"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["scenario_name"]["scenario_name"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if scenario_name_global_var == g["varName"]:
                                config_dict["inputs"]["scenario_name"]["scenario_name"] = g["defaultValue"]

                elif i["text"] == "Optimiser":
                    constraint_dict = config_dict["inputs"]["constraint_dict"]

                    scenario_name_global_var = config_dict["inputs"]["scenario_name"]["global_var"]
                    if scenario_name_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if scenario_name_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["scenario_name"]["scenarioName"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["scenario_name"]["scenarioName"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if scenario_name_global_var == g["varName"]:
                                config_dict["inputs"]["scenario_name"]["scenarioName"] = g["defaultValue"]

                    valuation_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if valuation_date_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if valuation_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["valuation_date"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["valuation_date"]["valuation_date"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if valuation_date_global_var == g["varName"]:
                                config_dict["inputs"]["valuation_date"]["valuation_date"] = g["defaultValue"]

                    risk_free_rate_global_var = config_dict["inputs"]["risk_free_rate"]["global_var"]
                    if risk_free_rate_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if risk_free_rate_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["risk_free_rate"]["riskFreeRate"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["risk_free_rate"]["riskFreeRate"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if risk_free_rate_global_var == g["varName"]:
                                config_dict["inputs"]["risk_free_rate"]["riskFreeRate"] = g["defaultValue"]

                    target_volatility_global_var = config_dict["inputs"]["target_volatility"]["global_var"]
                    if target_volatility_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if target_volatility_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["target_volatility"]["targetVolatility"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["target_volatility"]["targetVolatility"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if target_volatility_global_var == g["varName"]:
                                config_dict["inputs"]["target_volatility"]["targetVolatility"] = g[
                                    "defaultValue"
                                ]

                    target_return_global_var = config_dict["inputs"]["target_return"]["global_var"]
                    if target_return_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if target_return_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["target_return"]["targetRreturn"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["target_return"]["targetRreturn"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if target_return_global_var == g["varName"]:
                                config_dict["inputs"]["target_return"]["targetRreturn"] = g["defaultValue"]

                    investment_amount_global_var = config_dict["inputs"]["investment_amount"]["global_var"]
                    if investment_amount_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if investment_amount_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["investment_amount"][
                                        "investment_amount_allocation"
                                    ] = g["defaultValue"][run]
                                else:
                                    config_dict["inputs"]["investment_amount"][
                                        "investment_amount_allocation"
                                    ] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if investment_amount_global_var == g["varName"]:
                                config_dict["inputs"]["investment_amount"]["investment_amount_allocation"] = (
                                    g["defaultValue"]
                                )

                    for val in constraint_dict:
                        constraint_list = constraint_dict[val]["constraint_list"]
                        for j in constraint_list:
                            if j["globalVariable"] != "":
                                for g in global_dict["inputs"]["variables"]:
                                    if j["globalVariable"] == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            j["input_value"] = g["defaultValue"][run]
                                        else:
                                            j["input_value"] = g["defaultValue"]
                                for g in global_dict["inputs"]["mapper_variables"]:
                                    if j["globalVariable"] == g["varName"]:
                                        j["input_value"] = g["defaultValue"]

                        config_dict["inputs"]["constraint_dict"][val]["constraint_list"] = constraint_list

                elif i["text"] == "Goodness Of Fit Test":
                    val_text_var = json.loads(config_dict["inputs"]["use_case_check"])
                    use_case_fit_name = val_text_var["val_text"]
                    if val_text_var["global_Var"] != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_text_var["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    use_case_fit_name = g["defaultValue"][run]
                                else:
                                    use_case_fit_name = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_text_var["global_Var"] == g["varName"]:
                                use_case_fit_name = g["defaultValue"]
                    config_dict["inputs"]["use_case"] = use_case_fit_name

                elif i["text"] == "Fit Discrete Distribution":
                    val_text_var = json.loads(config_dict["inputs"]["use_case_check"])
                    use_case_discrete_name = val_text_var["val_text"]
                    if val_text_var["global_Var"] != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_text_var["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    use_case_discrete_name = g["defaultValue"][run]
                                else:
                                    use_case_discrete_name = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_text_var["global_Var"] == g["varName"]:
                                use_case_discrete_name = g["defaultValue"]
                    config_dict["inputs"]["use_case"] = use_case_discrete_name

                elif i["text"] == "Portfolio Valuation":
                    val_date_global_var = config_dict["inputs"]["Valuation_Date"]["global_Var"]
                    if val_date_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["Valuation_Date"]["val_date"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["Valuation_Date"]["val_date"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_date_global_var == g["varName"]:
                                config_dict["inputs"]["Valuation_Date"]["val_date"] = g["defaultValue"]

                    cf_analysis_id_global_var = config_dict["inputs"]["CF_Analysis_Id"]["global_Var"]
                    if cf_analysis_id_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if cf_analysis_id_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["CF_Analysis_Id"]["cf_analysis_id"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["CF_Analysis_Id"]["cf_analysis_id"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if cf_analysis_id_global_var == g["varName"]:
                                config_dict["inputs"]["CF_Analysis_Id"]["cf_analysis_id"] = g["defaultValue"]

                elif i["text"] == "TWRR":
                    fund_global_var = config_dict["inputs"]["fund_global_var"]
                    fund = config_dict["inputs"]["fund"]
                    if fund_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if fund_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    fund = g["defaultValue"][run]
                                else:
                                    fund = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if fund_global_var == g["varName"]:
                                fund = g["defaultValue"]
                        config_dict["inputs"]["fund"] = fund

                elif i["text"] == "Portfolio Metrics":
                    val_start_date_global_var = config_dict["inputs"]["option_config"][
                        "start_date_global_port_metr"
                    ]
                    val_end_date_global_var = config_dict["inputs"]["option_config"][
                        "end_date_global_port_metr"
                    ]

                    if val_start_date_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_start_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["start_date"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["option_config"]["start_date"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_start_date_global_var == g["varName"]:
                                config_dict["inputs"]["option_config"]["start_date"] = g["defaultValue"]

                    if val_end_date_global_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_end_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["end_date"] = g["defaultValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["option_config"]["end_date"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_end_date_global_var == g["varName"]:
                                config_dict["inputs"]["option_config"]["end_date"] = g["defaultValue"]

                elif i["text"] == "IR Curve Bootstrapping":
                    if config_dict["inputs"]["option"] != "swap":
                        val_global_term_tenor = config_dict["inputs"]["option_config"]["global_term_tenor"]
                        val_global_extr_date = config_dict["inputs"]["option_config"]["global_extr_date"]
                        val_global_short_term_tenor = None
                        val_global_medium_term_tenor = None
                        val_global_swap_extr_date = None
                    else:
                        val_global_term_tenor = None
                        val_global_extr_date = None
                        val_global_short_term_tenor = config_dict["inputs"]["option_config"][
                            "global_short_term_tenor"
                        ]
                        val_global_medium_term_tenor = config_dict["inputs"]["option_config"][
                            "global_medium_term_tenor"
                        ]
                        val_global_swap_extr_date = config_dict["inputs"]["option_config"][
                            "global_swap_extr_date"
                        ]

                    if config_dict["inputs"]["option"] == "ois":
                        val_funding_spread = config_dict["inputs"]["option_config"]["global_funding_spread"]
                    else:
                        val_funding_spread = None

                    if val_global_term_tenor != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_global_term_tenor == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Par Lim Tenor"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Par Lim Tenor"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_global_term_tenor == g["varName"]:
                                config_dict["inputs"]["option_config"]["Par Lim Tenor"] = g["defaultValue"]

                    if val_global_extr_date != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_global_extr_date == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Extraction Date"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Extraction Date"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_global_extr_date == g["varName"]:
                                config_dict["inputs"]["option_config"]["Extraction Date"] = g["defaultValue"]

                    if val_funding_spread != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_funding_spread == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Funding Spread"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Funding Spread"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_funding_spread == g["varName"]:
                                config_dict["inputs"]["option_config"]["Funding Spread"] = g["defaultValue"]

                    if val_global_short_term_tenor != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_global_short_term_tenor == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Short Term Tenor"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Short Term Tenor"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_global_short_term_tenor == g["varName"]:
                                config_dict["inputs"]["option_config"]["Short Term Tenor"] = g["defaultValue"]

                    if val_global_medium_term_tenor != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_global_medium_term_tenor == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Medium Term Tenor"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Medium Term Tenor"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_global_medium_term_tenor == g["varName"]:
                                config_dict["inputs"]["option_config"]["Medium Term Tenor"] = g[
                                    "defaultValue"
                                ]

                    if val_global_swap_extr_date != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_global_swap_extr_date == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Extraction Date"] = g[
                                        "defaultValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Extraction Date"] = g[
                                        "defaultValue"
                                    ]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_global_swap_extr_date == g["varName"]:
                                config_dict["inputs"]["option_config"]["Extraction Date"] = g["defaultValue"]

                elif i["text"] == "Options":
                    val_global_riskfree_rate = config_dict["inputs"]["option_config"]["global_riskfree_rate"]
                    val_global_n_steps = config_dict["inputs"]["option_config"]["global_n_steps"]

                    if val_global_riskfree_rate != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_global_riskfree_rate == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["r_rate"] = g["defaultValue"][run]
                                else:
                                    config_dict["inputs"]["option_config"]["r_rate"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_global_riskfree_rate == g["varName"]:
                                config_dict["inputs"]["option_config"]["r_rate"] = g["defaultValue"]

                    if val_global_n_steps != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_global_n_steps == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["n_step"] = g["defaultValue"][run]
                                else:
                                    config_dict["inputs"]["option_config"]["n_step"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_global_n_steps == g["varName"]:
                                config_dict["inputs"]["option_config"]["n_step"] = g["defaultValue"]
                elif i["text"] == "Editor":
                    global_str = ""
                    if global_dict["inputs"].get("variables"):
                        for g in global_dict["inputs"]["variables"]:
                            varName = re.sub(r"\s+", "_", g["varName"])
                            defaultVal = g["defaultValue"]
                            datatype = g["dataType"]
                            if datatype == "number":
                                global_str += f"""{varName} = {defaultVal}\n"""
                            if datatype == "datetime-local":
                                if defaultVal and defaultVal not in ["None"]:
                                    defaultVal = datetime.strptime(defaultVal, "%Y-%m-%dT%H:%M")
                                    global_str += f"""{varName} = '{defaultVal}'\n{varName} = datetime.datetime.strptime({varName}, '%Y-%m-%d %H:%M:%S')\n"""
                                else:
                                    global_str += f"""{varName} = '{defaultVal}'\n"""
                            if datatype in ["text", "dropdown"]:
                                global_str += f"""{varName} = '{defaultVal}'\n"""
                            if datatype in ["dropdown-multiple"]:
                                global_str += f"""{varName} = {defaultVal}\n"""
                            if datatype == "date":
                                if defaultVal and defaultVal not in ["None"]:
                                    if "T" in defaultVal:
                                        defaultVal = datetime.strptime(
                                            defaultVal.split(".")[0], "%Y-%m-%dT%H:%M:%S"
                                        ).strftime("%Y-%m-%d %H:%M:%S")
                                        global_str += f"""{varName} = '{defaultVal}'\n{varName} = datetime.datetime.strptime({varName}, '%Y-%m-%d %H:%M:%S')\n"""
                                    else:
                                        global_str += f"""{varName} = '{defaultVal}'\n{varName} = datetime.datetime.strptime({varName}, '%Y-%m-%d')\n"""
                                else:
                                    global_str += f"""{varName} = '{defaultVal}'\n"""
                            if datatype == "date-autonow":
                                global_str += f"""{varName} = '{datetime.now().strftime("%Y-%m-%d")}'\n"""
                            if datatype == "datetime-autonow":
                                global_str += (
                                    f"""{varName} = '{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'\n"""
                                )
                            if datatype == "current_user":
                                global_str += f"""{varName} = '{request_user}'\n"""

                    if global_dict["inputs"].get("mapper_variables"):
                        if len(global_dict["inputs"]["mapper_variables"]) > 0:
                            for g in global_dict["inputs"]["mapper_variables"]:
                                varName = re.sub(r"\s+", "_", g["varName"])
                                defaultVal = g["defaultValue"]
                                datatype = g["dataType"]
                                if datatype == "number":
                                    if defaultVal not in ["nan"]:
                                        global_str += f"""{varName} = {defaultVal}\n"""
                                    else:
                                        global_str += f"""{varName} = '{defaultVal}'\n"""
                                if datatype == "date":
                                    if defaultVal and defaultVal not in ["None"]:
                                        if "T" in defaultVal:
                                            defaultVal = datetime.strptime(
                                                defaultVal.split(".")[0], "%Y-%m-%dT%H:%M:%S"
                                            ).strftime("%Y-%m-%d %H:%M:%S")
                                            global_str += f"""{varName} = '{defaultVal}'\n{varName} = datetime.datetime.strptime({varName}, '%Y-%m-%d %H:%M:%S')\n"""
                                        else:
                                            global_str += f"""{varName} = '{defaultVal}'\n{varName} = datetime.datetime.strptime({varName}, '%Y-%m-%d')\n"""
                                    else:
                                        global_str += f"""{varName} = '{defaultVal}'\n"""
                                if datatype in ["text"]:
                                    global_str += f"""{varName} = '{defaultVal}'\n"""
                                if datatype in ["date-autonow"]:
                                    global_str += f"""{varName} = {defaultVal}\n"""
                                if datatype in ["datetime-local-autonow"]:
                                    global_str += f"""{varName} = {defaultVal}\n"""
                                if datatype in ["current_user"]:
                                    global_str += f"""{varName} = '{defaultVal}'\n"""
                    config_dict["inputs"]["global_str"] = global_str
                elif i["text"] == "Copula":
                    val_text_usecase = json.loads(config_dict["inputs"]["use_case_input"])
                    val_number_sim = json.loads(config_dict["inputs"]["simulation_input"])
                    val_number_percentile = json.loads(config_dict["inputs"]["percentile_input"])
                    val_text_scenerio = json.loads(config_dict["inputs"]["scenerio_input"])

                    if val_text_usecase["global_Var"] != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_text_usecase["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    val_text_usecase["val_text"] = g["defaultValue"][run]
                                else:
                                    val_text_usecase["val_text"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_text_usecase["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    val_text_usecase["val_text"] = g["defaultValue"][run]
                                else:
                                    val_text_usecase["val_text"] = g["defaultValue"]

                        config_dict["inputs"]["use_case_input"] = json.dumps(val_text_usecase)

                    if val_number_sim["global_Var"] != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_number_sim["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    val_number_sim["val_number"] = g["defaultValue"][run]
                                else:
                                    val_number_sim["val_number"] = g["defaultValue"]

                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_number_sim["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    val_number_sim["val_number"] = g["defaultValue"][run]
                                else:
                                    val_number_sim["val_number"] = g["defaultValue"]

                        config_dict["inputs"]["simulation_input"] = json.dumps(val_number_sim)

                    if val_number_percentile["global_Var"] != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_number_percentile["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    val_number_percentile["val_number"] = g["defaultValue"][run]
                                else:
                                    val_number_percentile["val_number"] = g["defaultValue"]

                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_number_percentile["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    val_number_percentile["val_number"] = g["defaultValue"][run]
                                else:
                                    val_number_percentile["val_number"] = g["defaultValue"]
                                config_dict["inputs"]["percentile_input"] = val_number_percentile
                        config_dict["inputs"]["percentile_input"] = json.dumps(val_number_percentile)

                    if val_text_scenerio["global_Var"] != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_text_scenerio["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    val_text_scenerio["val_text"] = g["defaultValue"][run]
                                else:
                                    val_text_scenerio["val_text"] = g["defaultValue"]

                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_text_scenerio["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    val_text_scenerio["val_text"] = g["defaultValue"][run]
                                else:
                                    val_text_scenerio["val_text"] = g["defaultValue"]
                                config_dict["inputs"]["scenerio_input"] = val_text_scenerio
                        config_dict["inputs"]["scenerio_input"] = json.dumps(val_text_scenerio)

                elif i["text"] == "Monte Carlo":
                    val_number_var = json.loads(config_dict["inputs"]["sim_check"])
                    simulation_count = val_number_var["val_number"]
                    if val_number_var["global_Var"] != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_number_var["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    simulation_count = g["defaultValue"][run]
                                else:
                                    simulation_count = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_number_var["global_Var"] == g["varName"]:
                                simulation_count = g["defaultValue"]
                    config_dict["inputs"]["monte_carlo_simulation"] = simulation_count

                elif i["text"] == "Monte Carlo":
                    val_number_var = json.loads(config_dict["inputs"]["sim_check"])
                    simulation_count = val_number_var["val_number"]
                    if val_number_var["global_Var"] != "":
                        for g in global_dict["inputs"]["variables"]:
                            if val_number_var["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    simulation_count = g["defaultValue"][run]
                                else:
                                    simulation_count = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if val_number_var["global_Var"] == g["varName"]:
                                simulation_count = g["defaultValue"]
                    config_dict["inputs"]["monte_carlo_simulation"] = simulation_count

                elif i["text"] == "FX Options - Implied Volatility":
                    global_fx_val_date_var = config_dict["inputs"]["global_fx_val_date"]

                    if global_fx_val_date_var != "":
                        for g in global_dict["inputs"]["variables"]:
                            if global_fx_val_date_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["global_fx_val_date"] = g["defaultValue"][run]
                                else:
                                    config_dict["inputs"]["global_fx_val_date"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if global_fx_val_date_var == g["varName"]:
                                config_dict["inputs"]["global_fx_val_date"] = g["defaultValue"]
                elif i["text"] == "ML Predict":
                    if config_dict["inputs"].get("global_no_of_steps"):
                        global_no_of_steps_ahead = config_dict["inputs"]["global_no_of_steps"]
                    else:
                        global_no_of_steps_ahead = ""

                    if global_no_of_steps_ahead != "":
                        for g in global_dict["inputs"]["variables"]:
                            if global_no_of_steps_ahead == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["no_of_steps"] = g["defaultValue"][run]
                                else:
                                    config_dict["inputs"]["no_of_steps"] = g["defaultValue"]
                        for g in global_dict["inputs"]["mapper_variables"]:
                            if global_no_of_steps_ahead == g["varName"]:
                                config_dict["inputs"]["no_of_steps"] = g["defaultValue"]
                else:
                    pass
            else:
                if i["text"] == "Import Data":
                    data_source = config_dict["inputs"]["Data_source"]
                    if data_source == "Model_output":
                        config_dict["current_global_dict"] = []
                        config_dict["current_run"] = run
                elif i["text"] == "Goodness Of Fit Test":
                    val_text_var = json.loads(config_dict["inputs"]["use_case_check"])
                    use_case_fit_name = val_text_var["val_text"]
                    config_dict["inputs"]["use_case"] = use_case_fit_name

                elif i["text"] == "Fit Discrete Distribution":
                    val_text_var = json.loads(config_dict["inputs"]["use_case_check"])
                    use_case_discrete_name = val_text_var["val_text"]
                    config_dict["inputs"]["use_case"] = use_case_discrete_name

                elif i["text"] == "Monte Carlo":
                    val_number_var = json.loads(config_dict["inputs"]["sim_check"])
                    simulation_count = val_number_var["val_number"]
                    config_dict["inputs"]["monte_carlo_simulation"] = simulation_count

            ele["element_config"] = config_dict
            if i["parent"] == "#":
                csv_data_list = []
                json_data_list = []
                pq_data_list = []
                rd_data_list = []
                sftp_list = []
                if config_dict["inputs"].get("current_table"):
                    curr_table = config_dict["inputs"]["current_table"]
                else:
                    curr_table = "No"
                if config_dict["inputs"].get("current_table_flow"):
                    curr_table_flow = config_dict["inputs"]["current_table_flow"]
                else:
                    curr_table_flow = "No"
                curr_table_flow
                try:
                    if i["text"] == "Import Data":
                        if config_dict.get("data_mapper"):
                            if config_dict["data_mapper"].get("parentData"):
                                mapper_element = config_dict["data_mapper"]["parentData"]
                                if mapper_element != "#":
                                    config_dict["data_mapper"]["data_source"] = element_flow_dict[
                                        mapper_element
                                    ]["output_data"]
                                else:
                                    pass
                            else:
                                pass
                        else:
                            pass
                        if upload_then_compute and elementid == upload_import_ele:
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=[data_csv],
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                                upload_then_compute=upload_then_compute,
                            )
                        elif config_dict["inputs"]["Data_source"] == "CSV":
                            if config_dict["inputs"]["global_var"] != "":
                                csv_data_list.append(csv_global_data)
                            else:
                                csv_data_list.append(f"{elementid}")
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=csv_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif config_dict["inputs"]["Data_source"] == "JSON":
                            if config_dict["inputs"]["global_var"] != "":
                                json_data_list.append(json_global_data)
                            else:
                                if redis_instance.exists(elementid) == 1:
                                    json_data = pickle.loads(redis_instance.get(elementid))
                                json_data_list.append(json_data)
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=json_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif config_dict["inputs"]["Data_source"] == "Parquet":
                            if config_dict["inputs"]["global_var"] != "":
                                pq_data_list.append(pq_global_data)
                            else:
                                if redis_instance.exists(elementid) == 1:
                                    pq_data = pickle.loads(redis_instance.get(elementid))
                                pq_data_list.append(pq_data)
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=pq_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif config_dict["inputs"]["Data_source"] == "XML":
                            if config_dict["inputs"]["global_var"] != "":
                                pq_data_list.append(pq_global_data)
                            else:
                                if redis_instance.exists(elementid) == 1:
                                    pq_data = pickle.loads(redis_instance.get(elementid))
                                pq_data_list.append(pq_data)
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=pq_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif config_dict["inputs"]["Data_source"] == "Database" and curr_table == "Yes":
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=[data_csv],
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif (
                            config_dict["inputs"]["Data_source"] == "Database"
                            and default == "yes"
                            and config_dict["inputs"]["Table"] == embedded_compute_table_name
                        ):
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=[data_csv],
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                                default=default,
                            )
                        elif config_dict["inputs"]["Data_source"] == "Redis":
                            redis_element_id = config_dict["inputs"]["RedisTable"]
                            if config_dict["inputs"]["global_var"] != "":
                                rd_data_list.append(red_data)
                            else:
                                if redis_instance.exists(redis_element_id) == 1:
                                    red_data = pickle.loads(redis_instance.get(redis_element_id))
                                rd_data_list.append(red_data)
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=rd_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif (
                            config_dict["inputs"]["Data_source"] == "SFTP"
                            or config_dict["inputs"]["Data_source"] == "FTP"
                            or config_dict["inputs"]["Data_source"] == "AWS_S3"
                            or config_dict["inputs"]["Data_source"] == "AZURE"
                            or config_dict["inputs"]["Data_source"] == "LOCAL"
                        ):
                            if config_dict["inputs"]["Data_source"] == "SFTP":
                                newlist, rename_list = SFTPconnectors.connect_to_sftp(config_dict, elementid)
                            elif config_dict["inputs"]["Data_source"] == "FTP":
                                newlist, rename_list = SFTPconnectors.connect_to_ftp(config_dict, elementid)
                            elif config_dict["inputs"]["Data_source"] == "AWS_S3":
                                newlist, rename_list = SFTPconnectors.connect_to_awsS3(config_dict, elementid)
                            elif config_dict["inputs"]["Data_source"] == "AZURE":
                                newlist, rename_list = SFTPconnectors.connect_to_azure(config_dict, elementid)
                            elif config_dict["inputs"]["Data_source"] == "LOCAL":
                                rename_list = []
                                selected_files = config_dict["inputs"]["files"]
                                rename_config = config_dict["inputs"]["renameConfig"]

                                for f in selected_files:
                                    rfile = f
                                    if rename_config and rfile in rename_config:
                                        rfile = rename_config[rfile]
                                    else:
                                        rfile = rfile.split(".")[0]
                                    rename_list.append(rfile)
                            for fname in rename_list:
                                sftp_list.append(f"{elementid}_{fname}")

                            saved_parent_val = read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "computation_model_configuration",
                                        "Columns": ["element_config"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "element_id",
                                            "condition": "Equal to",
                                            "input_value": elementid + "_multi_import_val",
                                            "and_or": "",
                                        },
                                    ],
                                },
                            )

                            if len(saved_parent_val) > 0:
                                elecon_dict = saved_parent_val.iloc[0, 0]
                                par_val = json.loads(elecon_dict)
                                multi_import_val = par_val
                            else:
                                multi_import_val = {}
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=sftp_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                                multi_import=True,
                                multi_import_val=multi_import_val,
                            )
                        else:
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                    elif i["text"] == "If then Else":
                        input_data = pd.DataFrame()
                        data = input_data.copy()
                        data_error = ""
                        elements_not_to_run, next_element = computationFlowController(
                            flowchart_elements, elementid, config_dict, input_data, global_dict, l3_run=False
                        )
                        if len(elements_not_to_run):
                            for ele_not in elements_not_to_run:
                                for fl_idx, fl_ele in enumerate(flowchart_elements):
                                    if fl_ele["element_id"] == ele_not:
                                        flowchart_elements.pop(fl_idx)
                            last_element_id = flowchart_elements[-1]["element_id"]
                            for fc_k, fc_data in next_element.items():
                                new_fc_k = elementid + fc_k
                                if isinstance(fc_data, pd.DataFrame):
                                    try:
                                        file_name = f"{new_fc_k}_{model_run_identifier}_{request.user.username}_{tenant}"
                                        to_diskstorage(fc_data, file_name)
                                        ele["output_data"] = file_name
                                    except Exception as e:
                                        ele["output_data"] = fc_data
                                        logging.warning(f"Following exception occured - {e}")
                                else:
                                    ele["output_data"] = fc_data
                                element_flow_dict[new_fc_k] = ele
                    else:
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            elementid=elementid,
                            scenario_name=scenario_name,
                            scenario_id=scenario_id,
                            scenario_config=scenario_config,
                        )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)

                    if data_error:
                        errorElement = i["text"]
                        if isinstance(data_error, str):
                            element_message = f"Error running {errorElement}! {data_error}"
                        else:
                            element_message = f"Error running {errorElement}!"
                            for de in data_error:
                                element_message += f"\n{de}"
                        break
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    errorElement = i["text"]
                    element_message = f"Error running {errorElement}! {e}"
                    data = pd.DataFrame()

                if isinstance(data, pd.DataFrame) and not in_memory_execution:
                    try:
                        file_name = f"{elementid}_{model_run_identifier}_{request.user.username}_{tenant}"
                        to_diskstorage(data, file_name)
                        ele["output_data"] = file_name
                    except Exception as e:
                        ele["output_data"] = data.copy()
                        logging.warning(f"Following exception occured - {e}")
                else:
                    ele["output_data"] = data.copy()
                element_flow_dict[elementid] = ele

            elif i["parent"] != "#":

                try:
                    if i["text"] == "Import Data":
                        if config_dict.get("data_mapper"):
                            if config_dict["data_mapper"].get("parentData"):
                                mapper_element = config_dict["data_mapper"]["parentData"]
                                config_dict["data_mapper"]["data_source"] = element_flow_dict[mapper_element][
                                    "output_data"
                                ]
                            else:
                                pass
                        else:
                            pass
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            elementid=elementid,
                            scenario_name=scenario_name,
                            scenario_id=scenario_id,
                            scenario_config=scenario_config,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "Goodness Of Fit Test":
                        select_data = json.loads(config_dict["inputs"]["Data"])
                        input_data_dict = input_data_element(
                            elementid,
                            select_data[0],
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            elementid=elementid,
                            data=[input_data_dict],
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "IR Curve Bootstrapping":
                        input_data_dict = {}
                        market_data_key = config_dict["inputs"]["market_data"]
                        if market_data_key != "" and market_data_key in element_flow_dict:
                            market_data = input_data_element(
                                elementid,
                                market_data_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["market_data"] = market_data
                        curve_data_key = config_dict["inputs"]["curve_data"]
                        if curve_data_key != "" and curve_data_key in element_flow_dict:
                            curve_data = input_data_element(
                                elementid,
                                curve_data_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["curve_data"] = curve_data
                        curve_components_data_key = config_dict["inputs"]["curve_components_data"]
                        if curve_components_data_key != "" and curve_components_data_key in element_flow_dict:
                            curve_components_data = input_data_element(
                                elementid,
                                curve_components_data_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["curve_components_data"] = curve_components_data
                        (
                            data,
                            frontend_output,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            elementid=elementid,
                            data=input_data_dict,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "CART" or i["text"] == "CART Algorithm":
                        input_data_dict = {}
                        username = request
                        config_dict["username"] = username
                        config_dict["element_id"] = elementid
                        train_data = config_dict["inputs"]["Data"]["training"]
                        test_data = config_dict["inputs"]["Data"]["testing"]
                        mapping_data = config_dict["inputs"]["Data"].get("mapping")
                        input_data_dict["train"] = input_data_element(
                            elementid,
                            train_data,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["test"] = input_data_element(
                            elementid,
                            test_data,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        mapping_dataset = input_data_element(
                            elementid,
                            mapping_data,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        if isinstance(mapping_dataset, pd.DataFrame):
                            if len(mapping_dataset):
                                input_data_dict["mapping"] = mapping_dataset
                        else:
                            input_data_dict["mapping"] = mapping_dataset
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_dict,
                            elementid=elementid,
                            scenario_name=scenario_name,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "Boosting Algorithm":
                        input_data_dict = {}
                        username = request
                        config_dict["username"] = username
                        config_dict["element_id"] = elementid
                        train_data = config_dict["inputs"]["Data"]["training"]
                        test_data = config_dict["inputs"]["Data"]["testing"]
                        mapping_data = config_dict["inputs"]["Data"].get("mapping")
                        input_data_dict["train"] = input_data_element(
                            elementid,
                            train_data,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["test"] = input_data_element(
                            elementid,
                            test_data,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        mapping_dataset = input_data_element(
                            elementid,
                            mapping_data,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        if isinstance(mapping_dataset, pd.DataFrame):
                            if len(mapping_dataset):
                                input_data_dict["mapping"] = mapping_dataset
                        else:
                            input_data_dict["mapping"] = mapping_dataset
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_dict,
                            elementid=elementid,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "Optimiser":
                        config_dict["user_name"] = request
                        input_data_dict = {}
                        if len(config_dict["inputs"]["data_mapping"]) == 2:
                            prices_key = config_dict["inputs"]["data_mapping"]["prices"]
                            constraints_key = config_dict["inputs"]["data_mapping"]["constraint"]
                            position_key = config_dict["inputs"]["data_mapping"]["positions_data"]
                            cashflow_key = config_dict["inputs"]["data_mapping"]["cashflow_data"]
                            security_key = config_dict["inputs"]["data_mapping"]["security_expected_returns"]
                            measure_key = config_dict["inputs"]["data_mapping"]["measure_data"]
                            benchmark_cashflow_key = config_dict["inputs"]["data_mapping"][
                                "benchmark_cashflow_data"
                            ]
                            security_liquidity_key = config_dict["inputs"]["data_mapping"][
                                "security_liquidity_data"
                            ]
                            uploaded_constraints_key = config_dict["inputs"]["data_mapping"][
                                "uploaded_constraints"
                            ]
                            input_data_dict["prices"] = input_data_element(
                                elementid,
                                prices_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["constraints"] = input_data_element(
                                elementid,
                                constraints_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["position_data"] = input_data_element(
                                elementid,
                                position_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["cashflow_data"] = input_data_element(
                                elementid,
                                cashflow_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["security_data"] = input_data_element(
                                elementid,
                                security_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["measure_data"] = input_data_element(
                                elementid,
                                measure_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["benchmark_cashflow_data"] = input_data_element(
                                elementid,
                                benchmark_cashflow_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["security_liquidity_data"] = input_data_element(
                                elementid,
                                security_liquidity_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["uploaded_constraints"] = input_data_element(
                                elementid,
                                uploaded_constraints_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )

                        else:
                            prices_key = config_dict["inputs"]["data_mapping"]["prices"]
                            constraints_key = config_dict["inputs"]["data_mapping"]["constraint"]
                            position_key = config_dict["inputs"]["data_mapping"]["positions_data"]
                            cashflow_key = config_dict["inputs"]["data_mapping"]["cashflow_data"]
                            security_key = config_dict["inputs"]["data_mapping"]["security_expected_returns"]
                            measure_key = config_dict["inputs"]["data_mapping"]["measure_data"]
                            benchmark_cashflow_key = config_dict["inputs"]["data_mapping"][
                                "benchmark_cashflow_data"
                            ]
                            security_liquidity_key = config_dict["inputs"]["data_mapping"][
                                "security_liquidity_data"
                            ]
                            uploaded_constraints_key = config_dict["inputs"]["data_mapping"][
                                "uploaded_constraints"
                            ]
                            input_data_dict["prices"] = input_data_element(
                                elementid,
                                prices_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["constraints"] = input_data_element(
                                elementid,
                                constraints_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["position_data"] = input_data_element(
                                elementid,
                                position_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["cashflow_data"] = input_data_element(
                                elementid,
                                cashflow_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["security_data"] = input_data_element(
                                elementid,
                                security_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["measure_data"] = input_data_element(
                                elementid,
                                measure_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["benchmark_cashflow_data"] = input_data_element(
                                elementid,
                                benchmark_cashflow_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["security_liquidity_data"] = input_data_element(
                                elementid,
                                security_liquidity_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                            input_data_dict["uploaded_constraints"] = input_data_element(
                                elementid,
                                uploaded_constraints_key,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_dict,
                            elementid=elementid,
                            scenario_name=scenario_name,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "Portfolio Valuation":
                        input_data_dict = {}
                        positions_key = config_dict["inputs"]["Data_mapper"]["positions"]
                        product_key = config_dict["inputs"]["Data_mapper"]["product_data"]
                        nmd_data_key = config_dict["inputs"]["Data_mapper"]["nmd_data"]
                        dpd_data_key = config_dict["inputs"]["Data_mapper"]["dpd_data"]
                        overdue_data_key = config_dict["inputs"]["Data_mapper"]["overdue_data"]
                        dpd_schedule_key = config_dict["inputs"]["Data_mapper"]["dpd_schedule"]
                        market_data_key = config_dict["inputs"]["Data_mapper"]["market_data"]
                        cashflow_data_uploaded_key = config_dict["inputs"]["Data_mapper"][
                            "cashflow_data_uploaded"
                        ]
                        repayment_data_key = config_dict["inputs"]["Data_mapper"]["repayment_data"]
                        product_model_mapper_key = config_dict["inputs"]["Data_mapper"][
                            "product_model_mapper"
                        ]

                        input_data_dict["positions_table"] = input_data_element(
                            elementid,
                            positions_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["product_data"] = input_data_element(
                            elementid,
                            product_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )

                        input_data_dict["nmd_data"] = input_data_element(
                            elementid,
                            nmd_data_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["market_data"] = input_data_element(
                            elementid,
                            market_data_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["cashflow_data_uploaded"] = input_data_element(
                            elementid,
                            cashflow_data_uploaded_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["repayment_data"] = input_data_element(
                            elementid,
                            repayment_data_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["dpd_data"] = input_data_element(
                            elementid,
                            dpd_data_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["overdue_data"] = input_data_element(
                            elementid,
                            overdue_data_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["dpd_schedule"] = input_data_element(
                            elementid,
                            dpd_schedule_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["product_model_mapper_table"] = input_data_element(
                            elementid,
                            product_model_mapper_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        (
                            final_output,
                            data,
                            var_plot,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_dict,
                            elementid=elementid,
                            scenario_name=scenario_name,
                        )
                        ele["portfolio_display_output"] = final_output
                        ele["portfolio_display_var"] = var_plot
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] in [
                        "Schedule Generation",
                        "Cashflow Generation",
                        "TTM Calculation",
                        "Bootstrapping",
                        "Interpolation",
                        "Discount Factor Calculation",
                    ]:
                        input_data_dict = {}
                        data_mapper = config_dict["inputs"]["data"]
                        for key, item in data_mapper.items():
                            if item is not None:
                                input_data_dict[key] = input_data_element(
                                    elementid,
                                    item,
                                    element_flow_dict,
                                    flow_control_element,
                                    flow_control_parent_element,
                                )
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_dict,
                            elementid=elementid,
                            scenario_name=scenario_name,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "TWRR":
                        input_data_dict = {}
                        position_data_id = config_dict["inputs"]["data_mapping"]["position"]
                        cashflow_data_id = config_dict["inputs"]["data_mapping"]["cashflow"]
                        transaction_data_id = config_dict["inputs"]["data_mapping"]["transaction"]
                        input_data_dict["position"] = input_data_element(
                            elementid,
                            position_data_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["cashflow"] = input_data_element(
                            elementid,
                            cashflow_data_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["transaction"] = input_data_element(
                            elementid,
                            transaction_data_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_dict,
                            elementid=elementid,
                            scenario_name=scenario_name,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)
                        if message:
                            element_message = message

                    elif i["text"] == "Portfolio Metrics":
                        input_data_dict = {}
                        portfolio_element_id = config_dict["inputs"]["option_config"]["portfolio"]

                        if config_dict["inputs"]["option_config"].get("riskfree"):
                            riskfree_element_id = config_dict["inputs"]["option_config"]["riskfree"]
                        else:
                            riskfree_element_id = 1

                        if config_dict["inputs"]["option_config"].get("market"):
                            market_element_id = config_dict["inputs"]["option_config"]["market"]
                        else:
                            market_element_id = 1

                        input_data_dict["portfolio_data"] = input_data_element(
                            elementid,
                            portfolio_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["riskfree_data"] = input_data_element(
                            elementid,
                            riskfree_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["market_data"] = input_data_element(
                            elementid,
                            market_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_dict,
                            elementid=elementid,
                            scenario_name=scenario_name,
                        )

                    elif i["text"] == "Fit Discrete Distribution":
                        select_data = json.loads(config_dict["inputs"]["Data"])
                        input_data_dict = input_data_element(
                            elementid,
                            select_data[0],
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            elementid=elementid,
                            data=[input_data_dict],
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "Options":
                        input_data_dict = {}
                        data_id = config_dict["inputs"]["option_config"]["pos_data"]
                        vix_id = config_dict["inputs"]["option_config"]["vix_data"]
                        input_data_dict["pos_data"] = input_data_element(
                            elementid,
                            data_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["vix_data"] = input_data_element(
                            elementid,
                            vix_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )

                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_dict,
                            elementid=elementid,
                            scenario_name=scenario_name,
                        )

                    elif i["text"] == "ML Predict":
                        input_data_list = []
                        if "Data" in config_dict["inputs"]["data"]:
                            prediction_data_id = config_dict["inputs"]["data"]["Data"]
                            input_data_list.append(
                                input_data_element(
                                    elementid,
                                    prediction_data_id,
                                    element_flow_dict,
                                    flow_control_element,
                                    flow_control_parent_element,
                                )
                            )
                        else:
                            prediction_data_id = ""
                        config_dict["element_id"] = elementid
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_list,
                            elementid=elementid,
                            scenario_name=scenario_name,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)
                        if message:
                            element_message = message

                    elif i["text"] == "Copula":
                        input_dict = {"loss_amt_df": pd.DataFrame(), "scenerio_mapping": pd.DataFrame()}
                        loss_amt_id = config_dict["inputs"]["loss_amount_id"]
                        scenerio_percentile_id = config_dict["inputs"]["scenerio_percentile_id"]
                        input_dict["loss_amt_df"] = input_data_element(
                            elementid,
                            loss_amt_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        if scenerio_percentile_id:
                            input_dict["scenerio_mapping"] = input_data_element(
                                elementid,
                                scenerio_percentile_id,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_dict,
                            elementid=elementid,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "Monte Carlo":
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict, request_user=request, elementid=elementid
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "VaR Backtesting":
                        input_data_list = []
                        pt_element_id = config_dict["inputs"]["data"]
                        dt_key, bk_element_id = list(pt_element_id.items())[0]
                        input_data_list.append(
                            input_data_element(
                                elementid,
                                bk_element_id,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                        )

                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_list,
                            elementid=elementid,
                        )

                    elif i["text"] == "FX Options - Implied Volatility":
                        input_data_list = {}
                        position_element_id = config_dict["inputs"]["position_data"]
                        vol_element_id = config_dict["inputs"]["volatility_data"]
                        spot_elements_id = config_dict["inputs"]["spot_data"]

                        input_data_list["pos_data"] = input_data_element(
                            elementid,
                            position_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_list["vol_data"] = input_data_element(
                            elementid,
                            vol_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_list["spot_data"] = input_data_element(
                            elementid,
                            spot_elements_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_list,
                            elementid=elementid,
                        )

                    elif i["text"] == "If then Else":
                        input_data = input_data_element(
                            elementid,
                            i["parent"][0],
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        (
                            elements_not_to_run,
                            next_element,
                            flow_control_parent_element,
                        ) = computationFlowController(
                            flowchart_elements, elementid, config_dict, input_data, global_dict, l3_run=False
                        )
                        flow_control_element = elementid
                        if len(elements_not_to_run):
                            for ele_not in elements_not_to_run:
                                for fl_idx, fl_ele in enumerate(flowchart_elements):
                                    if fl_ele["element_id"] == ele_not:
                                        flowchart_elements.pop(fl_idx)
                            last_element_id = flowchart_elements[-1]["element_id"]
                        for fc_k, fc_data in next_element.items():
                            new_fc_k = elementid + fc_k
                            output_dict = {}
                            if isinstance(fc_data, pd.DataFrame):
                                try:
                                    file_name = (
                                        f"{new_fc_k}_{model_run_identifier}_{request.user.username}_{tenant}"
                                    )
                                    to_diskstorage(fc_data, file_name)
                                    output_dict["output_data"] = file_name
                                except Exception as e:
                                    output_dict["output_data"] = fc_data
                                    logging.warning(f"Following exception occured - {e}")
                            else:
                                output_dict["output_data"] = fc_data
                            element_flow_dict[new_fc_k] = output_dict

                    elif i["text"] == "Data Mapping":
                        input_dict = {"base_data": pd.DataFrame(), "mapping_ruleset": pd.DataFrame()}
                        base_data_id = config_dict["inputs"]["base_data"]
                        mapping_ruleset_id = config_dict["inputs"]["mapping_ruleset"]
                        input_dict["base_data"] = input_data_element(
                            elementid,
                            base_data_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_dict["mapping_ruleset"] = input_data_element(
                            elementid,
                            mapping_ruleset_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_dict,
                            elementid=elementid,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "Portfolio Validation":

                        input_dict = {
                            "positions_data": pd.DataFrame(),
                            "product_data": pd.DataFrame(),
                            "product_to_model_data": pd.DataFrame(),
                        }
                        positions_data_id = config_dict["inputs"]["positions_data"]
                        product_data_id = config_dict["inputs"]["product_data"]
                        product_to_model_data_id = config_dict["inputs"]["product_to_model_data"]
                        input_dict["positions_data"] = input_data_element(
                            elementid,
                            positions_data_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_dict["products_data"] = input_data_element(
                            elementid,
                            product_data_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )

                        input_dict["product_to_model_data"] = input_data_element(
                            elementid,
                            product_to_model_data_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )

                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_dict,
                            elementid=elementid,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                    elif i["text"] == "Workdays":
                        input_data_list = {}
                        position_element_id = config_dict["inputs"]["pos_data"]
                        hol_element_id = config_dict["inputs"]["hol_data"]

                        input_data_list["pos_data"] = input_data_element(
                            elementid,
                            position_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )

                        if hol_element_id != "":
                            input_data_list["hol_data"] = input_data_element(
                                elementid,
                                hol_element_id,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                        else:
                            input_data_list["hol_data"] = []

                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_list,
                            elementid=elementid,
                        )
                    elif i["text"] == "Workdays.Intl":
                        input_data_list = {}
                        position_element_id = config_dict["inputs"]["pos_data"]
                        hol_element_id = config_dict["inputs"]["hol_data"]

                        input_data_list["pos_data"] = input_data_element(
                            elementid,
                            position_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )

                        if hol_element_id != "":
                            input_data_list["hol_data"] = input_data_element(
                                elementid,
                                hol_element_id,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                        else:
                            input_data_list["hol_data"] = []

                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_list,
                            elementid=elementid,
                        )
                    elif i["text"] == "Networkdays":
                        input_data_list = {}
                        position_element_id = config_dict["inputs"]["pos_data"]
                        hol_element_id = config_dict["inputs"]["hol_data"]

                        input_data_list["pos_data"] = input_data_element(
                            elementid,
                            position_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_list["hol_data"] = input_data_element(
                            elementid,
                            hol_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )

                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_list,
                            elementid=elementid,
                        )
                    elif i["text"] == "Networkdays.Intl":
                        input_data_list = {}
                        position_element_id = config_dict["inputs"]["pos_data"]
                        hol_element_id = config_dict["inputs"]["hol_data"]

                        input_data_list["pos_data"] = input_data_element(
                            elementid,
                            position_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )

                        if hol_element_id != "":
                            input_data_list["hol_data"] = input_data_element(
                                elementid,
                                hol_element_id,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                        else:
                            input_data_list["hol_data"] = []

                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_list,
                            elementid=elementid,
                        )
                    else:
                        input_data_list = []
                        for p_elem in i["parent"]:
                            input_data_list.append(
                                input_data_element(
                                    elementid,
                                    p_elem,
                                    element_flow_dict,
                                    flow_control_element,
                                    flow_control_parent_element,
                                )
                            )
                        if i["text"] == "Export Data":
                            (
                                data,
                                output_type_export,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=input_data_list,
                                elementid=elementid,
                                run_model=False,
                            )
                            ele["output_type"] = output_type_export
                            ele["element_id"] = elementid
                            ele["output_msg"] = data_error
                            extra_config.append({elementid: data_error})
                            data_error = ""
                        else:
                            username = request
                            config_dict["username"] = username
                            config_dict["element_id"] = elementid
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=input_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                            )
                            for exp_mes in result_save_list:
                                inter_output_export_message_list.append(exp_mes)
                    if data_error:
                        errorElement = i["text"]
                        if isinstance(data_error, str):
                            element_message = f"Error running {errorElement}! {data_error}"
                        else:
                            element_message = f"Error running {errorElement}!"
                            for de in data_error:
                                element_message += f"\n{de}"
                        break

                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    errorElement = i["text"]
                    element_message = f"Error running {errorElement}! {e}"
                    data = pd.DataFrame()
                    break

                if isinstance(data, pd.DataFrame) and not in_memory_execution:
                    try:
                        file_name = f"{elementid}_{model_run_identifier}_{request.user.username}_{tenant}"
                        to_diskstorage(data, file_name)
                        ele["output_data"] = file_name
                    except Exception as e:
                        ele["output_data"] = data.copy()
                        logging.warning(f"Following exception occured - {e}")
                else:
                    ele["output_data"] = data.copy()
                element_flow_dict[elementid] = ele

            else:
                pass
        else:
            ele = {"function": i["text"], "parent": i["parent"], "child": i["child"]}
            elementid = i["element_id"]
            element_config = element_config_data[element_config_data["element_id"] == elementid]

            elecon_dict = element_config.iloc[0, 0]
            config_dict = json.loads(elecon_dict)
            if config_dict["inputs"].get("variables"):
                vList = config_dict["inputs"].get("variables")
                if len(vList) > 0:
                    for indx, v in enumerate(vList):
                        if v["dataType"] == "date-autonow":
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = str(
                                datetime.now().strftime("%Y-%m-%d")
                            )
                        elif v["dataType"] == "datetime-local-autonow":
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = str(
                                datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            )
                        elif v["dataType"] == "current_user":
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = str(
                                request.user.username
                            )
                        elif v["dataType"] == "dynamic-date":
                            vartype = v["option"]
                            if vartype == "n_day_ago":
                                default_value = datetime.now() - relativedelta(days=int(v["nDays"]))
                                default_value = default_value.date()
                            elif vartype == "n_month_ago":
                                default_value = datetime.now() - relativedelta(months=int(v["nDays"]))
                                default_value = default_value.date()
                            elif vartype == "today":
                                default_value = datetime.now().date()
                            elif vartype == "yesterday":
                                default_value = datetime.now() - relativedelta(days=1)
                                default_value = default_value.date()
                            elif vartype == "last_week":
                                default_value = datetime.now() - relativedelta(days=7)
                                default_value = default_value.date()
                            elif vartype == "last_month":
                                default_value = datetime.now() - relativedelta(months=1)
                                default_value = default_value.date()
                            elif vartype == "last_year":
                                default_value = datetime.now() - relativedelta(years=1)
                                default_value = default_value.date()
                            else:
                                default_value = ""
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = str(default_value)
                        elif v["dataType"] == "dynamic-datetime":
                            vartype = v["option"]
                            if vartype == "n_day_ago":
                                default_value = datetime.now() - relativedelta(days=int(v["nDays"]))
                                default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                            elif vartype == "n_month_ago":
                                default_value = datetime.now() - relativedelta(months=int(v["nDays"]))
                                default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                            elif vartype == "n_min_ago":
                                default_value = datetime.now() - relativedelta(minutes=int(v["nDays"]))
                                default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                            elif vartype == "n_hour_ago":
                                default_value = datetime.now() - relativedelta(hours=int(v["nDays"]))
                                default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                            elif vartype == "now":
                                default_value = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            else:
                                default_value = ""
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = default_value

            if i["text"] == "ML Predict" and (
                config_dict["inputs"]["mlModel"].startswith("trainEWMA")
                | config_dict["inputs"]["mlModel"].startswith("trainARIMA")
                | config_dict["inputs"]["mlModel"].startswith("trainGARCH")
            ):
                if config_dict["inputs"].get("global_no_of_steps"):
                    global_no_of_steps_ahead = config_dict["inputs"]["global_no_of_steps"]
                else:
                    global_no_of_steps_ahead = ""

                if global_no_of_steps_ahead != "":
                    for g in global_dict["inputs"]["variables"]:
                        if global_no_of_steps_ahead == g["varName"]:
                            if g["varName"] in multi_run_vars:
                                config_dict["inputs"]["no_of_steps"] = g["defaultValue"][run]
                            else:
                                config_dict["inputs"]["no_of_steps"] = g["defaultValue"]
                    for g in global_dict["inputs"]["mapper_variables"]:
                        if global_no_of_steps_ahead == g["varName"]:
                            config_dict["inputs"]["no_of_steps"] = g["defaultValue"]

            if i["text"] in ["Interest Rate Products", "Equities", "Mutual Fund", "ML Predict"]:
                if i["text"] == "ML Predict":
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                    if message:
                        element_message = message
                else:
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                for exp_mes in result_save_list:
                    inter_output_export_message_list.append(exp_mes)

                if isinstance(data, pd.DataFrame) and not in_memory_execution:
                    try:
                        file_name = f"{elementid}_{model_run_identifier}_{request.user.username}_{tenant}"
                        to_diskstorage(data, file_name)
                        ele["output_data"] = file_name
                    except Exception as e:
                        ele["output_data"] = data.copy()
                        logging.warning(f"Following exception occured - {e}")
                else:
                    ele["output_data"] = data.copy()
                element_flow_dict[elementid] = ele

                if data_error:
                    errorElement = i["text"]
                    if isinstance(data_error, str):
                        element_message = f"Error running {errorElement}! {data_error}"
                    else:
                        element_message = f"Error running {errorElement}!"
                        for de in data_error:
                            element_message += f"\n{de}"
                    break

        if index != len(flowchart_elements) - 1 and run > 0:
            intermediate_output = {
                "current_element": i["text"],
                "next_element": flowchart_elements[index + 1]["text"],
                "inter_comp_per": ((index + 1) / len(flowchart_elements)),
                "element_message": element_message,
                "inter_output_export_message_list": inter_output_export_message_list,
                "run": run,
            }
            computation_storage(
                intermediate_output,
                "exception",
                db_connection_name + f"intermediate_multi_run_process_{model_name.replace('/', '')}",
            )
        if last_run_element and last_run_element == elementid:
            if isinstance(element_flow_dict[elementid]["output_data"], str):
                return read_diskstorage(element_flow_dict[elementid]["output_data"])
            else:
                return element_flow_dict[elementid]["output_data"]

    context["element_error_message"] = element_message
    context["inter_output_export_message_list"] = inter_output_export_message_list
    context["extra_config"] = extra_config
    output_elements = [out for out in output_elements if out in element_flow_dict]
    if not output_elements:
        context["output_display_type"] = "individual"
        if element_message == "Success":
            last_element_name = element_flow_dict[last_element_id]["function"]
            context["name"] = last_element_name

            context["last_element_id"] = last_element_id
            if isinstance(element_flow_dict[elementid]["output_data"], str):
                new_data = read_diskstorage(element_flow_dict[elementid]["output_data"])
            else:
                new_data = element_flow_dict[last_element_id]["output_data"]

            if last_element_name in [
                "Logistic Regression",
                "Linear Regression",
                "CART",
                "CART Algorithm",
                "Boosting Algorithm",
                "Copula",
                "Goodness Of Fit Test",
                "Fit Discrete Distribution",
                "Optimiser",
                "Interest Rate Products",
                "Equities",
                "Mutual Fund",
                "Analyse Time Series Data",
                "Train an ARIMA Model",
                "Train a GARCH Model",
                "Train an EWMA Model",
            ]:
                context["content"] = new_data
            elif last_element_name == "Portfolio Valuation":
                context["content"] = {
                    "output": json.dumps(
                        [
                            element_flow_dict[last_element_id]["portfolio_display_output"]
                            .head(100)
                            .to_dict("records"),
                        ],
                        cls=NpEncoder,
                    ),
                    "var_plot": element_flow_dict[last_element_id]["portfolio_display_var"],
                }
            elif last_element_name == "IR Curve Bootstrapping":
                context["content"] = frontend_output
            elif last_element_name == "VaR Backtesting":
                for key, value in new_data.items():
                    if isinstance(value, pd.DataFrame):
                        value = value.iloc[:, :150].head(100)
                        for col in value.columns:
                            if value[col].dtypes.name == "datetime64[ns]":
                                value[col] = value[col].dt.strftime("%Y-%m-%d %H:%M:%S")
                            else:
                                if value[col].dtypes.name == "float64":
                                    value[col] = value[col].round(4)
                                value[col] = value[col].astype("str")
                        new_data[key] = value.fillna("-").to_dict("records")
                context["content"] = new_data
            else:
                context["content"] = new_data
    else:
        context["output_display_type"] = "custom"
        context["output_elements"] = []
        if element_message == "Success":
            for otp_ele in output_elements:
                run_process_output_dict = {}
                last_element_name = element_flow_dict[otp_ele]["function"]
                run_process_output_dict["name"] = last_element_name
                run_process_output_dict["last_element_id"] = otp_ele
                run_process_output_dict["last_element_name"] = element_flow_dict[otp_ele]["element_name"]

                if isinstance(element_flow_dict[otp_ele]["output_data"], str):
                    new_data = read_diskstorage(element_flow_dict[otp_ele]["output_data"])
                else:
                    new_data = element_flow_dict[otp_ele]["output_data"]

                if last_element_name in [
                    "Logistic Regression",
                    "Linear Regression",
                    "CART",
                    "CART Algorithm",
                    "Boosting Algorithm",
                    "Copula",
                    "Goodness Of Fit Test",
                    "Fit Discrete Distribution",
                    "Optimiser",
                    "Interest Rate Products",
                    "Equities",
                    "Mutual Fund",
                    "Analyse Time Series Data",
                    "Train an ARIMA Model",
                    "Train a GARCH Model",
                    "Train an EWMA Model",
                ]:
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Portfolio Valuation":
                    run_process_output_dict["content"] = {
                        "output": json.dumps(
                            [
                                element_flow_dict[otp_ele]["portfolio_display_output"]
                                .head(100)
                                .to_dict("records"),
                            ],
                            cls=NpEncoder,
                        ),
                        "var_plot": element_flow_dict[otp_ele]["portfolio_display_var"],
                    }
                elif last_element_name == "IR Curve Bootstrapping":
                    run_process_output_dict["content"] = frontend_output
                elif last_element_name == "VaR Backtesting":
                    for key, value in new_data.items():
                        if isinstance(value, pd.DataFrame):
                            value = value.iloc[:, :150].head(100)
                            for col in value.columns:
                                if value[col].dtypes.name == "datetime64[ns]":
                                    value[col] = value[col].dt.strftime("%Y-%m-%d %H:%M:%S")
                                else:
                                    if value[col].dtypes.name == "float64":
                                        value[col] = value[col].round(4)
                                    value[col] = value[col].astype("str")
                            new_data[key] = value.fillna("-").to_dict("records")
                    run_process_output_dict["content"] = new_data
                else:
                    run_process_output_dict["content"] = new_data
                context["output_elements"].append(run_process_output_dict)

    return context


def run_model_run_handler(
    request,
    flowchart_elements,
    config,
    global_dict,
    global_element_id,
    run=0,
    element_id="",
    scenario_name=None,
    scenario_id=None,
    scenario_config=None,
    output_elements=[],
    transaction_id="NULL",
    data_pass_on_config={},
    child_element_id_email_box=[],
    in_memory_execution=True,
):
    if isinstance(request, dict):

        class AttrDict:
            def __init__(self, i_dict):
                for key, value in i_dict.items():
                    if key not in ["password", "last_login", "date_joined"]:
                        setattr(self, key, value)
                if i_dict.get("username"):
                    setattr(self, "is_anonymous", False)
                else:
                    setattr(self, "is_anonymous", True)

            def get_host(self):
                return self.host

        request["user"] = AttrDict(request["user"])
        request = AttrDict(request)
    request_user = request.user.username
    tenant = tenant_schema_from_request(request)
    curr_app_code, db_connection_name = current_app_db_extractor(request)
    model_name = config["model"]
    variable_list = config["configGlobalDict"]
    if global_dict.get("inputs") not in [None]:
        if global_dict["inputs"].get("variables"):
            vList1 = global_dict["inputs"].get("variables")
            if len(vList1) > 0:
                for i, v in enumerate(vList1):
                    if v["dataType"] == "date-autonow":
                        varDict = {
                            "varName": v["varName"],
                            "inputValue": str(datetime.now().strftime("%Y-%m-%d")),
                        }
                        variable_list.append(varDict)
                    elif v["dataType"] == "datetime-local-autonow":
                        varDict = {
                            "varName": v["varName"],
                            "inputValue": str(datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
                        }
                        variable_list.append(varDict)
                    elif v["dataType"] == "current_user":
                        varDict = {
                            "varName": v["varName"],
                            "inputValue": str(request_user),
                        }
                        variable_list.append(varDict)
                    elif v["dataType"] == "dynamic-date":
                        vartype = v["option"]
                        if vartype == "n_day_ago":
                            default_value = datetime.now() - relativedelta(days=int(v["nDays"]))
                            default_value = default_value.date()
                        elif vartype == "n_month_ago":
                            default_value = datetime.now() - relativedelta(months=int(v["nDays"]))
                            default_value = default_value.date()
                        elif vartype == "today":
                            default_value = datetime.now().date()
                        elif vartype == "yesterday":
                            default_value = datetime.now() - relativedelta(days=1)
                            default_value = default_value.date()
                        elif vartype == "last_week":
                            default_value = datetime.now() - relativedelta(days=7)
                            default_value = default_value.date()
                        elif vartype == "last_month":
                            default_value = datetime.now() - relativedelta(months=1)
                            default_value = default_value.date()
                        elif vartype == "last_year":
                            default_value = datetime.now() - relativedelta(years=1)
                            default_value = default_value.date()
                        else:
                            default_value = ""
                        varDict = {
                            "varName": v["varName"],
                            "inputValue": str(default_value),
                        }
                        variable_list.append(varDict)
                    elif v["dataType"] == "dynamic-datetime":
                        vartype = v["option"]
                        if vartype == "n_day_ago":
                            default_value = datetime.now() - relativedelta(days=int(v["nDays"]))
                            default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                        elif vartype == "n_month_ago":
                            default_value = datetime.now() - relativedelta(months=int(v["nDays"]))
                            default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                        elif vartype == "n_min_ago":
                            default_value = datetime.now() - relativedelta(minutes=int(v["nDays"]))
                            default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                        elif vartype == "n_hour_ago":
                            default_value = datetime.now() - relativedelta(hours=int(v["nDays"]))
                            default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                        elif vartype == "now":
                            default_value = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        else:
                            default_value = ""
                        varDict = {
                            "varName": v["varName"],
                            "inputValue": default_value,
                        }
                        variable_list.append(varDict)

                for v_idx, var_dict in enumerate(variable_list):
                    data_type = [
                        config_vars["dataType"]
                        for config_vars in vList1
                        if config_vars["varName"] == var_dict["varName"]
                    ]
                    if data_type:
                        data_type = data_type[0]
                    else:
                        data_type = "text"
                    var_dict["dataType"] = data_type
                    variable_list[v_idx] = var_dict
    global_function_list = config["configGlobalFunc"]
    element_flow_dict = {}
    last_element_id = flowchart_elements[-1]["element_id"]
    context = {}
    output_type = ""
    element_message = "Success"
    inter_output_export_message_list = []
    extra_config = []

    flow_control_element = "###"
    flow_control_parent_element = "###"

    if len(global_dict) > 0:
        if global_dict["inputs"].get("multi_run_vars"):
            multi_run_vars = global_dict["inputs"].get("multi_run_vars")
        else:
            multi_run_vars = []
        if global_dict["inputs"].get("mapper_variables"):
            variableMapperList = global_dict["inputs"]["mapper_variables"]
            if len(variableMapperList) > 0:
                mapper_lister = []
                globalMapperDict = {}
                global_mapper_config = global_dict["inputs"]["mapperConfig"]
                table_name = global_mapper_config["mapperTable"]
                column_name = global_mapper_config["mapperColumn"]
                defaultVal = global_mapper_config["globalDefaultVal"]

                for mapp_vars in variable_list:
                    if mapp_vars["varName"] == global_mapper_config["globalMapperName"]:
                        if mapp_vars["varName"] in multi_run_vars:
                            defaultVal = mapp_vars["inputValue"][run]
                        elif "dataType" in mapp_vars:
                            if mapp_vars["dataType"] == "dropdown-multiple":
                                defaultVal = mapp_vars["inputValue"][0]
                            else:
                                defaultVal = mapp_vars["inputValue"]
                        else:
                            defaultVal = mapp_vars["inputValue"]
                actual_model_name = dynamic_model_create.get_model_class(table_name, request)

                columns_list = [field.name for field in actual_model_name.concrete_fields]

                test_data = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": table_name,
                            "Columns": columns_list,
                        },
                        "condition": [
                            {
                                "column_name": column_name,
                                "condition": "Equal to",
                                "input_value": defaultVal,
                                "and_or": "",
                            }
                        ],
                    },
                )
                for g_map_vars in global_mapper_config["NewVariablesGlobal"]:
                    if g_map_vars["dataType"] == "date":
                        test_data[g_map_vars["associatedColumn"]] = pd.to_datetime(
                            test_data[g_map_vars["associatedColumn"]]
                        ).dt.date
                    elif g_map_vars["dataType"] == "datetime":
                        test_data[g_map_vars["associatedColumn"]] = pd.to_datetime(
                            test_data[g_map_vars["associatedColumn"]]
                        )
                    else:
                        pass
                    globalMapperDict = {
                        "varName": g_map_vars["varName"],
                        "inputValue": str(test_data[g_map_vars["associatedColumn"]].values[-1]),
                        "dataType": g_map_vars["dataType"],
                    }
                    mapper_lister.append(globalMapperDict)
                variable_list += mapper_lister
    element_config_data = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_configuration",
                "Columns": ["element_config", "element_id", "element_name"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": model_name,
                    "and_or": "",
                }
            ],
        },
    )
    for index, i in enumerate(flowchart_elements):
        if (i["parent"] != "#") | (i["child"] != "#"):
            ele = {"function": i["text"], "parent": i["parent"], "child": i["child"]}
            elementid = i["element_id"]
            element_config = element_config_data[element_config_data["element_id"] == elementid]
            elecon_dict = element_config.element_config.iloc[0]
            element_name = element_config.element_name.iloc[0]
            config_dict = json.loads(elecon_dict)
            ele["element_name"] = element_name
            if i["text"] == "Basic Aggregates":
                if not config_dict["inputs"].get("agg_config"):
                    config_dict_new = {
                        "function": "Elementary Statistics",
                        "inputs": {
                            "data": config_dict["inputs"]["data"],
                            "Type": config_dict["inputs"]["Type"],
                            "Groupby_column": config_dict["inputs"]["Groupby_column"],
                            "agg_config": [
                                {
                                    "Value_column": config_dict["inputs"]["Value_column"],
                                    "Sum_product_column": config_dict["inputs"]["Sum_product_column"],
                                    "Aggregate": config_dict["inputs"]["Aggregate"],
                                    "new_column_name": config_dict["inputs"]["new_column_name"],
                                    "Weights": config_dict["inputs"]["Weights"],
                                    "Conditional": config_dict["inputs"]["Conditional"],
                                }
                            ],
                        },
                        "outputs": config_dict["outputs"],
                    }
                    config_dict = config_dict_new.copy()

            if len(variable_list) > 0:
                if i["text"] == "Import Data":
                    data_source = config_dict["inputs"]["Data_source"]
                    if data_source == "Database":
                        condition_list = config_dict["condition"]
                        if config_dict.get("adv_condition"):
                            adv_condition_list = config_dict["adv_condition"]
                        else:
                            adv_condition_list = []
                        for cond in condition_list:
                            if cond["globalVariable"] != "":
                                for g in variable_list:
                                    if cond["globalVariable"] == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            if re.search(
                                                r"^\d{2}-\d{2}-\d{4}",
                                                g["inputValue"][run],
                                            ):
                                                g["inputValue"][run] = pd.to_datetime(
                                                    g["inputValue"][run]
                                                ).strftime("%Y-%m-%d %H:%M:%S")
                                            cond["input_value"] = g["inputValue"][run]
                                        else:
                                            if type(g["inputValue"]) == list:
                                                g_input_value = []
                                                for s in g["inputValue"]:
                                                    if re.search(r"^\d{2}-\d{2}-\d{4}", s):
                                                        s = pd.to_datetime(s).strftime(
                                                            "%Y-%m-%d %H:%M:%S"
                                                        )
                                                        g_input_value.append(s)
                                                    else:
                                                        g_input_value.append(s)
                                            else:
                                                if re.search(r"^\d{2}-\d{2}-\d{4}", g["inputValue"]) and g[
                                                    "dataType"
                                                ] in ["date", "datetime-local"]:
                                                    g["inputValue"] = pd.to_datetime(
                                                        g["inputValue"]
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                    g_input_value = g["inputValue"]
                                                else:
                                                    g_input_value = g["inputValue"]
                                            cond["input_value"] = g_input_value
                        config_dict["scenario_global_dict"] = variable_list
                        config_dict["condition"] = condition_list
                        for cond in adv_condition_list:
                            if cond["globalVariable"] != "":
                                for g in variable_list:
                                    if cond["globalVariable"] == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            if re.search(
                                                r"^\d{2}-\d{2}-\d{4}",
                                                g["inputValue"][run],
                                            ):
                                                g["inputValue"][run] = pd.to_datetime(
                                                    g["inputValue"][run]
                                                ).strftime("%Y-%m-%d %H:%M:%S")
                                            cond["input_value"] = g["inputValue"][run]
                                        else:
                                            if type(g["inputValue"]) == list:
                                                g_input_value = []
                                                for s in g["inputValue"]:
                                                    if re.search(r"^\d{2}-\d{2}-\d{4}", s):
                                                        s = pd.to_datetime(s).strftime(
                                                            "%Y-%m-%d %H:%M:%S"
                                                        )
                                                        g_input_value.append(s)
                                                    else:
                                                        g_input_value.append(s)
                                            else:
                                                if re.search(r"^\d{2}-\d{2}-\d{4}", g["inputValue"]) and g[
                                                    "dataType"
                                                ] in ["date", "datetime-local"]:
                                                    g["inputValue"] = pd.to_datetime(
                                                        g["inputValue"]
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                    g_input_value = g["inputValue"]
                                                else:
                                                    g_input_value = g["inputValue"]
                                            cond["input_value"] = g_input_value
                        config_dict["adv_condition"] = adv_condition_list
                    elif data_source == "CSV":
                        import_data_csv_global = config_dict["inputs"]["global_var"]
                        if import_data_csv_global != "":
                            csv_global_data = global_element_id + import_data_csv_global
                        else:
                            csv_global_data = f"{elementid}"
                    elif data_source == "JSON":
                        import_data_csv_global_json = config_dict["inputs"]["global_var"]
                        if import_data_csv_global_json != "":
                            json_global_data = global_element_id + import_data_csv_global_json
                        else:
                            if redis_instance.exists(elementid) == 1:
                                json_global_data = pickle.loads(redis_instance.get(elementid))
                    elif data_source == "Parquet":
                        import_data_csv_global_pq = config_dict["inputs"]["global_var"]
                        if import_data_csv_global_pq != "":
                            pq_global_data = global_element_id + import_data_csv_global_pq
                        else:
                            if redis_instance.exists(elementid) == 1:
                                pq_global_data = pickle.loads(redis_instance.get(elementid))
                    elif data_source == "XML":
                        if redis_instance.exists(elementid) == 1:
                            pq_global_data = pickle.loads(redis_instance.get(elementid))
                        else:
                            pass
                    elif data_source == "Model_output":
                        config_dict["current_global_dict"] = variable_list
                        config_dict["current_run"] = run
                        config_dict["scenario_global_dict"] = variable_list
                        condition_list = config_dict["inputs"]["condition"]
                        for cond in condition_list:
                            if cond["globalVariable"] != "":
                                for g in global_dict["inputs"]["variables"]:
                                    if cond["globalVariable"] == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            cond["input_value"] = g["defaultValue"][run]
                                        else:
                                            cond["input_value"] = g["defaultValue"]
                                for g in global_dict["inputs"]["mapper_variables"]:
                                    if cond["globalVariable"] == g["varName"]:
                                        cond["input_value"] = g["defaultValue"]
                        config_dict["inputs"]["condition"] = condition_list

                    elif data_source == "Redis":
                        import_data_csv_global_rd = config_dict["inputs"]["global_var"]
                        redis_element_id = config_dict["inputs"]["RedisTable"]
                        if import_data_csv_global_rd != "":
                            rd_global_data = global_element_id + import_data_csv_global_rd
                        else:
                            if redis_instance.exists(redis_element_id) == 1:
                                rd_global_data = pickle.loads(redis_instance.get(redis_element_id))

                elif i["text"] == "Data Transformation":
                    final_config = config_dict["inputs"]["final_config"]
                    if final_config["groupby"] != "":
                        groupby_config = final_config["groupby"]
                        option = groupby_config["inputs"]["option"]
                        option_config = groupby_config["inputs"]["option_config"]
                        if option == "where":
                            condition_list = option_config["condition"]
                            for cond in condition_list:
                                if cond["globalVariable"]:
                                    for g in variable_list:
                                        if cond["globalVariable"] == g["varName"]:
                                            if g["varName"] in multi_run_vars:
                                                if re.search(
                                                    r"^\d{2}-\d{2}-\d{4}",
                                                    g["inputValue"][run],
                                                ):
                                                    g["inputValue"][run] = pd.to_datetime(
                                                        g["inputValue"][run],
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                cond["input_value"] = g["inputValue"][run]
                                            else:
                                                if re.search(
                                                    r"^\d{2}-\d{2}-\d{4}",
                                                    g["inputValue"],
                                                ) and g[
                                                    "dataType"
                                                ] in ["date", "datetime-local"]:
                                                    g["inputValue"] = pd.to_datetime(
                                                        g["inputValue"]
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                cond["input_value"] = g["inputValue"]
                            groupby_config["inputs"]["option_config"]["condition"] = condition_list
                        elif option == "addCondColumn":
                            condition_list = option_config["condition"]["condition"]
                            for cond in condition_list:
                                if cond["globalVariable"]:
                                    for g in variable_list:
                                        if cond["globalVariable"] == g["varName"]:
                                            if g["varName"] in multi_run_vars:
                                                if re.search(
                                                    r"^\d{2}-\d{2}-\d{4}",
                                                    g["inputValue"][run],
                                                ):
                                                    g["inputValue"][run] = pd.to_datetime(
                                                        g["inputValue"][run],
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                cond["input_value"] = g["inputValue"][run]
                                            else:
                                                if re.search(
                                                    r"^\d{2}-\d{2}-\d{4}",
                                                    g["inputValue"],
                                                ) and g[
                                                    "dataType"
                                                ] in ["date", "datetime-local"]:
                                                    g["inputValue"] = pd.to_datetime(
                                                        g["inputValue"],
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                cond["condition_value"] = g["inputValue"]
                                if cond["repr_value"]["global_var"]:
                                    for g in variable_list:
                                        if cond["repr_value"]["global_var"] == g["varName"]:
                                            if g["varName"] in multi_run_vars:
                                                if re.search(
                                                    r"^\d{2}-\d{2}-\d{4}",
                                                    g["inputValue"][run],
                                                ):
                                                    g["inputValue"][run] = pd.to_datetime(
                                                        g["inputValue"][run],
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                cond["repr_value"]["repr_value"] = g["inputValue"][run]
                                            else:
                                                if re.search(
                                                    r"^\d{2}-\d{2}-\d{4}",
                                                    g["inputValue"],
                                                ) and g[
                                                    "dataType"
                                                ] in ["date", "datetime-local"]:
                                                    g["inputValue"] = pd.to_datetime(
                                                        g["inputValue"],
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                cond["repr_value"]["repr_value"] = g["inputValue"]
                            groupby_config["inputs"]["option_config"]["condition"][
                                "condition"
                            ] = condition_list
                        else:
                            pass

                elif i["text"] == "Conditional Aggregates":
                    if not config_dict["inputs"].get("agg_config"):
                        config_dict_new = {
                            "function": "Elementary Statistics",
                            "inputs": {
                                "data": config_dict["inputs"]["data"],
                                "Type": config_dict["inputs"]["Type"],
                                "Groupby_column": config_dict["inputs"]["Groupby_column"],
                                "agg_config": [
                                    {
                                        "Value_column": config_dict["inputs"]["Value_column"],
                                        "Sum_product_column": config_dict["inputs"]["Sum_product_column"],
                                        "Aggregate": config_dict["inputs"]["Aggregate"],
                                        "new_column_name": config_dict["inputs"]["new_column_name"],
                                        "Weights": config_dict["inputs"]["Weights"],
                                        "Conditional": config_dict["inputs"]["Conditional"],
                                    }
                                ],
                            },
                            "outputs": config_dict["outputs"],
                        }
                        config_dict = config_dict_new.copy()
                    agg_config = config_dict["inputs"]["agg_config"]
                    for agg_ind, agg in enumerate(agg_config):
                        aggregate = agg["Aggregate"]
                        if aggregate in ["Averageif", "Sumif", "Countif", "Productif"]:
                            condition_list = agg["Conditional"]["If_condition"]
                            for cond in condition_list:
                                if cond["globalVariable"] != "":
                                    for g in variable_list:
                                        if cond["globalVariable"] == g["varName"]:
                                            if g["varName"] in multi_run_vars:
                                                if re.search(
                                                    r"^\d{2}-\d{2}-\d{4}",
                                                    g["inputValue"][run],
                                                ):
                                                    g["inputValue"][run] = pd.to_datetime(
                                                        g["inputValue"][run]
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                cond["input_value"] = g["inputValue"][run]
                                            else:
                                                if re.search(r"^\d{2}-\d{2}-\d{4}", g["inputValue"]) and g[
                                                    "dataType"
                                                ] in ["date", "datetime-local"]:
                                                    g["inputValue"] = pd.to_datetime(
                                                        g["inputValue"]
                                                    ).strftime("%Y-%m-%d %H:%M:%S")
                                                cond["input_value"] = g["inputValue"]
                            config_dict["inputs"]["agg_config"][agg_ind]["Conditional"][
                                "If_condition"
                            ] = condition_list

                elif i["text"] == "Portfolio Liquidity Configuration":
                    liquidity_global_var = config_dict["inputs"]["liquidity"]["global_var"]
                    if liquidity_global_var != "":
                        for g in variable_list:
                            if liquidity_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["liquidity"]["liquidity_val"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["liquidity"]["liquidity_val"] = g["inputValue"]

                    val_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if val_date_global_var != "":
                        for g in variable_list:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["inputValue"]

                elif i["text"] == "Portfolio Limit Utilisation":
                    val_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if val_date_global_var != "":
                        for g in variable_list:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["inputValue"]

                    if config_dict["inputs"]["limits"]["source"] == "manual_entry_PLU":
                        for key, value in config_dict["inputs"]["limits"]["manual_limits"].items():
                            value_global_var = value["value"]["global_var"]
                            if value_global_var != "":
                                for g in variable_list:
                                    if value_global_var == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            value["value"]["input_value"] = g["inputValue"][run]
                                        else:
                                            value["value"]["input_value"] = g["inputValue"]

                elif i["text"] == "Expected Return":
                    val_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if val_date_global_var != "":
                        for g in variable_list:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["inputValue"]

                elif i["text"] == "Portfolio Allocation":
                    investment_global_var = config_dict["inputs"]["investment"]["global_var"]
                    if investment_global_var != "":
                        for g in variable_list:
                            if investment_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["investment"]["investment_val"] = g["inputValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["investment"]["investment_val"] = g["inputValue"]

                    val_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if val_date_global_var != "":
                        for g in variable_list:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["valuation_date"]["val_date"] = g["inputValue"]

                elif i["text"] == "Portfolio Attribution":
                    run_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if run_date_global_var != "":
                        for g in variable_list:
                            if run_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["run_date"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["valuation_date"]["run_date"] = g["inputValue"]

                    pool_name_global_var = config_dict["inputs"]["pool_name"]["global_var"]
                    if pool_name_global_var != "":
                        for g in variable_list:
                            if pool_name_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["pool_name"]["pool_name"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["pool_name"]["pool_name"] = g["inputValue"]

                    scenario_name_global_var = config_dict["inputs"]["scenario_name"]["global_var"]
                    if scenario_name_global_var != "":
                        for g in variable_list:
                            if scenario_name_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["scenario_name"]["scenario_name"] = g["inputValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["scenario_name"]["scenario_name"] = g["inputValue"]

                elif i["text"] == "Optimiser":
                    constraint_dict = config_dict["inputs"]["constraint_dict"]

                    scenario_name_global_var = config_dict["inputs"]["scenario_name"]["global_var"]
                    if scenario_name_global_var != "":
                        for g in variable_list:
                            if scenario_name_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["scenario_name"]["scenarioName"] = g["inputValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["scenario_name"]["scenarioName"] = g["inputValue"]

                    valuation_date_global_var = config_dict["inputs"]["valuation_date"]["global_var"]
                    if valuation_date_global_var != "":
                        for g in variable_list:
                            if valuation_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["valuation_date"]["valuation_date"] = g[
                                        "inputValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["valuation_date"]["valuation_date"] = g[
                                        "inputValue"
                                    ]

                    risk_free_rate_global_var = config_dict["inputs"]["risk_free_rate"]["global_var"]
                    if risk_free_rate_global_var != "":
                        for g in variable_list:
                            if risk_free_rate_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["risk_free_rate"]["riskFreeRate"] = g["inputValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["risk_free_rate"]["riskFreeRate"] = g["inputValue"]

                    target_volatility_global_var = config_dict["inputs"]["target_volatility"]["global_var"]
                    if target_volatility_global_var != "":
                        for g in variable_list:
                            if target_volatility_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["target_volatility"]["targetVolatility"] = g[
                                        "inputValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["target_volatility"]["targetVolatility"] = g[
                                        "inputValue"
                                    ]

                    target_return_global_var = config_dict["inputs"]["target_return"]["global_var"]
                    if target_return_global_var != "":
                        for g in variable_list:
                            if target_return_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["target_return"]["targetRreturn"] = g["inputValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["target_return"]["targetRreturn"] = g["inputValue"]

                    investment_amount_global_var = config_dict["inputs"]["investment_amount"]["global_var"]
                    if investment_amount_global_var != "":
                        for g in variable_list:
                            if investment_amount_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["investment_amount"][
                                        "investment_amount_allocation"
                                    ] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["investment_amount"][
                                        "investment_amount_allocation"
                                    ] = g["inputValue"]
                    for val in constraint_dict:
                        constraint_list = constraint_dict[val]["constraint_list"]
                        for j in constraint_list:
                            if j["globalVariable"] != "":
                                for g in variable_list:
                                    if j["globalVariable"] == g["varName"]:
                                        if g["varName"] in multi_run_vars:
                                            j["input_value"] = g["inputValue"][run]
                                        else:
                                            j["input_value"] = g["inputValue"]

                        config_dict["inputs"]["constraint_dict"][val]["constraint_list"] = constraint_list

                elif i["text"] == "Portfolio Valuation":
                    val_date_global_var = config_dict["inputs"]["Valuation_Date"]["global_Var"]
                    if val_date_global_var != "":
                        for g in variable_list:
                            if val_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["Valuation_Date"]["val_date"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["Valuation_Date"]["val_date"] = g["inputValue"]
                    cf_analysis_id_global_var = config_dict["inputs"]["CF_Analysis_Id"]["global_Var"]
                    if cf_analysis_id_global_var != "":
                        for g in variable_list:
                            if cf_analysis_id_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["CF_Analysis_Id"]["cf_analysis_id"] = g[
                                        "inputValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["CF_Analysis_Id"]["cf_analysis_id"] = g[
                                        "inputValue"
                                    ]

                elif i["text"] == "TWRR":
                    fund_global_var = config_dict["inputs"]["fund_global_var"]
                    fund = config_dict["inputs"]["fund"]
                    if fund_global_var != "":
                        for g in variable_list:
                            if fund_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    fund = g["inputValue"][run]
                                else:
                                    fund = g["inputValue"]

                        config_dict["inputs"]["fund"] = fund

                elif i["text"] == "Portfolio Metrics":
                    val_start_date_global_var = config_dict["inputs"]["option_config"][
                        "start_date_global_port_metr"
                    ]
                    val_end_date_global_var = config_dict["inputs"]["option_config"][
                        "end_date_global_port_metr"
                    ]

                    if val_start_date_global_var != "":
                        for g in variable_list:
                            if val_start_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["start_date"] = g["inputValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["option_config"]["start_date"] = g["inputValue"]

                    if val_end_date_global_var != "":
                        for g in variable_list:
                            if val_end_date_global_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["end_date"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["option_config"]["end_date"] = g["inputValue"]

                elif i["text"] == "IR Curve Bootstrapping":
                    if config_dict["inputs"]["option"] != "swap":
                        val_global_term_tenor = config_dict["inputs"]["option_config"]["global_term_tenor"]
                        val_global_extr_date = config_dict["inputs"]["option_config"]["global_extr_date"]
                        val_global_short_term_tenor = None
                        val_global_medium_term_tenor = None
                        val_global_swap_extr_date = None
                    else:
                        val_global_term_tenor = None
                        val_global_extr_date = None
                        val_global_short_term_tenor = config_dict["inputs"]["option_config"][
                            "global_short_term_tenor"
                        ]
                        val_global_medium_term_tenor = config_dict["inputs"]["option_config"][
                            "global_medium_term_tenor"
                        ]
                        val_global_swap_extr_date = config_dict["inputs"]["option_config"][
                            "global_swap_extr_date"
                        ]

                    if config_dict["inputs"]["option"] == "ois":
                        val_funding_spread = config_dict["inputs"]["option_config"]["global_funding_spread"]
                    else:
                        val_funding_spread = None

                    if val_global_term_tenor != "":
                        for g in variable_list:
                            if val_global_term_tenor == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Par Lim Tenor"] = g["inputValue"][
                                        run
                                    ]
                                else:
                                    config_dict["inputs"]["option_config"]["Par Lim Tenor"] = g["inputValue"]

                    if val_global_extr_date != "":
                        for g in variable_list:
                            if val_global_extr_date == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Extraction Date"] = g[
                                        "inputValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Extraction Date"] = g[
                                        "inputValue"
                                    ]

                    if val_funding_spread != "":
                        for g in variable_list:
                            if val_funding_spread == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Funding Spread"] = g[
                                        "inputValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Funding Spread"] = g["inputValue"]

                    if val_global_short_term_tenor != "":
                        for g in variable_list:
                            if val_global_short_term_tenor == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Short Term Tenor"] = g[
                                        "inputValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Short Term Tenor"] = g[
                                        "inputValue"
                                    ]

                    if val_global_medium_term_tenor != "":
                        for g in variable_list:
                            if val_global_medium_term_tenor == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Medium Term Tenor"] = g[
                                        "inputValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Medium Term Tenor"] = g[
                                        "inputValue"
                                    ]

                    if val_global_swap_extr_date != "":
                        for g in variable_list:
                            if val_global_swap_extr_date == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["Extraction Date"] = g[
                                        "inputValue"
                                    ][run]
                                else:
                                    config_dict["inputs"]["option_config"]["Extraction Date"] = g[
                                        "inputValue"
                                    ]

                elif i["text"] == "Options":
                    val_global_riskfree_rate = config_dict["inputs"]["option_config"]["global_riskfree_rate"]
                    val_global_n_steps = config_dict["inputs"]["option_config"]["global_n_steps"]

                    if val_global_riskfree_rate != "":
                        for g in variable_list:
                            if val_global_riskfree_rate == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["r_rate"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["option_config"]["r_rate"] = g["inputValue"]

                    if val_global_n_steps != "":
                        for g in variable_list:
                            if val_global_n_steps == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["option_config"]["n_step"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["option_config"]["n_step"] = g["inputValue"]

                elif i["text"] == "Editor":
                    global_str = ""
                    if len(variable_list) > 0:
                        global_data = global_dict["inputs"].get("variables")
                        for vi in variable_list:
                            if "dataType" not in vi:
                                for g_var in range(len(global_data)):
                                    if global_data[g_var]["varName"] == vi["varName"]:
                                        vi["dataType"] = global_data[g_var]["dataType"]
                        for g in variable_list:
                            varName = re.sub(r"\s+", "_", g["varName"])
                            defaultVal = g["inputValue"]
                            datatype = g.get("dataType")
                            if not datatype:
                                datatype = "text"
                            if datatype == "number":
                                if defaultVal not in ["nan"]:
                                    global_str += f"""{varName} = {defaultVal}\n"""
                                else:
                                    global_str += f"""{varName} = '{defaultVal}'\n"""
                            if datatype == "datetime-local":
                                if defaultVal and defaultVal not in ["None"]:
                                    defaultVal = datetime.strptime(defaultVal, "%Y-%m-%dT%H:%M")
                                    global_str += f"""{varName} = '{defaultVal}'\n{varName} = datetime.datetime.strptime({varName}, '%Y-%m-%d %H:%M:%S')\n"""
                                else:
                                    global_str += f"""{varName} = '{defaultVal}'\n"""
                            if datatype in ["text", "dropdown"]:
                                global_str += f"""{varName} = '{defaultVal}'\n"""
                            if datatype == "date":
                                if defaultVal and defaultVal not in ["None"]:
                                    if "T" in defaultVal:
                                        defaultVal = datetime.strptime(
                                            defaultVal.split(".")[0], "%Y-%m-%dT%H:%M:%S"
                                        ).strftime("%Y-%m-%d %H:%M:%S")
                                        global_str += f"""{varName} = '{defaultVal}'\n{varName} = datetime.datetime.strptime({varName}, '%Y-%m-%d %H:%M:%S')\n"""
                                    else:
                                        global_str += f"""{varName} = '{defaultVal}'\n{varName} = datetime.datetime.strptime({varName}, '%Y-%m-%d')\n"""
                                else:
                                    global_str += f"""{varName} = '{defaultVal}'\n"""
                            if datatype in ["dropdown-multiple"]:
                                global_str += f"""{varName} = {defaultVal}\n"""
                            if datatype == "date-autonow":
                                global_str += f"""{varName} = '{datetime.now().strftime("%Y-%m-%d")}'\n"""
                            if datatype == "datetime-autonow":
                                global_str += (
                                    f"""{varName} = '{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'\n"""
                                )
                            if datatype == "current_user":
                                global_str += f"""{varName} = '{request_user}'\n"""
                        config_dict["inputs"]["global_str"] = global_str

                elif i["text"] == "Copula":
                    val_text_usecase = json.loads(config_dict["inputs"]["use_case_input"])
                    val_number_sim = json.loads(config_dict["inputs"]["simulation_input"])
                    val_number_percentile = json.loads(config_dict["inputs"]["percentile_input"])
                    val_text_scenerio = json.loads(config_dict["inputs"]["scenerio_input"])
                    if len(variable_list) > 0:
                        if val_text_usecase["global_Var"] != "":
                            for g in variable_list:
                                if val_text_usecase["global_Var"] == g["varName"]:
                                    if g["varName"] in multi_run_vars:
                                        val_text_usecase["val_text"] = g["inputValue"][run]
                                    else:
                                        val_text_usecase["val_text"] = g["inputValue"]
                                    config_dict["inputs"]["use_case_input"] = json.dumps(val_text_usecase)

                        if val_number_sim["global_Var"] != "":
                            for g in variable_list:
                                if val_number_sim["global_Var"] == g["varName"]:
                                    if g["varName"] in multi_run_vars:
                                        val_number_sim["val_number"] = g["inputValue"][run]
                                    else:
                                        val_number_sim["val_number"] = g["inputValue"]
                                    config_dict["inputs"]["simulation_input"] = json.dumps(val_number_sim)

                        if val_number_percentile["global_Var"] != "":
                            for g in variable_list:
                                if val_number_percentile["global_Var"] == g["varName"]:
                                    if g["varName"] in multi_run_vars:
                                        val_number_percentile["val_number"] = g["inputValue"][run]
                                    else:
                                        val_number_percentile["val_number"] = g["inputValue"]
                                    config_dict["inputs"]["percentile_input"] = json.dumps(
                                        val_number_percentile
                                    )

                        if val_text_scenerio["global_Var"] != "":
                            for g in variable_list:
                                if val_text_scenerio["global_Var"] == g["varName"]:
                                    if g["varName"] in multi_run_vars:
                                        val_text_scenerio["val_text"] = g["inputValue"][run]
                                    else:
                                        val_text_scenerio["val_text"] = g["inputValue"]
                                    config_dict["inputs"]["scenerio_input"] = json.dumps(val_text_scenerio)

                elif i["text"] == "Goodness Of Fit Test":
                    val_text_var = json.loads(config_dict["inputs"]["use_case_check"])
                    use_case_fit_name = val_text_var["val_text"]
                    if val_text_var["global_Var"] != "":
                        for g in variable_list:
                            if val_text_var["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    use_case_fit_name = g["inputValue"][run]
                                else:
                                    use_case_fit_name = g["inputValue"]
                    config_dict["inputs"]["use_case"] = use_case_fit_name

                elif i["text"] == "Fit Discrete Distribution":
                    val_text_var = json.loads(config_dict["inputs"]["use_case_check"])
                    use_case_discrete_name = val_text_var["val_text"]
                    if val_text_var["global_Var"] != "":
                        for g in variable_list:
                            if val_text_var["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    use_case_discrete_name = g["inputValue"][run]
                                else:
                                    use_case_discrete_name = g["inputValue"]

                    config_dict["inputs"]["use_case"] = use_case_discrete_name

                elif i["text"] == "Monte Carlo":
                    val_numer_var = json.loads(config_dict["inputs"]["sim_check"])
                    simulation_count = val_numer_var["val_number"]
                    if val_numer_var["global_Var"] != "":
                        for g in variable_list:
                            if val_numer_var["global_Var"] == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    simulation_count = g["inputValue"][run]
                                else:
                                    simulation_count = g["inputValue"]

                    config_dict["inputs"]["monte_carlo_simulation"] = simulation_count

                elif i["text"] == "FX Options - Implied Volatility":
                    global_fx_val_date_var = config_dict["inputs"]["global_fx_val_date"]

                    if global_fx_val_date_var != "":
                        for g in variable_list:
                            if global_fx_val_date_var == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["global_fx_val_date"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["global_fx_val_date"] = g["inputValue"]

                elif i["text"] == "ML Predict":
                    if config_dict["inputs"].get("global_no_of_steps"):
                        global_no_of_steps_ahead = config_dict["inputs"]["global_no_of_steps"]
                    else:
                        global_no_of_steps_ahead = ""

                    if global_no_of_steps_ahead != "":
                        for g in variable_list:
                            if global_no_of_steps_ahead == g["varName"]:
                                if g["varName"] in multi_run_vars:
                                    config_dict["inputs"]["no_of_steps"] = g["inputValue"][run]
                                else:
                                    config_dict["inputs"]["no_of_steps"] = g["inputValue"]

                else:
                    pass

            else:
                if i["text"] == "Import Data":
                    data_source = config_dict["inputs"]["Data_source"]
                    if data_source == "Model_output":
                        config_dict["current_global_dict"] = []
                        config_dict["current_run"] = run

                if i["text"] == "Goodness Of Fit Test":
                    val_text_var = json.loads(config_dict["inputs"]["use_case_check"])
                    use_case_fit_name = val_text_var["val_text"]
                    config_dict["inputs"]["use_case"] = use_case_fit_name

                if i["text"] == "Fit Discrete Distribution":
                    val_text_var = json.loads(config_dict["inputs"]["use_case_check"])
                    use_case_fit_name = val_text_var["val_text"]
                    config_dict["inputs"]["use_case"] = use_case_fit_name

                if i["text"] == "Monte Carlo":
                    val_number_var = json.loads(config_dict["inputs"]["sim_check"])
                    simulation_count = val_number_var["val_number"]
                    config_dict["inputs"]["monte_carlo_simulation"] = simulation_count
            ele["element_config"] = config_dict
            csv_data_list = []
            json_data_list = []
            pq_data_list = []
            rd_data_list = []
            sftp_list = []
            if i["parent"] == "#":
                if i["text"] == "Import Data":
                    if elementid not in data_pass_on_config:
                        if config_dict.get("data_mapper"):
                            if config_dict["data_mapper"].get("parentData"):
                                mapper_element = config_dict["data_mapper"]["parentData"]
                                if mapper_element != "#":
                                    config_dict["data_mapper"]["data_source"] = element_flow_dict[
                                        mapper_element
                                    ]["output_data"]
                                else:
                                    pass
                            else:
                                pass
                        else:
                            pass
                        if config_dict["inputs"]["Data_source"] == "CSV":
                            if config_dict["inputs"]["global_var"] != "":
                                csv_data_list.append(csv_global_data)
                            else:
                                csv_data_list.append(f"{elementid}")
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=csv_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif config_dict["inputs"]["Data_source"] == "JSON":
                            if config_dict["inputs"]["global_var"] != "":
                                json_data_list.append(json_global_data)
                            else:
                                if redis_instance.exists(elementid) == 1:
                                    json_data = pickle.loads(redis_instance.get(elementid))
                                json_data_list.append(json_data)
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=json_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif config_dict["inputs"]["Data_source"] == "Parquet":
                            if config_dict["inputs"]["global_var"] != "":
                                pq_data_list.append(pq_global_data)
                            else:
                                if redis_instance.exists(elementid) == 1:
                                    pq_data = pickle.loads(redis_instance.get(elementid))
                                pq_data_list.append(pq_data)
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=pq_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif config_dict["inputs"]["Data_source"] == "XML":
                            if config_dict["inputs"]["global_var"] != "":
                                pq_data_list.append(pq_global_data)
                            else:
                                if redis_instance.exists(elementid) == 1:
                                    pq_data = pickle.loads(redis_instance.get(elementid))
                                pq_data_list.append(pq_data)
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=pq_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif config_dict["inputs"]["Data_source"] == "Redis":
                            redis_element_id = config_dict["inputs"]["RedisTable"]
                            if config_dict["inputs"]["global_var"] != "":
                                rd_data_list.append(rd_global_data)
                            else:
                                if redis_instance.exists(redis_element_id) == 1:
                                    red_data = pickle.loads(redis_instance.get(redis_element_id))
                                rd_data_list.append(red_data)
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=rd_data_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                        elif (
                            config_dict["inputs"]["Data_source"] == "SFTP"
                            or config_dict["inputs"]["Data_source"] == "FTP"
                            or config_dict["inputs"]["Data_source"] == "AWS_S3"
                            or config_dict["inputs"]["Data_source"] == "AZURE"
                            or config_dict["inputs"]["Data_source"] == "LOCAL"
                        ):
                            if config_dict["inputs"]["Data_source"] == "SFTP":
                                newlist, rename_list = SFTPconnectors.connect_to_sftp(config_dict, elementid)
                            elif config_dict["inputs"]["Data_source"] == "FTP":
                                newlist, rename_list = SFTPconnectors.connect_to_ftp(config_dict, elementid)
                            elif config_dict["inputs"]["Data_source"] == "AWS_S3":
                                newlist, rename_list = SFTPconnectors.connect_to_awsS3(config_dict, elementid)
                            elif config_dict["inputs"]["Data_source"] == "AZURE":
                                newlist, rename_list = SFTPconnectors.connect_to_azure(config_dict, elementid)
                            elif config_dict["inputs"]["Data_source"] == "LOCAL":
                                rename_list = []
                                selected_files = config_dict["inputs"]["files"]
                                rename_config = config_dict["inputs"]["renameConfig"]

                                for f in selected_files:
                                    rfile = f
                                    if rename_config and rfile in rename_config:
                                        rfile = rename_config[rfile]
                                    else:
                                        rfile = rfile.split(".")[0]
                                    rename_list.append(rfile)
                            for fname in rename_list:
                                sftp_list.append(f"{elementid}_{fname}")

                            saved_parent_val = read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "computation_model_configuration",
                                        "Columns": ["element_config"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "element_id",
                                            "condition": "Equal to",
                                            "input_value": elementid + "_multi_import_val",
                                            "and_or": "",
                                        },
                                    ],
                                },
                            )

                            if len(saved_parent_val) > 0:
                                elecon_dict = saved_parent_val.iloc[0, 0]
                                par_val = json.loads(elecon_dict)
                                multi_import_val = par_val
                            else:
                                multi_import_val = {}

                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                data=sftp_list,
                                elementid=elementid,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                                multi_import=True,
                                multi_import_val=multi_import_val,
                            )
                        else:
                            (
                                data,
                                message,
                                result_save_list,
                                data_error,
                            ) = Computation_master_file.master_run_process(
                                config_dict=config_dict,
                                request_user=request,
                                elementid=elementid,
                                element_id=element_id,
                                scenario_name=scenario_name,
                                scenario_id=scenario_id,
                                scenario_config=scenario_config,
                            )
                    else:
                        data = data_pass_on_config[elementid]
                        message, result_save_list, data_error = "", [], ""
                elif i["text"] == "If then Else":
                    input_data = pd.DataFrame()
                    data = input_data.copy()
                    data_error = ""
                    elements_not_to_run, next_element = computationFlowController(
                        flowchart_elements, elementid, config_dict, input_data, variable_list
                    )
                    if len(elements_not_to_run):
                        for ele_not in elements_not_to_run:
                            for fl_idx, fl_ele in enumerate(flowchart_elements):
                                if fl_ele["element_id"] == ele_not:
                                    flowchart_elements.pop(fl_idx)
                        last_element_id = flowchart_elements[-1]["element_id"]
                        for fc_k, fc_data in next_element.items():
                            new_fc_k = elementid + fc_k
                            if isinstance(fc_data, pd.DataFrame):
                                try:
                                    file_name = f"{new_fc_k}_{request.user.username}_{tenant}"
                                    to_diskstorage(fc_data, file_name)
                                    ele["output_data"] = file_name
                                except Exception as e:
                                    ele["output_data"] = fc_data
                                    logging.warning(f"Following exception occured - {e}")
                            else:
                                ele["output_data"] = fc_data
                            element_flow_dict[new_fc_k] = ele
                else:
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        elementid=elementid,
                        element_id=element_id,
                        scenario_name=scenario_name,
                        scenario_id=scenario_id,
                        scenario_config=scenario_config,
                    )
                for exp_mes in result_save_list:
                    inter_output_export_message_list.append(exp_mes)

                if data_error:
                    errorElement = i["text"]
                    if isinstance(data_error, str):
                        element_message = f"Error running {errorElement}! {data_error}"
                    else:
                        element_message = f"Error running {errorElement}!"
                        for de in data_error:
                            element_message += f"\n{de}"
                    break

                if isinstance(data, pd.DataFrame) and not in_memory_execution:
                    try:
                        file_name = f"{elementid}_{random_no_generator(4)}_{request.user.username}_{tenant}"
                        to_diskstorage(data, file_name)
                        ele["output_data"] = file_name
                    except Exception as e:
                        ele["output_data"] = data.copy()
                        logging.warning(f"Following exception occured - {e}")
                else:
                    ele["output_data"] = data.copy()
                element_flow_dict[elementid] = ele

            elif i["parent"] != "#":
                if i["text"] == "Import Data":
                    if elementid not in data_pass_on_config:
                        if config_dict.get("data_mapper"):
                            if config_dict["data_mapper"].get("parentData"):
                                mapper_element = config_dict["data_mapper"]["parentData"]
                                config_dict["data_mapper"]["data_source"] = element_flow_dict[mapper_element][
                                    "output_data"
                                ]
                            else:
                                pass
                        else:
                            pass
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            elementid=elementid,
                            element_id=element_id,
                            scenario_name=scenario_name,
                            scenario_id=scenario_id,
                            scenario_config=scenario_config,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)
                    else:
                        data = data_pass_on_config[elementid]
                        message, result_save_list, data_error = "", [], ""

                elif i["text"] == "IR Curve Bootstrapping":
                    input_data_dict = {}
                    market_data_key = config_dict["inputs"]["market_data"]
                    if market_data_key != "" and market_data_key in element_flow_dict:
                        market_data = input_data_element(
                            elementid,
                            market_data_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["market_data"] = market_data
                    curve_data_key = config_dict["inputs"]["curve_data"]
                    if curve_data_key != "" and curve_data_key in element_flow_dict:
                        curve_data = input_data_element(
                            elementid,
                            curve_data_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["curve_data"] = curve_data
                    curve_components_data_key = config_dict["inputs"]["curve_components_data"]
                    if curve_components_data_key != "" and curve_components_data_key in element_flow_dict:
                        curve_components_data = input_data_element(
                            elementid,
                            curve_components_data_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["curve_components_data"] = curve_components_data
                    (
                        data,
                        frontend_output,
                        message,
                        result_save_list,
                        data_error,
                    ) = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        elementid=elementid,
                        data=input_data_dict,
                        element_id=element_id,
                        scenario_name=scenario_name,
                        scenario_id=scenario_id,
                        scenario_config=scenario_config,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)

                elif i["text"] == "CART" or i["text"] == "CART Algorithm":
                    input_data_dict = {}
                    username = request
                    config_dict["username"] = username
                    config_dict["element_id"] = elementid
                    train_data = config_dict["inputs"]["Data"]["training"]
                    test_data = config_dict["inputs"]["Data"]["testing"]
                    mapping_data = config_dict["inputs"]["Data"].get("mapping")
                    input_data_dict["train"] = input_data_element(
                        elementid,
                        train_data,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["test"] = input_data_element(
                        elementid,
                        test_data,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    mapping_dataset = input_data_element(
                        elementid,
                        mapping_data,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    if isinstance(mapping_dataset, pd.DataFrame):
                        if len(mapping_dataset):
                            input_data_dict["mapping"] = mapping_dataset
                    else:
                        input_data_dict["mapping"] = mapping_dataset
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                        scenario_id=scenario_id,
                        scenario_config=scenario_config,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)

                elif i["text"] == "Boosting Algorithm":
                    input_data_dict = {}
                    username = request
                    config_dict["username"] = username
                    config_dict["element_id"] = elementid
                    train_data = config_dict["inputs"]["Data"]["training"]
                    test_data = config_dict["inputs"]["Data"]["testing"]
                    mapping_data = config_dict["inputs"]["Data"].get("mapping")
                    input_data_dict["train"] = input_data_element(
                        elementid,
                        train_data,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["test"] = input_data_element(
                        elementid,
                        test_data,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    mapping_dataset = input_data_element(
                        elementid,
                        mapping_data,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    if isinstance(mapping_dataset, pd.DataFrame):
                        if len(mapping_dataset):
                            input_data_dict["mapping"] = mapping_dataset
                    else:
                        input_data_dict["mapping"] = mapping_dataset
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)
                elif i["text"] == "Optimiser":
                    config_dict["user_name"] = request
                    input_data_dict = {}
                    if len(config_dict["inputs"]["data_mapping"]) == 2:
                        prices_key = config_dict["inputs"]["data_mapping"]["prices"]
                        constraints_key = config_dict["inputs"]["data_mapping"]["constraint"]
                        position_key = config_dict["inputs"]["data_mapping"]["positions_data"]
                        cashflow_key = config_dict["inputs"]["data_mapping"]["cashflow_data"]
                        security_key = config_dict["inputs"]["data_mapping"]["security_expected_returns"]
                        measure_key = config_dict["inputs"]["data_mapping"]["measure_data"]
                        benchmark_cashflow_key = config_dict["inputs"]["data_mapping"][
                            "benchmark_cashflow_data"
                        ]
                        security_liquidity_key = config_dict["inputs"]["data_mapping"][
                            "security_liquidity_data"
                        ]
                        uploaded_constraints_key = config_dict["inputs"]["data_mapping"][
                            "uploaded_constraints"
                        ]
                        input_data_dict["prices"] = input_data_element(
                            elementid,
                            prices_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["constraints"] = input_data_element(
                            elementid,
                            constraints_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["position_data"] = input_data_element(
                            elementid,
                            position_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["cashflow_data"] = input_data_element(
                            elementid,
                            cashflow_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["security_data"] = input_data_element(
                            elementid,
                            security_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["measure_data"] = input_data_element(
                            elementid,
                            measure_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["benchmark_cashflow_data"] = input_data_element(
                            elementid,
                            benchmark_cashflow_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["security_liquidity_data"] = input_data_element(
                            elementid,
                            security_liquidity_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["uploaded_constraints"] = input_data_element(
                            elementid,
                            uploaded_constraints_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                    else:
                        prices_key = config_dict["inputs"]["data_mapping"]["prices"]
                        constraints_key = config_dict["inputs"]["data_mapping"]["constraint"]
                        position_key = config_dict["inputs"]["data_mapping"]["positions_data"]
                        cashflow_key = config_dict["inputs"]["data_mapping"]["cashflow_data"]
                        security_key = config_dict["inputs"]["data_mapping"]["security_expected_returns"]
                        measure_key = config_dict["inputs"]["data_mapping"]["measure_data"]
                        benchmark_cashflow_key = config_dict["inputs"]["data_mapping"][
                            "benchmark_cashflow_data"
                        ]
                        security_liquidity_key = config_dict["inputs"]["data_mapping"][
                            "security_liquidity_data"
                        ]
                        uploaded_constraints_key = config_dict["inputs"]["data_mapping"][
                            "uploaded_constraints"
                        ]
                        input_data_dict["prices"] = input_data_element(
                            elementid,
                            prices_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["constraints"] = input_data_element(
                            elementid,
                            constraints_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["position_data"] = input_data_element(
                            elementid,
                            position_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["cashflow_data"] = input_data_element(
                            elementid,
                            cashflow_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["security_data"] = input_data_element(
                            elementid,
                            security_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["measure_data"] = input_data_element(
                            elementid,
                            measure_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["benchmark_cashflow_data"] = input_data_element(
                            elementid,
                            benchmark_cashflow_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["security_liquidity_data"] = input_data_element(
                            elementid,
                            security_liquidity_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                        input_data_dict["uploaded_constraints"] = input_data_element(
                            elementid,
                            uploaded_constraints_key,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                        scenario_id=scenario_id,
                        scenario_config=scenario_config,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)
                    output_type = "Optimiser-output"

                elif i["text"] == "Portfolio Valuation":
                    input_data_dict = {}
                    positions_key = config_dict["inputs"]["Data_mapper"]["positions"]
                    product_key = config_dict["inputs"]["Data_mapper"]["product_data"]
                    nmd_data_key = config_dict["inputs"]["Data_mapper"]["nmd_data"]
                    dpd_data_key = config_dict["inputs"]["Data_mapper"]["dpd_data"]
                    overdue_data_key = config_dict["inputs"]["Data_mapper"]["overdue_data"]
                    dpd_schedule_key = config_dict["inputs"]["Data_mapper"]["dpd_schedule"]
                    market_data_key = config_dict["inputs"]["Data_mapper"]["market_data"]
                    cashflow_data_uploaded_key = config_dict["inputs"]["Data_mapper"][
                        "cashflow_data_uploaded"
                    ]
                    repayment_data_key = config_dict["inputs"]["Data_mapper"]["repayment_data"]
                    product_model_mapper_key = config_dict["inputs"]["Data_mapper"]["product_model_mapper"]
                    input_data_dict["positions_table"] = input_data_element(
                        elementid,
                        positions_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["product_data"] = input_data_element(
                        elementid,
                        product_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["nmd_data"] = input_data_element(
                        elementid,
                        nmd_data_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["market_data"] = input_data_element(
                        elementid,
                        market_data_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["cashflow_data_uploaded"] = input_data_element(
                        elementid,
                        cashflow_data_uploaded_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["repayment_data"] = input_data_element(
                        elementid,
                        repayment_data_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["dpd_data"] = input_data_element(
                        elementid,
                        dpd_data_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["overdue_data"] = input_data_element(
                        elementid,
                        overdue_data_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["dpd_schedule"] = input_data_element(
                        elementid,
                        dpd_schedule_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["product_model_mapper_table"] = input_data_element(
                        elementid,
                        product_model_mapper_key,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    (
                        final_data,
                        data,
                        var_plot,
                        result_save_list,
                        data_error,
                    ) = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                    ele["portfolio_display_output"] = final_data
                    ele["portfolio_display_var"] = var_plot
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)
                    output_type = "Portfolio Valuation"

                elif i["text"] in [
                    "Schedule Generation",
                    "Cashflow Generation",
                    "TTM Calculation",
                    "Bootstrapping",
                    "Interpolation",
                    "Discount Factor Calculation",
                ]:
                    input_data_dict = {}
                    data_mapper = config_dict["inputs"]["data"]
                    for key, item in data_mapper.items():
                        if item is not None:
                            input_data_dict[key] = input_data_element(
                                elementid,
                                item,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                    (
                        data,
                        message,
                        result_save_list,
                        data_error,
                    ) = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)

                    output_type = i["text"]

                elif i["text"] == "TWRR":
                    input_data_dict = {}
                    position_data_id = config_dict["inputs"]["data_mapping"]["position"]
                    cashflow_data_id = config_dict["inputs"]["data_mapping"]["cashflow"]
                    transaction_data_id = config_dict["inputs"]["data_mapping"]["transaction"]
                    input_data_dict["position"] = input_data_element(
                        elementid,
                        position_data_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["cashflow"] = input_data_element(
                        elementid,
                        cashflow_data_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["transaction"] = input_data_element(
                        elementid,
                        transaction_data_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)
                    if message:
                        element_message = message

                elif i["text"] == "Portfolio Metrics":
                    input_data_dict = {}
                    portfolio_element_id = config_dict["inputs"]["option_config"]["portfolio"]

                    if config_dict["inputs"]["option_config"].get("riskfree"):
                        riskfree_element_id = config_dict["inputs"]["option_config"]["riskfree"]
                    else:
                        riskfree_element_id = 1

                    if config_dict["inputs"]["option_config"].get("market"):
                        market_element_id = config_dict["inputs"]["option_config"]["market"]
                    else:
                        market_element_id = 1

                    input_data_dict["portfolio_data"] = input_data_element(
                        elementid,
                        portfolio_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["riskfree_data"] = input_data_element(
                        elementid,
                        riskfree_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["market_data"] = input_data_element(
                        elementid,
                        market_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )

                elif i["text"] == "Options":
                    input_data_dict = {}
                    data_id = config_dict["inputs"]["option_config"]["pos_data"]
                    vix_id = config_dict["inputs"]["option_config"]["vix_data"]

                    input_data_dict["pos_data"] = input_data_element(
                        elementid,
                        data_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_dict["vix_data"] = input_data_element(
                        elementid,
                        vix_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                elif i["text"] == "ML Predict":
                    input_data_list = []
                    if "Data" in config_dict["inputs"]["data"]:
                        prediction_data_id = config_dict["inputs"]["data"]["Data"]
                        input_data_list.append(
                            input_data_element(
                                elementid,
                                prediction_data_id,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                        )
                    else:
                        prediction_data_id = ""
                    config_dict["element_id"] = elementid
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_list,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)
                    if message:
                        element_message = message
                elif i["text"] == "Copula":
                    input_dict = {"loss_amt_df": pd.DataFrame(), "scenerio_mapping": pd.DataFrame()}
                    loss_amt_id = config_dict["inputs"]["loss_amount_id"]
                    scenerio_percentile_id = config_dict["inputs"]["scenerio_percentile_id"]
                    input_dict["loss_amt_df"] = input_data_element(
                        elementid,
                        loss_amt_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    if scenerio_percentile_id:
                        input_dict["scenerio_mapping"] = input_data_element(
                            elementid,
                            scenerio_percentile_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_dict,
                        elementid=elementid,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)
                    output_type = "Copula"

                elif i["text"] == "Goodness Of Fit Test":
                    select_data = json.loads(config_dict["inputs"]["Data"])
                    input_data_dict = input_data_element(
                        elementid,
                        select_data[0],
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        elementid=elementid,
                        data=[input_data_dict],
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)
                    output_type = "Goodness Fit Test"

                elif i["text"] == "Fit Discrete Distribution":
                    select_data = json.loads(config_dict["inputs"]["Data"])
                    input_data_dict = input_data_element(
                        elementid,
                        select_data[0],
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        elementid=elementid,
                        data=[input_data_dict],
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)
                    output_type = "Fit Discrete Distribution"

                elif i["text"] == "Monte Carlo":
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict, request_user=request, elementid=elementid
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)

                elif i["text"] == "VaR Backtesting":
                    input_data_list = []
                    pt_element_id = config_dict["inputs"]["data"]
                    dt_key, bk_element_id = list(pt_element_id.items())[0]
                    input_data_list.append(
                        input_data_element(
                            elementid,
                            bk_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                    )

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_list,
                        elementid=elementid,
                    )

                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)
                    output_type = "Backtesting"

                elif i["text"] == "FX Options - Implied Volatility":
                    input_data_dict = {}
                    position_element_id = config_dict["inputs"]["position_data"]
                    vol_element_id = config_dict["inputs"]["volatility_data"]
                    spot_elements_id = config_dict["inputs"]["spot_data"]

                    input_data_list["pos_data"] = input_data_element(
                        elementid,
                        position_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_list["vol_data"] = input_data_element(
                        elementid,
                        vol_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_list["spot_data"] = input_data_element(
                        elementid,
                        spot_elements_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                elif i["text"] == "If then Else":
                    input_data = input_data_element(
                        elementid,
                        i["parent"][0],
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    (
                        elements_not_to_run,
                        next_element,
                        flow_control_parent_element,
                    ) = computationFlowController(
                        flowchart_elements, elementid, config_dict, input_data, variable_list
                    )
                    flow_control_element = elementid
                    if len(elements_not_to_run):
                        for ele_not in elements_not_to_run:
                            for fl_idx, fl_ele in enumerate(flowchart_elements):
                                if fl_ele["element_id"] == ele_not:
                                    flowchart_elements.pop(fl_idx)
                        last_element_id = flowchart_elements[-1]["element_id"]
                    for fc_k, fc_data in next_element.items():
                        new_fc_k = elementid + fc_k
                        output_dict = {}
                        if isinstance(fc_data, pd.DataFrame):
                            try:
                                file_name = (
                                    f"{new_fc_k}_{random_no_generator(4)}_{request.user.username}_{tenant}"
                                )
                                to_diskstorage(fc_data, file_name)
                                output_dict["output_data"] = file_name
                            except Exception as e:
                                output_dict["output_data"] = fc_data
                                logging.warning(f"Following exception occured - {e}")
                        else:
                            output_dict["output_data"] = fc_data
                        element_flow_dict[new_fc_k] = output_dict

                elif i["text"] == "Data Mapping":
                    input_dict = {"base_data": pd.DataFrame(), "mapping_ruleset": pd.DataFrame()}
                    base_data_id = config_dict["inputs"]["base_data"]
                    mapping_ruleset_id = config_dict["inputs"]["mapping_ruleset"]
                    input_dict["base_data"] = input_data_element(
                        elementid,
                        base_data_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_dict["mapping_ruleset"] = input_data_element(
                        elementid,
                        mapping_ruleset_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_dict,
                        elementid=elementid,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)

                elif i["text"] == "Portfolio Validation":

                    input_dict = {
                        "positions_data": pd.DataFrame(),
                        "product_data": pd.DataFrame(),
                        "product_to_model_data": pd.DataFrame(),
                    }
                    positions_data_id = config_dict["inputs"]["positions_data"]
                    product_data_id = config_dict["inputs"]["product_data"]
                    product_to_model_data_id = config_dict["inputs"]["product_to_model_data"]

                    input_dict["positions_data"] = input_data_element(
                        elementid,
                        positions_data_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_dict["products_data"] = input_data_element(
                        elementid,
                        product_data_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    input_dict["product_to_model_data"] = input_data_element(
                        elementid,
                        product_to_model_data_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_dict,
                        elementid=elementid,
                    )
                    for exp_mes in result_save_list:
                        inter_output_export_message_list.append(exp_mes)

                elif i["text"] == "Workdays":
                    input_data_dict = {}
                    position_element_id = config_dict["inputs"]["pos_data"]
                    hol_element_id = config_dict["inputs"]["hol_data"]

                    input_data_list["pos_data"] = input_data_element(
                        elementid,
                        position_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    if hol_element_id != "":
                        input_data_list["hol_data"] = input_data_element(
                            elementid,
                            hol_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                    else:
                        input_data_list["hol_data"] = []

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                elif i["text"] == "Workdays.Intl":
                    input_data_list = {}
                    position_element_id = config_dict["inputs"]["pos_data"]
                    hol_element_id = config_dict["inputs"]["hol_data"]

                    input_data_list["pos_data"] = input_data_element(
                        elementid,
                        position_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    if hol_element_id != "":
                        input_data_list["hol_data"] = input_data_element(
                            elementid,
                            hol_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                    else:
                        input_data_list["hol_data"] = []

                    (
                        data,
                        message,
                        result_save_list,
                        data_error,
                    ) = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_list,
                        elementid=elementid,
                    )
                elif i["text"] == "Networkdays":
                    input_data_dict = {}
                    position_element_id = config_dict["inputs"]["pos_data"]
                    hol_element_id = config_dict["inputs"]["hol_data"]

                    input_data_list["pos_data"] = input_data_element(
                        elementid,
                        position_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )
                    input_data_list["hol_data"] = input_data_element(
                        elementid,
                        hol_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                elif i["text"] == "Networkdays.Intl":
                    input_data_dict = {}
                    position_element_id = config_dict["inputs"]["pos_data"]
                    hol_element_id = config_dict["inputs"]["hol_data"]

                    input_data_list["pos_data"] = input_data_element(
                        elementid,
                        position_element_id,
                        element_flow_dict,
                        flow_control_element,
                        flow_control_parent_element,
                    )

                    if hol_element_id != "":
                        input_data_list["hol_data"] = input_data_element(
                            elementid,
                            hol_element_id,
                            element_flow_dict,
                            flow_control_element,
                            flow_control_parent_element,
                        )
                    else:
                        input_data_list["hol_data"] = []

                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        data=input_data_dict,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                else:
                    input_data_list = []
                    for p_elem in i["parent"]:
                        input_data_list.append(
                            input_data_element(
                                elementid,
                                p_elem,
                                element_flow_dict,
                                flow_control_element,
                                flow_control_parent_element,
                            )
                        )
                    if i["text"] == "Export Data":
                        (
                            data,
                            output_type_export,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_list,
                            elementid=elementid,
                            element_id=element_id,
                            scenario_name=scenario_name,
                            scenario_id=scenario_id,
                            scenario_config=scenario_config,
                            run_model=True,
                            transaction_id=transaction_id,
                        )
                        ele["output_type"] = output_type_export
                        ele["output_dict"] = data_error
                        extra_config.append({elementid: data_error})
                        data_error = ""
                    else:
                        username = request
                        config_dict["username"] = username
                        config_dict["element_id"] = elementid
                        (
                            data,
                            message,
                            result_save_list,
                            data_error,
                        ) = Computation_master_file.master_run_process(
                            config_dict=config_dict,
                            request_user=request,
                            data=input_data_list,
                            elementid=elementid,
                            scenario_name=scenario_name,
                            scenario_id=scenario_id,
                            scenario_config=scenario_config,
                        )
                        for exp_mes in result_save_list:
                            inter_output_export_message_list.append(exp_mes)

                if isinstance(data, pd.DataFrame) and not in_memory_execution:
                    try:
                        file_name = f"{elementid}_{random_no_generator(4)}_{request.user.username}_{tenant}"
                        to_diskstorage(data, file_name)
                        ele["output_data"] = file_name
                    except Exception as e:
                        ele["output_data"] = data.copy()
                        logging.warning(f"Following exception occured - {e}")
                else:
                    ele["output_data"] = data.copy()
                element_flow_dict[elementid] = ele

                if data_error:
                    errorElement = i["text"]
                    if isinstance(data_error, str):
                        element_message = f"Error running {errorElement}! {data_error}"
                    else:
                        element_message = f"Error running {errorElement}!"
                        for de in data_error:
                            element_message += f"\n{de}"
                    break

            else:
                pass
        else:
            ele = {"function": i["text"], "parent": i["parent"], "child": i["child"]}
            elementid = i["element_id"]
            element_config = element_config_data[element_config_data["element_id"] == elementid]
            elecon_dict = element_config.iloc[0, 0]
            config_dict = json.loads(elecon_dict)
            if config_dict["inputs"].get("variables"):
                vList = config_dict["inputs"].get("variables")
                if len(vList) > 0:
                    for indx, v in enumerate(vList):
                        if v["dataType"] == "date-autonow":
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = str(
                                datetime.now().strftime("%Y-%m-%d")
                            )
                        elif v["dataType"] == "datetime-local-autonow":
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = str(
                                datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            )
                        elif v["dataType"] == "current_user":
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = str(
                                request.user.username
                            )
                        elif v["dataType"] == "dynamic-date":
                            vartype = v["option"]
                            if vartype == "n_day_ago":
                                default_value = datetime.now() - relativedelta(days=int(v["nDays"]))
                                default_value = default_value.date()
                            elif vartype == "n_month_ago":
                                default_value = datetime.now() - relativedelta(months=int(v["nDays"]))
                                default_value = default_value.date()
                            elif vartype == "today":
                                default_value = datetime.now().date()
                            elif vartype == "yesterday":
                                default_value = datetime.now() - relativedelta(days=1)
                                default_value = default_value.date()
                            elif vartype == "last_week":
                                default_value = datetime.now() - relativedelta(days=7)
                                default_value = default_value.date()
                            elif vartype == "last_month":
                                default_value = datetime.now() - relativedelta(months=1)
                                default_value = default_value.date()
                            elif vartype == "last_year":
                                default_value = datetime.now() - relativedelta(years=1)
                                default_value = default_value.date()
                            else:
                                default_value = ""
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = str(default_value)
                        elif v["dataType"] == "dynamic-datetime":
                            vartype = v["option"]
                            if vartype == "n_day_ago":
                                default_value = datetime.now() - relativedelta(days=int(v["nDays"]))
                                default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                            elif vartype == "n_month_ago":
                                default_value = datetime.now() - relativedelta(months=int(v["nDays"]))
                                default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                            elif vartype == "n_min_ago":
                                default_value = datetime.now() - relativedelta(minutes=int(v["nDays"]))
                                default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                            elif vartype == "n_hour_ago":
                                default_value = datetime.now() - relativedelta(hours=int(v["nDays"]))
                                default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                            elif vartype == "now":
                                default_value = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            else:
                                default_value = ""
                            config_dict["inputs"]["variables"][indx]["defaultValue"] = default_value

            elif i["text"] == "ML Predict" and (
                config_dict["inputs"]["mlModel"].startswith("trainEWMA")
                | config_dict["inputs"]["mlModel"].startswith("trainARIMA")
                | config_dict["inputs"]["mlModel"].startswith("trainGARCH")
            ):
                if config_dict["inputs"].get("global_no_of_steps"):
                    global_no_of_steps_ahead = config_dict["inputs"]["global_no_of_steps"]
                else:
                    global_no_of_steps_ahead = ""

                if global_no_of_steps_ahead != "":
                    for g in variable_list:
                        if global_no_of_steps_ahead == g["varName"]:
                            if g["varName"] in multi_run_vars:
                                config_dict["inputs"]["no_of_steps"] = g["inputValue"][run]
                            else:
                                config_dict["inputs"]["no_of_steps"] = g["inputValue"]

            if i["text"] in ["Interest Rate Products", "Equities", "Mutual Fund", "ML Predict"]:
                if config_dict.get("globalVar"):
                    global_function = config_dict["globalVar"]
                    if global_function:
                        for gfunc in global_function_list:
                            if gfunc["elementID"] == elementid:
                                config_dict = gfunc["elementConfig"]
                if i["text"] == "ML Predict":
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                    if message:
                        element_message = message
                else:
                    data, message, result_save_list, data_error = Computation_master_file.master_run_process(
                        config_dict=config_dict,
                        request_user=request,
                        elementid=elementid,
                        scenario_name=scenario_name,
                    )
                for exp_mes in result_save_list:
                    inter_output_export_message_list.append(exp_mes)

                if isinstance(data, pd.DataFrame) and not in_memory_execution:
                    try:
                        file_name = f"{elementid}_{random_no_generator(4)}_{request.user.username}_{tenant}"
                        to_diskstorage(data, file_name)
                        ele["output_data"] = file_name
                    except Exception as e:
                        ele["output_data"] = data.copy()
                        logging.warning(f"Following exception occured - {e}")
                else:
                    ele["output_data"] = data.copy()
                element_flow_dict[elementid] = ele

                if data_error:
                    errorElement = i["text"]
                    if isinstance(data_error, str):
                        element_message = f"Error running {errorElement}! {data_error}"
                    else:
                        element_message = f"Error running {errorElement}!"
                        for de in data_error:
                            element_message += f"\n{de}"
                    break

        if index != len(flowchart_elements) - 1 and run > 0:
            intermediate_output = {
                "current_element": i["text"],
                "next_element": flowchart_elements[index + 1]["text"],
                "inter_comp_per": ((index + 1) / len(flowchart_elements)),
                "element_message": element_message,
                "inter_output_export_message_list": inter_output_export_message_list,
                "run": run,
            }
            computation_storage(
                intermediate_output,
                "exception",
                db_connection_name + f"intermediate_multi_run_model_{model_name}",
            )

    context["element_error_message"] = element_message
    context["inter_output_export_message_list"] = inter_output_export_message_list
    context["extra_config"] = extra_config
    output_elements = [out for out in output_elements if out in element_flow_dict]
    if not output_elements or scenario_name:
        context["output_display_type"] = "individual"
        if element_message == "Success":
            last_element_name = element_flow_dict[last_element_id]["function"]
            context["last_element_name"] = last_element_name

            context["output_type"] = output_type
            if isinstance(element_flow_dict[elementid]["output_data"], str) and element_flow_dict[elementid][
                "output_data"
            ].endswith(f"_{request.user.username}_{tenant}"):
                new_data = read_diskstorage(element_flow_dict[elementid]["output_data"])
            else:
                new_data = element_flow_dict[last_element_id]["output_data"]
            for comp_config in element_flow_dict.values():
                if isinstance(comp_config["output_data"], str):
                    flush_diskstorage(comp_config["output_data"])
            sendtodb = pd.DataFrame([model_name], columns=["model_name"])
            if last_element_name not in [
                "Interest Rate Products",
                "Portfolio Valuation",
                "Equities",
                "Mutual Fund",
                "Optimiser",
                "IR Curve Bootstrapping",
                "CART",
                "CART Algorithm",
                "Logistic Regression",
                "Linear Regression",
                "Analyse Time Series Data",
                "Train an ARIMA Model",
                "Train a GARCH Model",
                "Boosting Algorithm",
                "Copula",
                "Goodness Of Fit Test",
                "Fit Discrete Distribution",
                "VaR Backtesting",
                "Train an EWMA Model",
            ]:
                sendtodb["output_type"] = "dataframe"

                if isinstance(new_data, (dict, list)):
                    new_data = pd.DataFrame(new_data)
                    new_data.reset_index(inplace=True)
                    final_output_file_name = f"{tenant}_{element_id}"
                    computation_storage(
                        new_data, "dataframe", final_output_file_name, metadata={"output_type": "dataframe"}
                    )
                    form_fields_html = form_fields_where_pd_df(new_data)
                    context["form_fields"] = form_fields_html
                    context["output_source_file"] = final_output_file_name
                    context["columns_list"] = new_data.columns.to_list()
                    sendtodb["data_json"] = json.dumps(
                        {
                            "output_source_file": final_output_file_name,
                            "columns_list": new_data.columns.to_list(),
                            "form_fields": form_fields_html,
                        }
                    )
                    sendtodb["output_type"] = "dataframe"

                elif isinstance(new_data, pd.DataFrame):
                    new_data.reset_index(inplace=True)
                    form_fields_html = form_fields_where_pd_df(new_data)
                    context["form_fields"] = form_fields_html
                    context["columns_list"] = new_data.columns.to_list()
                    final_output_file_name = f"{tenant}_{element_id}"
                    computation_storage(
                        new_data, "dataframe", final_output_file_name, metadata={"output_type": "dataframe"}
                    )
                    context["output_source_file"] = final_output_file_name
                    context["columns_list"] = new_data.columns.to_list()
                    sendtodb["data_json"] = json.dumps(
                        {
                            "output_source_file": final_output_file_name,
                            "columns_list": new_data.columns.to_list(),
                            "form_fields": form_fields_html,
                        }
                    )
                    sendtodb["output_type"] = "dataframe"
                else:
                    context["content"] = ""
                    context["col_dtypes"] = ""
                    sendtodb["data_json"] = ""
                    sendtodb["output_type"] = ""

            elif last_element_name == "Optimiser":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "multi-output-optimiser"
            elif last_element_name == "CART" or last_element_name == "CART Algorithm":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "CART Algorithm"
            elif last_element_name == "Copula":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "Copula"
            elif last_element_name == "Goodness Of Fit Test":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "Goodness Fit Test"
            elif last_element_name == "Boosting Algorithm":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "Boosting Algorithm"

            elif last_element_name == "Fit Discrete Distribution":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "Fit Discrete Distribution"

            elif last_element_name == "IR Curve Bootstrapping":
                context["content"] = frontend_output
                sendtodb["data_json"] = json.dumps(frontend_output, default=str)
                sendtodb["output_type"] = "multi-output-bootstrap"
            elif last_element_name == "Linear Regression":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "multi-output-linearRegression"
            elif last_element_name == "Logistic Regression":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "multi-output-logisticRegression"
            elif last_element_name == "Analyse Time Series Data":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "multi-output-analyseTSData"
            elif last_element_name == "Train an ARIMA Model":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "multi-output-trainARIMA"
            elif last_element_name == "Train a GARCH Model":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "multi-output-trainGARCH"
            elif last_element_name == "Portfolio Valuation":
                context["content"] = {
                    "var_plot": element_flow_dict[last_element_id]["portfolio_display_var"],
                }
                final_output_file_name = f"{tenant}_{element_id}"
                element_flow_dict[last_element_id]["portfolio_display_output"]["Valuation_Date"].tolist()
                computation_storage(
                    element_flow_dict[last_element_id]["portfolio_display_output"].reset_index(),
                    "dataframe",
                    final_output_file_name,
                    metadata={"output_type": "dataframe"},
                )
                context["content"]["output_source_file"] = final_output_file_name
                context["content"]["columns_list"] = element_flow_dict[last_element_id][
                    "portfolio_display_output"
                ].columns.tolist()
                sendtodb["data_json"] = json.dumps(
                    {
                        "output_source_file": final_output_file_name,
                        "columns_list": element_flow_dict[last_element_id][
                            "portfolio_display_output"
                        ].columns.tolist(),
                        "var_plot": element_flow_dict[last_element_id]["portfolio_display_var"],
                    },
                    default=str,
                )
                sendtodb["output_type"] = "Portfolio_Valuation_Output"
            elif last_element_name == "VaR Backtesting":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "Backtesting"
            elif last_element_name == "Train an EWMA Model":
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "multi-output-trainEWMA"
            else:
                context["content"] = new_data
                sendtodb["data_json"] = json.dumps(new_data, default=str)
                sendtodb["output_type"] = "multi-output-finInstrument"
            sendtodb["created_by"] = request_user
            sendtodb["created_date"] = datetime.now()
            sendtodb["modified_by"] = request_user
            sendtodb["modified_date"] = datetime.now()
            data_handling(
                request,
                sendtodb,
                original_table_name="computation_model_run_history",
            )

            if child_element_id_email_box:
                for ceb in child_element_id_email_box:
                    try:
                        emailBox_functions.emailBox(
                            request, ceb, "comp", new_data.copy(), ""
                        )
                    except Exception as e:
                        logging.warning(f"Failure in email box function - {e}")
    else:
        context["output_display_type"] = "custom"
        context["output_elements"] = []
        if element_message == "Success":
            send_to_db_data = pd.DataFrame([model_name], columns=["model_name"])
            for otp_ele in output_elements:
                run_process_output_dict = {}
                run_process_output_dict["element_error_message"] = element_message
                last_element_name = element_flow_dict[otp_ele]["function"]
                run_process_output_dict["last_element_name"] = last_element_name
                run_process_output_dict["name"] = element_flow_dict[otp_ele]["element_name"]
                run_process_output_dict["last_element_id"] = otp_ele

                run_process_output_dict["output_type"] = output_type
                if isinstance(element_flow_dict[otp_ele]["output_data"], str) and element_flow_dict[otp_ele][
                    "output_data"
                ].endswith(f"_{request.user.username}_{tenant}"):
                    new_data = read_diskstorage(element_flow_dict[otp_ele]["output_data"])
                else:
                    new_data = element_flow_dict[otp_ele]["output_data"]

                if last_element_name not in [
                    "Interest Rate Products",
                    "Portfolio Valuation",
                    "Equities",
                    "Mutual Fund",
                    "Optimiser",
                    "IR Curve Bootstrapping",
                    "CART",
                    "CART Algorithm",
                    "Logistic Regression",
                    "Linear Regression",
                    "Analyse Time Series Data",
                    "Train an ARIMA Model",
                    "Train a GARCH Model",
                    "Boosting Algorithm",
                    "Copula",
                    "Goodness Of Fit Test",
                    "Fit Discrete Distribution",
                    "VaR Backtesting",
                    "Train an EWMA Model",
                ]:
                    if isinstance(new_data, (dict, list)):
                        new_data = pd.DataFrame(new_data)
                        new_data.reset_index(inplace=True)
                        final_output_file_name = f"{tenant}_{element_id}_{otp_ele}"
                        computation_storage(
                            new_data,
                            "dataframe",
                            final_output_file_name,
                            metadata={"output_type": "dataframe"},
                        )
                        run_process_output_dict["form_fields"] = form_fields_where_pd_df(new_data)
                        run_process_output_dict["output_source_file"] = final_output_file_name
                        run_process_output_dict["columns_list"] = new_data.columns.to_list()
                        run_process_output_dict["content"] = new_data.to_dict("records")
                    elif isinstance(new_data, pd.DataFrame):
                        new_data.reset_index(inplace=True)
                        final_output_file_name = f"{tenant}_{element_id}_{otp_ele}"
                        computation_storage(
                            new_data,
                            "dataframe",
                            final_output_file_name,
                            metadata={"output_type": "dataframe"},
                        )
                        run_process_output_dict["form_fields"] = form_fields_where_pd_df(new_data)
                        run_process_output_dict["output_source_file"] = final_output_file_name
                        run_process_output_dict["columns_list"] = new_data.columns.to_list()
                    else:
                        run_process_output_dict["output_source_file"] = ""
                        run_process_output_dict["columns_list"] = []

                elif last_element_name == "Optimiser":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "CART" or last_element_name == "CART Algorithm":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Copula":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Goodness Of Fit Test":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Boosting Algorithm":
                    run_process_output_dict["content"] = new_data

                elif last_element_name == "Fit Discrete Distribution":
                    run_process_output_dict["content"] = new_data

                elif last_element_name == "IR Curve Bootstrapping":
                    run_process_output_dict["content"] = frontend_output
                elif last_element_name == "Linear Regression":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Logistic Regression":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Analyse Time Series Data":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Train an ARIMA Model":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Train a GARCH Model":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Portfolio Valuation":
                    run_process_output_dict["content"] = {
                        "output": json.dumps(
                            [element_flow_dict[otp_ele]["portfolio_display_output"].to_dict("records")],
                            cls=NpEncoder,
                        ),
                        "var_plot": element_flow_dict[otp_ele]["portfolio_display_var"],
                    }
                elif last_element_name == "VaR Backtesting":
                    run_process_output_dict["content"] = new_data
                elif last_element_name == "Train an EWMA Model":
                    run_process_output_dict["content"] = new_data
                else:
                    run_process_output_dict["content"] = new_data

                context["output_elements"].append(run_process_output_dict)
            send_to_db_data["model_name"] = model_name
            send_to_db_data["output_type"] = "multi-output-display"
            send_to_db_data["data_json"] = json.dumps(context["output_elements"], default=str)
            send_to_db_data["created_by"] = request_user
            send_to_db_data["created_date"] = datetime.now()
            send_to_db_data["modified_by"] = request_user
            send_to_db_data["modified_date"] = datetime.now()
            data_handling(
                request,
                send_to_db_data,
                original_table_name="computation_model_run_history",
            )

            if child_element_id_email_box:
                for ceb in child_element_id_email_box:
                    try:
                        if isinstance(new_data, list):
                            new_data = pd.DataFrame(new_data)
                        emailBox_functions.emailBox(
                            request, ceb, "comp", new_data.head(100).copy(), ""
                        )
                    except Exception as e:
                        logging.warning(f"Failure in emailbox function - {e}")
    return context


def global_var_def_value(var_name, g_var_config, run=0, tuple_="no", in_cond=0, request=""):
    for g in g_var_config["inputs"]["variables"]:
        if var_name == g["varName"]:
            if g["dataType"] == "dropdown-multiple":
                if tuple_ == "yes":
                    tuple_ = "("
                    for k in g["defaultValue"]:
                        tuple_ = tuple_ + f"'{k}',"
                    tuple_ = tuple_ + ")"
                    tuple_ = tuple_.replace(",)", ")")
                    defaultVal = tuple_
                    return defaultVal
                elif in_cond and isinstance(g["defaultValue"], list):
                    return g["defaultValue"]
                else:
                    return g["defaultValue"][run]
            else:
                if g["dataType"] == "date-autonow":
                    return str(datetime.now().strftime("%Y-%m-%d"))
                elif g["dataType"] == "datetime-local-autonow":
                    return str(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                elif g["dataType"] == "current_user":
                    return str(request.user.username)
                elif g["dataType"] == "dynamic-date":
                    vartype = g["option"]
                    if vartype == "n_day_ago":
                        default_value = datetime.now() - relativedelta(days=int(g["nDays"]))
                        default_value = default_value.date()
                    elif vartype == "n_month_ago":
                        default_value = datetime.now() - relativedelta(months=int(g["nDays"]))
                        default_value = default_value.date()
                    elif vartype == "today":
                        default_value = datetime.now().date()
                    elif vartype == "yesterday":
                        default_value = datetime.now() - relativedelta(days=1)
                        default_value = default_value.date()
                    elif vartype == "last_week":
                        default_value = datetime.now() - relativedelta(days=7)
                        default_value = default_value.date()
                    elif vartype == "last_month":
                        default_value = datetime.now() - relativedelta(months=1)
                        default_value = default_value.date()
                    elif vartype == "last_year":
                        default_value = datetime.now() - relativedelta(years=1)
                        default_value = default_value.date()
                    else:
                        default_value = ""
                    return str(default_value)
                elif g["dataType"] == "dynamic-datetime":
                    vartype = g["option"]
                    if vartype == "n_day_ago":
                        default_value = datetime.now() - relativedelta(days=int(g["nDays"]))
                        default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                    elif vartype == "n_month_ago":
                        default_value = datetime.now() - relativedelta(months=int(g["nDays"]))
                        default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                    elif vartype == "n_min_ago":
                        default_value = datetime.now() - relativedelta(minutes=int(g["nDays"]))
                        default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                    elif vartype == "n_hour_ago":
                        default_value = datetime.now() - relativedelta(hours=int(g["nDays"]))
                        default_value = default_value.strftime("%Y-%m-%d %H:%M:%S")
                    elif vartype == "now":
                        default_value = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    else:
                        default_value = ""
                    return default_value
                else:
                    if g.get("defaultValueConfigs"):
                        if g["defaultValueConfigs"]["defaultvalue_filters"] and g["defaultValueConfigs"]["defaultvalue_table"] and g["defaultValueConfigs"]["defaultvalue_column"]:
                            default_value = (
                                read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": g["defaultValueConfigs"]["defaultvalue_table"],
                                            "Columns": [g["defaultValueConfigs"]["defaultvalue_column"]],
                                        },
                                        "condition": g["defaultValueConfigs"]["defaultvalue_filters"],
                                    },
                                )[g["defaultValueConfigs"]["defaultvalue_column"]]
                                .fillna("NULL")
                                .tolist()
                            )
                            if len(default_value)>0:
                                return default_value[0]
                    return g["defaultValue"]
    for g in g_var_config["inputs"]["mapper_variables"]:
        if var_name == g["varName"]:
            return g["defaultValue"]


def form_fields_where_pd_df(data):
    col_type_filters = {
        "object": [
            "Starts with",
            "Ends with",
            "Contains",
            "Equal to",
            "Not Starts with",
            "Not Ends with",
            "Not Contains",
            "Not Equal to",
        ],
        "datetime64[ns]": ["Equal to", "Greater than", "Smaller than", "Not Equal to"],
        "int64": ["Equal to", "Greater than", "Smaller than", "Not Equal to"],
        "int8": ["Equal to", "Greater than", "Smaller than", "Not Equal to"],
        "uint8": ["Equal to", "Greater than", "Smaller than", "Not Equal to"],
        "float64": ["Equal to", "Greater than", "Smaller than", "Not Equal to"],
        "bool": ["Equal to", "Not Equal to"],
    }
    form_fields = {}
    column_list = data.columns.to_list()
    field_type = data.dtypes.apply(lambda x: x.name).to_dict()
    for col_name in column_list:
        string = f"""
                <tr>
                <td class="dt-center">
                    <div class="" style="max-width:15em;">
                    <a href="javascript:void(0)" class="remove_filter fa fa-times" style="color:var(--primary-color);">&nbsp;<b style="font-family:Arial;font-size:12px;font-weight:200;">{col_name}</b>
                    </a>
                    </div>
                </td>
                <td class="dt-center">
                <div class="" style="max-width:25em;">
                <select class="form-control select2bs4" name={col_name} data-dropdown_purpose="select_filter_condition">
                """
        for val in col_type_filters[field_type[col_name]]:
            string = string + f'<option value="{val}">{val}</option>'
        if field_type[col_name] == "object":
            string = (
                string
                + f"""
                        </select>
                        </div>
                        </td>
                        <td class="dt-center">
                            <div class="" style="max-width:25em;">
                            <input type="text" placeholder='{col_name}' name={col_name} maxlength="100" class="textinput textInput form-control" required="" >
                            </div>
                        </td>
                        <td class="dt-center">
                        <div class="" style="max-width:25em;">
                        <select class="form-control select2bs4" name={col_name} data-dropdown_purpose="select_global_variable" data-type="text">
                            <option value="" selected disabled>Select Global Variable</option>
                        </select>
                        </div>
                        </td>
                        """
            )
        elif field_type[col_name] in ["int64", "float64"]:
            string = (
                string
                + f"""
                        </select>
                        </td>
                        <td class="dt-center">
                            <div class="" style="max-width:25em;">
                            <input type="number" placeholder='{col_name}' name={col_name} step="any" class="numberinput form-control" required="">
                            </div>
                        </td>
                        <td class="dt-center">
                        <div class="" style="max-width:25em;">
                        <select class="form-control select2bs4" name={col_name} data-dropdown_purpose="select_global_variable" data-type="number">
                            <option value="" selected disabled>Select Global Variable</option>
                        </select>
                        </div>
                        </td>
                        """
            )
        elif field_type[col_name] in ["datetime64[ns]"]:
            string = (
                string
                + """
                        </select>
                        </td>
                        <td class="dt-center">
                            <div class="input-group date" style="max-width:25em;">
                                <input type="date" placeholder="YYYY-MM-DD" class="form-control datepickerinput form-control" required="" dp_config="{&quot;id&quot;: &quot;dp_4&quot;, &quot;picker_type&quot;: &quot;DATE&quot;, &quot;linked_to&quot;: null, &quot;options&quot;: {&quot;showClose&quot;: true, &quot;showClear&quot;: true, &quot;showTodayButton&quot;: true, &quot;format&quot;: &quot;DD-MM-YYYY&quot;}}">
                                <div class="input-group-addon input-group-append" data-target="#datetimepicker1" data-toggle="datetimepickerv">
                                <div class="input-group-text"><i class="fa fa-calendar"></i></div>
                            </div>
                            </div>
                        </td>

                        <td class="dt-center">
                        <div class="" style="max-width:25em;">
                        <select class="form-control select2bs4" name={col_name} data-dropdown_purpose="select_global_variable" data-type="date">
                            <option value="" selected disabled>Select Global Variable</option>
                        </select>
                        </div>
                        </td>

                        <td class="dt-center">
                            <div class="" style="max-width:25em;">
                                <select data-dropdown_purpose="select_logical_operator">
                                    <option selected value="">-----</option>
                                    <option value="AND">AND</option>
                                    <option value="OR">OR</option>
                                </select>
                            </div>
                        </td>
                        """
            )
        elif field_type[col_name] in ["bool"]:
            string = (
                string
                + f"""
                        </select>
                        </td>
                        <td class="dt-center">
                            <div class="" style="max-width:25em;">
                            <input type="text" placeholder='{col_name}' name={col_name} step="any" class="textinput form-control" value="True" readonly>
                            </div>
                        </td>
                        <td class="dt-center">
                        <div class="" style="max-width:25em;">
                        <select class="form-control select2bs4" name={col_name} data-dropdown_purpose="select_global_variable" data-type="text">
                            <option value="" selected disabled>Select Global Variable</option>
                        </select>
                        </div>
                        </td>
                        """
            )
        else:
            string = (
                string
                + f"""
                        </select>
                        </div>
                        </td>
                        <td class="dt-center">
                            <div class="" style="max-width:25em;">
                            <input type="text" placeholder='{col_name}' name={col_name} maxlength="100" class="textinput textInput form-control" required="" >
                            </div>
                        </td>
                        <td class="dt-center">
                        <div class="" style="max-width:25em;">
                        <select class="form-control select2bs4" name={col_name} data-dropdown_purpose="select_global_variable" data-type="text">
                            <option value="" selected disabled>Select Global Variable</option>
                        </select>
                        </div>
                        </td>
                        """
            )

        form_fields[col_name] = string
    return form_fields


def save_model_outputs(model_name, element_id, output_name, request, multi=""):
    if output_name:
        existing_model_outputs = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "computation_output_repository",
                    "Columns": ["model_outputs"],
                },
                "condition": [
                    {
                        "column_name": "model_name",
                        "condition": "Equal to",
                        "input_value": model_name,
                        "and_or": "",
                    },
                ],
            },
        )

        existing_outputs2 = {}
        if not existing_model_outputs.empty:
            existing_outputs2 = existing_model_outputs.model_outputs.iloc[0]
            if existing_outputs2:
                existing_outputs2 = json.loads(existing_outputs2)

            existing_outputs = existing_outputs2.copy()
            for ele, value in existing_outputs2.items():
                if value["element_id"] == element_id:
                    if value["element_output_type"] == "single":
                        existing_outputs.pop(ele)
                    else:
                        if value["multi-name"] == multi:
                            existing_outputs.pop(ele)
            if multi == "":
                existing_outputs[output_name] = {
                    "element_id": element_id,
                    "element_output_type": "single",
                    "multi-name": "",
                }
            else:
                existing_outputs[output_name] = {
                    "element_id": element_id,
                    "element_output_type": "multiple",
                    "multi-name": multi,
                }

            existing_outputs = json.dumps(existing_outputs)
            update_data_func(
                request,
                config_dict={
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "computation_output_repository",
                        "Columns": [
                            {
                                "column_name": "model_outputs",
                                "input_value": existing_outputs,
                                "separator": "",
                            },
                        ],
                    },
                    "condition": [
                        {
                            "column_name": "model_name",
                            "condition": "Equal to",
                            "input_value": model_name,
                            "and_or": "",
                        },
                    ],
                },
            )
        else:
            output_name_df = pd.DataFrame(columns=["model_name", "model_outputs"])
            model_outputs = {}
            if multi == "":
                model_outputs[output_name] = {
                    "element_id": element_id,
                    "element_output_type": "single",
                    "multi-name": "",
                }
            else:
                model_outputs[output_name] = {
                    "element_id": element_id,
                    "element_output_type": "multiple",
                    "multi-name": multi,
                }

            model_outputs = json.dumps(model_outputs)
            output_name_df_dict = {
                "model_name": model_name,
                "model_outputs": model_outputs,
            }
            output_name_df_dict_df = pd.DataFrame.from_dict([output_name_df_dict])
            output_name_df = pd.concat(
                [output_name_df, output_name_df_dict_df],
                ignore_index=True,
            )
            data_handling(request, output_name_df, "computation_output_repository")


def save_interim_model_outputs(source, table_name, data, request):
    request_user = request.user.username
    table_name = table_name.replace(" ", "_")
    data = data_type_convertor(data)
    if not isinstance(data, str):
        if source == "existing_table":
            modelName = dynamic_model_create.get_model_class(table_name, request)

            table_field_names = {
                field.name: field.get_internal_type()
                for field in modelName.concrete_fields
                if field.get_internal_type() not in ["AutoField"]
                if not field.primary_key
            }
            nullable_field_names = [field.name for field in modelName.concrete_fields if field.null]

            final_data = table_format_validator(
                data,
                fields=table_field_names,
                nullable_fields=nullable_field_names,
                table_name=table_name,
            )
            if not isinstance(final_data, str):
                if "created_by" in table_field_names.keys():
                    final_data["created_by"] = request_user
                    final_data["created_date"] = datetime.now()
                    final_data["modified_by"] = request_user
                    final_data["modified_date"] = datetime.now()
                if "active_from" in table_field_names.keys():
                    final_data["active_from"] = datetime.now()
                if "active_to" in table_field_names.keys():
                    final_data["active_to"] = datetime.now() + relativedelta(years=100)
                data_handling(request, final_data, table_name)
                return f"Data exported to {table_name} table successfully"
            else:
                return final_data
        elif source == "create_table":
            tables_df = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "Tables",
                        "Columns": ["tablename", "model_type"],
                    },
                    "condition": [],
                },
            )
            if table_name in tables_df.tablename.tolist():
                modelName = dynamic_model_create.get_model_class(table_name, request)
                table_field_names = {
                    field.name: field.get_internal_type()
                    for field in modelName.concrete_fields
                    if field.get_internal_type() not in ["AutoField"]
                    if not field.primary_key
                }
                nullable_field_names = [field.name for field in modelName.concrete_fields if field.null]

                final_data = table_format_validator(
                    data,
                    fields=table_field_names,
                    nullable_fields=nullable_field_names,
                    table_name=table_name,
                )
                if not isinstance(final_data, str):
                    if "created_by" in table_field_names.keys():
                        final_data["created_by"] = request_user
                        final_data["created_date"] = datetime.now()
                        final_data["modified_by"] = request_user
                        final_data["modified_date"] = datetime.now()
                    if "active_from" in table_field_names.keys():
                        final_data["active_from"] = datetime.now()
                    if "active_to" in table_field_names.keys():
                        final_data["active_to"] = datetime.now() + relativedelta(years=100)
                    data_handling(request, final_data, table_name)
                    return f"Data exported to {table_name} table successfully"
                else:
                    return final_data
            else:
                data_field_type = data.dtypes.apply(lambda x: x.name).to_dict()
                model_fields = {}
                sql_table_name = "users_" + table_name.lower().replace(" ", "_")
                create_query = f"CREATE TABLE {sql_table_name} ("
                create_query += "id INT IDENTITY PRIMARY KEY,"
                model_fields["id"] = {
                    "internal_type": "AutoField",
                    "verbose_name": "id",
                    "null": 0,
                    "unique": 1,
                    "validators": [],
                    "primary_key": 1,
                }
                for col_name, col_type in data_field_type.items():
                    if col_type == "object":
                        add_string = f"{col_name} VARCHAR(526) NULL,"
                        # model_fields[
                        #     col_name
                        # ] = f"md.CharField(verbose_name='{col_name.replace('_', ' ').title()}',null=1,max_length=526,choices='',)"
                        model_fields[col_name] = {
                            "internal_type": "TextField",
                            "verbose_name": col_name.replace("_", " ").title(),
                            "null": 1,
                            "unique": 0,
                            "validators": [],
                        }
                    elif col_type == "datetime64[ns]":
                        add_string = f"{col_name} DATETIME NULL,"
                        # model_fields[
                        #     col_name
                        # ] = f"md.DateTimeField(verbose_name='{col_name.replace('_', ' ').title()}',null=1,auto_now=0, editable=1)"
                        model_fields[col_name] = {
                            "internal_type": "DateTimeField",
                            "verbose_name": col_name.replace("_", " ").title(),
                            "null": 1,
                            "unique": 0,
                            "validators": [],
                            "auto_now": 0,
                            "editable": 1,
                        }
                    elif col_type == "int64":
                        add_string = f"{col_name} INT NULL,"
                        # model_fields[
                        #     col_name
                        # ] = f"md.IntegerField(verbose_name='{col_name.replace('_', ' ').title()}',null=1,default=0,)"
                        model_fields[col_name] = {
                            "internal_type": "IntegerField",
                            "verbose_name": col_name.replace("_", " ").title(),
                            "null": 0,
                            "unique": 0,
                            "default": 0,
                            "validators": [],
                        }
                    elif col_type == "int64":
                        add_string = f"{col_name} BIGINT NULL,"
                        # model_fields[
                        #     col_name
                        # ] = f"md.IntegerField(verbose_name='{col_name.replace('_', ' ').title()}',null=1,default=0,)"
                        model_fields[col_name] = {
                            "internal_type": "BigIntegerField",
                            "verbose_name": col_name.replace("_", " ").title(),
                            "null": 0,
                            "unique": 0,
                            "default": 0,
                            "validators": [],
                        }
                    elif col_type == "float64":
                        add_string = f"{col_name} FLOAT NULL,"
                        # model_fields[
                        #     col_name
                        # ] = f"md.FloatField(verbose_name='{col_name.replace('_', ' ').title()}',null=1,default=0,)"
                        model_fields[col_name] = {
                            "internal_type": "FloatField",
                            "verbose_name": col_name.replace("_", " ").title(),
                            "null": 0,
                            "unique": 0,
                            "default": 0,
                            "validators": [],
                        }
                    elif col_type == "bool":
                        add_string = f"{col_name} BIT NULL,"
                        # model_fields[
                        #     col_name
                        # ] = f"md.BooleanField(verbose_name='{col_name.replace('_', ' ').title()}',null=1,)"
                        model_fields[col_name] = {
                            "internal_type": "BooleanField",
                            "verbose_name": col_name.replace("_", " ").title(),
                            "null": 0,
                            "unique": 0,
                            "validators": [],
                        }
                    create_query += add_string
                create_query += "created_by VARCHAR(100) NOT NULL,"
                create_query += "created_date DATETIME,"
                create_query += "modified_by VARCHAR(100) NOT NULL,"
                create_query += "modified_date DATETIME,"
                create_query += "approval_status VARCHAR(100),"
                create_query += "approved_by VARCHAR(100),"
                create_query += "active_from DATETIME,"
                create_query += "active_to DATETIME,"
                create_query += "transaction_id VARCHAR(100),"
                create_query += "is_active_flag VARCHAR(100),"
                create_query += ");"

                db_engine, db_type, schema = app_engine_generator(request)
                with db_engine.begin() as conn:
                    conn.execute(create_query)

                # model_fields[
                #     "created_by"
                # ] = "md.CharField(verbose_name='Created by',null=0,max_length=100,choices='',)"
                # model_fields[
                #     "created_date"
                # ] = "md.DateTimeField(verbose_name='Created date',null=0,auto_now=1, editable=0)"
                # model_fields[
                #     "modified_by"
                # ] = "md.CharField(verbose_name='Modified by',null=0,max_length=100,choices='',)"
                # model_fields[
                #     "modified_date"
                # ] = "md.DateTimeField(verbose_name='Modified date',auto_now=1, editable=0,null=1,)"
                # model_fields[
                #     "approval_status"
                # ] = "md.CharField(verbose_name='Approval status',null=1,max_length=100,choices='',)"
                # model_fields[
                #     "approved_by"
                # ] = "md.CharField(verbose_name='Approved by',null=1,max_length=100,choices='',)"
                # model_fields[
                #     "active_from"
                # ] = "md.DateTimeField(verbose_name='Active From',auto_now=1, editable=0,null=1,)"
                # model_fields[
                #     "active_to"
                # ] = "md.DateTimeField(verbose_name='Active To',auto_now=1, editable=0,null=1,)"

                model_fields["created_by"] = {
                    "internal_type": "CharField",
                    "verbose_name": "Created by",
                    "null": 0,
                    "unique": 0,
                    "max_length": 100,
                    "choices": "",
                }
                model_fields["modified_by"] = {
                    "internal_type": "CharField",
                    "verbose_name": "Modified by",
                    "null": 0,
                    "unique": 0,
                    "max_length": 100,
                    "choices": "",
                }
                model_fields["created_date"] = {
                    "internal_type": "DateTimeField",
                    "verbose_name": "Created date",
                    "null": 0,
                    "unique": 0,
                    "auto_now": 1,
                    "editable": 0,
                }
                model_fields["modified_date"] = {
                    "internal_type": "DateTimeField",
                    "verbose_name": "Modified date",
                    "null": 0,
                    "unique": 0,
                    "auto_now": 1,
                    "editable": 0,
                }
                model_fields["active_from"] = {
                    "internal_type": "DateTimeField",
                    "verbose_name": "Active From",
                    "null": 1,
                    "unique": 0,
                    "auto_now": 1,
                    "editable": 0,
                }
                model_fields["active_to"] = {
                    "internal_type": "DateTimeField",
                    "verbose_name": "Active To",
                    "null": 1,
                    "unique": 0,
                    "auto_now": 1,
                    "editable": 0,
                }
                model_fields["transaction_id"] = {
                    "internal_type": "CharField",
                    "verbose_name": "transaction_id",
                    "null": 1,
                    "unique": 0,
                    "editable": 0,
                    "max_length": 100,
                    "choices": "",
                }
                model_fields["is_active_flag"] = {
                    "internal_type": "CharField",
                    "verbose_name": "is_active_flag",
                    "null": 1,
                    "unique": 0,
                    "editable": 0,
                    "max_length": 100,
                    "choices": "",
                    "default": "Yes",
                }

                model_fields = json.dumps(model_fields)
                users_tables_df = pd.DataFrame(
                    {
                        "tablename": table_name,
                        "fields": model_fields,
                        "model_type": "user defined",
                    },
                    index=[0],
                )
                data_handling(request, users_tables_df, "Tables")

                data["created_by"] = request_user
                data["created_date"] = datetime.now()
                data["modified_by"] = request_user
                data["modified_date"] = datetime.now()
                data["active_from"] = datetime.now()
                data["active_to"] = datetime.now() + relativedelta(years=100)
                data_handling(request, data, table_name)
                return f"Data exported to {table_name} table successfully"
    else:
        data += f"! Failed to export data to {table_name}"
        return data


def table_format_validator(
    data,
    fields,
    nullable_fields,
    table_name,
    auto_fields=[
        "created_by",
        "created_date",
        "modified_by",
        "modified_date",
        "approval_status",
        "approved_by",
        "active_to",
        "active_from",
    ],
):
    data_field_type = data.dtypes.apply(lambda x: x.name).to_dict()
    field_type_mapper = {
        "CharField": "object",
        "TextField": "object",
        "DateField": "datetime64[ns]",
        "DateTimeField": "datetime64[ns]",
        "IntegerField": "int32",
        "BigIntegerField": "int64",
        "FloatField": "float64",
        "BooleanField": "bool",
    }
    mandatory_fields = [field for field in fields.keys() if field not in nullable_fields]
    editable_fields = [field for field in fields.keys() if field not in auto_fields]

    for col in editable_fields:
        if col not in data.columns.tolist() and col in mandatory_fields:
            return f"{col} is a mandatory field. Cant push data to this table"
        else:
            if col in data.columns.tolist():
                field_type = fields[col]
                if field_type_mapper[field_type] != data_field_type[col]:
                    try:
                        data[col] = data[col].astype(field_type_mapper[field_type])
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")
                        return f"{col} is a mandatory field. Failed to export data to {table_name}!"
    return data


def data_type_convertor(data):
    if isinstance(data, (dict, list)):
        new_data = pd.DataFrame(data)
        return new_data
    elif isinstance(data, pd.DataFrame):
        return data
    else:
        return "Data is of unknown type"


def fillNa(data, object_fill="None", num_fill=0, date_fill="2000-01-01"):
    columns_list = data.columns.tolist()
    field_type = data.dtypes.apply(lambda x: x.name).to_dict()
    for col_name in columns_list:
        if field_type[col_name] == "object":
            data[col_name] = data[col_name].fillna(object_fill)
        elif field_type[col_name] in ["int64", "float64", "Int64"]:
            data[col_name] = data[col_name].fillna(num_fill)
        elif field_type[col_name] in ["datetime64[ns]"]:
            data[col_name] = data[col_name].fillna(pd.to_datetime(date_fill))
        else:
            data[col_name] = data[col_name].fillna(object_fill)
    return data


def random_no_generator(N=16):
    code = "".join(random.SystemRandom().choice(string.ascii_letters + string.digits) for _ in range(N))
    return code


def sendColumnNamesDatatablesListViewAjaxCall(modelName):
    audit_log_fields = [
        "active_from",
        "active_to",
        "created_by",
        "created_date",
        "modified_by",
        "modified_date",
        "transaction_id",
        "is_active_flag",
    ]
    columnCombine = [
        {"verboseName": field.verbose_name, "originalName": field.name}
        for field in modelName.concrete_fields
        if field.name not in audit_log_fields
    ]
    columns_dict = {
        field.name: field.verbose_name
        for field in modelName.concrete_fields
        if field.name in audit_log_fields
    }
    finalColumnListDatatableFormat = []
    for c in columnCombine:
        finalColumnListDatatableFormat.append({"data": c["verboseName"]})
    for c in audit_log_fields:
        if c in columns_dict:
            finalColumnListDatatableFormat.append({"data": columns_dict[c]})
    return finalColumnListDatatableFormat


def sendDataFormattedDatatablesListViewAjaxCall(rawData, columnCombine):
    rawData.fillna(value="None", inplace=True)
    rawData1 = rawData.to_dict("list")
    rawData2 = {}
    finalColumnListDatatableFormat = []
    for c in columnCombine:
        rawData2[c["verboseName"]] = rawData1[c["originalName"]]
        finalColumnListDatatableFormat.append({"data": c["verboseName"]})

    rawData3 = pd.DataFrame.from_dict(rawData2)
    finalDataInDatatableFormat = rawData3.to_dict("records")
    return finalDataInDatatableFormat


def nodes_creation(model_name, request, type_scenario_model):
    model_config_data = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_flowchart",
                "Columns": [
                    "flowchart_elements",
                ],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": model_name,
                    "and_or": "",
                }
            ],
        },
    )
    nodes = model_flow(
        model_name,
        json.loads(model_config_data.flowchart_elements.iloc[0]),
        request,
        type_scenario_model,
    )
    return nodes


def model_flow(model_name, model_config, request, type_scenario_model):
    nodes = {"text": {"name": model_name}, "HTMLclass": "model_names"}
    node_list = []
    for i in model_config:
        if "importData" in i["element_id"]:
            node_dict = {}
            text_dict = {}
            element_id = i["element_id"]
            element_data = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "computation_model_configuration",
                        "Columns": ["element_name", "element_config"],
                    },
                    "condition": [
                        {
                            "column_name": "element_id",
                            "condition": "Equal to",
                            "input_value": element_id,
                            "and_or": "",
                        }
                    ],
                },
            )
            element_name = element_data.element_name.iloc[0]
            text_dict = {"title": element_name, "data-element_id": element_id}
            element_config = json.loads(element_data.element_config.iloc[0])
            if element_config["inputs"]["Data_source"] == "Model_output":
                model_name_child = element_config["inputs"]["model_selected"]
                children_list = [nodes_creation(model_name_child, request, type_scenario_model)]
                node_dict["HTMLclass"] = "data_model_input" + "_" + type_scenario_model
                text_dict["data-model_name_child"] = model_name_child
                text_dict["data-model_name"] = model_name
                text_dict["data-element_name"] = element_name
            elif (
                element_config["inputs"]["Data_source"] == "CSV"
                or element_config["inputs"]["Data_source"] == "JSON"
                or element_config["inputs"]["Data_source"] == "Parquet"
                or element_config["inputs"]["Data_source"] == "SFTP"
                or element_config["inputs"]["Data_source"] == "FTP"
                or element_config["inputs"]["Data_source"] == "AWS_S3"
                or element_config["inputs"]["Data_source"] == "AZURE"
                or element_config["inputs"]["Data_source"] == "LOCAL"
            ):
                children_list = []
                node_dict["HTMLclass"] = "csv_input"
            else:
                children_list = []
                node_dict["HTMLclass"] = "data_model_input" + "_" + type_scenario_model
                if "Table" in element_config["inputs"]:
                    text_dict["data-tablename"] = element_config["inputs"]["Table"]
                    text_dict["data-model_name"] = model_name
                    text_dict["data-element_name"] = element_name
            node_dict["text"] = text_dict
            node_dict["children"] = children_list
            node_list.append(node_dict)
    nodes["children"] = node_list
    return nodes


def flowNextElement(element_id, pr_code, request, status="pass", exceptions=""):
    if "__tab__" in element_id:
        element_id = element_id[: element_id.find("__tab__")]
    app_code = goback(request).split("/")[2]
    flow = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "Process_flow_model",
                "Columns": ["flow", "transaction_id", "current_status", "element_id"],
            },
            "condition": [
                {
                    "column_name": "subprocess",
                    "condition": "Equal to",
                    "input_value": pr_code,
                    "and_or": "AND",
                },
                {
                    "column_name": "app_code",
                    "condition": "Equal to",
                    "input_value": app_code,
                    "and_or": "",
                },
            ],
        },
    )
    current = flow[(flow.element_id == element_id) & (flow.current_status == "Not started")]
    if not current.empty:
        transaction_id = current.iloc[0]["transaction_id"]
        current_transaction = flow[(flow.element_id == element_id) & (flow.transaction_id == transaction_id)]
        flow1 = json.loads(current_transaction.iloc[0]["flow"])
        next_element = ""
        if flow1.index(element_id) != (len(flow1) - 1):
            next_element = flow1[flow1.index(element_id) + 1]
            if next_element.__contains__("flowControl"):
                next_element = flow1[flow1.index(element_id) + 2]
        if next_element.find("decision") >= 0:
            return "allowed"
        else:
            return "not allowed"
    else:
        return "allowed"


def randomFunc():
    mantissa = 0x10_0000_0000_0000 | random.getrandbits(52)
    return mantissa


def fetchFlowDetail(request, transaction_id):
    app_code = goback(request).split("/")[2]
    data = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "Process_flow_model",
                "Columns": [
                    "transaction_id",
                    "process",
                    "subprocess",
                    "current_status",
                    "element_id",
                    "detailed_status",
                    "tab_type",
                    "element_name",
                    "created_date",
                    "modified_date",
                ],
            },
            "condition": [
                {
                    "column_name": "app_code",
                    "condition": "Equal to",
                    "input_value": app_code,
                    "and_or": "AND",
                },
                {
                    "column_name": "transaction_id",
                    "condition": "Equal to",
                    "input_value": transaction_id,
                    "and_or": "",
                },
            ],
        },
    )
    data["created_date"] = pd.to_datetime(data["created_date"]).dt.strftime("%Y-%m-%d %H:%M:%S")
    data["modified_date"] = pd.to_datetime(data["modified_date"]).dt.strftime("%Y-%m-%d %H:%M:%S")
    data = data.to_dict("records")
    return {"data": data}


def getPrCodeFromElementId(element_id, request):
    if "__tab__" in element_id:
        element_id = element_id[: element_id.find("__tab__")]
    pr_code = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["related_item_code"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": element_id,
                    "and_or": "",
                },
            ],
        },
    )
    if not pr_code.empty:
        pr_code = pr_code.iloc[0]["related_item_code"]
    else:
        pr_code = "#"
    return pr_code


def checkLatestData(data, element_id, table, request, transaction_id=[], batch_use="", element=""):
    if element_id != "":
        if "__tab__" in element_id:
            element_id = element_id[: element_id.find("__tab__")]
        pr_code = getPrCodeFromElementId(element_id, request)
        app_code = goback(request).split("/")[2]
        flow = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Process_flow_model",
                    "Columns": [
                        "flow",
                        "transaction_id",
                        "current_status",
                        "element_id",
                        "modified_date",
                        "modified_by",
                        "data_id",
                        "total_batch_data",
                        "pass_batch_data",
                    ],
                },
                "condition": [
                    {
                        "column_name": "subprocess",
                        "condition": "Equal to",
                        "input_value": pr_code,
                        "and_or": "AND",
                    },
                    {
                        "column_name": "app_code",
                        "condition": "Equal to",
                        "input_value": app_code,
                        "and_or": "",
                    },
                ],
            },
        )
        update = True
        if len(transaction_id) == 1:
            current = flow[
                (flow.element_id == element_id)
                & (flow.transaction_id == transaction_id[0])
                & ((flow.current_status == "Not started") | (flow.current_status == "Ongoing"))
            ]
        elif len(transaction_id) > 1:
            condition = []
            transaction_id = list(set(transaction_id))
            for i in transaction_id:
                dic = {
                    "column_name": "transaction_id",
                    "condition": "Equal to",
                    "input_value": i,
                    "and_or": "or",
                }
                condition.append(dic)
            condition[len(condition) - 1]["and_or"] = ""
            current = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "Process_flow_model",
                        "Columns": [
                            "flow",
                            "transaction_id",
                            "current_status",
                            "element_id",
                            "modified_date",
                            "modified_by",
                            "data_id",
                            "total_batch_data",
                            "pass_batch_data",
                        ],
                    },
                    "condition": condition,
                },
            )
            current = current[(current.element_id == element_id)]
        else:
            current = flow[
                (flow.element_id == element_id)
                & ((flow.current_status == "Not started") | (flow.current_status == "Ongoing"))
            ]
        current = current.reindex(
            columns=[
                "transaction_id",
                "total_batch_data",
                "pass_batch_data",
                "element_id",
                "modified_by",
                "modified_date",
                "data_id",
                "flow",
            ]
        )
        transaction_id_ = current.to_dict("list")["transaction_id"]
        total_batch_data = current.to_dict("list")["total_batch_data"]
        pass_batch_data = current.to_dict("list")["pass_batch_data"]
        index = 0
        arr = {}
        for transaction_id in transaction_id_:
            if not current.empty:
                modified_date = flow[
                    (flow.transaction_id == transaction_id) & (flow.current_status != "Not started")
                ]
                modified_date = modified_date.to_dict("records")
                modified_date.reverse()
                current_transaction = flow[
                    (flow.element_id == element_id) & (flow.transaction_id == transaction_id)
                ]
                flow1 = json.loads(current_transaction.iloc[0]["flow"])
                previous_element = ""
                if flow1.index(element_id) != 0:
                    previous_element = flow1[flow1.index(element_id) - 1]
                if flow1.index(element_id) != (len(flow1) - 1):
                    pass
                if previous_element != "":
                    previous_element_status = flow[
                        (flow.element_id == previous_element)
                        & (flow.current_status != "Not started")
                        & (flow.current_status != "Ongoing")
                        & (flow.current_status != "Active")
                        & (flow.transaction_id == transaction_id)
                    ]
                    if len(previous_element_status) == 1:
                        update = True
                    else:
                        update = False
                if update:
                    result_ = {}
                    try:
                        data1 = data[
                            data.transaction_id.str.contains(
                                transaction_id,
                                na=False,
                            )
                        ]
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")
                        data1 = data[data["Transaction_Id"].str.contains(transaction_id, na=False)]

                    total_data = 1
                    if element in ["analysis"]:
                        result_flow = flowValidationTo(
                            element_id,
                            getPrCodeFromElementId(element_id, request),
                            request,
                            transaction_id=[transaction_id],
                        )
                        result_, FinalData_flow = validation_result_to(
                            data1,
                            result_flow,
                            {},
                            table,
                            transaction_id=[transaction_id],
                            element=element,
                            request=request,
                            element_id=element_id,
                        )
                        if element in ["computation", "analysis"]:
                            result_flowCC = flowValidationCC(
                                element_id,
                                getPrCodeFromElementId(element_id, request),
                                request,
                                transaction_id=[transaction_id],
                            )
                            result_cc, FinalData_flowCC = validation_result_CC(
                                data1,
                                result_flowCC,
                                {},
                                table,
                                transaction_id=[transaction_id],
                                element=element,
                                request=request,
                                element_id=element_id,
                            )
                            if True not in list(result_cc.values()):
                                if True not in list(result_.values()):
                                    result_[transaction_id] = str(result_[transaction_id]) + str(
                                        result_cc[transaction_id]
                                    )
                                else:
                                    result_ = result_cc
                            data1 = FinalData_flow
                    dic = {}
                    if element_id.__contains__("paral"):
                        dic["total_data"] = total_data
                    if redis_instance.exists("data_present_intransac"):
                        arr = pickle.loads(redis_instance.get("data_present_intransac"))
                    if batch_use == "pass_batch":
                        if pass_batch_data[index] not in ["NULL", None, ""]:
                            dic["data_left"] = str(int(pass_batch_data[index]) - len(data1))
                    else:
                        if True not in list(result_.values()):
                            dic["data_left"] = result_
                        else:
                            if total_batch_data[index] in [None, "NULL", "None"]:
                                dic["data_left"] = str(0)
                            else:
                                dic["data_left"] = str(int(total_batch_data[index]) - len(data1))

                    arr[transaction_id] = dic
                    if redis_instance.exists("data_present_intransac"):
                        redis_instance.set("data_present_intransac", pickle.dumps(arr))
                else:
                    dic = {}
                    dic["data_left"] = "No"
                    arr[transaction_id] = dic
                    if redis_instance.exists("data_present_intransac"):
                        redis_instance.set("data_present_intransac", pickle.dumps(arr))
            index = index + 1
        return arr


def goback(request):
    url_string = request.path
    f_occ = url_string.find("/", url_string.find("/") + 1)
    s_occ = url_string.find("/", url_string.find("/") + f_occ + 1)
    t_occ = url_string.find("/", url_string.find("/") + s_occ + 1)
    app_code = url_string[f_occ + 1 : s_occ]
    current_dev_mode = url_string[s_occ + 1 : t_occ]
    if app_code:
        return f"/users/{app_code}/{current_dev_mode}/homePage/"
    else:
        return "/users/selectApplication/"


def nestedForeignKey(
    field1,
    request_user,
    db_connection_name,
    input_data=pd.DataFrame(),
    i="",
    populate="no",
    db_engine=["", None],
    db_type="",
):
    table_h = []
    if field1.get_internal_type() == "ForeignKey":
        parent = field1.parent
        column = field1.name
        parent_table = field1.parent
        table_h.append(parent_table)
        if len(input_data) > 0 and populate == "no":
            input_data = foreignDataMapping(
                parent_table,
                db_connection_name,
                input_data,
                i,
                column,
                request_user,
                db_engine=db_engine,
                db_type=db_type,
            )
        while parent:
            model_name = dynamic_model_create.get_model_class(
                parent,
                request_user,
                db_connection_name=db_connection_name,
                db_engine=db_engine,
                db_type=db_type,
            )
            parent = None
            for field in model_name.concrete_fields:
                if field.get_internal_type() == "ForeignKey" and field.name == column:
                    parent = field.parent
                    parent_table = field.parent
                    table_h.append(parent_table)
                    if len(input_data) > 0:
                        input_data = foreignDataMapping(
                            parent_table,
                            db_connection_name,
                            input_data,
                            i,
                            column,
                            request_user,
                            db_engine=db_engine,
                            db_type=db_type,
                        )
        return (parent_table, input_data, table_h)


def foreignDataMapping(
    parent_table,
    db_connection_name,
    redis_data,
    i,
    column,
    request_user,
    db_engine=["", None],
    db_type="",
):
    modelName2 = dynamic_model_create.get_model_class(
        parent_table,
        request_user,
        db_connection_name=db_connection_name,
        db_engine=db_engine,
        db_type=db_type,
    )

    index_selected = redis_data[i].dropna().unique().tolist()
    override = False
    if db_type != "":
        override = True
    if index_selected:
        index_selected = str(tuple(index_selected)).replace(",)", ")")
        foreign_key_data = (
            read_data_func(
                request_user,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": parent_table,
                        "Columns": [modelName2.pk.name, column],
                    },
                    "condition": [
                        {
                            "column_name": modelName2.pk.name,
                            "condition": "IN",
                            "input_value": index_selected,
                            "and_or": "",
                        },
                    ],
                },
                engine2=db_engine,
                db_type=db_type,
                engine_override=override,
                fetch_all_entries=True,
                access_controller=False,
            )
            .set_index(modelName2.pk.name)[column]
            .to_dict()
        )
        redis_data[i] = redis_data[i].replace(to_replace=foreign_key_data)
    else:
        pass
    return redis_data


def cal_embeded_computation(data_csv, table_model_name, request, comp_name):

    e_string = data_csv[1]
    data_csv = data_csv[0]

    model_name = table_model_name
    flowchart_elements = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_flowchart",
                "Columns": ["flowchart_elements"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": comp_name,
                    "and_or": "",
                },
            ],
        },
    )
    flowchart_elements = flowchart_elements.iloc[0, 0]
    flowchart_elements = json.loads(flowchart_elements)
    global_element_id = ""
    for i in flowchart_elements:
        if i["element_id"].startswith("globalVariable"):
            global_element_id = i["element_id"]
            break
        else:
            continue
    if global_element_id:
        global_config = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "computation_model_configuration",
                    "Columns": ["element_config"],
                },
                "condition": [
                    {
                        "column_name": "model_name",
                        "condition": "Equal to",
                        "input_value": comp_name,
                        "and_or": "and",
                    },
                    {
                        "column_name": "element_id",
                        "condition": "Equal to",
                        "input_value": global_element_id,
                        "and_or": "",
                    },
                ],
            },
        )
        if len(global_config) > 0:
            global_dict = global_config.element_config.iloc[-1]
            global_dict = json.loads(global_dict)
        else:
            global_dict = {}
    else:
        global_dict = {}

    default = "yes"
    data_csv1 = run_process_model_run_handler(
        request,
        flowchart_elements=flowchart_elements,
        model_name=comp_name,
        global_dict=global_dict,
        global_element_id=global_element_id,
        data_csv=data_csv,
        default=default,
        embedded_compute_table_name=model_name,
        in_memory_execution=True,
    )
    if data_csv1["element_error_message"] == "Success":
        e_string = data_csv1["element_error_message"]
        if isinstance(data_csv1["content"], pd.DataFrame):
            data_csv1["content"] = data_csv1["content"].fillna("None").astype("str").to_dict("records")
            b = data_csv1
        else:
            b = data_csv1
    else:
        b = data_csv1
        e_string = data_csv1["element_error_message"]

    return [b, e_string]


def cal_computed_val(data_csv, table_model_name, field_name, request):

    pri_id = ""
    n_id = ""
    e_string = data_csv[1]
    data_csv = data_csv[0]
    data_csv_columns = data_csv.columns.tolist()

    if "transaction_id" in data_csv_columns:
        data_csv_columns.remove("transaction_id")

    contains_is_active = False
    if "is_active_flag" in data_csv_columns:
        contains_is_active = True
        data_csv_columns.remove("is_active_flag")

    if "primary_key" in data_csv_columns:
        pri_id = data_csv["primary_key"].tolist()
        data_csv_columns.remove("primary_key")

    if "id" in data_csv_columns:
        n_id = data_csv["id"].tolist()
        data_csv_columns.remove("id")

    model_name = table_model_name
    flowchart_elements = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "data_management_computed_fields_flow",
                "Columns": ["flowchart_elements"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": table_model_name + field_name,
                    "and_or": "",
                },
            ],
        },
    )
    flowchart_elements = flowchart_elements.iloc[0, 0]
    flowchart_elements = json.loads(flowchart_elements)
    global_dict = {}
    global_element_id = ""
    data_id = "datamgm"

    data_csv1 = run_process_model_run_handler(
        request,
        flowchart_elements=flowchart_elements,
        model_name=model_name,
        global_dict=global_dict,
        global_element_id=global_element_id,
        data_csv=data_csv,
        data_id=data_id,
        in_memory_execution=True,
    )
    if data_csv1["element_error_message"] == "Success":
        e_string = data_csv1["element_error_message"]
        if isinstance(data_csv1["content"], pd.DataFrame):
            b = data_csv1["content"]
            b = b[[i for i in b.columns if i in data_csv_columns]]
            b["transaction_id"] = "None"
            if contains_is_active:
                b["is_active_flag"] = "Yes"
            if pri_id:
                b["primary_key"] = "None"
                if len(pri_id) == 1:
                    b["primary_key"] = pri_id[0]
                else:
                    for ind in b.index:
                        b["primary_key"][ind] = pri_id[ind]
            if n_id:
                b["id"] = "None"
                if len(n_id) == 1:
                    b["id"] = n_id[0]
                else:
                    for ind in b.index:
                        b["id"][ind] = n_id[ind]

            b = b.replace([np.inf, -np.inf], np.nan)
        elif isinstance(data_csv1["content"], dict):
            a = data_csv1["content"]
            b = pd.DataFrame(a)
            b = b[[i for i in b.columns if i in data_csv_columns]]
            b["transaction_id"] = "None"
            if contains_is_active:
                b["is_active_flag"] = "Yes"
            if pri_id:
                b["primary_key"] = "None"
                if len(pri_id) == 1:
                    b["primary_key"] = pri_id[0]
                else:
                    for ind in b.index:
                        b["primary_key"][ind] = pri_id[ind]
            if n_id:
                b["id"] = "None"
                if len(n_id) == 1:
                    b["id"] = n_id[0]
                else:
                    for ind in b.index:
                        b["id"][ind] = n_id[ind]

            b = b.replace([np.inf, -np.inf], np.nan)
        else:
            b = pd.DataFrame(np.zeros(data_csv.shape))
    else:
        e_string = data_csv1["element_error_message"]
        b = pd.DataFrame(columns=[data_csv_columns])
        b["transaction_id"] = "None"
        if contains_is_active:
            b["is_active_flag"] = "Yes"
        if pri_id:
            if len(pri_id) == 1:
                b["primary_key"] = pri_id[0]
            else:
                for ind in b.index:
                    b["primary_key"][ind] = pri_id[ind]
        if n_id:
            if len(n_id) == 1:
                b["id"] = n_id[0]
            else:
                for ind in b.index:
                    b["id"][ind] = n_id[ind]

    return [b, e_string]


def computation_js(table_name, column, eq_model_name, valuesDic, datatypeList, request):

    flowchart_elements = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_flowchart",
                "Columns": ["flowchart_elements"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": eq_model_name,
                    "and_or": "",
                },
            ],
        },
    )
    flowchart_elements = flowchart_elements.iloc[0, 0]
    flowchart_elements = json.loads(flowchart_elements)
    global_dict = {
        "function": "Global Variable",
        "inputs": {"variables": [], "mapperConfig": {}, "multi_run_vars": [], "mapper_variables": []},
    }
    global_element_id = ""
    for k, v in valuesDic.items():
        vars = {}
        vars["varName"] = k
        vars["defaultValue"] = v
        vars["dataType"] = ""
        global_dict["inputs"]["variables"].append(vars)
    data_csv1 = run_process_model_run_handler(
        request,
        flowchart_elements=flowchart_elements,
        model_name=eq_model_name,
        global_dict=global_dict,
        global_element_id=global_element_id,
        in_memory_execution=True,
    )
    if data_csv1["element_error_message"] == "Success":
        e_string = data_csv1["element_error_message"]
        if isinstance(data_csv1["content"], pd.DataFrame):
            data_csv1["content"] = data_csv1["content"].fillna("None").astype("str").to_dict("records")
            b = data_csv1
        else:
            b = data_csv1
    else:
        b = data_csv1
        e_string = data_csv1["element_error_message"]

    return [b, e_string]


class data_preprocessing:
    def __init__(
        self,
        data_csv,
        table_model_name,
        request,
        customvalidation,
        message_show,
        user_operation,
        check_now=False,
        export_data="no",
        export_update_column="",
        export_type="append",
        check_multi_select=False,
        custom_msg_icon=None,
        upsert=False,
    ):

        self.data_csv = data_csv
        self.table_model_name = table_model_name
        self.request = request
        self.customvalidation = customvalidation
        self.message_show = message_show
        self.user_operation = user_operation
        self.upsert = upsert
        self.export_data = export_data
        self.export_update_column = export_update_column
        self.export_type = export_type
        self.custom_msg_icon = custom_msg_icon

        curr_app_code, db_connection_name = current_app_db_extractor(self.request)

        self.CharField_list = []
        self.DateField_list = []
        self.DateTimeField_list = []
        self.DateTimeField_list_nosec = []
        self.BooleanField_list = []
        self.ConcatenationField_list = []
        self.IntegerField_list = []
        self.FloatField_list = []
        self.TextField_list = []
        self.URLField_list = []
        self.FileField_list = []
        self.TimeField_list = []
        self.TimeField_list_nosec = []
        self.ForeignKey_list = []
        self.TimeRangeField_list = []
        self.DateTimeRangeField_list = []
        self.DateRangeField_list = []
        self.CardField_list = []
        self.CardCvvField_list = []
        self.CardExpiryField_list = []
        self.EmailTypeField_list = []
        self.multi_select_field_list = []
        self.multi_select_field_config_list = {}
        self.table_field_list = []

        # CharField Dictionary
        self.max_length_check = {}
        self.null_check = {}
        self.unique_check = {}
        self.editable_check = {}
        self.default_check = {}
        self.choices_check = []
        self.blank_check = {}

        # DateField ,TimeField and DateTimeField Dictionary
        self.auto_now_check = {}
        self.auto_now_list = []

        # FileField Dictionary
        self.file_upload_to = {}
        self.file_extension = {}

        # videoField Dictionary
        self.video_type = {}

        # ImageField Dictionary
        self.image_upload_to = {}

        # Concatenation Dictionary
        self.concatenation_columns = {}
        self.divider_check = {}

        # Float Field Dictionary
        self.DecimalValidator = {}
        self.MaxDigitsValidator = {}

        # Advanced Validation Dictionary
        self.advanced_validation_check = {}

        # MaxLength and MinLength Validation Dictionary
        self.max_min_validation_check = {}
        self.column_validation_check = {}

        # Datefield validation dictionary
        self.advance_date_validators = {}

        # Email validation dictionary
        self.email_validation_check = {}

        # ForeignKey Dictionary
        self.foreignKey_property = []

        # CardField Dictionary
        self.card_property = {}

        # CardField Maxlength
        self.max_length_check_card = {}

        self.field_list = []
        self.nested_table_list = []
        self.secure_with_list = []
        self.secure_with = {}
        self.datakey = {}
        self.hierarchy_check = []

        self.modelName = dynamic_model_create.get_model_class(self.table_model_name, self.request)
        self.primary_key_field = self.modelName.pk.name
        self.drop_cols_list = [
            "created_by",
            "modified_by",
            "created_date",
            "modified_date",
            "active_to",
            "active_from",
            "approved_by",
            "approval_status",
            "transaction_id",
            "is_active_flag",
            self.modelName.pk.name,
        ]

        if "Date_of_Extraction" not in self.data_csv.columns.tolist():
            self.drop_cols_list.append("Date_of_Extraction")

        if not self.request.user.is_superuser:
            hierarchy_dict = {}
            fk_columns = {}
            for field in self.modelName.concrete_fields:
                if field.get_internal_type() == "HierarchyField":
                    hierarchy_dict.setdefault(field.hierarchy_group, []).append(field.name)
                elif field.get_internal_type() == "ForeignKey":
                    actual_model_name_h = dynamic_model_create.get_model_class(field.parent, self.request)
                    if actual_model_name_h.get_field(field.name).get_internal_type() == "HierarchyField":
                        hierarchy_dict.setdefault(
                            actual_model_name_h.get_field(field.name).hierarchy_group, []
                        ).append(field.name)
                    fk_columns[field.name] = {
                        "field_class": field,
                        "primary_key": actual_model_name_h.pk.name,
                    }

            if hierarchy_dict:
                perm_dict = data_hierarchy_access_list(self.request, hierarchy_dict)
                if perm_dict:
                    for h_idx, h_group in enumerate(hierarchy_dict):
                        if perm_dict.get(h_group):
                            perm_list = tuple(perm_dict[h_group])
                            h_cols = hierarchy_dict[h_group]

                            for c_idx, col in enumerate(h_cols):
                                if col in fk_columns:
                                    fk_field = fk_columns[col]["field_class"]
                                    self.hierarchy_check.append({fk_field.name: perm_list})
                else:
                    self.hierarchy_check.append({"no_prem": ()})
        for field in self.modelName.concrete_fields:
            self.field_list.append(field.name)
            # Drop Fields
            if field.get_internal_type() == "AutoField":
                self.drop_cols_list.append(field.name)

            if (
                self.export_type == "update"
                and self.export_update_column
                and field.name not in self.export_update_column
            ):
                self.drop_cols_list.append(field.name)

            # CharField
            if field.get_internal_type() == "CharField" and field.name not in self.drop_cols_list:
                self.CharField_list.append(field.name)
                self.advanced_validation_check[field.name] = field.validators
                self.max_min_validation_check[field.name] = field.validators
                self.max_length_check[field.name] = field.max_length
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.editable_check[field.name] = field.editable
                self.default_check[field.name] = field.default
                self.blank_check[field.name] = field.blank
                self.email_validation_check[field.name] = field.validators
                if field.datakey not in [None]:
                    self.secure_with[field.name] = field.secure_with
                    self.datakey[field.name] = field.datakey
                    if field.secure_with != "None":
                        self.secure_with_list.append(field.secure_with)
                        if field.name in data_csv.columns:
                            key = get_key(bytes(self.datakey[field.name], "utf-8"))

                            def encrypt_data(x):
                                if x not in ["", None]:
                                    try:
                                        f = Fernet(key)
                                        token = f.encrypt(bytes(x.encode("utf-8")))
                                        if isinstance(token, bytes):
                                            token = token.decode()
                                        return token
                                    except Exception as e:
                                        logging.warning(f"Following exception occured - {e}")
                                        return x

                            self.data_csv[field.name] = self.data_csv[field.name].apply(encrypt_data)
                if field.validators:
                    self.column_validation_check[field.name] = field.validators
                if field.choices:
                    self.choices_check.append({field.name: field.choices})

            if field.get_internal_type() == "TextField" and field.name not in self.drop_cols_list:
                self.TextField_list.append(field.name)
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.editable_check[field.name] = field.editable
                self.default_check[field.name] = field.default
                self.blank_check[field.name] = field.blank
                self.email_validation_check[field.name] = field.validators

            if field.get_internal_type() == "URLField" and field.name not in self.drop_cols_list:
                self.URLField_list.append(field.name)
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.editable_check[field.name] = field.editable
                self.default_check[field.name] = field.default

            # DateField
            if field.get_internal_type() == "DateField" and field.name not in self.drop_cols_list:
                self.DateField_list.append(field.name)
                if field.validators:
                    self.column_validation_check[field.name] = field.validators
                    if field.validators.get("AdvanceDateValidation"):
                        self.advance_date_validators[field.name] = field.validators["AdvanceDateValidation"]
                    else:
                        pass
                else:
                    pass

                if field.auto_now in [True, 1]:
                    self.auto_now_list.append(field.name)
                self.auto_now_check[field.name] = field.auto_now
                self.editable_check[field.name] = field.editable
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique

            # TimeField
            if field.get_internal_type() == "TimeField" and field.name not in self.drop_cols_list:
                self.TimeField_list.append(field.name)
                if field.validators:
                    self.column_validation_check[field.name] = field.validators
                if field.use_seconds == "false":
                    self.TimeField_list_nosec.append(field.name)
                    if field.name in data_csv.columns and self.user_operation != "update":
                        self.data_csv[field.name] = pd.to_datetime(
                            self.data_csv[field.name], errors="ignore"
                        ).dt.strftime("%H:%M")
                    else:
                        pass
                if field.auto_now in [True, 1]:
                    self.auto_now_list.append(field.name)
                self.auto_now_check[field.name] = field.auto_now
                self.editable_check[field.name] = field.editable
                self.null_check[field.name] = field.null

            # DateTimeField
            if field.get_internal_type() == "DateTimeField" and field.name not in self.drop_cols_list:
                self.DateTimeField_list.append(field.name)
                if field.validators:
                    self.column_validation_check[field.name] = field.validators
                if field.use_seconds == "false":
                    self.DateTimeField_list_nosec.append(field.name)
                self.auto_now_check[field.name] = field.auto_now
                if field.auto_now in [True, 1]:
                    self.auto_now_list.append(field.name)
                self.editable_check[field.name] = field.editable
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique

            # IntegerField
            if (
                field.get_internal_type() == "IntegerField" or field.get_internal_type() == "BigIntegerField"
            ) and field.name not in self.drop_cols_list:
                self.IntegerField_list.append(field.name)
                if field.validators:
                    self.column_validation_check[field.name] = field.validators
                    self.max_min_validation_check[field.name] = field.validators
                self.null_check[field.name] = field.null
                if field.editable not in ["0", 0, "False", False]:
                    self.editable_check[field.name] = field.editable
                self.default_check[field.name] = field.default
                self.blank_check[field.name] = field.blank
                self.unique_check[field.name] = field.unique

            # FloatField
            if field.get_internal_type() == "FloatField" and field.name not in self.drop_cols_list:
                self.FloatField_list.append(field.name)
                if field.validators:
                    self.column_validation_check[field.name] = field.validators
                    self.max_min_validation_check[field.name] = field.validators
                    self.DecimalValidator[field.name] = field.validators
                    self.MaxDigitsValidator[field.name] = field.validators
                self.null_check[field.name] = field.null
                if field.editable not in ["0", 0, "False", False]:
                    self.editable_check[field.name] = field.editable
                self.default_check[field.name] = field.default
                self.blank_check[field.name] = field.blank
                self.unique_check[field.name] = field.unique

            # BooleanField
            if field.get_internal_type() == "BooleanField" and field.name not in self.drop_cols_list:
                self.BooleanField_list.append(field.name)
                self.null_check[field.name] = field.null
                self.default_check[field.name] = field.default
                self.unique_check[field.name] = field.unique
                if field.name in self.data_csv.columns:
                    self.data_csv[field.name] = self.data_csv[field.name].map({"on": 1, False: 0, True: 1})
                else:
                    pass

            # FileField and Image
            if field.get_internal_type() == "FileField" and field.name not in self.drop_cols_list:
                self.FileField_list.append(field.name)
                self.null_check[field.name] = field.null
                self.image_upload_to[field.name] = field.upload_to
                self.file_upload_to[field.name] = field.upload_to
                self.file_extension[field.name] = field.file_extension
                self.max_length_check[field.name] = field.max_length

            # TimeRangeField
            if field.get_internal_type() == "TimeRangeField" and field.name not in self.drop_cols_list:
                self.TimeRangeField_list.append(field.name)
                self.null_check[field.name] = field.null

            # EmailTypeField
            if field.get_internal_type() == "EmailTypeField" and field.name not in self.drop_cols_list:
                self.EmailTypeField_list.append(field.name)
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.max_length_check[field.name] = field.max_length

            if field.get_internal_type() == "VideoField" and field.name not in self.drop_cols_list:
                if field.video_type == "external_link":
                    self.advanced_validation_check[field.name] = field.validators
                    self.max_min_validation_check[field.name] = field.validators
                    self.null_check[field.name] = field.null
                    self.editable_check[field.name] = field.editable
                    self.default_check[field.name] = field.default
                    self.blank_check[field.name] = field.blank
                elif field.video_type == "Video":
                    self.null_check[field.name] = field.null
                    self.file_upload_to[field.name] = field.upload_to
                    self.video_type[field.name] = field.video_type
                    self.max_length_check[field.name] = field.max_length
                elif field.video_type == "mp4":
                    self.null_check[field.name] = field.null
                    self.file_upload_to[field.name] = field.upload_to
                    self.video_type[field.name] = field.video_type
                    self.max_length_check[field.name] = field.max_length
                elif field.video_type == "webm":
                    self.null_check[field.name] = field.null
                    self.file_upload_to[field.name] = field.upload_to
                    self.video_type[field.name] = field.video_type
                    self.max_length_check[field.name] = field.max_length
                elif field.video_type == "ogv":
                    self.null_check[field.name] = field.null
                    self.file_upload_to[field.name] = field.upload_to
                    self.video_type[field.name] = field.video_type
                    self.max_length_check[field.name] = field.max_length

            # ConcatenationField
            if field.get_internal_type() == "ConcatenationField" and field.name not in self.drop_cols_list:
                self.ConcatenationField_list.append(field.name)
                self.advanced_validation_check[field.name] = field.validators
                self.null_check[field.name] = field.null
                self.divider_check[field.name] = field.divider
                self.concatenation_columns[field.name] = field.columns
                self.unique_check[field.name] = field.unique
                self.max_min_validation_check[field.name] = field.validators
                self.max_length_check[field.name] = field.max_length

            # DateRangeField
            if field.get_internal_type() == "DateRangeField" and field.name not in self.drop_cols_list:
                self.DateRangeField_list.append(field.name)
                self.null_check[field.name] = field.null

            # DateTimeRangeField
            if field.get_internal_type() == "DateTimeRangeField" and field.name not in self.drop_cols_list:
                self.DateTimeRangeField_list.append(field.name)
                self.null_check[field.name] = field.null

            # CardField
            if field.get_internal_type() == "CardField" and field.name not in self.drop_cols_list:
                self.CardField_list.append(field.name)
                self.advanced_validation_check[field.name] = field.validators
                self.max_min_validation_check[field.name] = field.validators
                self.max_length_check_card[field.name] = 16
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.blank_check[field.name] = field.blank
                self.card_property[field.name] = json.loads(field.card_config)
                if field.validators:
                    self.column_validation_check[field.name] = field.validators

            # CardCvvField
            if field.get_internal_type() == "CardCvvField" and field.name not in self.drop_cols_list:
                self.CardCvvField_list.append(field.name)
                self.advanced_validation_check[field.name] = field.validators
                self.max_min_validation_check[field.name] = field.validators
                self.max_length_check[field.name] = field.max_length
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.blank_check[field.name] = field.blank
                if field.validators:
                    self.column_validation_check[field.name] = field.validators

            # CardExpiryField
            if field.get_internal_type() == "CardExpiryField" and field.name not in self.drop_cols_list:
                self.CardExpiryField_list.append(field.name)
                self.advanced_validation_check[field.name] = field.validators
                self.max_min_validation_check[field.name] = field.validators
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.blank_check[field.name] = field.blank
                if field.validators:
                    self.column_validation_check[field.name] = field.validators

            # MultiselectField
            if (
                field.get_internal_type() == "MultiselectField"
                and field.name not in self.drop_cols_list
                and check_multi_select
            ):
                self.multi_select_field_list.append(field.name)
                self.advanced_validation_check[field.name] = field.validators
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.blank_check[field.name] = field.blank
                self.multi_select_field_config_list[field.name] = json.loads(field.mulsel_config)
                if field.validators:
                    self.column_validation_check[field.name] = field.validators

            if field.get_internal_type() == "UserField" and field.name not in self.drop_cols_list:
                self.advanced_validation_check[field.name] = field.validators
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.blank_check[field.name] = field.blank
                if field.validators:
                    self.column_validation_check[field.name] = field.validators

            if field.get_internal_type() == "RTFField" and field.name not in self.drop_cols_list:
                self.advanced_validation_check[field.name] = field.validators
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                self.blank_check[field.name] = field.blank
                if field.validators:
                    self.column_validation_check[field.name] = field.validators

            if field.get_internal_type() == "TableField":
                self.table_field_list.append(field.name)
                self.null_check[field.name] = field.null

            if field.get_internal_type() == "UniqueIDField" and (
                self.user_operation != "update" or self.upsert
            ):
                self.max_length_check[field.name] = field.max_length
                data_csv[field.name] = ""
                if field.name in data_csv.columns:
                    n_rows = data_csv.shape[0]
                    data_csv = standard_uuid(
                        self.data_csv,
                        self.modelName.name,
                        field.name,
                        n_rows,
                        self.request,
                    )

            if not check_now:
                if field.computed_field:
                    test_data = [self.data_csv, "Success"]
                    if field.name in self.data_csv.columns:
                        for comp_col in test_data[0].columns.tolist():
                            if comp_col in self.DateTimeField_list or comp_col in self.DateField_list:
                                test_data[0][comp_col] = pd.to_datetime(
                                    test_data[0][comp_col], errors="coerce"
                                )
                        input_fields = [i[0] for i in field.computed_input]
                        if_field_exists = all(
                            [True if i in self.data_csv.columns else False for i in input_fields]
                        )
                        if if_field_exists:
                            if (field.editable in ["0", 0, "False", False]) or (
                                field.editable not in ["0", 0, "False", False]
                                and all(self.data_csv[field.name].isna().to_list())
                            ):
                                a3 = cal_computed_val(
                                    test_data, self.table_model_name, field.name, self.request
                                )

                                if a3[1] == "Success":
                                    self.data_csv = a3[0]
                                    for col in a3[0].columns:
                                        if a3[0][col].dtypes.name in ["float", "float64", "float32"]:
                                            a3[0][col] = a3[0][col].round(4)
                                else:
                                    messages.error(
                                        self.request,
                                        f"Error calculating for : {field.name} - {a3[1]}",
                                    )
                            else:
                                pass
                        else:
                            pass
                    else:
                        pass
            # ForeignKeyField
            if field.get_internal_type() == "ForeignKey" and field.name not in self.drop_cols_list:
                self.null_check[field.name] = field.null
                self.unique_check[field.name] = field.unique
                if field.name in self.data_csv.columns:
                    self.ForeignKey_list.append(field.name)
                    table_h = [field.parent]
                    parent = field.parent
                    while parent:
                        model_name = dynamic_model_create.get_model_class(parent, self.request)
                        fk_field_object = model_name.get_field(field.name)
                        if fk_field_object.internal_type == "ForeignKey":
                            parent = fk_field_object.parent
                            table_h.append(parent)
                        else:
                            break

                    table_h.reverse()
                    self.nested_table_list.append(table_h)
                    self.foreignKey_property.append(
                        {
                            "field_name": field.name,
                            "parent_table_name": parent,
                            "parent_table": field.parent,
                            "related_parent_column": dynamic_model_create.get_model_class(
                                parent, self.request
                            ).pk.name,
                        }
                    )
        self.data_csv_copy = self.data_csv.copy()
        self.data_csv_copy2 = self.data_csv.copy()
        self.upload = True
        self.edit_mode = False
        self.edit_inline = False
        self.edit_row = pd.DataFrame()
        if self.user_operation == "update":
            primary_key = ""
            edit_row = pd.DataFrame()
            if "primary_key" in self.data_csv.columns.tolist():
                primary_key = int(self.data_csv["primary_key"].values.tolist()[0])
                self.data_csv.drop(
                    columns=["primary_key"],
                    axis="columns",
                    inplace=True,
                )
                self.data_csv_copy.drop(
                    columns=["primary_key"],
                    axis="columns",
                    inplace=True,
                )
                self.data_csv_copy2.drop(
                    columns=["primary_key"],
                    axis="columns",
                    inplace=True,
                )
                edit_row = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": self.table_model_name,
                            "Columns": ["*"],
                        },
                        "condition": [
                            {
                                "column_name": self.modelName.pk.name,
                                "condition": "Equal to",
                                "input_value": str(primary_key),
                                "and_or": "",
                            }
                        ],
                    },
                )
                self.data_csv.replace([r"^\s*$", "None", None], np.nan, regex=True, inplace=True)
                self.data_csv_copy.replace([r"^\s*$", "None", None], np.nan, regex=True, inplace=True)
            else:
                if export_data != "yes":
                    primary_key = int(self.data_csv[self.modelName.pk.name].values.tolist()[0])
                    self.edit_inline = True
                    edit_row = read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": self.table_model_name,
                                "Columns": ["*"],
                            },
                            "condition": [
                                {
                                    "column_name": self.modelName.pk.name,
                                    "condition": "Equal to",
                                    "input_value": str(primary_key),
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                    self.data_csv.replace([r"^\s*$", "None", None], np.nan, regex=True, inplace=True)
                    self.data_csv_copy.replace([r"^\s*$", "None", None], np.nan, regex=True, inplace=True)
                    edit_row.replace([r"^\s*$", "None", None], np.nan, regex=True, inplace=True)
            self.edit_row = edit_row.copy()
            self.primary_key_id = primary_key

            for edit_col in self.drop_cols_list:
                if edit_col in edit_row.columns.tolist():
                    edit_row.drop(
                        columns=edit_col,
                        axis="columns",
                        inplace=True,
                    )
            revert_main = {}
            if len(self.ForeignKey_list) > 0:
                for i in range(len(self.ForeignKey_list)):
                    k = self.ForeignKey_list[i]
                    if k in self.data_csv.columns:
                        fk_index = self.ForeignKey_list.index(k)
                        field_Name = self.foreignKey_property[fk_index]["field_name"]
                        parent_table_name = self.foreignKey_property[fk_index]["parent_table_name"]
                        related_parent_column = self.foreignKey_property[fk_index]["related_parent_column"]
                        parent_df = read_data_func(
                            self.request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": parent_table_name,
                                    "Columns": [
                                        related_parent_column,
                                        field_Name,
                                    ],
                                },
                                "condition": [],
                            },
                        )

                        foreign_key_data = parent_df.loc[:, field_Name]
                        foreign_key_data.index = parent_df.iloc[:, 0].to_list()
                        foreign_key_data = foreign_key_data.to_dict()
                        revert_main[k] = foreign_key_data
                        foreign_key_data = {value: key for key, value in foreign_key_data.items()}
                        self.data_csv[k] = self.data_csv[k].astype(str).replace(to_replace=foreign_key_data)
                        self.data_csv_copy[k] = (
                            self.data_csv_copy[k].astype(str).replace(to_replace=foreign_key_data)
                        )
            else:
                pass

            # Conversion of Existing Data
            edit_row.select_dtypes(include="bool").astype(float).astype(int) * 1
            update_cols_drop = []
            for k in self.data_csv.columns.tolist():
                if k in edit_row.columns.tolist():
                    if k in self.data_csv.columns:
                        a = self.data_csv[k].astype(str).values
                        for i in range(len(a)):
                            if a[i] == edit_row[k].astype(str).values:
                                update_cols_drop.append(k)

            self.data_csv.drop(columns=update_cols_drop, axis="columns", inplace=True)
            for col in self.data_csv.columns:
                if col in revert_main.keys():
                    self.data_csv[col] = self.data_csv[col].replace(to_replace=revert_main[col])
            for field in self.modelName.concrete_fields:
                if field.internal_type == "ForeignKey" and field.name in self.edit_row.columns:
                    if self.edit_row[field.name].dropna().tolist():
                        field_Name = field.name
                        parent_table_name = field.parent
                        related_parent_column = dynamic_model_create.get_model_class(
                            parent_table_name, self.request
                        ).pk.name
                        foreign_key_data = (
                            read_data_func(
                                self.request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": parent_table_name,
                                        "Columns": [
                                            related_parent_column,
                                            field_Name,
                                        ],
                                    },
                                    "condition": [
                                        {
                                            "column_name": related_parent_column,
                                            "condition": "IN",
                                            "input_value": self.edit_row[field.name]
                                            .dropna()
                                            .unique()
                                            .tolist(),
                                            "and_or": "",
                                        },
                                    ],
                                },
                            )
                            .set_index(related_parent_column)[field_Name]
                            .to_dict()
                        )
                        self.edit_row[field_Name] = self.edit_row[field_Name].replace(
                            to_replace=foreign_key_data
                        )
                else:
                    continue
            if self.edit_inline:
                for field in self.modelName.concrete_fields:
                    if field.get_internal_type() == "BooleanField":
                        if field.name in self.data_csv.columns:
                            self.data_csv.replace(
                                {field.name: {"True": 1, "False": 0, " ": None, "None": None, np.nan: None}},
                                inplace=True,
                            )

            self.edit_mode = True

    def data_validation(self, check_now=False, message_out=True, col_val=False):

        # Store Total validation List Columnwise
        total_validation_list = []
        final_data = []
        # Store Summaries messages
        messages_list = []
        Datatype_error = []

        data_columns = self.data_csv.columns.tolist()
        # Store the index for Highlighting Error Cell
        navigation_list = {
            "Nullable": {},
            "Choices": {},
            "Unique": {},
            "MaxLength": {},
            "HierarchyColumn": {},
            "AdvanceDate": {},
        }
        datatype_navigation_list = {}

        custom_msg = ""
        custom_icon = ""
        if self.custom_msg_icon:
            custom_msg = self.custom_msg_icon.get("message")
            custom_icon = self.custom_msg_icon.get("icon")

        # Data Validation- Missing Columns
        data_csv_cols = self.data_csv.columns.tolist()
        all_null_cols = self.data_csv.isnull().values.all()
        missing_cols = []
        null_drop_cols = [
            k
            for k, v in self.null_check.items()
            if (self.null_check[k] and all_null_cols) or self.null_check[k]
        ]
        extra_drop_cols = self.auto_now_list + self.ConcatenationField_list + null_drop_cols
        if not self.edit_mode:
            if not check_now:
                if len(data_csv_cols) > 0 and not all_null_cols:
                    missing_cols = list(
                        set(set(set(self.field_list) - set(self.drop_cols_list)) - set(data_csv_cols))
                        - set(extra_drop_cols)
                    )
                    if len(missing_cols) > 0:
                        self.upload = False
                        self.data_csv["Error_Details"] = (
                            f"Error while uploading: {','.join(missing_cols)} column(s) must be present in data uploaded. Try mapping columns."
                        )
                        self.data_csv["Error_Cols"] = " ".join(missing_cols)
                        if not check_now and message_out:
                            icon = ""
                            message = f"Error while uploading: {','.join(missing_cols)} column(s) must be present in data uploaded. Try mapping columns."
                            if custom_msg:
                                if "{Validation Message}" in custom_msg:
                                    custom_msg = custom_msg.replace("{Validation Message}", message)
                                message = custom_msg

                            if custom_icon:
                                icon = custom_icon

                            messages.add_message(
                                self.request, level=messages.ERROR, message=message, extra_tags=icon
                            )
                        datalist = {
                            "feature_category": "L3-Upload",
                            "feature_subcategory": "Excel Upload",
                            "table_file_name": self.table_model_name,
                            "error_description": f"Error while uploading: {','.join(missing_cols)} column(s) must be present in data uploaded. Try mapping columns.",
                            "created_date": datetime.now(),
                            "created_by": self.request.user.username,
                            "modified_date": datetime.now(),
                            "modified_by": self.request.user.username,
                        }
                        final_data.append(datalist)
                        if self.message_show == "no":
                            return [final_data, self.data_csv]
                else:
                    if self.data_csv.isnull().values.all():
                        self.data_csv["Error_Details"] = (
                            "Error while uploading:  No Data Found in  Uploaded File."
                        )
                        self.data_csv["Error_Cols"] = " ".join(data_csv_cols)
                        if not check_now and message_out:
                            messages.error(
                                self.request,
                                "Error while uploading: No Data Found in  Uploaded File.",
                            )
                        datalist = {
                            "feature_category": "L3-Upload",
                            "feature_subcategory": "Excel Upload",
                            "table_file_name": self.table_model_name,
                            "error_description": "Error while uploading: No Data Found in  Uploaded File.",
                            "created_date": datetime.now(),
                            "created_by": self.request.user.username,
                            "modified_date": datetime.now(),
                            "modified_by": self.request.user.username,
                        }
                        final_data.append(datalist)
                        return [final_data, self.data_csv]

        # Data Validation- Extra Columns

        extra_cols = [
            i for i in data_columns if i not in list(set(self.field_list) - set(self.drop_cols_list))
        ]
        if self.modelName.pk.name in extra_cols:
            extra_cols.remove(self.modelName.pk.name)

        extra_cols_copy = extra_cols.copy()
        for i in extra_cols:
            if i in self.drop_cols_list:
                extra_cols_copy.remove(i)
        extra_cols = extra_cols_copy
        if not self.edit_mode:
            if len(extra_cols) > 0:

                self.upload = False
                self.data_csv["Error_Details"] = (
                    f"Error while uploading: {','.join(extra_cols)} column(s) not present in the {self.table_model_name}. Try mapping columns."
                )
                self.data_csv["Error_Cols"] = " ".join(extra_cols)
                if not check_now and message_out:

                    icon = ""
                    message = f"Error while uploading: {','.join(extra_cols)} column(s) not present in the {self.table_model_name}. Try mapping columns."
                    if custom_msg:
                        if "{Validation Message}" in custom_msg:
                            custom_msg = custom_msg.replace("{Validation Message}", message)
                        message = custom_msg

                    if custom_icon:
                        icon = custom_icon

                    messages.add_message(self.request, level=messages.ERROR, message=message, extra_tags=icon)
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading: {','.join(extra_cols)} column(s) not present in the {self.table_model_name}",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)
                if self.message_show == "no":
                    return [final_data, self.data_csv]

        # Data Validation-Editable
        if bool(self.editable_check):
            for k, v in self.editable_check.items():
                if k in self.data_csv.columns.tolist():
                    if k in self.auto_now_check.keys():
                        if self.auto_now_check[k] in [False, 0] and self.null_check[k] in [True, 1]:
                            if v == 0 or not v:
                                self.data_csv.drop(k, axis=1, inplace=True)
                    else:
                        if v == 0 or not v:
                            self.data_csv.drop(k, axis=1, inplace=True)

        # Data Validation - Null Column 0 = No, 1= Yes
        self.data_csv.replace(r"", np.NaN, inplace=True)
        null_list = self.data_csv.columns[self.data_csv.isnull().any()].tolist()

        null_cols_list = []
        if bool(self.null_check):
            for k, v in self.null_check.items():
                if k in self.multi_select_field_list and k in self.data_csv.columns:
                    if self.data_csv.loc[self.data_csv[k].astype(str) == "{}", k].any():
                        null_list.append(k)
                if k in null_list and k not in self.ConcatenationField_list:
                    if v in [0, False]:
                        null_cols_list.append(k)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""
                        self.data_csv.loc[
                            (
                                (self.data_csv[k].isna())
                                | (self.data_csv[k].astype(str) == "nan")
                                | (self.data_csv[k].astype(str) == "{}")
                            ),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[k].isna())
                                | (self.data_csv[k].astype(str) == "nan")
                                | (self.data_csv[k].astype(str) == "{}"),
                                "Error_Details",
                            ]
                            + f"Column {k} must not contain null values."
                        )
                        self.data_csv.loc[
                            (
                                (self.data_csv[k].isna())
                                | (self.data_csv[k].astype(str) == "nan")
                                | (self.data_csv[k].astype(str) == "{}")
                            ),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[k].isna())
                                | (self.data_csv[k].astype(str) == "nan")
                                | (self.data_csv[k].astype(str) == "{}"),
                                "Error_Cols",
                            ]
                            + f" {k} "
                        )
                        navigation_list["Nullable"].update(
                            {
                                k: list(
                                    self.data_csv.loc[
                                        (self.data_csv[k].astype(str) == "nan")
                                        | (self.data_csv[k].isna())
                                        | (self.data_csv[k].astype(str) == "{}")
                                    ].index
                                )
                            }
                        )

            if len(null_cols_list) > 0:
                self.upload = False
                messages_list.append(
                    f"""{','.join(null_cols_list)} column(s) must not have null values as the column may be mandatory."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: {','.join(null_cols_list)} column(s) must not have null values as the column may be mandatory."
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading: {','.join(null_cols_list)} column(s) must not have null values as the column may be mandatory.",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - Auto_now

        if bool(self.auto_now_check):
            for k, v in self.auto_now_check.items():
                if k in self.data_csv.columns.tolist() or k in self.field_list:
                    if v in [True, 1]:
                        if k in self.DateTimeField_list:
                            if k in self.DateTimeField_list_nosec:
                                self.data_csv[k] = datetime.now().strftime("%Y-%m-%d %H:%M")
                            else:
                                self.data_csv[k] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        elif k in self.TimeField_list:
                            if k in self.TimeField_list_nosec:
                                self.data_csv[k] = datetime.now().strftime("%H:%M")
                            else:
                                self.data_csv[k] = datetime.now().strftime("%H:%M:%S")
                        elif k in self.DateField_list:
                            self.data_csv[k] = datetime.now().strftime("%Y-%m-%d")

        # Data Validation - Integer Validation

        int_cols_val = []
        if len(self.IntegerField_list) > 0:
            for i in range(len(self.IntegerField_list)):
                if self.IntegerField_list[i] in self.data_csv.columns.tolist():
                    try:
                        self.data_csv[self.IntegerField_list[i]] = np.floor(
                            pd.to_numeric(self.data_csv[self.IntegerField_list[i]])
                        ).astype("Int64")
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""
                        int_cols_val.append(self.IntegerField_list[i])
                        self.data_csv.loc[
                            (self.data_csv[self.IntegerField_list[i]].notnull())
                            & (self.data_csv[self.IntegerField_list[i]] != "nan")
                            & (
                                ~self.data_csv[self.IntegerField_list[i]]
                                .astype(str)
                                .str.replace(".", "")
                                .astype(str)
                                .str.isdigit()
                            ),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[self.IntegerField_list[i]].notnull())
                                & (self.data_csv[self.IntegerField_list[i]] != "nan")
                                & (
                                    ~self.data_csv[self.IntegerField_list[i]]
                                    .astype(str)
                                    .str.replace(".", "")
                                    .astype(str)
                                    .str.isdigit()
                                ),
                                "Error_Details",
                            ]
                            + f"Column {self.IntegerField_list[i]} should contain only integers numbers."
                        )

                        self.data_csv.loc[
                            (self.data_csv[self.IntegerField_list[i]].notnull())
                            & (self.data_csv[self.IntegerField_list[i]] != "nan")
                            & (
                                ~self.data_csv[self.IntegerField_list[i]]
                                .astype(str)
                                .str.replace(".", "")
                                .astype(str)
                                .str.isdigit()
                            ),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[self.IntegerField_list[i]].notnull())
                                & (self.data_csv[self.IntegerField_list[i]] != "nan")
                                & (
                                    ~self.data_csv[self.IntegerField_list[i]]
                                    .astype(str)
                                    .str.replace(".", "")
                                    .astype(str)
                                    .str.isdigit()
                                ),
                                "Error_Cols",
                            ]
                            + f" {self.IntegerField_list[i]} "
                        )

                        datatype_navigation_list[self.IntegerField_list[i]] = list(
                            self.data_csv.loc[
                                (self.data_csv[self.IntegerField_list[i]].notnull())
                                & (self.data_csv[self.IntegerField_list[i]] != "nan")
                                & ~self.data_csv[self.IntegerField_list[i]]
                                .astype(str)
                                .str.replace(".", "")
                                .astype(str)
                                .str.isdigit()
                            ].index
                        )
                        if len(datatype_navigation_list[self.IntegerField_list[i]]) > 0:
                            Datatype_error.append(self.IntegerField_list[i])

            if len(int_cols_val) > 0:
                self.upload = False
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: {','.join(int_cols_val)} must contain only integers numbers."
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )
                messages_list.append(f"""{','.join(int_cols_val)} must contain only integers numbers.""")
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: {','.join(int_cols_val)} must contain only integers numbers.",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - MaxDigits Validation
        max_digits_fail_list = []
        if bool(self.MaxDigitsValidator):
            navigation_list["MaxDigitsValidator"] = {}
            error_message = {}
            for key in self.MaxDigitsValidator.keys():
                if key in self.data_csv.columns:
                    if len(self.MaxDigitsValidator.get(key)) and "DecimalValidator" in list(
                        self.MaxDigitsValidator[key].keys()
                    ):
                        idict = self.MaxDigitsValidator.get(key).get("DecimalValidator")
                        limit = idict["max_digits"]
                        error_message[key] = "MaxDigits Error"
                        if limit is not None:
                            adv_df = pd.DataFrame(columns=[key])
                            str_val = self.data_csv[key].astype(str)
                            adv_df[key] = str_val.str.len().le(limit + 1)
                            if False in adv_df[key].values:
                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (~str_val.str.len().le(limit + 1)),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (~str_val.str.len().le(limit + 1)),
                                        "Error_Details",
                                    ]
                                    + "Error while uploading, MaxDigits Error"
                                )

                                self.data_csv.loc[
                                    (~str_val.str.len().le(limit + 1)),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (~str_val.str.len().le(limit + 1)),
                                        "Error_Cols",
                                    ]
                                    + f" {key} "
                                )
                                max_digits_fail_list.append(key)
                                navigation_list["MaxDigitsValidator"][key] = list(
                                    self.data_csv.loc[(~str_val.str.len().le(limit + 1))].index
                                )
            if len(max_digits_fail_list) > 0:
                self.upload = False
                if self.message_show == "yes":
                    if len(error_message) > 0:
                        for k, v in error_message.items():
                            if k in max_digits_fail_list:
                                if not check_now and message_out:
                                    icon = ""
                                    message = f"Error while uploading, {k}:{v}"
                                    if custom_msg:
                                        if "{Validation Message}" in custom_msg:
                                            custom_msg = custom_msg.replace("{Validation Message}", message)
                                        message = custom_msg

                                    if custom_icon:
                                        icon = custom_icon

                                    messages.add_message(
                                        self.request, level=messages.ERROR, message=message, extra_tags=icon
                                    )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": "Error while uploading, MaxDigits Error",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - Float Validation
        float_cols_val = []
        if len(self.FloatField_list) > 0:
            for i in range(len(self.FloatField_list)):
                if self.FloatField_list[i] in self.data_csv.columns.tolist():
                    try:
                        if self.DecimalValidator:
                            if self.FloatField_list[i] in self.DecimalValidator:
                                if "DecimalValidator" in self.DecimalValidator[self.FloatField_list[i]]:
                                    decimal_places = self.DecimalValidator[self.FloatField_list[i]][
                                        "DecimalValidator"
                                    ]["decimal_places"]
                                else:
                                    decimal_places = ""
                            else:
                                decimal_places = ""
                        else:
                            decimal_places = ""

                        if decimal_places:
                            self.data_csv[self.FloatField_list[i]] = np.round(
                                self.data_csv[self.FloatField_list[i]].astype("float"),
                                decimals=decimal_places,
                            )

                        else:
                            self.data_csv[self.FloatField_list[i]] = self.data_csv[
                                self.FloatField_list[i]
                            ].astype("float")
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")
                        float_cols_val.append(self.FloatField_list[i])

                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""
                        self.data_csv.loc[
                            (self.data_csv[self.FloatField_list[i]].notnull())
                            & (self.data_csv[self.FloatField_list[i]] != "nan")
                            & (
                                ~self.data_csv[self.FloatField_list[i]]
                                .astype(str)
                                .str.replace(".", "")
                                .astype(str)
                                .str.isnumeric()
                            ),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[self.FloatField_list[i]].notnull())
                                & (self.data_csv[self.FloatField_list[i]] != "nan")
                                & (
                                    ~self.data_csv[self.FloatField_list[i]]
                                    .astype(str)
                                    .str.replace(".", "")
                                    .astype(str)
                                    .str.isnumeric()
                                ),
                                "Error_Details",
                            ]
                            + f"Column {self.FloatField_list[i]} should contain only float numbers."
                        )
                        self.data_csv.loc[
                            (self.data_csv[self.FloatField_list[i]].notnull())
                            & (self.data_csv[self.FloatField_list[i]] != "nan")
                            & (
                                ~self.data_csv[self.FloatField_list[i]]
                                .astype(str)
                                .str.replace(".", "")
                                .astype(str)
                                .str.isnumeric()
                            ),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[self.FloatField_list[i]].notnull())
                                & (self.data_csv[self.FloatField_list[i]] != "nan")
                                & (
                                    ~self.data_csv[self.FloatField_list[i]]
                                    .astype(str)
                                    .str.replace(".", "")
                                    .astype(str)
                                    .str.isnumeric()
                                ),
                                "Error_Cols",
                            ]
                            + f" {self.FloatField_list[i]} "
                        )

                        datatype_navigation_list[self.FloatField_list[i]] = list(
                            self.data_csv.loc[
                                (self.data_csv[self.FloatField_list[i]].notnull())
                                & (self.data_csv[self.FloatField_list[i]] != "nan")
                                & ~self.data_csv[self.FloatField_list[i]]
                                .astype(str)
                                .str.replace(".", "")
                                .astype(str)
                                .str.isnumeric()
                            ].index
                        )
                        if len(datatype_navigation_list[self.FloatField_list[i]]) > 0:
                            Datatype_error.append(self.FloatField_list[i])

            if len(float_cols_val) > 0:
                messages_list.append(f"""{','.join(float_cols_val)} should contain only float numbers.""")
                self.upload = False
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: {','.join(float_cols_val)} should contain only float numbers. "
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: {','.join(float_cols_val)} should contain only float numbers.",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - Boolean Validation
        bool_cols_list = []
        if len(self.BooleanField_list) > 0:
            for i in range(len(self.BooleanField_list)):
                if self.BooleanField_list[i] in self.data_csv.columns.tolist():
                    if self.null_check[self.BooleanField_list[i]]:
                        if (
                            all(
                                i in [0, 1, "0", "1"]
                                for i in self.data_csv[self.BooleanField_list[i]].values.tolist()
                                if str(i) not in ["nan", None, "None", " ", "null", "<NA>", np.nan]
                            )
                            is False
                        ):
                            bool_cols_list.append(self.BooleanField_list[i])

                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""
                            self.data_csv.loc[
                                (self.data_csv[self.BooleanField_list[i]].notnull())
                                & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                & (
                                    ~self.data_csv[self.BooleanField_list[i]]
                                    .astype(str)
                                    .isin(["0", "1", 0, 1])
                                ),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[self.BooleanField_list[i]].notnull())
                                    & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                    & (
                                        ~self.data_csv[self.BooleanField_list[i]]
                                        .astype(str)
                                        .isin(["0", "1", 0, 1])
                                    ),
                                    "Error_Details",
                                ]
                                + f"Column {self.BooleanField_list[i]} column(s) accepts value in  [0,1] only."
                            )

                            self.data_csv.loc[
                                (self.data_csv[self.BooleanField_list[i]].notnull())
                                & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                & (
                                    ~self.data_csv[self.BooleanField_list[i]]
                                    .astype(str)
                                    .isin(["0", "1", 0, 1])
                                ),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[self.BooleanField_list[i]].notnull())
                                    & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                    & (
                                        ~self.data_csv[self.BooleanField_list[i]]
                                        .astype(str)
                                        .isin(["0", "1", 0, 1])
                                    ),
                                    "Error_Cols",
                                ]
                                + f" {self.BooleanField_list[i]} "
                            )

                            datatype_navigation_list[self.BooleanField_list[i]] = list(
                                self.data_csv.loc[
                                    (self.data_csv[self.BooleanField_list[i]].notnull())
                                    & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                    & (
                                        ~self.data_csv[self.BooleanField_list[i]]
                                        .astype(str)
                                        .isin(["0", "1", 0, 1])
                                    )
                                ].index
                            )
                            if len(datatype_navigation_list[self.BooleanField_list[i]]) > 0:
                                Datatype_error.append(self.BooleanField_list[i])
                        else:
                            try:
                                self.data_csv[self.BooleanField_list[i]] = (
                                    self.data_csv[self.BooleanField_list[i]].astype("boolean") * 1
                                )
                                self.data_csv[self.BooleanField_list[i]] = self.data_csv[
                                    self.BooleanField_list[i]
                                ].astype("Int64")
                            except Exception as e:
                                logging.warning(f"Following exception occured - {e}")

                    else:
                        if (
                            all(
                                i in [0, 1, "0", "1"]
                                for i in self.data_csv[self.BooleanField_list[i]].values.tolist()
                            )
                            is False
                        ):
                            bool_cols_list.append(self.BooleanField_list[i])

                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""
                            self.data_csv.loc[
                                (self.data_csv[self.BooleanField_list[i]].notnull())
                                & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                & (
                                    ~self.data_csv[self.BooleanField_list[i]]
                                    .astype(str)
                                    .isin(["0", "1", 0, 1])
                                ),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[self.BooleanField_list[i]].notnull())
                                    & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                    & (
                                        ~self.data_csv[self.BooleanField_list[i]]
                                        .astype(str)
                                        .isin(["0", "1", 0, 1])
                                    ),
                                    "Error_Details",
                                ]
                                + f"Column {self.BooleanField_list[i]} column(s) accepts value in  [0,1] only."
                            )

                            self.data_csv.loc[
                                (self.data_csv[self.BooleanField_list[i]].notnull())
                                & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                & (
                                    ~self.data_csv[self.BooleanField_list[i]]
                                    .astype(str)
                                    .isin(["0", "1", 0, 1])
                                ),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[self.BooleanField_list[i]].notnull())
                                    & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                    & (
                                        ~self.data_csv[self.BooleanField_list[i]]
                                        .astype(str)
                                        .isin(["0", "1", 0, 1])
                                    ),
                                    "Error_Cols",
                                ]
                                + f" {self.BooleanField_list[i]} "
                            )

                            datatype_navigation_list[self.BooleanField_list[i]] = list(
                                self.data_csv.loc[
                                    (self.data_csv[self.BooleanField_list[i]].notnull())
                                    & (self.data_csv[self.BooleanField_list[i]] != "nan")
                                    & (
                                        ~self.data_csv[self.BooleanField_list[i]]
                                        .astype(str)
                                        .isin(["0", "1", 0, 1])
                                    )
                                ].index
                            )
                            if len(datatype_navigation_list[self.BooleanField_list[i]]) > 0:
                                Datatype_error.append(self.BooleanField_list[i])
                        else:
                            try:
                                self.data_csv[self.BooleanField_list[i]] = (
                                    self.data_csv[self.BooleanField_list[i]].astype("boolean") * 1
                                )
                                self.data_csv[self.BooleanField_list[i]] = self.data_csv[
                                    self.BooleanField_list[i]
                                ].astype("Int64")
                            except Exception as e:
                                logging.warning(f"Following exception occured - {e}")

        if len(bool_cols_list) > 0:
            self.upload = False
            messages_list.append(f"""{' ,'.join(bool_cols_list)}  column(s) accepts value in  [0,1] only.""")
            if self.message_show == "yes":
                if not check_now and message_out:
                    icon = ""
                    message = f"Error while uploading:{' ,'.join(bool_cols_list)}  column(s) accepts value in  [0,1] only"
                    if custom_msg:
                        if "{Validation Message}" in custom_msg:
                            custom_msg = custom_msg.replace("{Validation Message}", message)
                        message = custom_msg

                    if custom_icon:
                        icon = custom_icon

                    messages.add_message(self.request, level=messages.ERROR, message=message, extra_tags=icon)

            datalist = {
                "feature_category": "L3-Upload",
                "feature_subcategory": "Excel Upload",
                "table_file_name": self.table_model_name,
                "error_description": f"Error while uploading {self.table_model_name}: {' ,'.join(bool_cols_list)}  column(s) accepts value in  [0,1] only.",
                "created_date": datetime.now(),
                "created_by": self.request.user.username,
                "modified_date": datetime.now(),
                "modified_by": self.request.user.username,
            }
            final_data.append(datalist)
        # Data Validation - DateTimeField  Validation
        date__time_col_list = []
        total_date_cols = self.DateTimeField_list
        logging.warning(
            "dt_format--------------------------------------------------------------------------->"
        )
        logging.warning(total_date_cols)
        if len(total_date_cols) > 0:
            for i in range(len(total_date_cols)):
                if total_date_cols[i] in self.data_csv.columns.tolist():
                    if total_date_cols[i] in self.DateTimeField_list_nosec:
                        dt_format = "%Y-%m-%d %H:%M"
                        time_message = "YYYY-MM-DD HH:MM"
                    else:
                        dt_format = "%Y-%m-%d %H:%M:%S"
                        time_message = "YYYY-MM-DD HH:MM:SS"
                    logging.warning(
                        "dt_format--------------------------------------------------------------------------->"
                    )
                    logging.warning(total_date_cols[i])
                    logging.warning(dt_format)
                    logging.warning(time_message)
                    logging.warning(self.data_csv[total_date_cols[i]])
                    logging.warning(
                        pd.to_datetime(self.data_csv[total_date_cols[i]], format=dt_format, errors="coerce")
                    )
                    logging.warning(
                        pd.to_datetime(
                            self.data_csv[total_date_cols[i]], format=dt_format, errors="coerce"
                        ).notnull()
                    )
                    logging.warning(
                        pd.to_datetime(self.data_csv[total_date_cols[i]], format=dt_format, errors="coerce")
                        .notnull()
                        .all()
                    )
                    if self.null_check[total_date_cols[i]] == 0:
                        if total_date_cols[i] in self.data_csv.columns.tolist():
                            if (
                                bool(
                                    pd.to_datetime(
                                        self.data_csv[total_date_cols[i]],
                                        format=dt_format,
                                        errors="coerce",
                                    )
                                    .notnull()
                                    .all()
                                )
                                is False
                            ):

                                date__time_col_list.append(total_date_cols[i])
                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format=dt_format,
                                            errors="coerce",
                                        ).isna()
                                    ),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[total_date_cols[i]].notnull())
                                        & (self.data_csv[total_date_cols[i]] != "nan")
                                        & (
                                            pd.to_datetime(
                                                self.data_csv[total_date_cols[i]],
                                                format=dt_format,
                                                errors="coerce",
                                            ).isna()
                                        ),
                                        "Error_Details",
                                    ]
                                    + f"Column {total_date_cols[i]} must contain only dates in {time_message} format."
                                )

                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format=dt_format,
                                            errors="coerce",
                                        ).isna()
                                    ),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[total_date_cols[i]].notnull())
                                        & (self.data_csv[total_date_cols[i]] != "nan")
                                        & (
                                            pd.to_datetime(
                                                self.data_csv[total_date_cols[i]],
                                                format=dt_format,
                                                errors="coerce",
                                            ).isna()
                                        ),
                                        "Error_Cols",
                                    ]
                                    + f" {total_date_cols[i]} "
                                )

                                datatype_navigation_list[total_date_cols[i]] = list(
                                    self.data_csv.loc[
                                        (self.data_csv[total_date_cols[i]].notnull())
                                        & (self.data_csv[total_date_cols[i]] != "nan")
                                        & (
                                            pd.to_datetime(
                                                self.data_csv[total_date_cols[i]],
                                                format=dt_format,
                                                errors="coerce",
                                            ).isna()
                                        ),
                                    ].index
                                )
                                if len(datatype_navigation_list[total_date_cols[i]]) > 0:
                                    Datatype_error.append(total_date_cols[i])

                    else:

                        date_row_check = (
                            pd.to_datetime(
                                self.data_csv[total_date_cols[i]].fillna(datetime.now()),
                                format=dt_format,
                                errors="coerce",
                                dayfirst=True,
                            )
                            .isnull()
                            .any()
                        )

                        if date_row_check:
                            date__time_col_list.append(total_date_cols[i])
                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""
                            self.data_csv.loc[
                                (self.data_csv[total_date_cols[i]].notnull())
                                & (self.data_csv[total_date_cols[i]] != "nan")
                                & (
                                    pd.to_datetime(
                                        self.data_csv[total_date_cols[i]],
                                        format=dt_format,
                                        errors="coerce",
                                    ).isna()
                                ),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format=dt_format,
                                            errors="coerce",
                                        ).isna()
                                    ),
                                    "Error_Details",
                                ]
                                + f"Column {total_date_cols[i]} must contain  datetime only in {time_message} format."
                            )

                            self.data_csv.loc[
                                (self.data_csv[total_date_cols[i]].notnull())
                                & (self.data_csv[total_date_cols[i]] != "nan")
                                & (
                                    pd.to_datetime(
                                        self.data_csv[total_date_cols[i]],
                                        format=dt_format,
                                        errors="coerce",
                                    ).isna()
                                ),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format=dt_format,
                                            errors="coerce",
                                        ).isna()
                                    ),
                                    "Error_Cols",
                                ]
                                + f" {total_date_cols[i]} "
                            )

                            datatype_navigation_list[total_date_cols[i]] = list(
                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format=dt_format,
                                            errors="coerce",
                                        ).isna()
                                    ),
                                ].index
                            )

                            if len(datatype_navigation_list[total_date_cols[i]]) > 0:
                                Datatype_error.append(total_date_cols[i])

            if len(date__time_col_list) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(date__time_col_list))) } column must contain datetime only  in {time_message} format."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: { ' ,'.join(list(set(date__time_col_list))) } column must contain datetime only  in {time_message} format"
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: { ' ,'.join(list(set(date__time_col_list))) } column must contain datetime only in {time_message}  format",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - DateField   Validation
        date_col_list = []
        total_date_cols = self.DateField_list
        if len(total_date_cols) > 0:
            for i in range(len(total_date_cols)):
                if total_date_cols[i] in self.data_csv.columns.tolist():
                    if self.null_check[total_date_cols[i]] == 0:
                        if total_date_cols[i] in self.data_csv.columns.tolist():
                            if (
                                bool(
                                    pd.to_datetime(
                                        self.data_csv[total_date_cols[i]], format="%Y-%m-%d", errors="coerce"
                                    )
                                    .notnull()
                                    .all()
                                )
                                is False
                            ):
                                date_col_list.append(total_date_cols[i])

                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format="%Y-%m-%d",
                                            errors="coerce",
                                        ).isna()
                                    ),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[total_date_cols[i]].notnull())
                                        & (self.data_csv[total_date_cols[i]] != "nan")
                                        & (
                                            pd.to_datetime(
                                                self.data_csv[total_date_cols[i]],
                                                format="%Y-%m-%d",
                                                errors="coerce",
                                            ).isna()
                                        ),
                                        "Error_Details",
                                    ]
                                    + f"Column {total_date_cols[i]} accept dates only in YYYY-MM-DD format."
                                )

                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format="%Y-%m-%d",
                                            errors="coerce",
                                        ).isna()
                                    ),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[total_date_cols[i]].notnull())
                                        & (self.data_csv[total_date_cols[i]] != "nan")
                                        & (
                                            pd.to_datetime(
                                                self.data_csv[total_date_cols[i]],
                                                format="%Y-%m-%d",
                                                errors="coerce",
                                            ).isna()
                                        ),
                                        "Error_Cols",
                                    ]
                                    + f" {total_date_cols[i]} "
                                )

                                datatype_navigation_list[total_date_cols[i]] = list(
                                    self.data_csv.loc[
                                        (self.data_csv[total_date_cols[i]].notnull())
                                        & (self.data_csv[total_date_cols[i]] != "nan")
                                        & (
                                            pd.to_datetime(
                                                self.data_csv[total_date_cols[i]],
                                                format="%Y-%m-%d",
                                                errors="coerce",
                                            ).isna()
                                        ),
                                    ].index
                                )
                                if len(datatype_navigation_list[total_date_cols[i]]) > 0:
                                    Datatype_error.append(total_date_cols[i])

                    else:

                        date_row_check = (
                            pd.to_datetime(
                                self.data_csv[total_date_cols[i]].dropna(),
                                format="%Y-%m-%d",
                                errors="coerce",
                            )
                            .isna()
                            .any()
                        )
                        if date_row_check:
                            date_col_list.append(total_date_cols[i])

                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""
                            self.data_csv.loc[
                                (self.data_csv[total_date_cols[i]].notnull())
                                & (self.data_csv[total_date_cols[i]] != "nan")
                                & (
                                    pd.to_datetime(
                                        self.data_csv[total_date_cols[i]], format="%Y-%m-%d", errors="coerce"
                                    ).isna()
                                ),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format="%Y-%m-%d",
                                            errors="coerce",
                                        ).isna()
                                    ),
                                    "Error_Details",
                                ]
                                + f"Column {total_date_cols[i]} accept dates only in YYYY-MM-DD format."
                            )

                            self.data_csv.loc[
                                (self.data_csv[total_date_cols[i]].notnull())
                                & (self.data_csv[total_date_cols[i]] != "nan")
                                & (
                                    pd.to_datetime(
                                        self.data_csv[total_date_cols[i]], format="%Y-%m-%d", errors="coerce"
                                    ).isna()
                                ),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format="%Y-%m-%d",
                                            errors="coerce",
                                        ).isna()
                                    ),
                                    "Error_Cols",
                                ]
                                + f" {total_date_cols[i]} "
                            )

                            datatype_navigation_list[total_date_cols[i]] = list(
                                self.data_csv.loc[
                                    (self.data_csv[total_date_cols[i]].notnull())
                                    & (self.data_csv[total_date_cols[i]] != "nan")
                                    & (
                                        pd.to_datetime(
                                            self.data_csv[total_date_cols[i]],
                                            format="%Y-%m-%d",
                                            errors="coerce",
                                        ).isna()
                                    ),
                                ].index
                            )
                            if len(datatype_navigation_list[total_date_cols[i]]) > 0:
                                Datatype_error.append(total_date_cols[i])

            if len(date_col_list) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(date_col_list))) } column must contain datetime only in YYYY-MM-DD format."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: { ' ,'.join(list(set(date_col_list))) } column must contain  dates only in YYYY-MM-DD format"
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: { ' ,'.join(list(set(date_col_list))) } column must contain  dates only  in YYYY-MM-DD format",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # my custom validation

        def check_validations(date_entry, validator_config):

            valid = False
            if date_entry and (not pd.isna(date_entry)):
                date_entry = date_entry.date()
                if validator_config:
                    if validator_config["colV_cond_val"] == "Equal to":
                        if validator_config["colV_cond_val2"] == "Today":
                            if date_entry == date.today():
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Yesterday":
                            yesterday = date.today() - timedelta(days=1)
                            if date_entry == yesterday:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Tomorrow":
                            tomorrow = date.today() + timedelta(days=1)
                            if date_entry == tomorrow:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last week":
                            today = date.today()
                            start_of_last_week = today - timedelta(days=today.weekday() + 8)
                            end_of_last_week = today - timedelta(days=today.weekday() + 2)
                            if start_of_last_week <= date_entry <= end_of_last_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This week":
                            today = date.today()
                            start_of_this_week = today - timedelta(days=today.weekday() + 1)
                            end_of_this_week = today + timedelta(days=5 - today.weekday())
                            if start_of_this_week <= date_entry <= end_of_this_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This month":
                            today = date.today()
                            first_day_of_this_month = today + relativedelta(day=1)
                            last_day_of_this_month = today + relativedelta(day=31)
                            if first_day_of_this_month <= date_entry <= last_day_of_this_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last month":
                            today = date.today()
                            first_day_of_last_month = today + relativedelta(day=1, months=-1)
                            last_day_of_last_month = today + relativedelta(day=1, days=-1)
                            if first_day_of_last_month <= date_entry <= last_day_of_last_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This year":
                            today = date.today()
                            first_day_of_this_year = today + relativedelta(day=1, month=1)
                            last_day_of_this_year = today + relativedelta(day=31, month=12)
                            if first_day_of_this_year <= date_entry <= last_day_of_this_year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last year":
                            today = date.today()
                            first_day_of_last_year = today + relativedelta(years=-1, day=1, month=1)
                            last_day_of_last_year = today + relativedelta(years=-1, day=31, month=12)
                            if first_day_of_last_year <= date_entry <= last_day_of_last_year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Custom date":
                            custom_date = datetime.strptime(validator_config["custom-date"], "%Y-%m-%d")
                            if date_entry == custom_date:
                                valid = True
                            else:
                                valid = False
                    if validator_config["colV_cond_val"] == "Not Equal to":
                        if validator_config["colV_cond_val2"] == "Today":
                            if date_entry != date.today():
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Yesterday":
                            yesterday = date.today() - timedelta(days=1)
                            if date_entry != yesterday:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Tomorrow":
                            tomorrow = date.today() + timedelta(days=1)
                            if date_entry != tomorrow:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last week":
                            today = date.today()
                            start_of_last_week = today - timedelta(days=today.weekday() + 8)
                            end_of_last_week = today - timedelta(days=today.weekday() + 2)
                            if start_of_last_week <= date_entry <= end_of_last_week:
                                valid = False
                            else:
                                valid = True
                        elif validator_config["colV_cond_val2"] == "This week":
                            today = date.today()
                            start_of_this_week = today - timedelta(days=today.weekday() + 1)
                            end_of_this_week = today + timedelta(days=5 - today.weekday())
                            if start_of_this_week <= date_entry <= end_of_this_week:
                                valid = False
                            else:
                                valid = True
                        elif validator_config["colV_cond_val2"] == "This month":
                            today = date.today()
                            first_day_of_this_month = today + relativedelta(day=1)
                            last_day_of_this_month = today + relativedelta(day=31)
                            if first_day_of_this_month <= date_entry <= last_day_of_this_month:
                                valid = False
                            else:
                                valid = True
                        elif validator_config["colV_cond_val2"] == "Last month":
                            today = date.today()
                            first_day_of_last_month = today + relativedelta(day=1, months=-1)
                            last_day_of_last_month = today + relativedelta(day=1, days=-1)
                            if first_day_of_last_month <= date_entry <= last_day_of_last_month:
                                valid = False
                            else:
                                valid = True
                        elif validator_config["colV_cond_val2"] == "This year":
                            today = date.today()
                            first_day_of_this_year = today + relativedelta(day=1, month=1)
                            last_day_of_this_year = today + relativedelta(day=31, month=12)
                            if first_day_of_this_year <= date_entry <= last_day_of_this_year:
                                valid = False
                            else:
                                valid = True
                        elif validator_config["colV_cond_val2"] == "Last year":
                            today = date.today()
                            first_day_of_last_year = today + relativedelta(years=-1, day=1, month=1)
                            last_day_of_last_year = today + relativedelta(years=-1, day=31, month=12)
                            if first_day_of_last_year <= date_entry <= last_day_of_last_year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Custom date":
                            custom_date = datetime.strptime(validator_config["custom-date"], "%Y-%m-%d")
                            if date_entry != custom_date:
                                valid = True
                            else:
                                valid = False
                    if validator_config["colV_cond_val"] == "Greater than":
                        if validator_config["colV_cond_val2"] == "Today":
                            if date_entry > date.today():
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Yesterday":
                            yesterday = date.today() - timedelta(days=1)
                            if date_entry > yesterday:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Tomorrow":
                            tomorrow = date.today() + timedelta(days=1)
                            if date_entry > tomorrow:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last week":
                            today = date.today()
                            start_of_this_week = today - timedelta(days=today.weekday() + 1)
                            if date_entry >= start_of_this_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This week":
                            today = date.today()
                            end_of_this_week = today + timedelta(days=5 - today.weekday())
                            if date_entry > end_of_this_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This month":
                            today = date.today()
                            last_day_of_this_month = today + relativedelta(day=31)
                            if date_entry > last_day_of_this_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last month":
                            today = date.today()
                            first_day_of_this_month = today + relativedelta(day=1)
                            if date_entry >= first_day_of_this_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This year":
                            today = date.today()
                            last_day_of_this_year = today + relativedelta(day=31, month=12)
                            if date_entry > last_day_of_this_year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last year":
                            today = date.today()
                            first_day_of_this_year = today + relativedelta(day=1, month=1)
                            if date_entry >= first_day_of_this_year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Custom date":
                            custom_date = datetime.strptime(validator_config["custom-date"], "%Y-%m-%d")
                            if date_entry > custom_date:
                                valid = True
                            else:
                                valid = False
                    if validator_config["colV_cond_val"] == "Smaller than":
                        if validator_config["colV_cond_val2"] == "Today":
                            if date_entry < date.today():
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Yesterday":
                            yesterday = date.today() - timedelta(days=1)
                            if date_entry < yesterday:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Tomorrow":
                            tomorrow = date.today() + timedelta(days=1)
                            if date_entry < tomorrow:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last week":
                            today = date.today()
                            start_of_last_week = today - timedelta(days=today.weekday() + 8)
                            if date_entry < start_of_last_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This week":
                            today = date.today()
                            end_of_last_week = today - timedelta(days=today.weekday() + 2)
                            if date_entry <= end_of_last_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This month":
                            today = date.today()
                            first_day_of_this_month = today + relativedelta(day=1)
                            if date_entry < first_day_of_this_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last month":
                            today = date.today()
                            first_day_of_current_month = today.replace(day=1)
                            first_day_of_last_month = first_day_of_current_month - relativedelta(months=1)
                            if date_entry < first_day_of_last_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This year":
                            today = date.today()
                            first_day_of_this_year = today + relativedelta(day=1, month=1)
                            if date_entry < first_day_of_this_year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last year":
                            today = date.today()
                            last_year = today.year - 1
                            if date_entry.year < last_year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Custom date":
                            custom_date = datetime.strptime(validator_config["custom-date"], "%Y-%m-%d")
                            if date_entry < custom_date:
                                valid = True
                            else:
                                valid = False
                    if validator_config["colV_cond_val"] == "Greater than equal to":
                        if validator_config["colV_cond_val2"] == "Today":
                            if date_entry >= date.today():
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Yesterday":
                            yesterday = date.today() - timedelta(days=1)
                            if date_entry >= yesterday:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Tomorrow":
                            tomorrow = date.today() + timedelta(days=1)
                            if date_entry >= tomorrow:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last week":
                            today = date.today()
                            start_of_last_week = today - timedelta(days=today.weekday() + 8)
                            if date_entry >= start_of_last_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This week":
                            today = date.today()
                            start_of_this_week = today - timedelta(days=today.weekday() + 1)
                            if date_entry >= start_of_this_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This month":
                            today = date.today()
                            first_day_of_this_month = today + relativedelta(day=1)
                            if date_entry >= first_day_of_this_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last month":
                            today = date.today()
                            first_day_of_last_month = today + relativedelta(day=1, months=-1)
                            if date_entry >= first_day_of_last_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This year":
                            today = date.today()
                            if date_entry.year >= today.year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last year":
                            today = date.today()
                            last_year = today.year - 1
                            if date_entry.year >= last_year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Custom date":
                            custom_date = datetime.strptime(validator_config["custom-date"], "%Y-%m-%d")
                            if date_entry >= custom_date:
                                valid = True
                            else:
                                valid = False
                    if validator_config["colV_cond_val"] == "Smaller than equal to":
                        if validator_config["colV_cond_val2"] == "Today":
                            if date_entry <= date.today():
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Yesterday":
                            yesterday = date.today() - timedelta(days=1)
                            if date_entry <= yesterday:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Tomorrow":
                            tomorrow = date.today() + timedelta(days=1)
                            if date_entry <= tomorrow:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last week":
                            today = date.today()
                            end_of_last_week = today - timedelta(days=today.weekday() + 2)
                            if date_entry <= end_of_last_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This week":
                            today = date.today()
                            end_of_this_week = today + timedelta(days=5 - today.weekday())
                            if date_entry <= end_of_this_week:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This month":
                            today = date.today()
                            last_day_of_this_month = today + relativedelta(day=31)
                            if date_entry <= last_day_of_this_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last month":
                            today = date.today()
                            last_day_of_last_month = today + relativedelta(day=1, days=-1)
                            if date_entry <= last_day_of_last_month:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "This year":
                            today = date.today()
                            if date_entry.year <= today.year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Last year":
                            today = date.today()
                            last_year = today.year - 1
                            if date_entry.year <= last_year:
                                valid = True
                            else:
                                valid = False
                        elif validator_config["colV_cond_val2"] == "Custom date":
                            custom_date = datetime.strptime(validator_config["custom-date"], "%Y-%m-%d")
                            if date_entry <= custom_date:
                                valid = True
                            else:
                                valid = False
                else:
                    valid = True
            else:
                valid = True
            return valid

        advance_date_validation_col_list = []
        if len(self.advance_date_validators):
            for i in self.advance_date_validators:
                if i in self.data_csv.columns.tolist():
                    main_validator_config = self.advance_date_validators
                    validator_config = self.advance_date_validators[i]
                    result = pd.to_datetime(
                        self.data_csv[i],
                        format="%Y-%m-%d",
                        errors="coerce",
                    ).apply(check_validations, validator_config=validator_config)

                    if not result.all():
                        advance_date_validation_col_list.append(i)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""

                        if validator_config["error_message_colV"]:
                            self.data_csv.loc[
                                (self.data_csv[i].notnull()) & (self.data_csv[i] != "nan") & (~result),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[i].notnull()) & (self.data_csv[i] != "nan") & (~result),
                                    "Error_Details",
                                ]
                                + f"Column {i} {validator_config['error_message_colV']}\n"
                            )
                        else:
                            self.data_csv.loc[
                                (self.data_csv[i].notnull()) & (self.data_csv[i] != "nan") & (~result),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (self.data_csv[i].notnull()) & (self.data_csv[i] != "nan") & (~result),
                                    "Error_Details",
                                ]
                                + f"Column {i} Advance Datefield Validation Error. \n "
                            )

                        self.data_csv.loc[
                            (self.data_csv[i].notnull()) & (self.data_csv[i] != "nan") & (~result),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[i].notnull()) & (self.data_csv[i] != "nan") & (~result),
                                "Error_Cols",
                            ]
                            + f" {i} "
                        )

                        navigation_list["AdvanceDate"].update(
                            {
                                i: list(
                                    self.data_csv.loc[
                                        (self.data_csv[i].notnull())
                                        & (self.data_csv[i] != "nan")
                                        & (~result),
                                    ].index
                                )
                            }
                        )

            if len(advance_date_validation_col_list) > 0:
                self.upload = False

                for i in range(len(advance_date_validation_col_list)):
                    if len(main_validator_config[advance_date_validation_col_list[i]]) != 0:
                        v_config = main_validator_config[advance_date_validation_col_list[i]]

                    if v_config["error_message_colV"]:
                        messages_list.append(
                            f"""{ advance_date_validation_col_list[i] } - {v_config['error_message_colV']}. \n"""
                        )
                    else:
                        messages_list.append(
                            f"""{ advance_date_validation_col_list[i] }- Advance Datefield Validation Error. \n"""
                        )

                    if self.message_show == "yes":
                        if not check_now and message_out:

                            icon = ""
                            if v_config["error_message_colV"]:
                                message = f"Error while uploading: { advance_date_validation_col_list[i] } - {v_config['error_message_colV']}. \n"
                            else:
                                message = f"Error while uploading: {advance_date_validation_col_list[i]} - Advance Datefield Validation Error. \n"
                            if custom_msg:
                                if "{Validation Message}" in custom_msg:
                                    custom_msg = custom_msg.replace("{Validation Message}", message)
                                message = custom_msg

                            if custom_icon:
                                icon = custom_icon

                            messages.add_message(
                                self.request, level=messages.ERROR, message=message, extra_tags=icon
                            )
                    if v_config["error_message_colV"]:
                        datalist = {
                            "feature_category": "L3-Upload",
                            "feature_subcategory": "Excel Upload",
                            "table_file_name": self.table_model_name,
                            "error_description": f"Error while uploading {self.table_model_name}: { advance_date_validation_col_list[i] } - {v_config['error_message_colV']}. \n",
                            "created_date": datetime.now(),
                            "created_by": self.request.user.username,
                            "modified_date": datetime.now(),
                            "modified_by": self.request.user.username,
                        }
                    else:
                        datalist = {
                            "feature_category": "L3-Upload",
                            "feature_subcategory": "Excel Upload",
                            "table_file_name": self.table_model_name,
                            "error_description": f"Error while uploading {self.table_model_name}: {advance_date_validation_col_list[i] } - Advance Datefield Validation Error. \n",
                            "created_date": datetime.now(),
                            "created_by": self.request.user.username,
                            "modified_date": datetime.now(),
                            "modified_by": self.request.user.username,
                        }
                    final_data.append(datalist)

        # DateRangeField Validation
        if bool(self.DateRangeField_list):
            dr_fail_list = []

            for key in self.DateRangeField_list:
                if key in self.data_csv.columns:
                    idict = r"^\d{4}\-(0[1-9]|1[012])\-(0[1-9]|[12][0-9]|3[01]) - \d{4}\-(0[1-9]|1[012])\-(0[1-9]|[12][0-9]|3[01])$"

                    rec = re.compile(idict)
                    adv_df = self.data_csv.copy()
                    try:
                        adv_df[key] = self.data_csv[key].str.match(rec)
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")

                    if False in adv_df[key].values:
                        adv_df[key].fillna(True, inplace=True)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Details",
                            ]
                            + "Error while uploading, please upload in YYYY-MM-DD - YYYY-MM-DD format"
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Details",
                        ] = np.nan

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Cols",
                            ]
                            + f" {key} "
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Cols",
                        ] = np.nan
                        dr_fail_list.append(key)

                        datatype_navigation_list[key] = list(self.data_csv.loc[(~adv_df[key]),].index)

                        if len(datatype_navigation_list[key]) > 0:
                            Datatype_error.append(key)

            if len(dr_fail_list) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(dr_fail_list))) } column must contain value only  in YYYY-MM-DD - YYYY-MM-DD format."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: { ' ,'.join(list(set(dr_fail_list))) } column must contain value only in YYYY-MM-DD - YYYY-MM-DD format"
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: { ' ,'.join(list(set(dr_fail_list))) } column must contain  value only  in YYYY-MM-DD - YYYY-MM-DD format",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - TimeField Validation
        time_col_list = []
        total_time_cols = self.TimeField_list
        time_format = "%H:%M:%S"
        time_message = "HH-MM-SS"

        if len(total_time_cols) > 0 and self.user_operation != "update":
            for total_time_col in total_time_cols:
                if total_time_col in self.data_csv.columns.tolist():
                    if total_time_col in self.TimeField_list_nosec:
                        if self.user_operation != "update":
                            time_format = "%H:%M"
                        else:
                            time_format = "%H:%M:00"
                        time_message = "HH-MM"
                    else:
                        time_format = "%H:%M:%S"
                        time_message = "HH-MM-SS"

                    if self.null_check[total_time_col] == 0:
                        time_check = (
                            pd.to_datetime(self.data_csv[total_time_col], format=time_format, errors="coerce")
                            .notnull()
                            .all()
                        )

                        if not time_check:
                            time_col_list.append(total_time_col)
                            self.data_csv.loc[
                                (self.data_csv[total_time_col].notnull())
                                & (self.data_csv[total_time_col] != "nan")
                                & (
                                    pd.to_datetime(
                                        self.data_csv[total_time_col],
                                        format=time_format,
                                        errors="coerce",
                                    ).isna()
                                ),
                                "Error_Details",
                            ] += f"Column {total_time_col} accept time only in {time_message} format."

                            self.data_csv.loc[
                                (self.data_csv[total_time_col].notnull())
                                & (self.data_csv[total_time_col] != "nan")
                                & (
                                    pd.to_datetime(
                                        self.data_csv[total_time_col],
                                        format=time_format,
                                        errors="coerce",
                                    ).isna()
                                ),
                                "Error_Cols",
                            ] += f" {total_time_col} "

                            datatype_navigation_list[total_time_col] = list(
                                self.data_csv.loc[
                                    (
                                        pd.to_datetime(
                                            self.data_csv[total_time_col],
                                            format=time_format,
                                            errors="coerce",
                                        ).isna()
                                    ),
                                ].index
                            )
                            if len(datatype_navigation_list[total_time_col]) > 0:
                                Datatype_error.append(total_time_col)

            if len(time_col_list) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(time_col_list))) } column must contain datetime only  in  {time_message} format."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: { ' ,'.join(list(set(time_col_list))) } column must contain time only in {time_message} format."
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: { ' ,'.join(list(set(time_col_list))) }  column must contain time only in {time_message} format.",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - Choices
        choices_col_list = []
        choice_set = None
        resultant_choice_set = []
        if len(self.choices_check) > 0:
            for i in range(len(self.choices_check)):
                if list(self.choices_check[i].keys())[0] in self.data_csv.columns.tolist():
                    for k, v in self.choices_check[i].items():
                        choice_set = {single_item for t in v for single_item in t}
                        if self.null_check[k] in [True, "True", 1, "1"]:
                            null_list = {np.nan, "NaN", "NaT", pd.NaT, " ", "nan"}
                            choice_set.update(null_list)
                            if (
                                bool(
                                    all(
                                        str(i).strip() in choice_set
                                        for i in list(self.data_csv[k].astype(str).str.strip())
                                    )
                                )
                                is False
                            ):
                                choices_col_list.append(k)
                                if self.null_check[k] in [True, "True", 1, "1"]:
                                    choice_set.remove(np.nan)
                                    choice_set.remove("NaN")
                                    choice_set.remove("NaT")
                                    choice_set.remove("nan")
                                    choice_set.remove(pd.NaT)
                                    choice_set.remove(" ")
                                resultant_choice_set.append(choice_set)
                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (self.data_csv[k].notnull())
                                    & (self.data_csv[k] != "nan")
                                    & (~self.data_csv[k].isin(choice_set)),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[k].notnull())
                                        & (self.data_csv[k] != "nan")
                                        & (~self.data_csv[k].isin(choice_set)),
                                        "Error_Details",
                                    ]
                                    + f"Column {k}  accepts value in {' ,'.join(choice_set)}."
                                )

                                self.data_csv.loc[
                                    (self.data_csv[k].notnull())
                                    & (self.data_csv[k] != "nan")
                                    & (~self.data_csv[k].isin(choice_set)),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[k].notnull())
                                        & (self.data_csv[k] != "nan")
                                        & (~self.data_csv[k].isin(choice_set)),
                                        "Error_Cols",
                                    ]
                                    + f" {k} "
                                )

                                navigation_list["Choices"].update(
                                    {k: list(self.data_csv.loc[(~self.data_csv[k].isin(choice_set))].index)}
                                )
                        else:
                            if bool(all(str(i) in choice_set for i in self.data_csv[k].tolist())) is False:
                                choices_col_list.append(k)
                                if self.null_check[k] in [True, "True", 1, "1"]:
                                    choice_set.remove(np.nan)
                                    choice_set.remove("NaN")
                                    choice_set.remove("NaT")
                                    choice_set.remove(pd.NaT)
                                    choice_set.remove(" ")
                                resultant_choice_set.append(choice_set)
                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (self.data_csv[k].notnull())
                                    & (self.data_csv[k] != "nan")
                                    & (~self.data_csv[k].isin(choice_set)),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[k].notnull())
                                        & (self.data_csv[k] != "nan")
                                        & (~self.data_csv[k].isin(choice_set)),
                                        "Error_Details",
                                    ]
                                    + f"Column {k}  accepts value in {' ,'.join(choice_set)}."
                                )

                                self.data_csv.loc[
                                    (self.data_csv[k].notnull())
                                    & (self.data_csv[k] != "nan")
                                    & (~self.data_csv[k].isin(choice_set)),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[k].notnull())
                                        & (self.data_csv[k] != "nan")
                                        & (~self.data_csv[k].isin(choice_set)),
                                        "Error_Cols",
                                    ]
                                    + f" {k} "
                                )

                                navigation_list["Choices"].update(
                                    {k: list(self.data_csv.loc[(~self.data_csv[k].isin(choice_set))].index)}
                                )

        if len(choices_col_list) > 0:
            self.upload = False
            messages_list.append(
                f"""{' ,'.join(choices_col_list)}  column(s) accepts value in {resultant_choice_set}."""
            )
            if self.message_show == "yes":
                if not check_now and message_out:

                    icon = ""
                    message = f"Error while uploading:{' ,'.join(choices_col_list)}  column(s) accepts value in {resultant_choice_set}. "
                    if custom_msg:
                        if "{Validation Message}" in custom_msg:
                            custom_msg = custom_msg.replace("{Validation Message}", message)
                        message = custom_msg

                    if custom_icon:
                        icon = custom_icon

                    messages.add_message(self.request, level=messages.ERROR, message=message, extra_tags=icon)

            datalist = {
                "feature_category": "L3-Upload",
                "feature_subcategory": "Excel Upload",
                "table_file_name": self.table_model_name,
                "error_description": f"Error while uploading :{' ,'.join(choices_col_list)}  column(s) accepts value in {resultant_choice_set}. ",
                "created_date": datetime.now(),
                "created_by": self.request.user.username,
                "modified_date": datetime.now(),
                "modified_by": self.request.user.username,
            }
            final_data.append(datalist)

        # Data Validation - Hierarchy Columns
        hierarchy_col_list = []
        h_value_set = None
        resultant_h_value_set = []
        if len(self.hierarchy_check) > 0:
            for i in range(len(self.hierarchy_check)):
                if list(self.hierarchy_check[i].keys())[0] in self.data_csv.columns.tolist():
                    for k, v in self.hierarchy_check[i].items():
                        h_value_set = {t for t in v}
                        if self.null_check[k] in [True, "True", 1, "1"]:
                            null_list = {np.nan, "NaN", "NaT", pd.NaT, " ", "nan"}
                            h_value_set.update(null_list)
                            if (
                                bool(
                                    all(
                                        str(i).strip() in h_value_set
                                        for i in list(self.data_csv[k].astype(str).str.strip())
                                    )
                                )
                                is False
                            ):
                                hierarchy_col_list.append(k)
                                if self.null_check[k] in [True, "True", 1, "1"]:
                                    h_value_set.remove(np.nan)
                                    h_value_set.remove("NaN")
                                    h_value_set.remove("NaT")
                                    h_value_set.remove("nan")
                                    h_value_set.remove(pd.NaT)
                                    h_value_set.remove(" ")
                                resultant_h_value_set.append(h_value_set)

                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (self.data_csv[k].notnull())
                                    & (self.data_csv[k] != "nan")
                                    & (~self.data_csv[k].isin(h_value_set)),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[k].notnull())
                                        & (self.data_csv[k] != "nan")
                                        & (~self.data_csv[k].isin(h_value_set)),
                                        "Error_Details",
                                    ]
                                    + f"User does not have access to the values entered. Allowed values are {' ,'.join(h_value_set)}"
                                )

                                self.data_csv.loc[
                                    (self.data_csv[k].notnull())
                                    & (self.data_csv[k] != "nan")
                                    & (~self.data_csv[k].isin(h_value_set)),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[k].notnull())
                                        & (self.data_csv[k] != "nan")
                                        & (~self.data_csv[k].isin(h_value_set)),
                                        "Error_Cols",
                                    ]
                                    + f" {k} "
                                )

                                navigation_list["HierarchyColumn"].update(
                                    {k: list(self.data_csv.loc[(~self.data_csv[k].isin(h_value_set))].index)}
                                )
                        else:
                            if bool(all(str(i) in h_value_set for i in self.data_csv[k].tolist())) is False:
                                hierarchy_col_list.append(k)
                                if self.null_check[k] in [True, "True", 1, "1"]:
                                    h_value_set.remove(np.nan)
                                    h_value_set.remove("NaN")
                                    h_value_set.remove("NaT")
                                    h_value_set.remove(pd.NaT)
                                    h_value_set.remove(" ")
                                resultant_h_value_set.append(h_value_set)

                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (self.data_csv[k].notnull())
                                    & (self.data_csv[k] != "nan")
                                    & (~self.data_csv[k].isin(h_value_set)),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[k].notnull())
                                        & (self.data_csv[k] != "nan")
                                        & (~self.data_csv[k].isin(h_value_set)),
                                        "Error_Details",
                                    ]
                                    + f"User does not have access to the values entered. Allowed values are {' ,'.join(h_value_set)}"
                                )

                                self.data_csv.loc[
                                    (self.data_csv[k].notnull())
                                    & (self.data_csv[k] != "nan")
                                    & (~self.data_csv[k].isin(h_value_set)),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[k].notnull())
                                        & (self.data_csv[k] != "nan")
                                        & (~self.data_csv[k].isin(h_value_set)),
                                        "Error_Cols",
                                    ]
                                    + f" {k} "
                                )

                                navigation_list["HierarchyColumn"].update(
                                    {k: list(self.data_csv.loc[(~self.data_csv[k].isin(h_value_set))].index)}
                                )

        if len(hierarchy_col_list) > 0:
            self.upload = False
            res_vallist = [j for i in resultant_h_value_set for j in i]
            messages_list.append(
                f"""User does not have access to the values entered. Allowed values are {' ,'.join(res_vallist)}"""
            )
            if self.message_show == "yes":
                if not check_now and message_out:

                    icon = ""
                    message = f"Error while uploading: User does not have access to the values entered. Allowed values are {' ,'.join(res_vallist)}. "
                    if custom_msg:
                        if "{Validation Message}" in custom_msg:
                            custom_msg = custom_msg.replace("{Validation Message}", message)
                        message = custom_msg

                    if custom_icon:
                        icon = custom_icon

                    messages.add_message(self.request, level=messages.ERROR, message=message, extra_tags=icon)

            datalist = {
                "feature_category": "L3-Upload",
                "feature_subcategory": "Excel Upload",
                "table_file_name": self.table_model_name,
                "error_description": f"Error while uploading :User does not have access to the values entered. Allowed values are {' ,'.join(res_vallist)}",
                "created_date": datetime.now(),
                "created_by": self.request.user.username,
                "modified_date": datetime.now(),
                "modified_by": self.request.user.username,
            }
            final_data.append(datalist)

        if bool(self.FileField_list):
            file_fail_list = []
            navigation_list["FileExtensionValidation"] = {}
            error_message = {}
            for key in self.FileField_list:
                if key in self.file_extension and key in self.data_csv.columns:
                    if self.file_extension[key] == "PDF":
                        fformat = ".pdf"
                    elif self.file_extension[key] == "Images":
                        fformat = (".png", ".bmp", ".jpeg", ".jpg", ".gif", ".tif", ".tiff")
                    elif self.file_extension[key] == "Document":
                        fformat = (".doc", ".docx", ".rtf", ".pdf", ".csv", ".xlsx", ".odt")
                    else:
                        fformat = ""

                    error_message[key] = f"Wrong file extension. Valid formats are {fformat}"
                    ff_df = pd.DataFrame(columns=[key])
                    if len(self.data_csv[key].astype("object").str.split(", ")) > 0:
                        for fd in self.data_csv[key].astype("object").str.split(", "):
                            if type(fd) is list:
                                for fd1 in fd:
                                    if fd1.endswith(fformat) is False:
                                        ff_df[key] = pd.Series([False], name=key)
                                        break
                                    else:
                                        ff_df[key] = pd.Series([True], name=key)

                    if False in ff_df[key].values:
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""
                        self.data_csv.loc[
                            (~pd.Series([False], name=key)),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (~pd.Series([False], name=key)),
                                "Error_Details",
                            ]
                            + f"Error while uploading, {key}: {error_message[key]}"
                        )
                        self.data_csv.loc[
                            (~pd.Series([False], name=key)),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (~pd.Series([False], name=key)),
                                "Error_Cols",
                            ]
                            + f" {key} "
                        )
                        file_fail_list.append(key)
                        navigation_list["FileExtensionValidation"][key] = list(
                            self.data_csv.loc[(~pd.Series([False], name=key))].index
                        )

            if len(file_fail_list) > 0:
                self.upload = False
                if len(error_message) > 0:
                    for k, v in error_message.items():
                        if k in file_fail_list:
                            messages_list.append(f" {k}: {v}")
                if self.message_show == "yes":
                    if len(error_message) > 0:
                        for k, v in error_message.items():
                            if k in file_fail_list:
                                if not check_now and message_out:
                                    icon = ""
                                    message = f"Error while uploading, {k}: {v}"
                                    if custom_msg:
                                        if "{Validation Message}" in custom_msg:
                                            custom_msg = custom_msg.replace("{Validation Message}", message)
                                        message = custom_msg

                                    if custom_icon:
                                        icon = custom_icon

                                    messages.add_message(
                                        self.request, level=messages.ERROR, message=message, extra_tags=icon
                                    )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading, {k}: {v}",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # DateRangeField Validation
        if bool(self.DateTimeRangeField_list):
            dtr_fail_list = []

            for key in self.DateTimeRangeField_list:
                if key in self.data_csv.columns:
                    idict = r"^\d{4}\-(0[1-9]|1[012])\-(0[1-9]|[12][0-9]|3[01]) (?:[01]\d|2[0123]):(?:[012345]\d):(?:[012345]\d) - \d{4}\-(0[1-9]|1[012])\-(0[1-9]|[12][0-9]|3[01]) (?:[01]\d|2[0123]):(?:[012345]\d):(?:[012345]\d)$"

                    rec = re.compile(idict)
                    adv_df = self.data_csv.copy()
                    try:
                        adv_df[key] = self.data_csv[key].str.match(rec)
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")

                    if False in adv_df[key].values:
                        adv_df[key].fillna(True, inplace=True)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Details",
                            ]
                            + "Error while uploading, please upload in YYYY-MM-DD hh:mm:ss - YYYY-MM-DD hh:mm:ss format"
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Details",
                        ] = np.nan

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Cols",
                            ]
                            + f" {key} "
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Cols",
                        ] = np.nan
                        dtr_fail_list.append(key)

                        datatype_navigation_list[key] = list(self.data_csv.loc[(~adv_df[key]),].index)

                        if len(datatype_navigation_list[key]) > 0:
                            Datatype_error.append(key)

            if len(dtr_fail_list) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(dtr_fail_list))) } column must contain value only  in YYYY-MM-DD hh:mm:ss - YYYY-MM-DD hh:mm:ss format."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = (
                            f"Error while uploading: { ' ,'.join(list(set(dtr_fail_list))) } column must contain value only in YYYY-MM-DD hh:mm:ss - YYYY-MM-DD hh:mm:ss format",
                        )
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: { ' ,'.join(list(set(dtr_fail_list))) } column must contain  value only  in YYYY-MM-DD hh:mm:ss - YYYY-MM-DD hh:mm:ss format",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # TimeRangeField Validation
        if bool(self.TimeRangeField_list):
            tr_fail_list = []

            for key in self.TimeRangeField_list:
                if key in self.data_csv.columns:
                    idict = r"^(?:[01]\d|2[0123]):(?:[012345]\d):(?:[012345]\d) - (?:[01]\d|2[0123]):(?:[012345]\d):(?:[012345]\d)$"

                    rec = re.compile(idict)
                    adv_df = self.data_csv.copy()
                    try:
                        adv_df[key] = self.data_csv[key].str.match(rec)
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")

                    if False in adv_df[key].values:
                        adv_df[key].fillna(True, inplace=True)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Details",
                            ]
                            + "Error while uploading, please upload in HH:mm:ss - HH:mm:ss format"
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Details",
                        ] = np.nan

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Cols",
                            ]
                            + f" {key} "
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Cols",
                        ] = np.nan
                        tr_fail_list.append(key)

                        datatype_navigation_list[key] = list(self.data_csv.loc[(~adv_df[key]),].index)

                        if len(datatype_navigation_list[key]) > 0:
                            Datatype_error.append(key)

            if len(tr_fail_list) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(tr_fail_list))) } column must contain value only  in HH:mm:ss - HH:mm:ss format."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: { ' ,'.join(list(set(tr_fail_list))) } column must contain value only in HH:mm:ss - HH:mm:ss format"
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: { ' ,'.join(list(set(tr_fail_list))) } column must contain  value only  in HH:mm:ss - HH:mm:ss format",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - CardField
        _col_list_card = []
        total_cols_card = self.card_property

        if len(total_cols_card) > 0:
            for key, value in total_cols_card.items():
                if key in self.data_csv.columns.tolist():
                    for k1, v1 in value.items():

                        if k1 == "cvv_field_create_fname":

                            cvv_colname = v1
                            adv_df = self.data_csv.copy()
                            try:
                                for i in range(len(adv_df)):
                                    adv_df.loc[i, key] = Credit_Card_Validator.check_valid_card(
                                        adv_df.loc[i, key], adv_df.loc[i, cvv_colname]
                                    )
                            except Exception as e:
                                logging.warning(f"Following exception occured - {e}")

                            if False in adv_df[key].values:
                                adv_df[key].fillna(True, inplace=True)
                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""

                                self.data_csv.loc[
                                    (~adv_df[key]),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (~adv_df[key]),
                                        "Error_Details",
                                    ]
                                    + "Error while uploading, Invalid card number"
                                )
                                self.data_csv.loc[
                                    (adv_df[key]),
                                    "Error_Details",
                                ] = np.nan

                                self.data_csv.loc[
                                    (~adv_df[key]),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (~adv_df[key]),
                                        "Error_Cols",
                                    ]
                                    + f" {key} "
                                )
                                self.data_csv.loc[
                                    (adv_df[key]),
                                    "Error_Cols",
                                ] = np.nan
                                _col_list_card.append(key)

                                datatype_navigation_list[key] = list(self.data_csv.loc[(~adv_df[key]),].index)

                                if len(datatype_navigation_list[key]) > 0:
                                    Datatype_error.append(key)

                            break

            if len(_col_list_card) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(_col_list_card))) } column must contain proper card number."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: { ' ,'.join(list(set(_col_list_card))) } column must contain proper card number"
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: { ' ,'.join(list(set(_col_list_card))) } column must contain proper card number",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - CardField MaxLength
        str_col_list_card = []
        max_size_card = []
        if bool(self.max_length_check_card):
            for k, v in self.max_length_check_card.items():
                if k in self.data_csv.columns.tolist():
                    if self.data_csv[k].astype(str).str.len().max() > v:
                        str_col_list_card.append(k)
                        max_size_card.append(str(v))
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""
                        self.data_csv.loc[
                            (self.data_csv[k].notnull())
                            & (self.data_csv[k] != "nan")
                            & (self.data_csv[k].astype(str).str.len().ge(v)),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[k].notnull())
                                & (self.data_csv[k] != "nan")
                                & (self.data_csv[k].astype(str).str.len().ge(v)),
                                "Error_Details",
                            ]
                            + f"CardField column {k} has max length of {v}."
                        )

                        self.data_csv.loc[
                            (self.data_csv[k].notnull())
                            & (self.data_csv[k] != "nan")
                            & (self.data_csv[k].astype(str).str.len().ge(v)),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[k].notnull())
                                & (self.data_csv[k] != "nan")
                                & (self.data_csv[k].astype(str).str.len().ge(v)),
                                "Error_Cols",
                            ]
                            + f" {k} "
                        )

                        navigation_list["MaxLength"].update(
                            {k: list(self.data_csv.loc[(self.data_csv[k].astype(str).str.len().ge(v))].index)}
                        )

            if len(str_col_list_card) > 0:
                self.upload = False
                messages_list.append(
                    f"""Max character length for CardField column {' ,'.join(str_col_list_card)} is {' ,'.join(max_size_card)}."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: Max character length for CardField column  {' ,'.join(str_col_list_card)} is {' ,'.join(max_size_card)}."
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name} :Max character length for CardField column  {' ,'.join(str_col_list_card)} is {' ,'.join(max_size_card)}.",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - CardCvvField
        _col_list_cardcvv = []
        total_cols_card_cvv = self.CardCvvField_list

        if len(total_cols_card_cvv) > 0:
            for key in total_cols_card_cvv:
                if key in self.data_csv.columns.tolist():

                    idict = r"^[0-9]+$"

                    rec = re.compile(idict)
                    adv_df = self.data_csv.copy()
                    try:
                        adv_df[key] = self.data_csv[key].str.match(rec)
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")

                    if False in adv_df[key].values:
                        adv_df[key].fillna(True, inplace=True)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Details",
                            ]
                            + "Error while uploading, Invalid cvv number"
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Details",
                        ] = np.nan

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Cols",
                            ]
                            + f" {key} "
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Cols",
                        ] = np.nan
                        _col_list_cardcvv.append(key)

                        datatype_navigation_list[key] = list(self.data_csv.loc[(~adv_df[key]),].index)

                        if len(datatype_navigation_list[key]) > 0:
                            Datatype_error.append(key)

            if len(_col_list_cardcvv) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(_col_list_cardcvv))) } column must contain proper CVV number."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: { ' ,'.join(list(set(_col_list_cardcvv))) } column must contain proper CVV number"
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: { ' ,'.join(list(set(_col_list_cardcvv))) } column must contain proper CVV number",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - CardExpiryField
        _col_list_cardexpiry = []
        total_cols_card_expiry = self.CardExpiryField_list

        if len(total_cols_card_expiry) > 0:
            for key in total_cols_card_expiry:
                if key in self.data_csv.columns.tolist():

                    idict = r"^(20[0-2][0-9])-((0[1-9])|(1[0-2]))$"

                    rec = re.compile(idict)
                    adv_df = self.data_csv.copy()
                    try:
                        adv_df[key] = self.data_csv[key].str.match(rec)
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")

                    if False in adv_df[key].values:
                        adv_df[key].fillna(True, inplace=True)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Details",
                            ]
                            + "Error while uploading, Invalid card expiry details. Value should be in YYYY-MM"
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Details",
                        ] = np.nan

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Cols",
                            ]
                            + f" {key} "
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Cols",
                        ] = np.nan
                        _col_list_cardexpiry.append(key)

                        datatype_navigation_list[key] = list(self.data_csv.loc[(~adv_df[key]),].index)

                        if len(datatype_navigation_list[key]) > 0:
                            Datatype_error.append(key)

            if len(_col_list_cardexpiry) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(_col_list_cardexpiry))) } column must contain value in YYYY-MM format."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: { ' ,'.join(list(set(_col_list_cardexpiry))) } column must contain value in YYYY-MM format"
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}: { ' ,'.join(list(set(_col_list_cardexpiry))) } column must contain value in YYYY-MM format",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # EmailTypeField Validation
        if bool(self.EmailTypeField_list):
            email_fail_list = []

            for key in self.EmailTypeField_list:
                if key in self.data_csv.columns:
                    idict = r"^([\w\.\-]+)@([\w\-]+)((\.(\w){2,63}){1,3})$"

                    rec = re.compile(idict)
                    adv_df = self.data_csv.copy()
                    try:
                        adv_df[key] = self.data_csv[key].str.fullmatch(rec)
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")

                    if False in adv_df[key].values:
                        adv_df[key].fillna(True, inplace=True)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Details",
                            ]
                            + f"Error while uploading: {key} column must contain a value in valid email format."
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Details",
                        ] = np.nan

                        self.data_csv.loc[
                            (~adv_df[key]),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Cols",
                            ]
                            + f" {key} "
                        )
                        self.data_csv.loc[
                            (adv_df[key]),
                            "Error_Cols",
                        ] = np.nan
                        email_fail_list.append(key)

                        datatype_navigation_list[key] = list(self.data_csv.loc[(~adv_df[key]),].index)

                        if len(datatype_navigation_list[key]) > 0:
                            Datatype_error.append(key)

            if len(email_fail_list) > 0:
                self.upload = False
                messages_list.append(
                    f"""{ ' ,'.join(list(set(email_fail_list))) } column must contain a value in valid email format."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: { ' ,'.join(list(set(email_fail_list))) } column must contain a value in valid email format."
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading: { ' ,'.join(list(set(email_fail_list))) } column must contain a value in valid email format.",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # MultiSelectField Validation
        multi_select_fail_list = []
        if bool(self.multi_select_field_list):
            multi_select_pass_data = {}
            navigation_list["MultiSelectValidator"] = {}
            for mul_field, mul_config in self.multi_select_field_config_list.items():
                if mul_field in self.data_csv.columns:
                    master_table = mul_config["value"][0]
                    master_field = mul_config["masterColumn"][0]
                    raw_condition = mul_config["condition"][0]
                    filter_condition = []
                    for i in raw_condition:
                        filter_condition.append(
                            {
                                "column_name": i["condColumn"],
                                "condition": i["cond"],
                                "input_value": i["condValue"],
                                "and_or": "",
                                "constraintName": i["constraint"],
                                "ruleSet": i["ruleSet"],
                            }
                        )
                    master_data = read_data_func(
                        self.request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": master_table,
                                "Columns": ["id", master_field],
                            },
                            "condition": filter_condition,
                        },
                    )
                    master_data_id_to_value = master_data.set_index("id").to_dict()[master_field]
                    master_data_value_to_id = master_data.set_index(master_field).to_dict()["id"]
                    mul_df = self.data_csv.copy()
                    mul_df["valid"] = True
                    for idx, row in mul_df.iterrows():
                        mul_value = row[mul_field]
                        if mul_value and str(mul_value) not in ["nan", "None"]:
                            if mul_value.startswith("{"):
                                mul_value = json.loads(mul_value.replace("'", '"'))
                                mul_value = mul_value.keys()
                                try:
                                    mul_value = [int(i) for i in mul_value]
                                    data_valid = all(
                                        [True if i in master_data_id_to_value else False for i in mul_value]
                                    )
                                    master_data = master_data_id_to_value
                                except Exception:
                                    data_valid = all(
                                        [
                                            True if i.strip() in master_data_value_to_id else False
                                            for i in mul_value
                                        ]
                                    )
                                    master_data = master_data_value_to_id
                            else:
                                mul_value = mul_value.split(",")
                                data_valid = all(
                                    [
                                        True if i.strip() in master_data_value_to_id else False
                                        for i in mul_value
                                    ]
                                )
                                master_data = master_data_value_to_id
                            mul_df.loc[idx, "valid"] = data_valid
                        else:
                            pass
                    if not all(mul_df["valid"]):
                        self.upload = False
                        multi_select_fail_list.append(mul_field)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""
                        self.data_csv.loc[~mul_df["valid"], "Error_Details"] = (
                            self.data_csv.loc[~mul_df["valid"], "Error_Details"]
                            + f"Error while uploading, {mul_field}: Incorrect values entered! Please enter values from the {master_table}."
                        )
                        self.data_csv.loc[~mul_df["valid"], "Error_Cols"] = (
                            self.data_csv.loc[~mul_df["valid"], "Error_Cols"] + f" {mul_field} "
                        )
                        navigation_list["MultiSelectValidator"][mul_field] = list(
                            self.data_csv.loc[(~mul_df["valid"])].index
                        )
                    else:
                        multi_select_pass_data[mul_field] = master_data
                else:
                    continue

            if multi_select_fail_list:
                self.upload = False
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading:{' ,'.join( multi_select_fail_list)}  column(s) values has no match in the parent table column."
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}:{' ,'.join( multi_select_fail_list)}  column(s) values has no match in the parent table column.",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)
            else:
                for col in multi_select_pass_data:
                    master_data = multi_select_pass_data[col]
                    self.data_csv[col] = self.data_csv[col].map(
                        lambda x: multi_select_value_converter(x, master_data), na_action="ignore"
                    )

        # TableField Validation
        table_field_fail_list = []
        if bool(self.table_field_list):
            navigation_list["TableFieldValidator"] = {}
            for tb_field in self.table_field_list:
                if tb_field in self.data_csv.columns:
                    tb_df = self.data_csv[~self.data_csv[tb_field].isna()]
                    tb_df["valid"] = tb_df[tb_field].astype(str).str.startswith("[")
                    if not all(tb_df["valid"]):
                        self.upload = False
                        table_field_fail_list.append(tb_field)
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""
                        self.data_csv.loc[~tb_df["valid"], "Error_Details"] = (
                            self.data_csv.loc[~tb_df["valid"], "Error_Details"]
                            + f"Error while uploading, {tb_field}: Incorrect values entered."
                        )
                        self.data_csv.loc[~tb_df["valid"], "Error_Cols"] = (
                            self.data_csv.loc[~tb_df["valid"], "Error_Cols"] + f" {tb_field} "
                        )
                        navigation_list["TableFieldValidator"][tb_field] = list(
                            self.data_csv.loc[(~tb_df["valid"])].index
                        )
                    else:
                        pass
                else:
                    continue

            if table_field_fail_list:
                self.upload = False
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading:{' ,'.join( table_field_fail_list)}. Incorrect values entered."
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name}:{' ,'.join( table_field_fail_list)}. Incorrect values entered.",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)
            else:
                pass

        # Custom Validation
        custom_condition_dict = {}
        selected_custom = []
        remove_unnesscary_dict_list = []
        custom_dict = {}
        if len(self.customvalidation) > 0:
            if self.table_model_name in self.customvalidation.keys():
                custom_condition_dict = {
                    "Greater than": {},
                    "Smaller than": {},
                    "Equal to": {},
                    "Not Equal to": {},
                    "Starts with": {},
                    "Ends with": {},
                    "Contains": {},
                    "Not Contains": {},
                    "Not Starts with": {},
                    "Not Ends with": {},
                    "IN": {},
                    "NOT IN": {},
                    "Isin": {},
                }
                condition_list = {
                    "IntegerField_list": self.IntegerField_list,
                    "FloatField_list": self.FloatField_list,
                    "DateTimeField_list": self.DateTimeField_list,
                    "TimeField_list": self.TimeField_list,
                    "DateField_list": self.DateField_list,
                    "BooleanField_list": self.BooleanField_list,
                }
                custom_dict = {self.table_model_name: {}}
                constraint_name_list = list(
                    {con["constraint_name"] for con in self.customvalidation[self.table_model_name]}
                )

                if self.customvalidation.get("Master_filter"):
                    for con_master in self.customvalidation["Master_filter"]:
                        constraint_name_list.append(con_master["constraint_name"])
                    constraint_name_list = set(constraint_name_list)
                    constraint_name_list = list(constraint_name_list)
                # Structure Constraint name with Rule Set which consist a list of dict
                for cname in constraint_name_list:
                    custom_dict[self.table_model_name][cname] = {}
                    for i in range(len(self.customvalidation[self.table_model_name])):
                        if self.customvalidation[self.table_model_name][i]["constraint_name"] == cname:
                            rule_name = self.customvalidation[self.table_model_name][i]["rule_set"]
                            if rule_name not in custom_dict[self.table_model_name][cname].keys():
                                custom_dict[self.table_model_name][cname][rule_name] = [
                                    self.customvalidation[self.table_model_name][i]
                                ]
                            else:
                                custom_dict[self.table_model_name][cname][rule_name].append(
                                    self.customvalidation[self.table_model_name][i]
                                )
                    if self.customvalidation.get("Master_filter"):
                        for i in range(len(self.customvalidation["Master_filter"])):
                            if self.customvalidation["Master_filter"][i]["constraint_name"] == cname:
                                rule_name = self.customvalidation["Master_filter"][i]["rule_set"]
                                if rule_name not in custom_dict[self.table_model_name][cname].keys():
                                    custom_dict[self.table_model_name][cname][rule_name] = [
                                        self.customvalidation["Master_filter"][i]
                                    ]
                                else:
                                    custom_dict[self.table_model_name][cname][rule_name].append(
                                        self.customvalidation["Master_filter"][i]
                                    )

                # Dictionary for holding the boolean result

                overall_failed_index = []
                test_data_csv = self.data_csv.copy()

                # Search Rule_set which is True/False
                constraint_string = ""
                final_message_list = []
                error_message_list = []
                query_list = []
                for constraint_name, constraint_content in custom_dict[self.table_model_name].items():
                    final_inner_message = ""
                    err_string = ""
                    final_evaluation_string = """("""
                    for rule_name, rule_list in constraint_content.items():
                        for r in range(len(rule_list)):
                            column_name = rule_list[r]["column_name"]
                            condition_name = rule_list[r]["condition_name"]
                            input_value = rule_list[r]["input_value"]
                            if rule_list[r].get("table_name"):
                                master_table_name = rule_list[r]["table_name"]
                            else:
                                master_table_name = ""
                            custom_validation_error = {}
                            property_custom_dict = {
                                "column_name": column_name,
                                "condition_name": condition_name,
                                "input_value": input_value,
                                "master_table_name": master_table_name,
                            }
                            if column_name in data_columns and column_name not in self.auto_now_list:
                                condition_list["table_model_name"] = self.table_model_name
                                condition_list["custom_validation_error"] = custom_validation_error
                                condition_list["property_custom_dict"] = property_custom_dict
                                (final_string, inner_message) = custom_validation_condition_test(
                                    data_csv=test_data_csv,
                                    condition_list=condition_list,
                                    request=self.request,
                                )
                                query_list.append(
                                    {
                                        "condition_name": condition_name,
                                        "column_name": column_name,
                                        "query_string": final_string,
                                    }
                                )
                                if final_evaluation_string != """(""":
                                    final_evaluation_string += f"& {final_string}"
                                else:
                                    final_evaluation_string += final_string

                                if final_inner_message != "":
                                    final_inner_message += f" and {inner_message}"
                                    err_string = err_string + " " + column_name
                                else:
                                    final_inner_message += inner_message
                                    err_string = err_string + column_name
                    final_evaluation_string += ")"
                    constraint_string += final_evaluation_string + " | "
                    final_message_list.append(
                        f"""<strong>{constraint_name}</strong>: {final_inner_message}"""
                    )
                    final_message_list.append("Custom validation")
                    error_message_list.append(f"""{constraint_name}: {final_inner_message}""")

                if constraint_string.endswith(" | "):
                    constraint_string = constraint_string.strip(" | ")

                condition_df = pd.DataFrame(columns=["Condition_Result"])
                condition_df["Condition_Result"] = pd.eval(
                    constraint_string, parser="python", target=self.data_csv, engine="python"
                )

                overall_failed_index = list(self.data_csv[~condition_df["Condition_Result"]].index)

                if False in condition_df["Condition_Result"].values:
                    self.upload = False
                    if len(query_list) > 0:
                        for i in range(len(query_list)):
                            condition_name = query_list[i]["condition_name"]
                            column_name = query_list[i]["column_name"]
                            query_string = query_list[i]["query_string"]
                            condition_df2 = pd.DataFrame(columns=["Condition_Result"])
                            selected_custom.append(condition_name)
                            condition_df2["Condition_Result"] = pd.eval(
                                query_string,
                                parser="python",
                                target=self.data_csv[~condition_df["Condition_Result"]],
                                engine="python",
                            )
                            if condition_name in list(custom_condition_dict.keys()):
                                remove_unnesscary_dict_list.append(condition_name)
                                custom_condition_dict[condition_name][column_name] = list(
                                    self.data_csv[
                                        ~condition_df2["Condition_Result"] & ~condition_df["Condition_Result"]
                                    ].index
                                )
                    if "Error_Details" not in self.data_csv.columns:
                        self.data_csv["Error_Details"] = ""
                    if "Error_Cols" not in self.data_csv.columns:
                        self.data_csv["Error_Cols"] = ""
                    messages_list = messages_list + final_message_list
                    self.data_csv.loc[
                        (self.data_csv.index.isin(overall_failed_index)),
                        "Error_Details",
                    ] = self.data_csv.loc[
                        (self.data_csv.index.isin(overall_failed_index)),
                        "Error_Details",
                    ] + ".".join(
                        error_message_list
                    )
                    self.data_csv.loc[
                        (self.data_csv.index.isin(overall_failed_index)),
                        "Error_Cols",
                    ] = (
                        self.data_csv.loc[
                            (self.data_csv.index.isin(overall_failed_index)),
                            "Error_Cols",
                        ]
                        + err_string
                    )

                    if self.message_show == "yes":
                        for msg in range(len(error_message_list)):
                            icon = ""
                            message = f"Error while uploading: {error_message_list[msg]}."
                            if custom_msg:
                                if "{Validation Message}" in custom_msg:
                                    custom_msg = custom_msg.replace("{Validation Message}", message)
                                message = custom_msg

                            if custom_icon:
                                icon = custom_icon

                            messages.add_message(
                                self.request, level=messages.ERROR, message=message, extra_tags=icon
                            )

                else:
                    if len(query_list) > 0:
                        for i in range(len(query_list)):
                            condition_name = query_list[i]["condition_name"]
                            column_name = query_list[i]["column_name"]
                            query_string = query_list[i]["query_string"]
                            condition_df2 = pd.DataFrame(columns=["Condition_Result"])
                            selected_custom.append(condition_name)
                            if condition_name in list(custom_condition_dict.keys()):
                                remove_unnesscary_dict_list.append(condition_name)
                                custom_condition_dict[condition_name][column_name] = []

                if len(remove_unnesscary_dict_list) > 0:
                    remove_unnesscary_dict_list = list(set(remove_unnesscary_dict_list))
                    for k, v in custom_condition_dict.copy().items():
                        if k not in remove_unnesscary_dict_list and k not in selected_custom:
                            del custom_condition_dict[k]

        # Data Validation - Concatenation Validation
        if len(self.ConcatenationField_list) > 0 and self.upload:
            for k in self.divider_check:
                if self.divider_check[k] is None:
                    self.divider_check[k] = ""
            for i in range(len(self.ConcatenationField_list)):
                self.data_csv[self.ConcatenationField_list[i]] = ""
                if (
                    self.ConcatenationField_list[i] in self.concatenation_columns.keys()
                    and self.upload is True
                ):
                    for ind, j in enumerate(
                        json.loads(self.concatenation_columns[self.ConcatenationField_list[i]])
                    ):
                        if j in self.data_csv.columns.tolist():
                            self.data_csv[self.ConcatenationField_list[i]] += (
                                self.data_csv[j].astype(object).fillna("").astype(str)
                            )
                            if (
                                ind
                                != len(
                                    json.loads(self.concatenation_columns[self.ConcatenationField_list[i]])
                                )
                                - 1
                            ):
                                self.data_csv[self.ConcatenationField_list[i]] += self.divider_check[
                                    self.ConcatenationField_list[i]
                                ]
                        elif self.user_operation == "update":
                            if not self.edit_row.empty:
                                if j in self.edit_row.columns.tolist():
                                    if ind == 0:
                                        sep_val = ""
                                    else:
                                        sep_val = self.divider_check[self.ConcatenationField_list[i]]

                                    self.data_csv[self.ConcatenationField_list[i]] = (
                                        self.data_csv[self.ConcatenationField_list[i]]
                                        .reset_index(drop=True)
                                        .str.cat(
                                            self.edit_row[j].reset_index(drop=True).astype(str),
                                            sep=sep_val,
                                        )
                                    )
                                    if (
                                        ind
                                        != len(
                                            json.loads(
                                                self.concatenation_columns[self.ConcatenationField_list[i]]
                                            )
                                        )
                                        - 1
                                    ):
                                        self.data_csv[self.ConcatenationField_list[i]] += self.divider_check[
                                            self.ConcatenationField_list[i]
                                        ]
                        else:
                            continue

        # Data Validation - ForeignKey Validation
        foreign_cols_list = []
        foreign_navigation_list = {}
        if len(self.foreignKey_property) > 0:
            for i in range(len(self.foreignKey_property)):
                for t in self.nested_table_list[i]:
                    related_parent_column = dynamic_model_create.get_model_class(t, self.request).pk.name
                    if self.foreignKey_property[i]["field_name"] in self.data_csv.columns:
                        self.data_csv[self.foreignKey_property[i]["field_name"]].replace(
                            {"nan": np.nan}, inplace=True
                        )
                        if (
                            self.data_csv[self.foreignKey_property[i]["field_name"]]
                            .dropna()
                            .unique()
                            .tolist()
                        ):
                            parent_df = read_data_func(
                                self.request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": t,
                                        "Columns": [
                                            related_parent_column,
                                            self.foreignKey_property[i]["field_name"],
                                        ],
                                    },
                                    "condition": [
                                        {
                                            "column_name": self.foreignKey_property[i]["field_name"],
                                            "condition": "IN",
                                            "input_value": self.data_csv[
                                                self.foreignKey_property[i]["field_name"]
                                            ]
                                            .dropna()
                                            .unique()
                                            .tolist(),
                                            "and_or": "",
                                        },
                                    ],
                                },
                                access_controller=False,
                            )
                        else:
                            parent_df = pd.DataFrame()
                        if not parent_df.empty:
                            fk_col_check = all(
                                item
                                in parent_df[self.foreignKey_property[i]["field_name"]].astype(str).tolist()
                                for item in self.data_csv[self.foreignKey_property[i]["field_name"]]
                                .astype(str)
                                .tolist()
                                if str(item) not in [np.nan, None, "nan", " ", "None"]
                            )
                            if bool(fk_col_check) is False:
                                self.upload = False
                                foreign_cols_list.append(self.foreignKey_property[i]["field_name"])
                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (self.data_csv[self.foreignKey_property[i]["field_name"]].notnull())
                                    & (self.data_csv[self.foreignKey_property[i]["field_name"]] != "nan")
                                    & (
                                        ~self.data_csv[self.foreignKey_property[i]["field_name"]].isin(
                                            parent_df[self.foreignKey_property[i]["field_name"]].tolist()
                                        )
                                    ),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[self.foreignKey_property[i]["field_name"]].notnull())
                                        & (self.data_csv[self.foreignKey_property[i]["field_name"]] != "nan")
                                        & (
                                            ~self.data_csv[self.foreignKey_property[i]["field_name"]].isin(
                                                parent_df[self.foreignKey_property[i]["field_name"]].tolist()
                                            )
                                        ),
                                        "Error_Details",
                                    ]
                                    + f"Column {self.foreignKey_property[i]['field_name']} values has no match in the parent table column."
                                )

                                self.data_csv.loc[
                                    (self.data_csv[self.foreignKey_property[i]["field_name"]].notnull())
                                    & (self.data_csv[self.foreignKey_property[i]["field_name"]] != "nan")
                                    & (
                                        ~self.data_csv[self.foreignKey_property[i]["field_name"]].isin(
                                            parent_df[self.foreignKey_property[i]["field_name"]].tolist()
                                        )
                                    ),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[self.foreignKey_property[i]["field_name"]].notnull())
                                        & (self.data_csv[self.foreignKey_property[i]["field_name"]] != "nan")
                                        & (
                                            ~self.data_csv[self.foreignKey_property[i]["field_name"]].isin(
                                                parent_df[self.foreignKey_property[i]["field_name"]].tolist()
                                            )
                                        ),
                                        "Error_Cols",
                                    ]
                                    + f" {self.foreignKey_property[i]['field_name']} "
                                )

                                foreign_navigation_list[self.foreignKey_property[i]["field_name"]] = list(
                                    self.data_csv.loc[
                                        (
                                            ~self.data_csv[self.foreignKey_property[i]["field_name"]].isin(
                                                parent_df[self.foreignKey_property[i]["field_name"]].tolist()
                                            )
                                        )
                                    ].index
                                )
                            else:
                                if self.upload:
                                    list1 = ["nan", np.nan, "None", None]
                                    data_df = self.data_csv[
                                        self.foreignKey_property[i]["field_name"]
                                    ].tolist()
                                    parent_df = parent_df.drop_duplicates(
                                        subset=[self.foreignKey_property[i]["field_name"]]
                                    )
                                    for f in range(len(data_df)):
                                        data_df[f] = str(data_df[f])

                                    for j in range(len(data_df)):
                                        if data_df[j] and str(data_df[j]) not in list1:
                                            replaced_val = parent_df[
                                                parent_df[self.foreignKey_property[i]["field_name"]].astype(
                                                    str
                                                )
                                                == data_df[j]
                                            ][related_parent_column]
                                            if not replaced_val.empty:
                                                self.data_csv[
                                                    self.foreignKey_property[i]["field_name"]
                                                ].replace(
                                                    str(data_df[j]), str(replaced_val.iloc[0]), inplace=True
                                                )
                                        else:
                                            if str(data_df[j]) in list1 and self.null_check[
                                                self.foreignKey_property[i]["field_name"]
                                            ] in [1, "1", True, "True"]:
                                                pass
                                else:
                                    pass
                        else:
                            if (
                                self.data_csv[self.foreignKey_property[i]["field_name"]]
                                .dropna()
                                .unique()
                                .tolist()
                            ):
                                self.upload = False
                                foreign_cols_list.append(self.foreignKey_property[i]["field_name"])
                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (self.data_csv[self.foreignKey_property[i]["field_name"]].notnull())
                                    & (self.data_csv[self.foreignKey_property[i]["field_name"]] != "nan"),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[self.foreignKey_property[i]["field_name"]].notnull())
                                        & (self.data_csv[self.foreignKey_property[i]["field_name"]] != "nan"),
                                        "Error_Details",
                                    ]
                                    + f"Column {self.foreignKey_property[i]['field_name']} values has no match in the parent table column."
                                )

                                self.data_csv.loc[
                                    (self.data_csv[self.foreignKey_property[i]["field_name"]].notnull())
                                    & (self.data_csv[self.foreignKey_property[i]["field_name"]] != "nan"),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv[self.foreignKey_property[i]["field_name"]].notnull())
                                        & (self.data_csv[self.foreignKey_property[i]["field_name"]] != "nan"),
                                        "Error_Cols",
                                    ]
                                    + f" {self.foreignKey_property[i]['field_name']} "
                                )

                                foreign_navigation_list[self.foreignKey_property[i]["field_name"]] = list(
                                    self.data_csv.loc[
                                        (self.data_csv[self.foreignKey_property[i]["field_name"]].notnull())
                                    ].index
                                )
                            else:
                                pass
                    else:
                        pass
        if len(foreign_cols_list) > 0:
            self.upload = False
            if self.message_show == "yes":
                if not check_now and message_out:

                    icon = ""
                    message = f"Error while uploading:{' ,'.join( foreign_cols_list)}  column(s) values has no match in the parent table column."
                    if custom_msg:
                        if "{Validation Message}" in custom_msg:
                            custom_msg = custom_msg.replace("{Validation Message}", message)
                        message = custom_msg

                    if custom_icon:
                        icon = custom_icon

                    messages.add_message(self.request, level=messages.ERROR, message=message, extra_tags=icon)

            datalist = {
                "feature_category": "L3-Upload",
                "feature_subcategory": "Excel Upload",
                "table_file_name": self.table_model_name,
                "error_description": f"Error while uploading {self.table_model_name}:{' ,'.join( foreign_cols_list)}  column(s) values has no match in the parent table column.",
                "created_date": datetime.now(),
                "created_by": self.request.user.username,
                "modified_date": datetime.now(),
                "modified_by": self.request.user.username,
            }
            final_data.append(datalist)

        if self.edit_mode:
            if "Error_Details" not in self.data_csv.columns:
                for edit_col in self.data_csv.columns.tolist():
                    self.data_csv_copy[edit_col] = self.data_csv[edit_col]
                self.data_csv = self.data_csv_copy
            else:
                for edit_col in self.data_csv.columns.tolist():
                    if edit_col not in self.ForeignKey_list:
                        self.data_csv_copy2[edit_col] = self.data_csv[edit_col]
                self.data_csv = self.data_csv_copy2

        # Data Validation - MaxLength
        str_col_list = []
        max_size = []
        if bool(self.max_length_check):
            for k, v in self.max_length_check.items():
                if k in self.data_csv.columns.tolist():
                    if self.data_csv[k].astype(str).str.len().max() > v:
                        str_col_list.append(k)
                        max_size.append(str(v))
                        if "Error_Details" not in self.data_csv.columns:
                            self.data_csv["Error_Details"] = ""
                        if "Error_Cols" not in self.data_csv.columns:
                            self.data_csv["Error_Cols"] = ""
                        self.data_csv.loc[
                            (self.data_csv[k].notnull())
                            & (self.data_csv[k] != "nan")
                            & (self.data_csv[k].astype(str).str.len().ge(v)),
                            "Error_Details",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[k].notnull())
                                & (self.data_csv[k] != "nan")
                                & (self.data_csv[k].astype(str).str.len().ge(v)),
                                "Error_Details",
                            ]
                            + f"Column {k}  has max length of {v}."
                        )

                        self.data_csv.loc[
                            (self.data_csv[k].notnull())
                            & (self.data_csv[k] != "nan")
                            & (self.data_csv[k].astype(str).str.len().ge(v)),
                            "Error_Cols",
                        ] = (
                            self.data_csv.loc[
                                (self.data_csv[k].notnull())
                                & (self.data_csv[k] != "nan")
                                & (self.data_csv[k].astype(str).str.len().ge(v)),
                                "Error_Cols",
                            ]
                            + f" {k} "
                        )

                        navigation_list["MaxLength"].update(
                            {k: list(self.data_csv.loc[(self.data_csv[k].astype(str).str.len().ge(v))].index)}
                        )

            if len(str_col_list) > 0:
                self.upload = False
                messages_list.append(
                    f"""Max character length for the following  {' ,'.join(str_col_list)} column(s) is {' ,'.join(max_size)}."""
                )
                if self.message_show == "yes":
                    if not check_now and message_out:

                        icon = ""
                        message = f"Error while uploading: Max character length for the following  {' ,'.join(str_col_list)} column(s) is {' ,'.join(max_size)}."
                        if custom_msg:
                            if "{Validation Message}" in custom_msg:
                                custom_msg = custom_msg.replace("{Validation Message}", message)
                            message = custom_msg

                        if custom_icon:
                            icon = custom_icon

                        messages.add_message(
                            self.request, level=messages.ERROR, message=message, extra_tags=icon
                        )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading {self.table_model_name} :Max character length for the following  {' ,'.join(str_col_list)} column(s) is {' ,'.join(max_size)}.",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - MaxLengthValidation
        max_fail_list = []
        if bool(self.max_min_validation_check):
            navigation_list["MaxLengthValidation"] = {}
            error_message = {}
            for key in self.max_min_validation_check.keys():
                if key in self.data_csv.columns:
                    if len(self.max_min_validation_check.get(key)) and "MaxLengthValidator" in list(
                        self.max_min_validation_check[key].keys()
                    ):
                        idict = self.max_min_validation_check.get(key).get("MaxLengthValidator")
                        error_message[key] = idict.get("message")
                        limit = idict["limit_value"]
                        adv_df = pd.DataFrame(columns=[key])
                        adv_df[key] = self.data_csv[key].str.len().le(limit)
                        if False in adv_df[key].values:
                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""
                            self.data_csv.loc[
                                (~self.data_csv[key].str.len().le(limit)),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (~self.data_csv[key].str.len().le(limit)),
                                    "Error_Details",
                                ]
                                + f"Error while uploading, {key}: {error_message[key]}"
                            )

                            self.data_csv.loc[
                                (~self.data_csv[key].str.len().le(limit)),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (~self.data_csv[key].str.len().le(limit)),
                                    "Error_Cols",
                                ]
                                + f" {key} "
                            )
                            max_fail_list.append(key)
                            navigation_list["MaxLengthValidation"][key] = list(
                                self.data_csv.loc[(~self.data_csv[key].str.len().le(limit))].index
                            )

            if len(max_fail_list) > 0:
                self.upload = False
                if len(error_message) > 0:
                    for k, v in error_message.items():
                        if k in max_fail_list:
                            messages_list.append(f" {k}: {v}")
                if self.message_show == "yes":
                    if len(error_message) > 0:
                        for k, v in error_message.items():
                            if k in max_fail_list:
                                if not check_now and message_out:

                                    icon = ""
                                    message = f"Error while uploading, {k}: {v}"
                                    if custom_msg:
                                        if "{Validation Message}" in custom_msg:
                                            custom_msg = custom_msg.replace("{Validation Message}", message)
                                        message = custom_msg

                                    if custom_icon:
                                        icon = custom_icon

                                    messages.add_message(
                                        self.request, level=messages.ERROR, message=message, extra_tags=icon
                                    )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading, {k}: {v}",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - Numeric MaxValueValidation
        max_value_fail_list = []
        if bool(self.max_min_validation_check):
            navigation_list["MaxValueValidation"] = {}
            error_message = {}
            for key in self.max_min_validation_check.keys():
                if key in self.data_csv.columns:
                    if len(self.max_min_validation_check.get(key)) and "MaxValueValidator" in list(
                        self.max_min_validation_check[key].keys()
                    ):
                        idict = self.max_min_validation_check.get(key).get("MaxValueValidator")
                        error_message[key] = idict.get("message")
                        limit = idict["limit_value"]
                        adv_df = pd.DataFrame(columns=[key])
                        adv_df[key] = self.data_csv[key].le(limit)
                        if False in adv_df[key].values:
                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""
                            self.data_csv.loc[
                                (~self.data_csv[key].le(limit)),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (~self.data_csv[key].le(limit)),
                                    "Error_Details",
                                ]
                                + f"Error while uploading, {key}: {error_message[key]}"
                            )

                            self.data_csv.loc[
                                (~self.data_csv[key].le(limit)),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (~self.data_csv[key].le(limit)),
                                    "Error_Cols",
                                ]
                                + f" {key} "
                            )
                            max_value_fail_list.append(key)
                            navigation_list["MaxValueValidation"][key] = list(
                                self.data_csv.loc[(~self.data_csv[key].le(limit))].index
                            )

            if len(max_value_fail_list) > 0:
                self.upload = False
                if len(error_message) > 0:
                    for k, v in error_message.items():
                        if k in max_value_fail_list:
                            messages_list.append(f" {k}: {v}")
                if self.message_show == "yes":
                    if len(error_message) > 0:
                        for k, v in error_message.items():
                            if k in max_value_fail_list:
                                if not check_now and message_out:

                                    icon = ""
                                    message = f"Error while uploading, {k}: {v}"
                                    if custom_msg:
                                        if "{Validation Message}" in custom_msg:
                                            custom_msg = custom_msg.replace("{Validation Message}", message)
                                        message = custom_msg

                                    if custom_icon:
                                        icon = custom_icon

                                    messages.add_message(
                                        self.request, level=messages.ERROR, message=message, extra_tags=icon
                                    )

                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading, {k}: {v}",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - MinLengthValidation
        min_fail_list = []
        if bool(self.max_min_validation_check):
            navigation_list["MinLengthValidation"] = {}
            error_message = {}
            for key in self.max_min_validation_check.keys():
                if key in self.data_csv.columns:
                    if len(self.max_min_validation_check.get(key)) and "MinLengthValidator" in list(
                        self.max_min_validation_check[key].keys()
                    ):
                        idict = self.max_min_validation_check.get(key).get("MinLengthValidator")
                        error_message[key] = idict.get("message")
                        limit = idict["limit_value"]
                        adv_df = pd.DataFrame(columns=[key])
                        adv_df[key] = self.data_csv[key].str.len().ge(limit)
                        if False in adv_df[key].values:
                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""
                            self.data_csv.loc[
                                (~self.data_csv[key].str.len().ge(limit)),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (~self.data_csv[key].str.len().ge(limit)),
                                    "Error_Details",
                                ]
                                + f"Error while uploading, {key}: {error_message[key]}"
                            )

                            self.data_csv.loc[
                                (~self.data_csv[key].str.len().ge(limit)),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (~self.data_csv[key].str.len().ge(limit)),
                                    "Error_Cols",
                                ]
                                + f" {key} "
                            )
                            min_fail_list.append(key)
                            navigation_list["MinLengthValidation"][key] = list(
                                self.data_csv.loc[(~self.data_csv[key].str.len().ge(limit))].index
                            )

            if len(min_fail_list) > 0:
                self.upload = False
                if len(error_message) > 0:
                    for k, v in error_message.items():
                        if k in min_fail_list:
                            messages_list.append(f" {k}: {v}")
                if self.message_show == "yes":
                    if len(error_message) > 0:
                        for k, v in error_message.items():
                            if k in min_fail_list:
                                if not check_now and message_out:
                                    icon = ""
                                    message = f"Error while uploading, {k}: {v}"
                                    if custom_msg:
                                        if "{Validation Message}" in custom_msg:
                                            custom_msg = custom_msg.replace("{Validation Message}", message)
                                        message = custom_msg

                                    if custom_icon:
                                        icon = custom_icon

                                    messages.add_message(
                                        self.request, level=messages.ERROR, message=message, extra_tags=icon
                                    )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading, {k}: {v}",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - Numeric MinValueValidation
        if bool(self.max_min_validation_check):
            min_value_fail_list = []
            navigation_list["MinValueValidation"] = {}
            error_message = {}
            for key in self.max_min_validation_check.keys():
                if key in self.data_csv.columns:
                    if len(self.max_min_validation_check.get(key)) and "MinValueValidator" in list(
                        self.max_min_validation_check[key].keys()
                    ):
                        idict = self.max_min_validation_check.get(key).get("MinValueValidator")
                        error_message[key] = idict.get("message")
                        limit = idict["limit_value"]
                        adv_df = pd.DataFrame(columns=[key])
                        adv_df[key] = self.data_csv[key].ge(limit)
                        if False in adv_df[key].values:
                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""
                            self.data_csv.loc[
                                (~self.data_csv[key].ge(limit)),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (~self.data_csv[key].ge(limit)),
                                    "Error_Details",
                                ]
                                + f"Error while uploading, {key}: {error_message[key]}"
                            )

                            self.data_csv.loc[
                                (~self.data_csv[key].ge(limit)),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (~self.data_csv[key].ge(limit)),
                                    "Error_Cols",
                                ]
                                + f" {key} "
                            )
                            min_value_fail_list.append(key)
                            navigation_list["MinValueValidation"][key] = list(
                                self.data_csv.loc[(~self.data_csv[key].ge(limit))].index
                            )

            if len(min_value_fail_list) > 0:
                self.upload = False
                if len(error_message) > 0:
                    for k, v in error_message.items():
                        if k in min_value_fail_list:
                            messages_list.append(f" {k}: {v}")
                if self.message_show == "yes":
                    if len(error_message) > 0:
                        for k, v in error_message.items():
                            if k in min_value_fail_list:
                                if not check_now and message_out:
                                    icon = ""
                                    message = f"Error while uploading, {k}: {v}"
                                    if custom_msg:
                                        if "{Validation Message}" in custom_msg:
                                            custom_msg = custom_msg.replace("{Validation Message}", message)
                                        message = custom_msg

                                    if custom_icon:
                                        icon = custom_icon

                                    messages.add_message(
                                        self.request, level=messages.ERROR, message=message, extra_tags=icon
                                    )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading, {k}: {v}",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - EmailValidation
        if bool(self.email_validation_check):
            email_fail_list = []
            navigation_list["EmailValidator"] = {}
            error_message_email = {}
            for key in self.email_validation_check.keys():
                if key in self.data_csv.columns:
                    if len(self.email_validation_check.get(key)) and "EmailValidator" in list(
                        self.email_validation_check[key].keys()
                    ):
                        idict = r"([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\.[A-Z|a-z]{2,})+"

                        rec = re.compile(idict)

                        error_message_email[key] = self.email_validation_check[key]["EmailValidator"].get(
                            "error_message_emailV"
                        )
                        adv_df = self.data_csv.copy()
                        try:
                            adv_df[key] = self.data_csv[key].str.fullmatch(rec)
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                        if False in adv_df[key].values:
                            adv_df[key].fillna(True, inplace=True)
                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""

                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (~adv_df[key]),
                                    "Error_Details",
                                ]
                                + f"Error while uploading:{key} - {error_message_email[key]}."
                            )
                            self.data_csv.loc[
                                (adv_df[key]),
                                "Error_Details",
                            ] = np.nan

                            self.data_csv.loc[
                                (~adv_df[key]),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (~adv_df[key]),
                                    "Error_Cols",
                                ]
                                + f" {key} "
                            )
                            self.data_csv.loc[
                                (adv_df[key]),
                                "Error_Cols",
                            ] = np.nan
                            email_fail_list.append(key)

                            datatype_navigation_list[key] = list(self.data_csv.loc[(~adv_df[key]),].index)

                            if len(datatype_navigation_list[key]) > 0:
                                Datatype_error.append(key)

            if len(email_fail_list) > 0:
                self.upload = False
                if len(error_message_email) > 0:
                    for k, v in error_message_email.items():
                        if k in email_fail_list:
                            messages_list.append(f" {k}: {v}")
                if self.message_show == "yes":
                    if len(error_message_email) > 0:
                        for k, v in error_message_email.items():
                            if k in email_fail_list:
                                if not check_now and message_out:
                                    icon = ""
                                    message = f"Error while uploading, {k}: {v}"
                                    if custom_msg:
                                        if "{Validation Message}" in custom_msg:
                                            custom_msg = custom_msg.replace("{Validation Message}", message)
                                        message = custom_msg

                                    if custom_icon:
                                        icon = custom_icon

                                    messages.add_message(
                                        self.request, level=messages.ERROR, message=message, extra_tags=icon
                                    )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading: {k} - {v}",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - AdvancedValidation
        adv_fail_list = []
        if bool(self.advanced_validation_check):
            navigation_list["AdvancedValidation"] = {}
            error_message = {}
            for key in self.advanced_validation_check.keys():
                if key in self.data_csv.columns:
                    if len(self.advanced_validation_check.get(key)) and "AdvancedValidator" in list(
                        self.max_min_validation_check[key].keys()
                    ):
                        idict = self.advanced_validation_check.get(key).get("AdvancedValidator")

                        rec = re.compile(dynamic_model_create.regex_validation(idict), flags=re.IGNORECASE)

                        error_message[key] = idict.get("message")
                        adv_df = self.data_csv.copy()
                        try:
                            adv_df[key] = self.data_csv[key].str.match(rec)
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                        if False in adv_df[key].values:
                            if "Error_Details" not in self.data_csv.columns:
                                self.data_csv["Error_Details"] = ""
                            if "Error_Cols" not in self.data_csv.columns:
                                self.data_csv["Error_Cols"] = ""
                            self.data_csv.loc[
                                (~adv_df[key].fillna(True)),
                                "Error_Details",
                            ] = (
                                self.data_csv.loc[
                                    (~adv_df[key].fillna(True)),
                                    "Error_Details",
                                ]
                                + f"Error while uploading, {key}: {error_message[key]}"
                            )

                            self.data_csv.loc[
                                (~adv_df[key].fillna(True)),
                                "Error_Cols",
                            ] = (
                                self.data_csv.loc[
                                    (~adv_df[key].fillna(True)),
                                    "Error_Cols",
                                ]
                                + f" {key} "
                            )
                            adv_fail_list.append(key)
                            navigation_list["AdvancedValidation"][key] = list(
                                self.data_csv.loc[(~adv_df[key].fillna(True))].index
                            )

            if len(adv_fail_list) > 0:
                self.upload = False
                if len(error_message) > 0:
                    for k, v in error_message.items():
                        if k in adv_fail_list:
                            messages_list.append(f" {k}: {v}")
                if self.message_show == "yes":
                    if len(error_message) > 0:
                        for k, v in error_message.items():
                            if k in adv_fail_list:
                                if not check_now and message_out:
                                    icon = ""
                                    message = f"Error while uploading, {k}: {v}"
                                    if custom_msg:
                                        if "{Validation Message}" in custom_msg:
                                            custom_msg = custom_msg.replace("{Validation Message}", message)
                                        message = custom_msg

                                    if custom_icon:
                                        icon = custom_icon

                                    messages.add_message(
                                        self.request, level=messages.ERROR, message=message, extra_tags=icon
                                    )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading, {k}: {v}",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation - Column based validation
        _colV_list = []
        total_colsV = self.column_validation_check
        navigation_list["ColumnValidator"] = {}
        error_message1 = {}
        operator_dict = {
            "Equal to": "==",
            "Not Equal to": "!=",
            "Greater than": ">",
            "Smaller than": "<",
            "Greater than equal to": ">=",
            "Smaller than equal to": "<=",
        }

        if len(total_colsV) > 0:
            for key, value in total_colsV.items():
                if key in self.data_csv.columns.tolist():
                    for k1, v1 in value.items():
                        if k1 == "ColumnValidator":
                            if (self.null_check[v1["colV_col1_val"]] == 0) or col_val:
                                if (
                                    v1["colV_col1_val"] in self.data_csv.columns
                                    and v1["colV_col2_val"] in self.data_csv.columns
                                ):
                                    eval_string = f"(self.data_csv['{v1['colV_col1_val']}'] {operator_dict[v1['colV_cond_val']]} self.data_csv['{v1['colV_col2_val']}'])"
                                    mask = pd.eval(eval_string)

                                    error_message1[key] = v1["error_message_colV"]
                                    if False in mask.values:
                                        if "Error_Details" not in self.data_csv.columns:
                                            self.data_csv["Error_Details"] = ""
                                        if "Error_Cols" not in self.data_csv.columns:
                                            self.data_csv["Error_Cols"] = ""

                                        self.data_csv.loc[~mask, "Error_Details"] = (
                                            self.data_csv.loc[~mask, "Error_Details"]
                                            + f"Error while uploading, {key}: {error_message1[key]}"
                                        )

                                        self.data_csv.loc[~mask, "Error_Cols"] = (
                                            self.data_csv.loc[~mask, "Error_Cols"] + f" {key} "
                                        )

                                        _colV_list.append(key)
                                        navigation_list["ColumnValidator"][key] = list(
                                            self.data_csv.loc[(~mask)].index
                                        )
                                else:
                                    pass
                            else:
                                null_mask = self.data_csv[v1["colV_col1_val"]].isnull()
                                adv_df = self.data_csv.copy()
                                adv_df.loc[null_mask, key] = adv_df.loc[null_mask, v1["colV_col2_val"]]
                                eval_string = f"(adv_df['{v1['colV_col1_val']}'] {operator_dict[v1['colV_cond_val']]} adv_df['{v1['colV_col2_val']}'])"

                                mask = pd.eval(eval_string)
                                adv_df[key] = mask
                                adv_df.loc[null_mask, key] = True

                                error_message1[key] = v1["error_message_colV"]
                                if False in adv_df[key].values:
                                    if "Error_Details" not in self.data_csv.columns:
                                        self.data_csv["Error_Details"] = ""
                                    if "Error_Cols" not in self.data_csv.columns:
                                        self.data_csv["Error_Cols"] = ""

                                    self.data_csv.loc[(~adv_df[key]), "Error_Details"] = (
                                        self.data_csv.loc[(~adv_df[key]), "Error_Details"]
                                        + f"Error while uploading, {key}: {error_message1[key]}"
                                    )

                                    self.data_csv.loc[
                                        (adv_df[key]),
                                        "Error_Details",
                                    ] = np.nan

                                    self.data_csv.loc[(~adv_df[key]), "Error_Cols"] = (
                                        self.data_csv.loc[(~adv_df[key]), "Error_Cols"] + f" {key} "
                                    )

                                    self.data_csv.loc[
                                        (adv_df[key]),
                                        "Error_Cols",
                                    ] = np.nan

                                    _colV_list.append(key)
                                    navigation_list["ColumnValidator"][key] = list(
                                        self.data_csv.loc[(~adv_df[key])].index
                                    )

            if len(_colV_list) > 0:
                self.upload = False
                if len(error_message1) > 0:
                    for k, v in error_message1.items():
                        if k in _colV_list:
                            messages_list.append(f" {k}: {v}")
                if self.message_show == "yes":
                    if len(error_message1) > 0:
                        for k, v in error_message1.items():
                            if k in _colV_list:
                                if not check_now and message_out:
                                    icon = ""
                                    message = f"Error while uploading, {k}: {v}"
                                    if custom_msg:
                                        if "{Validation Message}" in custom_msg:
                                            custom_msg = custom_msg.replace("{Validation Message}", message)
                                        message = custom_msg

                                    if custom_icon:
                                        icon = custom_icon

                                    messages.add_message(
                                        self.request, level=messages.ERROR, message=message, extra_tags=icon
                                    )
                datalist = {
                    "feature_category": "L3-Upload",
                    "feature_subcategory": "Excel Upload",
                    "table_file_name": self.table_model_name,
                    "error_description": f"Error while uploading, {k}: {v}",
                    "created_date": datetime.now(),
                    "created_by": self.request.user.username,
                    "modified_date": datetime.now(),
                    "modified_by": self.request.user.username,
                }
                final_data.append(datalist)

        # Data Validation- Unique Column
        unique_cols_list = []

        unique_flag = True
        if bool(self.unique_check) and self.export_type != "replace":
            ind = 0
            for k, v in self.unique_check.items():
                if v in [True, 1]:
                    if k in self.data_csv.columns.tolist():
                        if (self.export_data == "yes" and k in self.export_update_column) or (
                            self.export_data != "yes"
                        ):
                            if self.data_csv.duplicated(subset=k).sum() == 0:
                                non_unique_values = []
                                if k in self.ForeignKey_list:
                                    fk_index = self.ForeignKey_list.index(k)
                                    self.nested_table_list[fk_index].reverse()
                                    values_list = self.data_csv[k].dropna().unique().tolist()
                                    mapper_dict = {}
                                    for t in self.nested_table_list[fk_index]:
                                        related_parent_column = dynamic_model_create.get_model_class(
                                            t, self.request
                                        ).pk.name
                                        field_Name = self.foreignKey_property[fk_index]["field_name"]
                                        parent_table_name = t
                                        fk_index_value_map = (
                                            read_data_func(
                                                self.request,
                                                {
                                                    "inputs": {
                                                        "Data_source": "Database",
                                                        "Table": parent_table_name,
                                                        "Columns": [
                                                            related_parent_column,
                                                            field_Name,
                                                        ],
                                                    },
                                                    "condition": [
                                                        {
                                                            "column_name": field_Name,
                                                            "condition": "IN",
                                                            "input_value": values_list,
                                                            "and_or": "",
                                                            "constraintName": "unique_checker_constraint",
                                                            "ruleSet": "non_null_values",
                                                        },
                                                    ],
                                                    "adv_condition": [],
                                                },
                                            )
                                            .set_index(field_Name)[related_parent_column]
                                            .to_dict()
                                        )
                                        mapper_dict[t] = {
                                            str(fk_v): fk_k for fk_k, fk_v in fk_index_value_map.items()
                                        }
                                        values_list = [
                                            fk_index_value_map[val] if val in fk_index_value_map else val
                                            for val in values_list
                                        ]

                                    unique_checker_conditions_list = [
                                        {
                                            "column_name": k,
                                            "condition": "IN",
                                            "input_value": values_list,
                                            "and_or": "",
                                            "constraintName": "unique_checker_constraint",
                                            "ruleSet": "non_null_values",
                                        },
                                    ]
                                    if self.data_csv[k].isna().sum():
                                        unique_checker_conditions_list.append(
                                            {
                                                "column_name": k,
                                                "condition": "Equal to",
                                                "input_value": "NULL",
                                                "and_or": "",
                                                "constraintName": "unique_checker_constraint",
                                                "ruleSet": "null_value",
                                            }
                                        )
                                    else:
                                        pass
                                    if self.user_operation == "update":
                                        unique_checker_conditions_list.append(
                                            {
                                                "column_name": self.modelName.pk.name,
                                                "condition": "Not Equal to",
                                                "input_value": str(self.primary_key_id),
                                                "and_or": "",
                                                "constraintName": "unique_checker_constraint_update",
                                                "ruleSet": "updates_record",
                                            }
                                        )
                                    else:
                                        pass
                                    unique_checker = read_data_func(
                                        self.request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": self.table_model_name,
                                                "Columns": [k],
                                            },
                                            "condition": unique_checker_conditions_list,
                                            "adv_condition": [],
                                        },
                                        fetch_all_entries=True,
                                    )
                                    if not unique_checker.empty:
                                        unique_cols_list.append(k)
                                        unique_flag = False
                                        non_unique_values = unique_checker[k].tolist()
                                        for fk_tab in self.nested_table_list[fk_index][::-1]:
                                            fk_mapper_dict = mapper_dict[fk_tab]
                                            non_unique_values = [
                                                (
                                                    fk_mapper_dict[str(val)]
                                                    if str(val) in fk_mapper_dict
                                                    else val
                                                )
                                                for val in non_unique_values
                                            ]
                                        for l in range(len(self.nested_table_list)):
                                            self.nested_table_list[l] = []
                                    else:
                                        fk_mapper_dict = None
                                        del fk_mapper_dict
                                    self.nested_table_list[fk_index].reverse()
                                else:
                                    values_list = self.data_csv[k].dropna().unique().tolist()
                                    # Apply type conversion if k is a timestamp column
                                    if self.data_csv[k].dtype == "datetime64[ns]":
                                        # Format timestamp values for SQL query
                                        values_list = [
                                            (
                                                pd.Timestamp(val).strftime("%Y-%m-%d %H:%M:%S")
                                                if pd.notna(val)
                                                else "NULL"
                                            )
                                            for val in values_list
                                        ]
                                    if values_list:
                                        if values_list[0] == "0" or values_list[0] == "1":
                                            values_list = [str(val) for val in values_list]
                                        else:
                                            pass
                                        unique_checker_conditions_list = [
                                            {
                                                "column_name": k,
                                                "condition": "IN",
                                                "input_value": values_list,
                                                "and_or": "",
                                                "constraintName": "unique_checker_constraint",
                                                "ruleSet": "non_null_values",
                                            },
                                        ]
                                    else:
                                        unique_checker_conditions_list = []
                                    if self.data_csv[k].isna().sum():
                                        unique_checker_conditions_list.append(
                                            {
                                                "column_name": k,
                                                "condition": "Equal to",
                                                "input_value": "NULL",
                                                "and_or": "",
                                                "constraintName": "unique_checker_constraint",
                                                "ruleSet": "null_value",
                                            }
                                        )
                                    else:
                                        pass
                                    if self.user_operation == "update":
                                        unique_checker_conditions_list.append(
                                            {
                                                "column_name": self.modelName.pk.name,
                                                "condition": "Not Equal to",
                                                "input_value": str(self.primary_key_id),
                                                "and_or": "",
                                                "constraintName": "unique_checker_constraint_update",
                                                "ruleSet": "updates_record",
                                            }
                                        )
                                    else:
                                        pass

                                    if unique_checker_conditions_list:
                                        unique_checker = read_data_func(
                                            self.request,
                                            {
                                                "inputs": {
                                                    "Data_source": "Database",
                                                    "Table": self.table_model_name,
                                                    "Columns": [k],
                                                },
                                                "condition": unique_checker_conditions_list,
                                                "adv_condition": [],
                                            },
                                            fetch_all_entries=True,
                                        )
                                        if not unique_checker.empty:
                                            unique_cols_list.append(k)
                                            unique_flag = False
                                            non_unique_values = unique_checker[k].tolist()
                                        else:
                                            pass
                                    else:
                                        pass
                                ind = ind + 1
                                if not unique_flag:
                                    if "Error_Details" not in self.data_csv.columns:
                                        self.data_csv["Error_Details"] = ""
                                    if "Error_Cols" not in self.data_csv.columns:
                                        self.data_csv["Error_Cols"] = ""
                                    self.data_csv.loc[
                                        (self.data_csv[k].isin(non_unique_values)),
                                        "Error_Details",
                                    ] += f"Column {k} must contain unique values."

                                    self.data_csv.loc[
                                        (self.data_csv[k].isin(non_unique_values)),
                                        "Error_Cols",
                                    ] += f" {k} "

                                    navigation_list["Unique"].update(
                                        {
                                            k: list(
                                                self.data_csv.loc[
                                                    (self.data_csv[k].isin(non_unique_values))
                                                ].index
                                            )
                                        }
                                    )

                            else:
                                if "Error_Details" not in self.data_csv.columns:
                                    self.data_csv["Error_Details"] = ""
                                if "Error_Cols" not in self.data_csv.columns:
                                    self.data_csv["Error_Cols"] = ""
                                self.data_csv.loc[
                                    (self.data_csv.duplicated(subset=k)),
                                    "Error_Details",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv.duplicated(subset=k)),
                                        "Error_Details",
                                    ]
                                    + f"Column {k} must contain unique values."
                                )

                                self.data_csv.loc[
                                    (self.data_csv.duplicated(subset=k)),
                                    "Error_Cols",
                                ] = (
                                    self.data_csv.loc[
                                        (self.data_csv.duplicated(subset=k)),
                                        "Error_Cols",
                                    ]
                                    + f" {k} "
                                )

                                unique_cols_list.append(k)
                                navigation_list["Unique"].update(
                                    {k: list(self.data_csv.loc[(self.data_csv.duplicated(subset=k))].index)}
                                )

        if len(unique_cols_list) > 0:
            self.upload = False
            messages_list.append(
                f"""{','.join(list(set(unique_cols_list)))} column(s)  must contain unique values."""
            )
            if self.message_show == "yes":
                if not check_now and message_out:

                    custom_msg = ""
                    custom_icon = ""
                    if self.custom_msg_icon:
                        custom_msg = self.custom_msg_icon.get("message")
                        custom_icon = self.custom_msg_icon.get("icon")

                    icon = ""
                    message = f"Error while uploading: {','.join(list(set(unique_cols_list)))} column(s) must contain unique values."
                    if custom_msg:
                        if "{Validation Message}" in custom_msg:
                            custom_msg = custom_msg.replace("{Validation Message}", message)
                        message = custom_msg

                    if custom_icon:
                        icon = custom_icon

                    messages.add_message(self.request, level=messages.ERROR, message=message, extra_tags=icon)

            datalist = {
                "feature_category": "L3-Upload",
                "feature_subcategory": "Excel Upload",
                "table_file_name": self.table_model_name,
                "error_description": f"Error while uploading: {','.join(list(set(unique_cols_list)))} column(s) must contain unique values.",
                "created_date": datetime.now(),
                "created_by": self.request.user.username,
                "modified_date": datetime.now(),
                "modified_by": self.request.user.username,
            }
            final_data.append(datalist)

        # Count Status
        error_val_count_dict = {}
        col_headers = self.data_csv.columns.tolist()
        if "Error_Cols" in col_headers:
            diff = 0
            for col in range(len(col_headers)):
                if col_headers[col] not in self.auto_now_list:
                    error_val_count_dict[col_headers[col]] = {
                        "Passed": str(
                            self.data_csv.shape[0]
                            - self.data_csv["Error_Cols"]
                            .str.contains(rf"(?:\s|^){col_headers[col]}(?:\s|$)")
                            .sum(axis=0)
                        ),
                        "Failed": str(
                            self.data_csv["Error_Cols"]
                            .str.contains(rf"(?:\s|^){col_headers[col]}(?:\s|$)")
                            .sum(axis=0)
                        ),
                    }
                    if error_val_count_dict[col_headers[col]]["Failed"] != "0":
                        diff += 1
                else:
                    error_val_count_dict[col_headers[col]] = {
                        "Passed": str(self.data_csv.shape[0]),
                        "Failed": "0",
                    }

            error_val_count_dict["total_error_count"] = {
                "Total": str(self.data_csv.shape[0]),
                "Diff": str(diff),
            }

            self.data_csv.drop("Error_Cols", axis=1, inplace=True)
        else:
            for col in range(len(col_headers)):
                error_val_count_dict[col_headers[col]] = {
                    "Passed": str(self.data_csv.shape[0]),
                    "Failed": "0",
                }

            error_val_count_dict["total_error_count"] = {"Total": str(self.data_csv.shape[0]), "Diff": "0"}
        if "Error_Cols" in error_val_count_dict:
            del error_val_count_dict["Error_Cols"]
        # Validation List
        total_validation_list.append({"Nullable": null_cols_list})
        total_validation_list.append({"Unique": unique_cols_list})
        total_validation_list.append({"Choices": choices_col_list})
        total_validation_list.append({"HierarchyColumn": hierarchy_col_list})
        total_validation_list.append({"Datatype": Datatype_error})
        total_validation_list.append({"MaxLength": str_col_list})
        total_validation_list.append({"AdvanceDate": date_col_list})

        if len(adv_fail_list) > 0:
            total_validation_list.append({"AdvancedValidation": adv_fail_list})
        if len(min_fail_list) > 0:
            total_validation_list.append({"MinLengthValidation": min_fail_list})
        if len(max_fail_list) > 0:
            total_validation_list.append({"MaxLengthValidation": max_fail_list})
        if len(_colV_list) > 0:
            total_validation_list.append({"ColumnValidator": _colV_list})
        if len(multi_select_fail_list) > 0:
            total_validation_list.append({"MultiSelectValidator": multi_select_fail_list})
        if len(max_digits_fail_list) > 0:
            total_validation_list.append({"MaxDigitsValidator": max_digits_fail_list})
        if len(self.foreignKey_property) > 0:
            total_validation_list.append({"ForeignKey": foreign_cols_list})
            if len(foreign_cols_list) > 0:
                messages_list.append(
                    f"""{' ,'.join( foreign_cols_list)}  column(s) values has no match in the parent table column."""
                )
            navigation_list["ForeignKey"] = foreign_navigation_list

        if len(datatype_navigation_list) > 0:
            navigation_list["Datatype"] = datatype_navigation_list
        if self.upload:
            self.data_csv["validation_list"] = json.dumps(total_validation_list)
            self.data_csv["error_val_count_dict"] = json.dumps(error_val_count_dict)
            self.data_csv["custom_condition_dict"] = json.dumps(custom_condition_dict)
            return self.data_csv
        else:
            if len(total_validation_list) > 0:
                return [
                    final_data,
                    self.data_csv.astype(str),
                    total_validation_list,
                    messages_list,
                    navigation_list,
                    custom_condition_dict,
                    error_val_count_dict,
                ]
            else:
                return [final_data, self.data_csv]


def random_generator(random_type, random_length=None):
    random_start = int("1" + "0" * (random_length - 1))
    random_end = int("9" * (random_length))
    if random_type == "int":
        return random.randint(random_start, random_end)
    elif random_type == "alphanum":
        return "".join(
            random.choice(string.ascii_uppercase + string.ascii_lowercase + string.digits)
            for _ in range(random_length)
        )


def standard_uuid(df, table_name, c, n, request):
    model_class = dynamic_model_create.get_model_class(table_name, request)
    primary_key = model_class.pk.name
    uuid_config = model_class.get_field(c).uuid_config
    last_id_row = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": table_name,
                "Agg_Type": "TOP(1)",
                "Order_Type": f"ORDER BY created_date DESC",
                "Columns": [c, "created_date"],
            },
            "condition": [],
        },
        fetch_all_entries=True,
    )
    last_id_row_in_approval = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "ApprovalTable",
                "Agg_Type": "TOP(1)",
                "Order_Type": "ORDER BY id DESC",
                "Columns": ["json_data", "created_date"],
            },
            "condition": [
                {
                    "column_name": "tablename",
                    "condition": "Equal to",
                    "input_value": table_name,
                    "and_or": "",
                }
            ],
        },
    )
    uuid_df = []
    if not last_id_row.empty and last_id_row.iloc[0][c] and last_id_row.iloc[0][c] not in ["", "NULL"]:
        last_id = last_id_row.iloc[0][c]
    else:
        last_id = 0
    if not last_id_row_in_approval.empty:
        if last_id:
            if last_id_row_in_approval["created_date"].iloc[0] > last_id_row["created_date"].iloc[0]:
                transaction_details = json.loads(last_id_row_in_approval["json_data"].iloc[0])[0]
                if transaction_details.get(c):
                    last_id = transaction_details[c]
                else:
                    pass
        else:
            transaction_details = json.loads(last_id_row_in_approval["json_data"].iloc[0])[0]
            if transaction_details.get(c):
                last_id = transaction_details[c]
            else:
                pass
    else:
        pass
    uuid_config = json.loads(uuid_config)
    id_serial = uuid_config["serial"]
    if uuid_config["id_type"] == "Alphanumeric":
        id_position = uuid_config["position"]
        id_text = uuid_config["id_text"]
        if id_serial == "Sequencial":
            if id_position == "Prefix":
                try:
                    last_id = int(last_id[len(id_text) :])
                except Exception:
                    last_id = 0
                for i in range(n):
                    last_id += 1
                    uuid = id_text + str(last_id)
                    uuid_df.append(uuid)
            elif id_position == "Suffix":
                try:
                    last_id = int(last_id[: -len(id_text)])
                except Exception:
                    last_id = 0
                for i in range(n):
                    last_id += 1
                    uuid = str(last_id) + id_text
                    uuid_df.append(uuid)

        elif id_serial == "Random":
            id_length = int(uuid_config["id_length"])
            if id_position == "Prefix":
                for i in range(n):
                    uuid = id_text + random_generator(
                        random_type="alphanum", random_length=id_length - len(id_text)
                    )
                    uuid_df.append(uuid)
            elif id_position == "Suffix":
                for i in range(n):
                    uuid = (
                        random_generator(random_type="alphanum", random_length=id_length - len(id_text))
                        + id_text
                    )
                    uuid_df.append(uuid)

    elif uuid_config["id_type"] == "Numeric":
        if id_serial == "Sequencial":
            last_id = int(last_id)
            for i in range(n):
                last_id += 1
                uuid_df.append(last_id)
        elif id_serial == "Random":
            id_length = int(uuid_config["id_length"])
            for i in range(n):
                uuid = random_generator("int", id_length)
                uuid_df.append(uuid)
    df[c] = uuid_df
    return df


def flowValidation(element_id, pr_code, request, transaction_id=None):
    connector = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["tab_body_content", "element_id"],
            },
            "condition": [
                {
                    "column_name": "related_item_code",
                    "condition": "Equal to",
                    "input_value": pr_code,
                    "and_or": "AND",
                },
                {
                    "column_name": "tab_type",
                    "condition": "Equal to",
                    "input_value": "connector",
                    "and_or": "",
                },
            ],
        },
    )
    condition = []
    dic = {}
    if transaction_id not in ["NULL", None]:
        dic[transaction_id] = {
            "dataValidation": True,
            "customValidation": True,
            "userValidation": False,
            "emailValidation": True,
            "userValidationTo": False,
            "userValidationCC": False,
        }
        dic_ = {
            "column_name": "transaction_id",
            "condition": "Equal to",
            "input_value": transaction_id,
            "and_or": "OR",
        }
        condition.append(dic_)
        if len(condition) > 0:
            condition[len(condition) - 1]["and_or"] = ""
        trans_id = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Process_flow_model",
                    "Columns": ["transaction_id", "element_id"],
                },
                "condition": condition,
            },
        )
        trans_id = trans_id.to_dict("records")
        connected_eid = {}

        if not connector.empty:
            is_present = []
            body_content = connector.to_dict("records")
            for i in body_content:
                content = json.loads(i["tab_body_content"])
                if content["parent"] == element_id and content["child"] not in is_present:
                    for j in trans_id:
                        if j["element_id"] == content["child"]:
                            is_present.append(content["child"])
                            connected_eid[j["transaction_id"]] = content["child"]

            for key, value in connected_eid.items():
                dic[key] = {
                    "dataValidation": True,
                    "customValidation": True,
                    "userValidation": False,
                    "emailValidation": True,
                    "userValidationTo": False,
                    "userValidationCC": False,
                }
                for i in body_content:
                    dic[key]["element_id__"] = value
                    content = json.loads(i["tab_body_content"])
                    if (
                        content["parent"] == element_id
                        and content["dependency"]
                        and value == content["child"]
                    ):
                        if content.get("dataValidation") not in [True, None, "true"]:
                            dic[key]["dataValidation"] = False
                        if content.get("customValidation") not in [True, None, "true"]:
                            dic[key]["customValidation"] = False
                        if content.get("userValidation") in [True]:
                            dic[key]["userValidation"] = content["condition"]
                        if content.get("userValidationTo") in [True]:
                            dic[key]["userValidationTo"] = content["conditionTo"]
                        if content.get("customValidation") not in [True, None, "true"]:
                            dic[key]["customValidation"] = False
                        if content.get("userValidationCC") in [True]:
                            dic[key]["userValidationCC"] = content["conditionCC"]
    return dic


def flowValidationTo(element_id, pr_code, request, transaction_id=None):
    if transaction_id is not None:
        if isinstance(transaction_id, list):
            transaction_id = transaction_id[0]
    connector = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["tab_body_content", "element_id"],
            },
            "condition": [
                {
                    "column_name": "related_item_code",
                    "condition": "Equal to",
                    "input_value": pr_code,
                    "and_or": "AND",
                },
                {
                    "column_name": "tab_type",
                    "condition": "Equal to",
                    "input_value": "connector",
                    "and_or": "",
                },
            ],
        },
    )
    condition = []
    dic = {}
    if transaction_id not in ["NULL", None]:
        dic[transaction_id] = {
            "dataValidation": True,
            "customValidation": True,
            "userValidation": False,
            "emailValidation": True,
            "userValidationTo": False,
        }
        dic_ = {
            "column_name": "transaction_id",
            "condition": "Equal to",
            "input_value": transaction_id,
            "and_or": "OR",
        }
        condition.append(dic_)
        if len(condition) > 0:
            condition[len(condition) - 1]["and_or"] = ""
        trans_id = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Process_flow_model",
                    "Columns": ["transaction_id", "element_id"],
                },
                "condition": condition,
            },
        )
        trans_id = trans_id.to_dict("records")
        connected_eid = {}

        if not connector.empty:
            is_present = []
            body_content = connector.to_dict("records")
            for i in body_content:
                content = json.loads(i["tab_body_content"])
                if content["child"] == element_id and content["parent"] not in is_present:
                    for j in trans_id:
                        if j["element_id"] == content["parent"]:
                            is_present.append(content["parent"])
                            connected_eid[j["transaction_id"]] = content["parent"]

            for key, value in connected_eid.items():
                dic[key] = {
                    "dataValidation": True,
                    "customValidation": True,
                    "userValidation": False,
                    "emailValidation": True,
                    "userValidationTo": False,
                }
                for i in body_content:
                    dic[key]["element_id__"] = value
                    content = json.loads(i["tab_body_content"])
                    if (
                        content["child"] == element_id
                        and content["dependency"]
                        and value == content["parent"]
                    ):
                        if content.get("dataValidation") not in [True, None, "true"]:
                            dic[key]["dataValidation"] = False
                        if content.get("customValidation") not in [True, None, "true"]:
                            dic[key]["customValidation"] = False
                        if content.get("userValidation") in [True]:
                            dic[key]["userValidation"] = content["condition"]
                        if content.get("userValidationTo") in [True]:
                            dic[key]["userValidationTo"] = content["conditionTo"]
                        if content.get("customValidation") not in [True, None, "true"]:
                            dic[key]["customValidation"] = False
    return dic


def get_client_ip(request):
    x_forwarded_for = request.META.get("HTTP_X_FORWARDED_FOR")
    if x_forwarded_for:
        ip = x_forwarded_for.split(",")[0]
    else:
        ip = request.META.get("REMOTE_ADDR")
    return ip


def scenario_comparative_analysis(scenario_comparative_config, scenario_output, base_model_output):
    identifiers = scenario_comparative_config["identifier"]
    identifier_values = scenario_comparative_config["parameters"]
    comparative_analysis_output = pd.DataFrame(base_model_output["content"])
    comparative_cols = scenario_comparative_config["comparative"]
    if len(identifiers) > 0 and len(comparative_cols) > 0:
        comparative_cols_processed = {i: "{}{}".format("Base model - ", i) for i in comparative_cols}
        comparative_analysis_output.rename(columns=comparative_cols_processed, inplace=True)
        base_model_final_columns = identifiers + list(comparative_cols_processed.values())
        string = ""
        for key, value in identifier_values.items():
            if len(value) > 0:
                string += f"(comparative_analysis_output['{key}'].isin({value}))"
                if list(identifier_values.keys())[-1] != key:
                    string += "&"
        if string != "":
            comparative_analysis_output = comparative_analysis_output.loc[
                pd.eval(string), base_model_final_columns
            ]
        else:
            comparative_analysis_output = comparative_analysis_output.loc[:, base_model_final_columns]
        for scenario_name, scenario_model_json in scenario_output.items():
            scenario_model_output = pd.DataFrame(scenario_model_json["content"])
            comparative_cols_processed_scenario = {
                i: "{}{}".format(f"{scenario_name} - ", i) for i in comparative_cols
            }
            scenario_model_output.rename(columns=comparative_cols_processed_scenario, inplace=True)
            scenario_model__final_columns = identifiers + list(comparative_cols_processed_scenario.values())
            scenario_model_output = scenario_model_output.loc[:, scenario_model__final_columns]
            comparative_analysis_output = pd.merge(
                comparative_analysis_output, scenario_model_output, on=identifiers, how="left"
            )

        final_data = base_model_output
        final_data["content"] = comparative_analysis_output.reset_index().fillna("None").to_dict("records")
        final_data["msg"] = "Output"
        final_data["scenario_id"] = "SC" + random_no_generator()
        scenario_output["Scenario Comparative Analysis"] = final_data
    return scenario_output


def execute_computation_model(
    request,
    flowchart_elements,
    config,
    global_dict,
    global_element_id,
    element_id,
    pr_code,
    scenarios_config,
    scenario_comparative_config,
    transaction_id="NULL",
    output_elements=[],
    is_trigger_event=False,
    request2={},
    data_pass_on_config={},
    attempt=1,
    subprocess_linkto_dict_main={},
    child_element_id_email_box=[],
    in_memory_execution=True,
):
    start_time = time.time()
    if isinstance(request, dict):

        class AttrDict:
            def __init__(self, i_dict):
                for key, value in i_dict.items():
                    if key not in ["password", "last_login", "date_joined"]:
                        setattr(self, key, value)
                if i_dict.get("username"):
                    setattr(self, "is_anonymous", False)
                else:
                    setattr(self, "is_anonymous", True)

            def get_host(self):
                return self.host

        request["user"] = AttrDict(request["user"])
        request = AttrDict(request)
    try:
        if scenarios_config.empty:
            ind_run_output = run_model_run_handler(
                request,
                flowchart_elements,
                config,
                global_dict,
                global_element_id,
                0,
                element_id,
                output_elements=output_elements,
                transaction_id=transaction_id,
                data_pass_on_config=data_pass_on_config,
                child_element_id_email_box=child_element_id_email_box,
                in_memory_execution=in_memory_execution,
            )
        else:
            ind_run_output = run_model_run_handler(
                request,
                flowchart_elements,
                config,
                global_dict,
                global_element_id,
                0,
                element_id,
                transaction_id=transaction_id,
                child_element_id_email_box=child_element_id_email_box,
                in_memory_execution=in_memory_execution,
            )
            if ind_run_output.get("output_source_file"):
                data = read_computation_from_storage(ind_run_output["output_source_file"])
                if isinstance(data, pd.DataFrame):
                    data.fillna("-", inplace=True)
                    for i in data.columns:
                        data[i] = data[i].astype(str)
                    ind_run_output["content"] = data.to_dict("records")
                else:
                    pass
            else:
                pass
        context = ind_run_output
        if redis_instance.exists("data_present_intransac") == 1:
            if len(pickle.loads(redis_instance.get("data_present_intransac"))) > 0:
                if context.get("total_data") not in [None]:
                    total_data = context.get("total_data")
                else:
                    total_data = "0"

                if "content" in context:
                    output = context["content"]
                elif context.get("output_source_file"):
                    output = read_computation_from_storage(context["output_source_file"])
                    output.drop(columns="index", inplace=True, errors="ignore")
                else:
                    output = None

                if transaction_id == "NULL" or transaction_id is None:
                    transaction_id = list((pickle.loads(redis_instance.get("data_present_intransac"))).keys())
                    transaction_id = transaction_id[-1]

                app_code, __ = current_app_db_extractor(request)
                end_time = time.time() - start_time
                process_flow_monitor(
                    element_id,
                    pr_code,
                    app_code,
                    request,
                    transaction_id=transaction_id,
                    total_data=total_data,
                    passed_data=total_data,
                    computation_data_pass_on={
                        "global_config": config.get("configGlobalDict"),
                        "output": output,
                    },
                    run_time=round(end_time / 60, 2),
                    subprocess_linkto_dict_main=subprocess_linkto_dict_main,
                )
            else:
                on_trigger_scheduler_config = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "ProcessScheduler",
                            "Columns": ["element_id", "config"],
                        },
                        "condition": [
                            {
                                "column_name": "item_code",
                                "condition": "Equal to",
                                "input_value": pr_code,
                                "and_or": "AND",
                            },
                            {
                                "column_name": "dependent_block",
                                "condition": "Equal to",
                                "input_value": element_id,
                                "and_or": "AND",
                            },
                            {
                                "column_name": "trigger_option",
                                "condition": "Equal to",
                                "input_value": "trigger",
                                "and_or": "",
                            },
                        ],
                    },
                )
                if not on_trigger_scheduler_config.empty:
                    element_to_run = on_trigger_scheduler_config["element_id"].iloc[0]
                    computation_data_pass_on = {}
                    execute_auto_run_computation(
                        element_to_run, pr_code, request, computation_data_pass_on=computation_data_pass_on
                    )
                else:
                    pass
            redis_instance.delete("data_present_intransac")
        else:
            pass
    except Exception as e:
        model_name = ""
        if redis_instance.exists("data_present_intransac") == 1:
            redis_instance.delete("data_present_intransac")
        logging.warning(f"Following exception occured - {e}")
        app_code, __ = current_app_db_extractor(request)
        transaction_ids = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Process_flow_model",
                    "Columns": ["transaction_id"],
                },
                "condition": [
                    {
                        "column_name": "subprocess",
                        "condition": "Equal to",
                        "input_value": pr_code,
                        "and_or": "AND",
                    },
                    {
                        "column_name": "app_code",
                        "condition": "Equal to",
                        "input_value": app_code,
                        "and_or": "AND",
                    },
                    {
                        "column_name": "element_id",
                        "condition": "Equal to",
                        "input_value": element_id,
                        "and_or": "AND",
                    },
                    {
                        "column_name": "(current_status",
                        "condition": "Equal to",
                        "input_value": "Not started",
                        "and_or": "OR",
                    },
                    {
                        "column_name": "current_status",
                        "condition": "Equal to",
                        "input_value": "Ongoing",
                        "and_or": ")",
                    },
                ],
            },
        ).transaction_id.tolist()
        for trns in transaction_ids:
            end_time = time.time() - start_time
            process_flow_monitor(
                element_id,
                pr_code,
                app_code,
                request,
                transaction_id=trns,
                current_element_status="Fail",
                current_element_message=str(e),
                run_time=round(end_time / 60, 2),
            )
        context = {"element_error_message": f"Error in {model_name} run - " + str(e)}
    if not scenarios_config.empty:
        scenario_output = {}
        for row in scenarios_config.index:
            sc_row = scenarios_config.iloc[row]
            scenario_name = sc_row["scenario_name"]
            scenario_id = sc_row["scenario_id"]
            scenario_config = sc_row["scenario_config"]
            if scenario_config:
                scenario_config = json.loads(scenario_config)
            else:
                scenario_config = []
            scn_run_output = run_model_run_handler(
                request,
                flowchart_elements,
                config,
                global_dict,
                global_element_id,
                0,
                element_id,
                scenario_name,
                scenario_id,
                scenario_config,
                child_element_id_email_box=child_element_id_email_box,
                in_memory_execution=in_memory_execution,
            )
            scn_run_output["scenario_id"] = scenario_id
            if scn_run_output.get("output_source_file"):
                data = read_computation_from_storage(scn_run_output["output_source_file"])
                if isinstance(data, pd.DataFrame):
                    data.fillna("-", inplace=True)
                    for i in data.columns:
                        data[i] = data[i].astype(str)
                    scn_run_output["content"] = data.to_dict("records")
                else:
                    pass
            else:
                pass
            scenario_output[scenario_name] = scn_run_output
        context = {}
        context["base_model_output"] = ind_run_output
        if scenario_comparative_config:
            base_model_output = ind_run_output.copy()
            scenario_output = scenario_comparative_analysis(
                scenario_comparative_config, scenario_output, base_model_output
            )
        context["scenario_output"] = scenario_output
        context["run_type"] = "scenario_run"
    else:
        context["run_type"] = "individual"
    context["datetime"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return context


def run_process_multi_run_model(request, flowchart_elements, model_name, global_dict, global_element_id):
    if isinstance(request, dict):

        class AttrDict:
            def __init__(self, i_dict):
                for key, value in i_dict.items():
                    if key not in ["password", "last_login", "date_joined"]:
                        setattr(self, key, value)
                if i_dict.get("username"):
                    setattr(self, "is_anonymous", False)
                else:
                    setattr(self, "is_anonymous", True)

            def get_host(self):
                return self.host

        request["user"] = AttrDict(request["user"])
        request = AttrDict(request)
    curr_app_code, db_connection_name = current_app_db_extractor(request)
    multi_run_vars = global_dict["inputs"].get("multi_run_vars")
    multi_run_vars_length = [
        len(var["defaultValue"])
        for var in global_dict["inputs"]["variables"]
        if var["varName"] in multi_run_vars
    ]
    len_multi_runs = max(multi_run_vars_length)
    run = 0
    while run < len_multi_runs:
        global_dictionary = global_dict
        try:
            ind_run_output = run_process_model_run_handler(
                request, flowchart_elements, model_name, global_dictionary, global_element_id, run=run
            )
        except Exception as e:
            logging.warning(f"Following exception occured - {e}")
            ind_run_output = {"content": {}}
            message = f"Error while performing run {run+1}."
        else:
            message = "Run_successfull"
        if run == (len_multi_runs - 1):
            run_stage = "Model run complete."
        else:
            run_stage = f"Completed run {run+1}"
        comp_per = 100 * (run + 1) / len_multi_runs
        ind_output = json.dumps(
            {
                "content": ind_run_output,
                "message": message,
                "run_stage": run_stage,
                "run": run + 1,
                "main_comp_per": comp_per,
            },
            default=datetime_handler,
        )
        run += 1
        computation_storage(ind_output, "exception", f"{db_connection_name}run_process_{model_name}")
    return True


def run_model_multi_run_model(
    request,
    flowchart_elements,
    model_name,
    global_dict,
    global_element_id,
    config,
    element_id,
):
    if isinstance(request, dict):

        class AttrDict:
            def __init__(self, i_dict):
                for key, value in i_dict.items():
                    if key not in ["password", "last_login", "date_joined"]:
                        setattr(self, key, value)
                if i_dict.get("username"):
                    setattr(self, "is_anonymous", False)
                else:
                    setattr(self, "is_anonymous", True)

            def get_host(self):
                return self.host

        request["user"] = AttrDict(request["user"])
        request = AttrDict(request)
    curr_app_code, db_connection_name = current_app_db_extractor(request)
    multi_run_vars = global_dict["inputs"].get("multi_run_vars")
    multi_run_vars_length = [
        len(var["inputValue"]) for var in config["configGlobalDict"] if var["varName"] in multi_run_vars
    ]
    len_multi_runs = max(multi_run_vars_length)
    run = 0
    while run < len_multi_runs:
        global_dictionary = global_dict
        try:
            ind_run_output = run_model_run_handler(
                request,
                flowchart_elements,
                config,
                global_dictionary,
                global_element_id,
                run=run,
                element_id=element_id,
            )
            if ind_run_output.get("output_source_file"):
                data = read_computation_from_storage(ind_run_output.get("output_source_file"))
                if type(data) != type(None):
                    if isinstance(data, pd.DataFrame):
                        ind_run_output["content"] = data.astype("str").fillna("-").to_dict("records")
                    else:
                        ind_run_output["content"] = data
                else:
                    ind_run_output["content"] = {}
                    message = f"Error while performing run {run+1}."
            else:
                pass
        except Exception as e:
            logging.warning(f"Following exception occured - {e}")
            ind_run_output = {"content": {}}
            message = f"Error while performing run {run+1}."
        else:
            message = "Run_successfull"
        if run == (len_multi_runs - 1):
            run_stage = "Model run complete."
        else:
            run_stage = f"Completed run {run+1}"
        comp_per = 100 * (run + 1) / len_multi_runs
        ind_output = json.dumps(
            {
                "content": ind_run_output,
                "message": message,
                "run_stage": run_stage,
                "run": run + 1,
                "main_comp_per": comp_per,
                "dataframe_data": ind_run_output["content"],
            },
            default=datetime_handler,
        )
        run += 1
        computation_storage(ind_output, "exception", f"{db_connection_name}run_model_{model_name}")


def validation_result(
    FinalData1,
    data,
    custom_validation={},
    table="",
    email_success=True,
    transaction_id=None,
    element="",
    request="",
    element_id="",
    uploaded_data="",
):
    error = {"0": True}
    FinalData_ = FinalData1.copy()
    if transaction_id not in ["NULL", None]:
        error = {}
        is_error = {}
        is_custom_validation = {}
        for i in [transaction_id]:
            error[i] = ""
            FinalData1 = FinalData_
            is_error[i] = False
            is_custom_validation[i] = False
            error_dic = {}
            id__ = []
            if type(FinalData1) != list:
                table_data = FinalData1.to_dict("records")
                for k in range(len(table_data)):
                    id__.append(k + 1)
                FinalData1["id__"] = id__
                table_data = FinalData1.to_dict("records")
            if type(FinalData1) == list:
                modelName = dynamic_model_create.get_model_class(str(table), request)
                k = {field.name: "" for field in modelName.concrete_fields}
                k["id__"] = 1
                for j in FinalData1:
                    if "Custom validation" in j:
                        is_custom_validation[i] = True
                        break
                if is_custom_validation[i]:
                    if data[i]["customValidation"]:
                        error[i] = ""
                        table_data1 = FinalData1.to_dict("records")
                        for k in table_data:
                            present = False
                            for k1 in table_data1:
                                if k1["id__"] == k["id__"]:
                                    present = True
                            error_dic = {}
                            if present:
                                error_dic[str(k["id__"])] = {
                                    "message": "Success",
                                    "config": ["All custom validation passed"],
                                    "status": "pass",
                                    "data": k,
                                }
                            else:
                                error_dic[str(k["id__"])] = {
                                    "message": "Custom validation failed",
                                    "config": ["Custom validation set by user not met"],
                                    "status": "fail",
                                    "data": k,
                                }
                        error_dic[str(k["id__"])] = {
                            "message": "Custom validation failed",
                            "config": ["Custom validation set by user not met"],
                            "status": "fail",
                            "data": k,
                        }
                        update_flow_error_table(table, i, error_dic, element_id, request)
                    else:
                        if not is_error[i]:
                            is_error[i] = False
                            error_dic[str(k["id__"])] = {
                                "message": "Success",
                                "config": ["All custom validation passed"],
                                "status": "pass",
                                "data": k,
                            }
                            update_flow_error_table(table, i, error_dic, element_id, request)
                else:
                    if data[i]["dataValidation"]:
                        error[i] = ""
                        if type(FinalData1) != list:
                            table_data1 = FinalData1.to_dict("records")
                            for k in table_data:
                                present = False
                                for k1 in table_data1:
                                    if k1["id__"] == k["id__"]:
                                        present = True
                                error_dic = {}
                                if present:
                                    error_dic[str(k["id__"])] = {
                                        "message": "Success",
                                        "config": ["All the data are validated"],
                                        "status": "pass",
                                        "data": k,
                                    }
                                else:
                                    error_dic[str(k["id__"])] = {
                                        "message": "Data validation failed",
                                        "config": ["Data failed to meet data validation"],
                                        "status": "fail",
                                        "data": k,
                                    }
                        error_dic[str(k["id__"])] = {
                            "message": "Data validation failed",
                            "config": ["Data failed to meet data validation"],
                            "status": "fail",
                            "data": k,
                        }
                        update_flow_error_table(table, i, error_dic, element_id, request)
                    else:
                        if not is_error[i]:
                            is_error[i] = False
                            error_dic[str(k["id__"])] = {
                                "message": "Success",
                                "config": ["All the data are validated"],
                                "status": "pass",
                                "data": k,
                            }
                            update_flow_error_table(table, i, error_dic, element_id, request)
            else:
                if data[i]["userValidation"]:
                    if data[i]["userValidation"]["table"] != table:
                        if not is_error[i]:
                            is_error[i] = False
                        error[i] = error[i] + f"Data does not belong to table {table}."
                    else:
                        condition = data[i]["userValidation"]["condition"]
                        length = len(FinalData1)
                        for j in condition:
                            if j["type"] == "FloatField":
                                j["input_value"] = float(j["input_value"])
                            elif j["type"] == "IntegerField":
                                j["input_value"] = int(j["input_value"])
                            elif j["type"] == "BigIntegerField":
                                j["input_value"] = int(j["input_value"])
                            elif j["type"] == "DateField":
                                j["input_value"] = j["input_value"]
                            elif j["type"] == "DateTimeField":
                                j["input_value"] = j["input_value"]

                            if j["condition"] == "Starts with":
                                FinalData1 = FinalData1[
                                    FinalData1[j["column_name"]].astype("str").startswith(j["input_value"])
                                ]
                            if j["condition"] == "Ends with":
                                FinalData1 = FinalData1[
                                    FinalData1[j["column_name"]].str.endswith(j["input_value"])
                                ]
                            if j["condition"] == "Equal to":
                                FinalData1 = FinalData1[FinalData1[j["column_name"]] == j["input_value"]]
                            if j["condition"] == "Not Equal to":
                                FinalData1 = FinalData1[FinalData1[j["column_name"]] != j["input_value"]]
                            if j["condition"] == "Greater than":
                                FinalData1 = FinalData1[FinalData1[j["column_name"]] > j["input_value"]]
                            if j["condition"] == "Smaller than":
                                FinalData1 = FinalData1[FinalData1[j["column_name"]] < j["input_value"]]
                            if j["condition"] == "IN":
                                FinalData1 = FinalData1[FinalData1[j["column_name"]].isin(j["input_value"])]
                            if j["condition"] == "NOT IN":
                                FinalData1 = FinalData1[~FinalData1[j["column_name"]].isin(j["input_value"])]
                        if length == len(FinalData1):
                            if not is_error[i]:
                                is_error[i] = False
                        else:
                            is_error[i] = True
                            error[i] = (
                                error[i]
                                + f"User validation failed, {length - len(FinalData1)} out of {length} rows of data failed to meet validation."
                            )
                            table_data1 = FinalData1.to_dict("records")
                            for k in table_data:
                                present = False
                                for k1 in table_data1:
                                    if k1["id__"] == k["id__"]:
                                        present = True
                                error_dic = {}
                                if present:
                                    error_dic[str(k["id__"])] = {
                                        "message": "Success",
                                        "config": condition,
                                        "status": "pass",
                                        "data": k,
                                    }
                                else:
                                    error_dic[str(k["id__"])] = {
                                        "message": "User validation from condition failed",
                                        "config": condition,
                                        "status": "fail",
                                        "data": k,
                                    }
                                update_flow_error_table(table, i, error_dic, element_id, request)
                else:
                    is_error[i] = False
                if not is_error[i]:
                    if data[i]["userValidationCC"]:
                        result_cc, FinalData_flowCC = validation_result_CC(
                            FinalData1,
                            data,
                            {},
                            table,
                            transaction_id=[i],
                            element="uploading",
                            request=request,
                            element_id=element_id,
                        )
                        if True not in list(result_cc.values()):
                            is_error[i] = True
                            error[i] = result_cc[i]
                if element == "computation":
                    if data[i]["userValidationTo"]:
                        if data[i]["userValidationTo"]["table"] != table:
                            if not is_error[i]:
                                is_error[i] = False
                            error[i] = error[i] + f"Data does not belong to table {table}."
                        else:
                            condition = data[i]["userValidationTo"]["condition"]
                            length = len(FinalData1)
                            for j in condition:
                                if j["type"] == "FloatField":
                                    j["input_value"] = float(j["input_value"])
                                elif j["type"] == "IntegerField":
                                    j["input_value"] = int(j["input_value"])
                                elif j["type"] == "BigIntegerField":
                                    j["input_value"] = int(j["input_value"])
                                elif j["type"] == "DateField":
                                    j["input_value"] = j["input_value"]
                                elif j["type"] == "DateTimeField":
                                    j["input_value"] = j["input_value"]

                                if j["condition"] == "Starts with":
                                    FinalData1 = FinalData1[
                                        FinalData1[j["column_name"]]
                                        .astype("str")
                                        .startswith(j["input_value"])
                                    ]
                                if j["condition"] == "Ends with":
                                    FinalData1 = FinalData1[
                                        FinalData1[j["column_name"]].str.endswith(j["input_value"])
                                    ]
                                if j["condition"] == "Equal to":
                                    FinalData1 = FinalData1[FinalData1[j["column_name"]] == j["input_value"]]
                                if j["condition"] == "Not Equal to":
                                    FinalData1 = FinalData1[FinalData1[j["column_name"]] != j["input_value"]]
                                if j["condition"] == "Greater than":
                                    FinalData1 = FinalData1[FinalData1[j["column_name"]] > j["input_value"]]
                                if j["condition"] == "Smaller than":
                                    FinalData1 = FinalData1[FinalData1[j["column_name"]] < j["input_value"]]
                                if j["condition"] == "IN":
                                    FinalData1 = FinalData1[
                                        FinalData1[j["column_name"]].isin(j["input_value"])
                                    ]
                                if j["condition"] == "NOT IN":
                                    FinalData1 = FinalData1[
                                        ~FinalData1[j["column_name"]].isin(j["input_value"])
                                    ]
                            if length == len(FinalData1):
                                if not is_error[i]:
                                    is_error[i] = False
                            else:
                                is_error[i] = True
                                error[i] = (
                                    error[i]
                                    + f"User validation from condition failed, {length - len(FinalData1)} out of {length} rows of data failed to meet validation."
                                )
            if data[i]["emailValidation"]:
                if not email_success:
                    is_error[i] = True
                    error[i] = error[i] + "Email failed to sent."
                else:
                    if not is_error[i]:
                        is_error[i] = False
            if error[i] == "":
                error[i] = True
    return error


def validation_result_to(
    FinalData,
    data,
    custom_validation={},
    table="",
    email_success=True,
    transaction_id=None,
    element="",
    request="",
    element_id="",
):
    error = {"0": True}
    if request != "" and element == "analysis":
        modelName = dynamic_model_create.get_model_class(str(table), request)
        columnCombine = {field.verbose_name.title(): field.name for field in modelName.concrete_fields}
        FinalData.rename(columns=columnCombine, inplace=True)
    FinalData_ = FinalData
    if type(transaction_id) in [list]:
        transaction_id = transaction_id
    elif type(transaction_id) == str:
        transaction_id = [transaction_id]
    if transaction_id not in ["NULL", None]:
        error = {}
        is_error = {}
        is_custom_validation = {}
        for i in transaction_id:
            error[i] = ""
            FinalData = FinalData_
            is_error[i] = False
            is_custom_validation[i] = False
            error_dic = {}
            max_id = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": str(table),
                        "Agg_Type": "MAX(id)",
                        "Columns": [],
                    },
                    "condition": [],
                },
            )
            id__ = []
            FinalData = fillNa(FinalData, object_fill="None", num_fill=0, date_fill="2000-01-01")
            table_data = FinalData.to_dict("records")
            for k in range(len(table_data)):
                id__.append(k + 1 + int(max_id.iloc[0]))
            FinalData["id__"] = id__
            table_data = FinalData.to_dict("records")
            if data[i]["userValidationTo"]:
                if data[i]["userValidationTo"]["table"] != str(table):
                    if not is_error[i]:
                        is_error[i] = False
                    error[i] = error[i] + f"Data does not belong to table {table}."
                else:
                    condition = data[i]["userValidationTo"]["condition"]
                    length = len(FinalData)
                    for j in condition:
                        if j["type"] == "FloatField":
                            j["input_value"] = float(j["input_value"])
                        elif j["type"] == "IntegerField":
                            j["input_value"] = int(j["input_value"])
                        elif j["type"] == "BigIntegerField":
                            j["input_value"] = int(j["input_value"])
                        elif j["type"] == "DateField":
                            j["input_value"] = j["input_value"]
                        elif j["type"] == "DateTimeField":
                            j["input_value"] = j["input_value"]

                        if j["condition"] == "Starts with":
                            FinalData = FinalData[
                                FinalData[j["column_name"]].astype("str").startswith(j["input_value"])
                            ]
                        if j["condition"] == "Ends with":
                            FinalData = FinalData[FinalData[j["column_name"]].str.endswith(j["input_value"])]
                        if j["condition"] == "Equal to":
                            FinalData = FinalData[FinalData[j["column_name"]] == j["input_value"]]
                        if j["condition"] == "Not Equal to":
                            FinalData = FinalData[FinalData[j["column_name"]] != j["input_value"]]
                        if j["condition"] == "Greater than":
                            FinalData = FinalData[FinalData[j["column_name"]] > j["input_value"]]
                        if j["condition"] == "Smaller than":
                            FinalData = FinalData[FinalData[j["column_name"]] < j["input_value"]]
                        if j["condition"] == "IN":
                            FinalData = FinalData[FinalData[j["column_name"]].isin(j["input_value"])]
                        if j["condition"] == "NOT IN":
                            FinalData = FinalData[~FinalData[j["column_name"]].isin(j["input_value"])]
                    if length == len(FinalData):
                        if not is_error[i]:
                            is_error[i] = False
                    else:
                        is_error[i] = True
                        error[i] = (
                            error[i]
                            + f"User validation to condition failed, {length - len(FinalData)} out of {length} rows of data failed to meet validation."
                        )
                        table_data1 = FinalData.to_dict("records")
                        for k in table_data:
                            present = False
                            for k1 in table_data1:
                                if k1["id__"] == k["id__"]:
                                    present = True
                            error_dic = {}
                            if k.get("id") not in [None]:
                                k.pop("id")
                            if k.get("created_date") not in [None]:
                                k["created_date"] = k["created_date"].strftime("%Y-%m-%d %H:%M:%S")
                            if k.get("modified_date") not in [None]:
                                k["modified_date"] = k["modified_date"].strftime("%Y-%m-%d %H:%M:%S")
                            if k.get("active_to") not in [None]:
                                k["active_to"] = k["active_to"].strftime("%Y-%m-%d %H:%M:%S")
                            if k.get("active_from") not in [None]:
                                k["active_from"] = k["active_from"].strftime("%Y-%m-%d %H:%M:%S")
                            if present:
                                error_dic[str(k["id__"])] = {
                                    "message": "Success",
                                    "config": condition,
                                    "status": "pass",
                                    "data": k,
                                }
                            else:
                                error_dic[str(k["id__"])] = {
                                    "message": "User validation to condition failed",
                                    "config": condition,
                                    "status": "fail",
                                    "data": k,
                                }
                            update_flow_error_table(table, i, error_dic, element_id, request)
            else:
                is_error[i] = False
            if error[i] == "":
                error[i] = True

    return error, FinalData


def flowValidationCC(element_id, pr_code, request, transaction_id=None):
    if transaction_id is not None:
        if isinstance(transaction_id, list):
            transaction_id = transaction_id[0]
    connector = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["tab_body_content", "element_id"],
            },
            "condition": [
                {
                    "column_name": "related_item_code",
                    "condition": "Equal to",
                    "input_value": pr_code,
                    "and_or": "AND",
                },
                {
                    "column_name": "tab_type",
                    "condition": "Equal to",
                    "input_value": "connector",
                    "and_or": "",
                },
            ],
        },
    )
    condition = []
    dic = {}
    if transaction_id not in ["NULL", None]:
        dic[transaction_id] = {
            "dataValidation": True,
            "customValidation": True,
            "userValidation": False,
            "emailValidation": True,
            "userValidationCC": False,
        }
        dic_ = {
            "column_name": "transaction_id",
            "condition": "Equal to",
            "input_value": transaction_id,
            "and_or": "OR",
        }
        condition.append(dic_)
        if len(condition) > 0:
            condition[len(condition) - 1]["and_or"] = ""
        trans_id = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Process_flow_model",
                    "Columns": ["transaction_id", "element_id"],
                },
                "condition": condition,
            },
        )
        trans_id = trans_id.to_dict("records")
        connected_eid = {}

        if not connector.empty:
            is_present = []
            body_content = connector.to_dict("records")
            for i in body_content:
                content = json.loads(i["tab_body_content"])
                if content["child"] == element_id and content["parent"] not in is_present:
                    for j in trans_id:
                        if j["element_id"] == content["parent"]:
                            is_present.append(content["parent"])
                            connected_eid[j["transaction_id"]] = content["parent"]

            for key, value in connected_eid.items():
                dic[key] = {
                    "dataValidation": True,
                    "customValidation": True,
                    "userValidation": False,
                    "emailValidation": True,
                    "userValidationCC": False,
                }
                for i in body_content:
                    dic[key]["element_id__"] = value
                    content = json.loads(i["tab_body_content"])
                    if (
                        content["child"] == element_id
                        and content["dependency"]
                        and value == content["parent"]
                    ):
                        if content.get("dataValidation") not in [True, None, "true"]:
                            dic[key]["dataValidation"] = False
                        if content.get("customValidation") not in [True, None, "true"]:
                            dic[key]["customValidation"] = False
                        if content.get("userValidation") in [True]:
                            dic[key]["userValidation"] = content["condition"]
                        if content.get("userValidationCC") in [True]:
                            dic[key]["userValidationCC"] = content["conditionCC"]
                        if content.get("customValidation") not in [True, None, "true"]:
                            dic[key]["customValidation"] = False
    return dic


def validation_result_CC(
    FinalData,
    data,
    custom_validation={},
    table="",
    email_success=True,
    transaction_id=None,
    element="",
    request="",
    element_id="",
):
    error = {"0": True}
    if request != "" and element == "analysis":
        modelName = dynamic_model_create.get_model_class(str(table), request)
        columnCombine = {field.verbose_name.title(): field.name for field in modelName.concrete_fields}
        FinalData.rename(columns=columnCombine, inplace=True)
    FinalData_ = FinalData.copy()
    if type(transaction_id) in [list]:
        transaction_id = transaction_id
    elif type(transaction_id) == str:
        transaction_id = [transaction_id]
    if transaction_id not in ["NULL", None]:
        error = {}
        is_error = {}
        is_custom_validation = {}
        FinalData_ = fillNa(FinalData_, object_fill="None", num_fill=0, date_fill="2000-01-01")
        for i in transaction_id:
            error[i] = ""
            FinalData = FinalData_
            is_error[i] = False
            is_custom_validation[i] = False
            error_dic = {}
            max_id = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": str(table),
                        "Columns": ["MAX(id)"],
                    },
                    "condition": [],
                },
            )
            id__ = []
            if data[i]["userValidationCC"]:

                def isfloat(num):
                    if str(num).__contains__("."):
                        return True
                    else:
                        return False

                e_id__ = data[i]["userValidationCC"]["config"]["config"]
                model_name_cc = data[i]["userValidationCC"]["config"]["model_name"]
                modelName = dynamic_model_create.get_model_class(
                    str(data[i]["userValidationCC"]["table"]), request
                )
                columnCombine = [field.name for field in modelName.concrete_fields]
                FinalData = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": data[i]["userValidationCC"]["table"],
                            "Columns": columnCombine,
                        },
                        "condition": [],
                    },
                )
                if data[i]["userValidationCC"]["table"] == str(table):
                    if element != "uploading":
                        FinalData = FinalData[
                            FinalData.transaction_id.str.contains(
                                str(i),
                                na=False,
                            )
                        ]
                    else:
                        FinalData = FinalData_
                global_dict = {}
                global_element_id = ""
                FinalData = fillNa(FinalData, object_fill="None", num_fill=0, date_fill="2000-01-01")
                data_csv1 = run_process_model_run_handler(
                    request,
                    flowchart_elements=e_id__,
                    model_name=str(model_name_cc),
                    global_dict=global_dict,
                    global_element_id=global_element_id,
                    data_csv=FinalData,
                )
                if data_csv1["element_error_message"] == "Success":
                    a = data_csv1["content"]
                    FinalData = pd.DataFrame(a)
                FinalData = fillNa(FinalData, object_fill="None", num_fill=0, date_fill="2000-01-01")
                table_data = FinalData.to_dict("records")
                for k in range(len(table_data)):
                    id__.append(k + 1 + int(max_id.iloc[0]))
                FinalData["id__"] = id__
                table_data = FinalData.to_dict("records")
                if data_csv1["element_error_message"] != "Success":
                    if not is_error[i]:
                        is_error[i] = False
                    error[i] = error[i] + f"Computation model failed. {data_csv1['element_error_message']}"
                    error_dic = {}
                    error_dic[str(k["id__"])] = {
                        "message": f"Computation model failed. {data_csv1['element_error_message']}",
                        "config": [f"Computation model failed. {data_csv1['element_error_message']}"],
                        "status": "fail",
                        "data": k,
                    }
                    update_flow_error_table(table, i, error_dic, element_id, request)
                else:
                    condition = data[i]["userValidationCC"]["condition"]
                    length = len(FinalData)
                    for j in condition:
                        if isfloat(j["input_value"]):
                            j["input_value"] = float(j["input_value"])
                        elif j["input_value"].isdigit():
                            j["input_value"] = int(j["input_value"])
                        else:
                            j["input_value"] = j["input_value"]

                        if j["condition"] == "Starts with":
                            FinalData = FinalData[
                                FinalData[j["column_name"]].astype("str").startswith(j["input_value"])
                            ]
                        if j["condition"] == "Ends with":
                            FinalData = FinalData[FinalData[j["column_name"]].str.endswith(j["input_value"])]
                        if j["condition"] == "Equal to":
                            FinalData = FinalData[FinalData[j["column_name"]] == j["input_value"]]
                        if j["condition"] == "Not Equal to":
                            FinalData = FinalData[FinalData[j["column_name"]] != j["input_value"]]
                        if j["condition"] == "Greater than":
                            FinalData = FinalData[FinalData[j["column_name"]] > j["input_value"]]
                        if j["condition"] == "Smaller than":
                            FinalData = FinalData[FinalData[j["column_name"]] < j["input_value"]]
                        if j["condition"] == "IN":
                            FinalData = FinalData[FinalData[j["column_name"]].isin(j["input_value"])]
                        if j["condition"] == "NOT IN":
                            FinalData = FinalData[~FinalData[j["column_name"]].isin(j["input_value"])]
                    if length == len(FinalData):
                        if not is_error[i]:
                            is_error[i] = False
                    else:
                        if data[i]["userValidationCC"]["table"] == str(table):
                            is_error[i] = True
                            error[i] = (
                                error[i]
                                + f"Computation based validation failed, {length - len(FinalData)} out of {length} rows of data failed to meet computation validations."
                            )
                            table_data1 = FinalData.to_dict("records")
                            for k in table_data:

                                present = False
                                for k1 in table_data1:
                                    if k1["id__"] == k["id__"]:
                                        present = True
                                error_dic = {}
                                if present:
                                    error_dic[str(k["id__"])] = {
                                        "message": "Success",
                                        "config": condition,
                                        "status": "pass",
                                        "data": k,
                                    }
                                else:
                                    error_dic[str(k["id__"])] = {
                                        "message": "Computation based validation failed",
                                        "config": condition,
                                        "status": "fail",
                                        "data": k,
                                    }
                                update_flow_error_table(table, i, error_dic, element_id, request)
                        else:
                            if (length - len(FinalData)) == length:
                                is_error[i] = True
                                error[i] = (
                                    error[i]
                                    + f"Computation based validation failed, No data out of {length} rows of data matches the required condition in table "
                                    + str(data[i]["userValidationCC"]["table"])
                                    + "."
                                )
                                table_data1 = FinalData.to_dict("records")
                                for k in table_data:
                                    present = False
                                    for k1 in table_data1:
                                        if k1["id__"] == k["id__"]:
                                            present = True
                                    error_dic = {}
                                    if present:
                                        error_dic[str(k["id__"])] = {
                                            "message": "Success",
                                            "config": condition,
                                            "status": "pass",
                                            "data": k,
                                        }
                                    else:
                                        error_dic[str(k["id__"])] = {
                                            "message": "Computation based validation failed",
                                            "config": condition,
                                            "status": "fail",
                                            "data": k,
                                        }
                                    update_flow_error_table(
                                        table,
                                        i,
                                        error_dic,
                                        element_id,
                                        request,
                                        data[i]["userValidationCC"]["table"],
                                    )
                            else:
                                if not is_error[i]:
                                    is_error[i] = False
                                    table_data1 = FinalData.to_dict("records")
                                    for k in table_data:
                                        present = False
                                        for k1 in table_data1:
                                            if k1["id__"] == k["id__"]:
                                                present = True
                                        error_dic = {}
                                        if present:
                                            error_dic[str(k["id__"])] = {
                                                "message": "Success",
                                                "config": condition,
                                                "status": "pass",
                                                "data": k,
                                            }
                                        else:
                                            error_dic[str(k["id__"])] = {
                                                "message": "Computation based validation failed",
                                                "config": condition,
                                                "status": "fail",
                                                "data": k,
                                            }

            else:
                is_error[i] = False
            if error[i] == "":
                error[i] = True

    return error, FinalData


def computationFlowController(
    flowchart, element_id, config_dict, input_data, global_dict, l3_run=True, run_model=True
):
    if isinstance(input_data, str):
        input_data = read_diskstorage(input_data)
    data_based_scenarios = config_dict["inputs"]["data_scenario_config"]
    data_agg_based_scenarios = config_dict["inputs"]["data_agg_scenario_config"]
    var_based_scenarios = config_dict["inputs"]["var_scenario_config"]
    default_next_element = config_dict["inputs"]["default_next_element"]
    condition_format_dict = {
        "Equal to": "input_data['{parameter}'] == {threshold}",
        "Not Equal to": "input_data['{parameter}'] != {threshold}",
        "Greater than": "input_data['{parameter}'] > {threshold}",
        "Smaller than": "input_data['{parameter}'] < {threshold}",
        "Greater than equal to": "input_data['{parameter}'] >= {threshold}",
        "Smaller than equal to": "input_data['{parameter}'] <= {threshold}",
    }
    condition_format_str_dict = {
        "Equal to": "input_data['{parameter}'] == '{threshold}'",
        "Not Equal to": "input_data['{parameter}'] != '{threshold}'",
        "Greater than": "input_data['{parameter}'] > '{threshold}'",
        "Smaller than": "input_data['{parameter}'] < '{threshold}'",
        "Greater than equal to": "input_data['{parameter}'] >= '{threshold}'",
        "Smaller than equal to": "input_data['{parameter}'] <= '{threshold}'",
    }
    condition_format_agg_dict = {
        "Equal to": "{agg_value} == {threshold}",
        "Not Equal to": "{agg_value} != {threshold}",
        "Greater than": "{agg_value} > {threshold}",
        "Smaller than": "{agg_value} < {threshold}",
        "Greater than equal to": "{agg_value} >= {threshold}",
        "Smaller than equal to": "{agg_value} <= {threshold}",
    }
    scenario_result_dict = []
    # Data based scenarios checker
    input_data["next_element"] = np.nan
    for scn in data_based_scenarios:
        scn_data = scn
        parameter = scn["parameter"]
        condition = scn["condition"]
        threshold = scn["threshold"]
        next_element = scn["next_element"]
        scn_data["scenario_type"] = "data_based"
        if input_data[parameter].dtype.name == "object":
            scenario_result = pd.eval(
                condition_format_str_dict[condition].format(parameter=parameter, threshold=threshold)
            )
        else:
            if input_data[parameter].dtype.name == "datetime64[ns]":
                threshold = pd.to_datetime(threshold)
                scenario_result = pd.eval(
                    condition_format_str_dict[condition].format(parameter=parameter, threshold=threshold)
                )
            else:
                scenario_result = pd.eval(
                    condition_format_dict[condition].format(parameter=parameter, threshold=threshold)
                )
        input_data.loc[scenario_result, "next_element"] = next_element
        scenario_result = input_data[scenario_result]
        if len(scenario_result):
            scn_data["result"] = True
            scn_data["data"] = scenario_result
        else:
            scn_data["result"] = False
            scn_data["data"] = pd.DataFrame()
        scenario_result_dict.append(scn_data)

    for agg_scn in data_agg_based_scenarios:
        scn_data = agg_scn
        parameter = scn_data["parameter"]
        aggregation = scn_data["aggregation"]
        condition = scn_data["condition"]
        threshold = scn_data["threshold"]
        scn_data["scenario_type"] = "data_aggregation_based"
        if aggregation == "Sum":
            agg_value = input_data[parameter].sum()
        elif aggregation == "Mean":
            agg_value = input_data[parameter].mean()
        elif aggregation == "Count":
            agg_value = input_data[parameter].count()
        if pd.eval(condition_format_agg_dict[condition].format(agg_value=agg_value, threshold=threshold)):
            scn_data["result"] = True
        else:
            scn_data["result"] = False
        scenario_result_dict.append(scn_data)

    for v_scn in var_based_scenarios:
        scn_data = v_scn
        parameter = v_scn["parameter"]
        condition = v_scn["condition"]
        threshold = v_scn["threshold"]
        scn_data["scenario_type"] = "variable_based"
        if l3_run:
            for g in global_dict:
                if g["varName"] == parameter:
                    if condition == "Equal to":
                        if g["inputValue"] == threshold:
                            scn_data["result"] = True
                        else:
                            scn_data["result"] = False
                            break
                    elif condition == "Not Equal to":
                        if g["inputValue"] != threshold:
                            scn_data["result"] = True
                        else:
                            scn_data["result"] = False
                            break
        else:
            for g in global_dict["inputs"]["variables"] + global_dict["inputs"]["mapper_variables"]:
                if g["varName"] == parameter:
                    if condition == "Equal to":
                        if g["defaultValue"] == threshold:
                            scn_data["result"] = True
                        else:
                            scn_data["result"] = False
                            break
                    elif condition == "Not Equal to":
                        if g["defaultValue"] != threshold:
                            scn_data["result"] = True
                        else:
                            scn_data["result"] = False
                            break
        scenario_result_dict.append(scn_data)

    passed_scenarios = [scenario for scenario in scenario_result_dict if scenario["result"] is True]
    if run_model:
        if len(passed_scenarios):
            var_scn = [
                scenario for scenario in passed_scenarios if scenario["scenario_type"] == "variable_based"
            ]
            data_agg_scn = [
                scenario
                for scenario in passed_scenarios
                if scenario["scenario_type"] == "data_aggregation_based"
            ]
            if len(var_scn):
                for v_scn in var_scn:
                    next_element = {
                        v_scn["next_element"]: input_data.drop(columns=["next_element"], errors="ignore")
                    }
            elif len(data_agg_scn):
                for agg_scn in data_agg_scn:
                    next_element = {
                        agg_scn["next_element"]: input_data.drop(columns=["next_element"], errors="ignore")
                    }
            else:
                next_element = {
                    i["next_element"]: i["data"].drop(columns=["next_element"], errors="ignore")
                    for i in passed_scenarios
                }
                if len(input_data[input_data["next_element"].isna()]):
                    if default_next_element in next_element:
                        nxt_passed_data = next_element[default_next_element]
                        nxt_passed_data = nxt_passed_data.append(
                            input_data[input_data["next_element"].isna()]
                        )
                    else:
                        nxt_passed_data = input_data[input_data["next_element"].isna()]
                    nxt_passed_data.drop(columns=["next_element"], errors="ignore", inplace=True)
                    next_element[default_next_element] = nxt_passed_data
        else:
            next_element = {default_next_element: input_data.drop(columns=["next_element"], errors="ignore")}
    else:
        next_element = {}
        if len(passed_scenarios):
            var_scn = [
                scenario for scenario in passed_scenarios if scenario["scenario_type"] == "variable_based"
            ]
            data_agg_scn = [
                scenario
                for scenario in passed_scenarios
                if scenario["scenario_type"] == "data_aggregation_based"
            ]
            if len(var_scn):
                for v_scn in var_scn:
                    next_element = {
                        v_scn["scenario_name"]: {
                            "data": input_data.drop(columns=["next_element"], errors="ignore"),
                            "next_element": v_scn["next_element"],
                        }
                    }
            elif len(data_agg_scn):
                for agg_scn in data_agg_scn:
                    next_element = {
                        agg_scn["scenario_name"]: {
                            "data": input_data.drop(columns=["next_element"], errors="ignore"),
                            "next_element": agg_scn["next_element"],
                        }
                    }
            else:
                next_element = {
                    i["scenario_name"]: {
                        "data": i["data"].drop(columns=["next_element"], errors="ignore"),
                        "next_element": i["next_element"],
                    }
                    for i in passed_scenarios
                }
                if len(input_data[input_data["next_element"].isna()]):
                    nxt_passed_data = input_data[input_data["next_element"].isna()]
                    nxt_passed_data.drop(columns=["next_element"], errors="ignore", inplace=True)
                    next_element["No scenario"] = {"data": nxt_passed_data, "next_element": "#"}
        else:
            next_element = {
                "No scenario": {
                    "data": input_data.drop(columns=["next_element"], errors="ignore"),
                    "next_element": "#",
                }
            }
        for nxt in next_element:
            nxt_element_id = next_element[nxt]["next_element"]
            nxt_data = next_element[nxt]["data"]
            files, __ = filemanager_diskstorage()
            for fi in files:
                if fi.startswith(element_id):
                    flush_diskstorage(fi)
                else:
                    continue
            computation_storage(nxt_data, "dataframe", element_id + nxt_element_id)
        return next_element, "If Then Else", [], "If Then Else"

    # Child elements
    child_elements = []
    flow_parent_element = "#"
    for f_ele in flowchart:
        if f_ele["element_id"] == element_id:
            child_elements += f_ele["child"]
            if f_ele["parent"] != "#":
                flow_parent_element = f_ele["parent"][0]

    flowchart_elements = [i["element_id"] for i in flowchart]
    # Failed elements
    next_element = {
        (nxt_ele if nxt_ele in flowchart_elements else default_next_element): value
        for nxt_ele, value in next_element.items()
    }
    elements_not_to_run = [i for i in child_elements if i not in next_element.keys()]

    if len(elements_not_to_run):
        for fail_ele in elements_not_to_run:
            for f_ele in flowchart:
                if f_ele["parent"] != "#":
                    if f_ele["parent"].count(fail_ele):
                        elements_not_to_run.append(f_ele["element_id"])
    return elements_not_to_run, next_element, flow_parent_element


def input_data_element(
    element_id, parent_element, element_flow_dict, flow_control_element, flow_control_parent_element
):
    if parent_element:
        if parent_element == f"{flow_control_element}{element_id}" or parent_element == flow_control_element:
            if element_flow_dict.get(flow_control_element + element_id):
                parent_data = element_flow_dict[flow_control_element + element_id]["output_data"]
                if isinstance(parent_data, pd.DataFrame):
                    parent_data = parent_data.copy(deep=True)
                else:
                    pass
            else:
                parent_data = pd.DataFrame()
        else:
            if element_flow_dict.get(parent_element):
                parent_data = element_flow_dict[parent_element]["output_data"]
                if isinstance(parent_data, pd.DataFrame):
                    parent_data = parent_data.copy(deep=True)
                else:
                    pass
            else:
                parent_data = pd.DataFrame()
    else:
        parent_data = pd.DataFrame()
    return parent_data


def update_flow_error_table(table_, i, error_dic, element_id, request, table_cc=""):
    if table_cc == "":
        error_dic["table"] = str(table_)
    else:
        error_dic["table"] = str(table_cc)
    c_config = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "flow_monitor_error_log",
                "Columns": ["error_dic"],
            },
            "condition": [
                {
                    "column_name": "error_dic",
                    "condition": "Equal to",
                    "input_value": json.dumps(error_dic, cls=NpEncoder),
                    "and_or": "AND",
                },
                {
                    "column_name": "transaction_id_data",
                    "condition": "Equal to",
                    "input_value": str(i),
                    "and_or": "",
                },
            ],
        },
    )
    if c_config.empty and (list(error_dic.values())[0]["data"]).get("id__") not in [None]:
        flowData = pd.DataFrame(
            columns=[
                "table_name",
                "transaction_id_data",
                "error_dic",
                "error_description",
                "flow",
                "element_id",
                "subprocess",
                "process",
                "app_code",
                "created_by",
                "created_date",
                "modified_by",
                "modified_date",
            ]
        )
        if table_cc == "":
            error_dic["table"] = str(table_)
        else:
            error_dic["table"] = str(table_cc)
        flowData_dict = {
            "table_name": str(table_),
            "transaction_id_data": str(i),
            "error_dic": json.dumps(error_dic, cls=NpEncoder),
            "element_id": element_id,
            "created_by": request.user.username,
            "created_date": datetime.now(),
            "modified_by": request.user.username,
            "modified_date": datetime.now(),
        }
        flowData_dict_df = pd.DataFrame.from_dict([flowData_dict])
        flowData = pd.concat(
            [flowData, flowData_dict_df],
            ignore_index=True,
        )
        data_handling(request, flowData, "flow_monitor_error_log")


def fetch_computation_config(
    request, element_id, pr_code, is_trigger=False, request2={}, computation_data_pass_on={}
):
    model_name = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["tab_body_content", "computation_name"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": element_id,
                    "and_or": "",
                },
            ],
        },
    ).iloc[0]["computation_name"]
    model_config = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_flowchart",
                "Columns": ["flowchart_elements", "scenario_comparative_config"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": model_name,
                    "and_or": "",
                },
            ],
        },
    )
    flowchart_elements = model_config.flowchart_elements.iloc[0]
    flowchart_elements = json.loads(flowchart_elements)
    global_variable_list = []
    global_dict = {"inputs": {}}
    global_element_id = "###"
    data_pass_on_config = {}
    if computation_data_pass_on.get("computationInputConfig"):
        if computation_data_pass_on["computationInputConfig"].get("globalVariableMapper"):
            g_var_mapper = computation_data_pass_on["computationInputConfig"]["globalVariableMapper"]
            source_global_var_list = computation_data_pass_on["global_config"]
            global_config = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "computation_model_configuration",
                        "Columns": ["element_config", "element_id"],
                    },
                    "condition": [
                        {
                            "column_name": "model_name",
                            "condition": "Equal to",
                            "input_value": model_name,
                            "and_or": "and",
                        },
                        {
                            "column_name": "element_id",
                            "condition": "Contains",
                            "input_value": "globalVariable",
                            "and_or": "",
                        },
                    ],
                },
            )
            if len(global_config) > 0:
                global_dict = global_config.element_config.iloc[-1]
                global_element_id = global_config.element_id.iloc[-1]
                global_dict = json.loads(global_dict)
                global_variable_list = []
                for gvar in global_dict["inputs"]["variables"]:
                    config = {
                        "varName": gvar["varName"],
                        "inputValue": gvar["defaultValue"],
                    }
                    if gvar["varName"] in g_var_mapper:
                        for i in source_global_var_list:
                            if gvar["varName"] == i["varName"]:
                                config["inputValue"] = i["inputValue"]
                            else:
                                continue
                    else:
                        pass
                    global_variable_list.append(config)
            else:
                pass
        else:
            pass
        if computation_data_pass_on["computationInputConfig"].get("passPrecedingOutputTo"):
            pass_preceding_output_to = computation_data_pass_on["computationInputConfig"][
                "passPrecedingOutputTo"
            ]
            data_pass_on_config[pass_preceding_output_to] = computation_data_pass_on["output"]
        else:
            pass
    else:
        pass

    config = {
        "model": model_name,
        "configGlobalDict": global_variable_list,
        "configGlobalFunc": [],
    }
    execute_computation_model(
        request,
        flowchart_elements,
        config,
        global_dict,
        global_element_id,
        element_id,
        pr_code,
        pd.DataFrame(),
        pd.DataFrame(),
        is_trigger_event=is_trigger,
        request2=request2,
        data_pass_on_config=data_pass_on_config,
    )
    return None


def find_replace_convert(find, replace, datatype):
    try:
        if datatype == "FloatField":
            find = float(find)
            replace = float(replace)
        elif datatype in ["IntegerField", "BigIntegerField", "AutoField", "ForeignKey"]:
            find = int(find)
            replace = int(replace)
        elif datatype == "DateTimeField":
            find = pd.to_datetime(dt.datetime.strptime(find, "%Y-%m-%dT%H:%M:%S"))
            replace = pd.to_datetime(dt.datetime.strptime(replace, "%Y-%m-%dT%H:%M:%S"))
        elif datatype == "DateField":
            tf = dt.datetime.strptime(find, "%Y-%m-%d")
            find = dt.date(tf.year, tf.month, tf.day)
            tf = dt.datetime.strptime(replace, "%Y-%m-%d")
            replace = dt.date(tf.year, tf.month, tf.day)
        elif datatype == "TimeField":
            tf = dt.datetime.strptime(find, "%H:%M:%S")
            find = dt.time(tf.hour, tf.minute, tf.second)
            tf = dt.datetime.strptime(replace, "%H:%M:%S")
            replace = dt.time(tf.hour, tf.minute, tf.second)
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
    return find, replace


def uploadScreenTable(reportJson, request):
    tableUS = []
    try:
        list_view_tab_body_content = reportJson
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        list_view_tab_body_content = {
            "Category_attributes": {
                "Mandatory": {"Table_name": "CountryMaster"},
                "Connector": {"Template_choice": "Upload functionality"},
            },
            "Category_sub_elements": [
                {
                    "Category_sub_element_name": "Upload",
                    "Category_sub_element_attributes": [
                        {"attr": "Table_name", "value": "CountryMaster"},
                        {
                            "attr": "Upload",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Date",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Last upload date",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                        {
                            "attr": "Next upload date",
                            "value": "Yes",
                            "html_attributes": {"data-parent_group_no": "g2"},
                        },
                    ],
                },
            ],
        }
    ltbc = list_view_tab_body_content
    list_view_table_name = ltbc["Category_attributes"]["Mandatory"]["Table_name"]
    for i in list_view_table_name:
        sql_table_name = "users_" + i.lower().strip()
        tableUS1 = {}
        tableUS1["tableName"] = i
        tableUS1["DBtableName"] = sql_table_name
        tableUS.append(tableUS1)
    return tableUS


def upload_table_info(model_name, request):
    tableUS1 = {}
    sql_table_name = "users_" + model_name.lower().strip()
    tableUS1["tableName"] = model_name
    tableUS1["DBtableName"] = sql_table_name
    rawDate = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": model_name,
                "Agg_Type": "MAX(created_date)",
                "Columns": [],
            },
            "condition": [],
        },
    )

    rawDatenext = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "summary_table",
                "Columns": ["frequency"],
            },
            "condition": [
                {
                    "column_name": "input_file_name",
                    "condition": "Equal to",
                    "input_value": model_name,
                    "and_or": "",
                }
            ],
        },
    )
    if rawDate.empty is False:
        rawDate.fillna(datetime.now(), inplace=True)
        if rawDate.iloc[0, 0]:
            tableUS1["lastuploaddate"] = str(rawDate.iloc[0, 0].strftime("%d %B %Y"))

        if rawDatenext.empty is False:
            result = rawDatenext.iloc[0, 0].strip()
            result = (result.split("/")[0]).strip()
            if result == "Fortnightly":
                newdate = str((rawDate.iloc[0, 0].date()).strftime("%d %B %Y"))
                newdate1 = str((rawDate.iloc[0, 0].date()).strftime("%d"))
                if int(newdate1) < 15:
                    new_month_year = (rawDate.iloc[0, 0].date() + timedelta(15)).strftime("%B %Y")
                    tableUS1["nextuploaddate"] = "15" + "-" + str(new_month_year)
                else:
                    new_month_year = ((rawDate.iloc[0, 0] + pd.DateOffset(months=1)).date()).strftime("%B %Y")
                    tableUS1["nextuploaddate"] = "1" + "-" + str(new_month_year)
            if result == "Monthly":
                newdate = ((rawDate.iloc[0, 0] + pd.DateOffset(months=1)).date()).strftime("%B %Y")
                nextmonth = "1" + " " + str(newdate)
                tableUS1["nextuploaddate"] = nextmonth
            if result == "Yearly":
                newdate = ((rawDate.iloc[0, 0] + pd.DateOffset(years=1)).date()).strftime("%Y")
                nextyear = "1" + "-" + "April" + "-" + str(newdate)
                tableUS1["nextuploaddate"] = nextyear
            if result == "One time":
                tableUS1["nextuploaddate"] = "NA"
        else:
            tableUS1["nextuploaddate"] = "NA"
    else:
        tableUS1["lastuploaddate"] = "NA"

        if rawDatenext.empty is False:
            result = rawDatenext.iloc[0, 0]
            result = (result.split("/")[0]).strip()
            if result == "Fortnightly":
                newdate = str((date.today()).strftime("%d %B %Y"))
                newdate1 = str((date.today()).strftime("%d"))
                if int(newdate1) < 15:
                    new_month_year = (date.today() + timedelta(15)).strftime("%B %Y")
                    tableUS1["nextuploaddate"] = "15" + " " + str(new_month_year)
                else:
                    new_month_year = (date.today() + pd.DateOffset(months=1)).strftime("%B %Y")
                    tableUS1["nextuploaddate"] = "1" + " " + str(new_month_year)
            if result == "Monthly":
                newdate = (date.today() + pd.DateOffset(months=1)).strftime("%B %Y")
                nextmonth = "1" + " " + str(newdate)
                tableUS1["nextuploaddate"] = nextmonth
            if result == "Yearly":
                newdate = ((date.today() + pd.DateOffset(years=1)).date()).strftime("%Y")
                nextyear = "1" + " " + "April" + " " + str(newdate)
                tableUS1["nextuploaddate"] = nextyear
            if result == "One time":
                tableUS1["nextuploaddate"] = "NA"
        else:
            tableUS1["nextuploaddate"] = "NA"
    return tableUS1


def updateBodyContent(request, element_id, body_content):
    update_data_func(
        request,
        config_dict={
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": [
                    {
                        "column_name": "tab_body_content",
                        "input_value": json.dumps(body_content),
                        "separator": "",
                    },
                ],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": element_id,
                    "and_or": "",
                },
            ],
        },
    )


def approval_table_data(request):
    group_name = list(request.user.groups.values_list("name", flat=True))

    approval_data = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "ApprovalTable",
                "Columns": [
                    "id",
                    "tablename",
                    "json_data",
                    "approval_status",
                    "create_view_element_id",
                    "created_by",
                    "created_date",
                    "approver_group",
                    "approver_user",
                    "approval_type",
                ],
            },
            "condition": [
                {
                    "column_name": "approval_status",
                    "condition": "Equal to",
                    "input_value": "Pending",
                    "and_or": "",
                }
            ],
        },
    )
    context_data = {}
    approvalslist = []
    approval_data_demo = approval_data.reindex(
        columns=[
            "create_view_element_id",
            "tablename",
            "created_by",
            "approver_group",
            "approver_user",
            "approval_type",
        ]
    )
    approval_data_demo = approval_data_demo.drop_duplicates(
        subset=[
            "create_view_element_id",
            "created_by",
            "approval_type",
            "tablename",
            "approver_group",
            "approver_user",
        ]
    )
    table_names = (approval_data_demo["tablename"]).tolist()
    users_names = (approval_data_demo["created_by"]).tolist()
    create_view_element_ids = approval_data_demo["create_view_element_id"].tolist()
    approval_type = approval_data_demo["approval_type"].tolist()
    group_name_list = (approval_data_demo["approver_group"]).tolist()
    user_name_list = (approval_data_demo["approver_user"]).tolist()

    for i in range(len(table_names)):
        table_data = {}
        if "process" in create_view_element_ids[i]:
            if "process" in create_view_element_ids[i]:
                approval_data_edit = approval_data[
                    approval_data["create_view_element_id"].str.contains("process")
                ]
            x = approval_data_edit["tablename"] == f"{table_names[i]}"
            y = approval_data_edit["created_by"] == f"{users_names[i]}"
            xy = approval_data_edit["create_view_element_id"] == f"{create_view_element_ids[i]}"
            xyz = approval_data_edit["approval_type"] == f"{approval_type[i]}"
            group_identifier = approval_data_edit["approver_group"] == group_name_list[i]
            user_identifier = approval_data_edit["approver_user"] == user_name_list[i]
            z = x & y & xy & xyz & group_identifier & user_identifier
            approval_data_tablename = approval_data_edit.loc[z,]
            table_data["table_name_update"] = table_names[i]
            table_data["approval_count_update"] = len(approval_data_tablename)
            table_data["create_view_element_id"] = create_view_element_ids[i]
            table_data["temp_name"] = "list_view"
            if "create" in approval_type[i]:
                table_data["edit_type"] = "update"
                table_data["edit_type_disp"] = "New data insertion"
            else:
                table_data["edit_type"] = "edit"
                table_data["edit_type_disp"] = "Edit existing data"
            table_data["created_by_update"] = users_names[i]
            table_data["recent_user"] = request.user.username
            table_data["group_name_list"] = group_name_list[i]
            table_data["user_name_list"] = user_name_list[i]
            table_data["recent_group_name"] = json.dumps(group_name)
            approvalslist.append(table_data)
        else:
            approval_data_update = approval_data[
                ~approval_data["create_view_element_id"].str.contains("process")
            ]
            x = approval_data_update["tablename"] == f"{table_names[i]}"
            y = approval_data_update["created_by"] == f"{users_names[i]}"
            xy = approval_data_update["create_view_element_id"] == f"{create_view_element_ids[i]}"
            xyz = approval_data_update["approval_type"] == f"{approval_type[i]}"
            group_identifier = approval_data_update["approver_group"] == group_name_list[i]
            user_identifier = approval_data_update["approver_user"] == user_name_list[i]
            z = x & y & xy & xyz & group_identifier & user_identifier
            approval_data_tablename = approval_data_update.loc[z,]
            table_data["table_name_update"] = table_names[i]
            table_data["approval_count_update"] = len(approval_data_tablename)
            table_data["create_view_element_id"] = create_view_element_ids[i]
            table_data["temp_name"] = "create_view"
            if "create" in approval_type[i]:
                table_data["edit_type"] = "update"
                table_data["edit_type_disp"] = "New data insertion"
            else:
                table_data["edit_type"] = "edit"
                table_data["edit_type_disp"] = "Edit existing data"
            table_data["created_by_update"] = users_names[i]
            table_data["recent_user"] = request.user.username
            table_data["group_name_list"] = group_name_list[i]
            table_data["user_name_list"] = user_name_list[i]
            table_data["recent_group_name"] = json.dumps(group_name)
            approvalslist.append(table_data)

    context_data["approvals"] = approvalslist
    return context_data


def active_flow_element(request, type_="l3"):
    status = False
    if type_ != "l3":
        redirect_config = read_data_func(
            request,
            {
                "inputs": {"Data_source": "Database", "Table": "Process_flow_model", "Columns": ["flow_id"]},
                "condition": [
                    {
                        "column_name": "redirect_status",
                        "condition": "Equal to",
                        "input_value": "Active",
                        "and_or": "AND",
                    },
                    {
                        "column_name": "current_status",
                        "condition": "Equal to",
                        "input_value": "Pass",
                        "and_or": "",
                    },
                ],
            },
        )
    else:
        redirect_config = read_data_func(
            request,
            {
                "inputs": {"Data_source": "Database", "Table": "Process_flow_model", "Columns": ["flow_id"]},
                "condition": [
                    {
                        "column_name": "redirect_status",
                        "condition": "Equal to",
                        "input_value": "Active/",
                        "and_or": "AND",
                    },
                    {
                        "column_name": "current_status",
                        "condition": "Equal to",
                        "input_value": "Pass",
                        "and_or": "",
                    },
                ],
            },
        )
        if redirect_config.empty:
            redirect_config = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "Process_flow_model",
                        "Columns": ["flow_id"],
                    },
                    "condition": [
                        {
                            "column_name": "redirect_status",
                            "condition": "Equal to",
                            "input_value": "Active",
                            "and_or": "AND",
                        },
                        {
                            "column_name": "current_status",
                            "condition": "Equal to",
                            "input_value": "Pass",
                            "and_or": "",
                        },
                    ],
                },
            )
    if not redirect_config.empty:
        redirect_config = redirect_config.iloc[0]["flow_id"]
        if redirect_config not in ["NULL", '"NULL"', "'NULL'"]:
            redirect_config = json.loads(redirect_config)
            status = True
        else:
            redirect_config = {}
    else:
        redirect_config = {}
    if status and type_ == "l3":
        update_data_func(
            request,
            config_dict={
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Process_flow_model",
                    "Columns": [
                        {
                            "column_name": "redirect_status",
                            "input_value": "Not active",
                            "separator": "",
                        },
                    ],
                },
                "condition": [
                    {
                        "column_name": "redirect_status",
                        "condition": "Equal to",
                        "input_value": "Active",
                        "and_or": "OR",
                    },
                    {
                        "column_name": "redirect_status",
                        "condition": "Equal to",
                        "input_value": "Active/",
                        "and_or": "",
                    },
                ],
            },
        )
    return redirect_config, status


def send_Emails(
    request,
    from_user,
    to_user,
    subject,
    content,
    username=None,
    approval=0,
    tenant_id="default_user",
    to_cc=[],
    to_bcc=[],
    attachments=[],
    smtpConfigKey="default",
):
    mimemsg = MIMEMultipart()
    mimemsg["To"] = ", ".join(to_user)
    if to_cc:
        mimemsg["CC"] = ", ".join(to_cc)
    else:
        pass
    if to_bcc:
        mimemsg["BCC"] = ", ".join(to_bcc)
    else:
        pass
    mimemsg["Subject"] = subject
    schema = tenant_schema_from_request(request)
    app_code, db_connection_name = current_app_db_extractor(request)
    try:
        operation = request.POST["operation"]
    except:
        operation = None

    if operation == "email_otp":
        html = """\
            <html>
            <head></head>
            <body>
                <p>$(message_body)</p>
            </body>
            </html>
            """
        if username:
            html = html.replace("$(message_body)", content)
            if request.headers.get("X-Forwarded-Proto", "http") == "https":
                reset_url = reset_url.replace("http", "https")
        else:
            html = html.replace("$(message_body)", content)
    else:
        html = """\
            <html>
            <head></head>
            <body>
                <p>$(message_body)</p>
                $(reset_url)$(en_uname)
            </body>
            </html>
            """

        if username:
            html = html.replace("$(message_body)", content)
            reset_url = request.build_absolute_uri("/accounts/password/new_password/")
            if tenant_id == "tenant_admin":
                reset_url = request.build_absolute_uri("/tenant_admin/accounts/password/new_password/")
            if request.headers.get("X-Forwarded-Proto", "http") == "https":
                reset_url = reset_url.replace("http", "https")
            html = html.replace("$(reset_url)", reset_url)
            html = html.replace("$(en_uname)", username + "/")
        else:
            html = html.replace("$(message_body)", content)
            html = html.replace("$(reset_url)", "")
            html = html.replace("$(en_uname)", "")

    smtp_requires_auth = "yes"
    if (smtpConfigKey.lower() == "default" and approval) or not approval:
        if os.path.exists(f"{PLATFORM_FILE_PATH}tenant_database_mapping.json"):
            with open(f"{PLATFORM_FILE_PATH}tenant_database_mapping.json") as json_file:
                tenant_data = json.load(json_file)
                t_config = tenant_data.get(schema)
                if not approval:
                    if (
                        t_config.get("smtp_host")
                        and t_config.get("smtp_host_user")
                        and t_config.get("smtp_host_password")
                        and t_config.get("smtp_port")
                    ):
                        smtp_host = t_config["smtp_host"]
                        smtp_host_user = t_config["smtp_host_user"]
                        smtp_host_password = t_config["smtp_host_password"]
                        smtp_port = int(t_config["smtp_port"])
                        smtp_requires_auth = t_config.get("smtp_requires_auth", "yes")
                else:
                    if (
                        t_config.get("mail_provider")
                        and t_config.get("approval_password")
                        and t_config.get("approval_email")
                    ):
                        smtp_host = t_config["mail_provider"]
                        smtp_host_user = t_config["approval_email"]
                        smtp_host_password = t_config["approval_password"]
                        smtp_port = int(t_config.get("approval_smtp_port", "587"))
                        smtp_requires_auth = t_config.get("approval_smtp_requires_auth", "yes")
                        from_user = t_config["approval_email"]
                json_file.close()
    else:
        if os.path.exists(f"{PLATFORM_FILE_PATH}user_smtp_configurations.json"):
            with open(f"{PLATFORM_FILE_PATH}user_smtp_configurations.json") as json_file:
                tenant_data = json.load(json_file)
                t_config = tenant_data.get(schema)
                if t_config.get(app_code):
                    if t_config[app_code].get(smtpConfigKey):
                        if (
                            t_config[app_code][smtpConfigKey].get("smtp_provider")
                            and t_config[app_code][smtpConfigKey].get("smtp_user")
                            and t_config[app_code][smtpConfigKey].get("smtp_password")
                            and t_config[app_code][smtpConfigKey].get("smtp_port")
                        ):
                            smtp_host = t_config[app_code][smtpConfigKey]["smtp_provider"]
                            smtp_host_user = t_config[app_code][smtpConfigKey]["smtp_user"]
                            smtp_host_password = t_config[app_code][smtpConfigKey]["smtp_password"]
                            smtp_port = int(t_config[app_code][smtpConfigKey]["smtp_port"])
                            smtp_requires_auth = t_config[app_code][smtpConfigKey].get(
                                "smtp_requires_auth", "yes"
                            )
                            from_user = smtp_host_user
                json_file.close()

    mimemsg["From"] = from_user
    mimemsg.attach(MIMEText(html, "html"))
    if attachments:
        for name, file in attachments.items():
            part = MIMEBase("application", "octet-stream")
            part.set_payload(file)
            encoders.encode_base64(part)
            part.add_header("Content-Disposition", f"attachment; filename={name}")
            mimemsg.attach(part)
    else:
        pass
    connection = smtplib.SMTP(host=smtp_host, port=smtp_port)
    connection.connect(smtp_host, smtp_port)
    connection.ehlo()
    connection.starttls()
    connection.ehlo()
    if smtp_requires_auth == "yes":
        connection.login(smtp_host_user, smtp_host_password)
    else:
        pass
    connection.sendmail(from_user, [*to_user, *to_cc, *to_bcc], mimemsg.as_string())
    connection.quit()

    return None


def find_replace_convert(find, replace, datatype):
    try:
        if datatype == "FloatField":
            find = float(find)
            replace = float(replace)
        elif datatype in ["IntegerField", "BigIntegerField", "AutoField", "ForeignKey"]:
            find = int(find)
            replace = int(replace)
        elif datatype == "DateTimeField":
            find = pd.to_datetime(dt.datetime.strptime(find, "%Y-%m-%dT%H:%M:%S"))
            replace = pd.to_datetime(dt.datetime.strptime(replace, "%Y-%m-%dT%H:%M:%S"))
        elif datatype == "DateField":
            tf = dt.datetime.strptime(find, "%Y-%m-%d")
            find = dt.date(tf.year, tf.month, tf.day)
            tf = dt.datetime.strptime(replace, "%Y-%m-%d")
            replace = dt.date(tf.year, tf.month, tf.day)
        elif datatype == "TimeField":
            tf = dt.datetime.strptime(find, "%H:%M:%S")
            find = dt.time(tf.hour, tf.minute, tf.second)
            tf = dt.datetime.strptime(replace, "%H:%M:%S")
            replace = dt.time(tf.hour, tf.minute, tf.second)
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
    return find, replace


def find_and_replace(dataframe, columnName, replacecolumnName, find, replace, find_case, is_find=True):
    if find_case == "Equal to":
        if is_find:
            dataframe = dataframe[dataframe[columnName] == find]
        else:
            if find != "NULL":
                dataframe.loc[dataframe[columnName] == find, replacecolumnName] = replace
            else:
                dataframe.loc[dataframe[columnName].isna(), replacecolumnName] = replace

    elif find_case == "Not Equal to":
        if is_find:
            dataframe = dataframe[dataframe[columnName] != find]
        else:
            if find != "NULL":
                dataframe.loc[dataframe[columnName] != find, replacecolumnName] = replace
            else:
                dataframe.loc[~dataframe[columnName].isna(), replacecolumnName] = replace

    elif find_case == "Entire Column":
        dataframe[replacecolumnName] = replace

    elif find_case == "Greater than":
        if is_find:
            dataframe = dataframe[dataframe[columnName] > find]
        else:
            dataframe.loc[dataframe[columnName] > find, replacecolumnName] = replace

    elif find_case == "Smaller than":
        if is_find:
            dataframe = dataframe[dataframe[columnName] < find]
        else:
            dataframe.loc[dataframe[columnName] < find, replacecolumnName] = replace

    elif find_case == "Greater than equal to":
        if is_find:
            dataframe = dataframe[dataframe[columnName] >= find]
        else:
            dataframe.loc[dataframe[columnName] >= find, replacecolumnName] = replace

    elif find_case == "Smaller than equal to":
        if is_find:
            dataframe = dataframe[dataframe[columnName] <= find]
        else:
            dataframe.loc[dataframe[columnName] <= find, replacecolumnName] = replace

    elif find_case == "Starts with":
        if is_find:
            dataframe = dataframe.loc[dataframe[columnName].astype(str).str.startswith(str(find), na="-")]
        else:
            dataframe.loc[
                dataframe[columnName].astype(str).str.startswith(str(find), na="-"), replacecolumnName
            ] = replace

    elif find_case == "Ends with":
        if is_find:
            dataframe = dataframe.loc[dataframe[columnName].astype(str).str.endswith(str(find), na="-")]
        else:
            dataframe.loc[
                dataframe[columnName].astype(str).str.endswith(str(find), na="-"), replacecolumnName
            ] = replace

    elif find_case == "Not Starts with":
        if is_find:
            dataframe = dataframe.loc[~dataframe[columnName].astype(str).str.startswith(str(find), na="-")]
        else:
            dataframe.loc[~dataframe[columnName].astype(str).str.startswith(str(find)), replacecolumnName] = (
                replace
            )

    elif find_case == "Not Ends with":
        if is_find:
            dataframe = dataframe.loc[~dataframe[columnName].astype(str).str.endswith(str(find), na="-")]
        else:
            dataframe.loc[~dataframe[columnName].astype(str).str.endswith(str(find)), replacecolumnName] = (
                replace
            )

    elif find_case == "Contains":
        if is_find:
            dataframe = dataframe[dataframe[columnName].astype(str).str.contains(str(find))]
        else:
            dataframe.loc[dataframe[columnName].astype(str).str.contains(str(find)), replacecolumnName] = (
                replace
            )

    elif find_case == "Not Contains":
        if is_find:
            dataframe = dataframe[~dataframe[columnName].astype(str).str.contains(str(find))]
        else:
            dataframe.loc[~dataframe[columnName].astype(str).str.contains(str(find)), replacecolumnName] = (
                replace
            )
    return dataframe


def mulitiselect_json_operation(
    rows_data, results, masterColumn, masterColumn_id, column_name, replacecolumnName, find, find_case
):
    try:
        find = int(find)
    except Exception as e:
        logging.warning(f"Following exception occurred - {e}")

    if type(find) is int:
        results = find_and_replace(results, masterColumn_id, replacecolumnName, find, None, find_case)
    else:
        results = find_and_replace(results, masterColumn, replacecolumnName, find, None, find_case)
    results_list = results[masterColumn_id].tolist()
    contain_str = ""
    for x in results_list:
        contain_str += f'"{str(x)}"' + "|"
    rows_data = rows_data[rows_data[column_name].str.contains(contain_str[:-1], na=False)]
    rows_data.reset_index(drop=True, inplace=True)
    return rows_data


def operation_audit_log(request, db_connection_name, operation, message):
    df = pd.DataFrame(
        columns=[
            "username",
            "url",
            "operation",
            "message",
            "datetime",
        ]
    )
    df_dict = {
        "username": request.user.username,
        "url": request.path,
        "operation": operation,
        "message": message,
        "datetime": datetime.now(),
    }
    df_dict_df = pd.DataFrame.from_dict([df_dict])
    df = pd.concat([df, df_dict_df], ignore_index=True)
    data_handling(request, df, "audit_operation")


def get_button_access(request_user, curr_app_code, element_id=None, item_code=None, request2={}):
    group_list = list(request_user.user.groups.all().values_list("name", flat=True))
    level_button_access = []
    permButtonList = [
        "CreateView - Save",
        "CreateView - Save as Draft",
        "CreateView - Back",
        "CreateView - Custom Validation",
        "CreateView - Refresh Computation",
        "CreateView - View History",
        "CreateView - View Rejected Records",
        "CreateView - View Transaction Status",
        "UploadView - Upload",
        "UploadView - Map Columns",
        "UploadView - Custom Validation",
        "UploadView - Add computation logic",
        "UploadView - Download data",
        "UploadView - Upload history",
        "UploadView - Last upload errors",
        "UploadView - Detailed error log",
        "UploadView - Transaction status",
        "ListView - Save template",
        "ListView - Set Alerts",
        "ListView - Upload",
        "ListView - Paste Tabular Data",
        "ListView - Edit Mode",
        "ListView - Delete all data",
        "ListView - Find and replace",
        "ListView - Freeze Panes",
        "ListView - Formatters",
        "ListView - Transactions Status",
        "ListView - Plot Charts",
        "ListView - Filter",
        "ListView - Add Computed Fields",
        "ListView - Expand",
        "ListView - Edit Record",
        "ListView - Delete Record",
        "ListView - View Record",
        "Computation - Run Model",
        "Computation - Configure Scenario",
        "Computation - Filter",
        "Analysis - Previous Versions",
        "Analysis - Save and Share",
        "Analysis - Plot charts",
        "Analysis - Global Settings",
        "Analysis - PDF",
        "Analysis - Save",
        "Analysis - Add tab",
    ]
    if item_code is not None:
        lba_condition = {
            "column_name": "permission_name",
            "condition": "Contains",
            "input_value": item_code,
            "and_or": "",
        }
    else:
        lba_condition = {
            "column_name": "level_button_access",
            "condition": "Contains",
            "input_value": element_id,
            "and_or": "",
        }
    for group in group_list:
        lba = read_data_func(
            request_user,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "UserPermission_Master",
                    "Columns": ["level_button_access"],
                },
                "condition": [
                    {
                        "column_name": "app_code",
                        "condition": "Equal to",
                        "input_value": curr_app_code,
                        "and_or": "and",
                    },
                    {
                        "column_name": "usergroup",
                        "condition": "Equal to",
                        "input_value": group,
                        "and_or": "and",
                    },
                    {
                        "column_name": "permission_type",
                        "condition": "Equal to",
                        "input_value": "Navbar",
                        "and_or": "and",
                    },
                    {
                        "column_name": "permission_level",
                        "condition": "Equal to",
                        "input_value": "3",
                        "and_or": "and",
                    },
                    lba_condition,
                ],
            },
        )
        if len(lba) > 0:
            if lba.iloc[0]["level_button_access"] is not None:
                tdict = json.loads(lba.iloc[0]["level_button_access"])
                level_button_access.append(tdict)
    if level_button_access:
        tmp = {}
        for i in level_button_access:
            for j in i:
                if j not in tmp:
                    tmp[j] = i[j]
                else:
                    tmp[j] = list(set(tmp[j] + i[j]))
        if item_code is not None:
            return tmp
        else:
            return tmp[element_id]
    return permButtonList


def email_table_style():
    return """
            table {
            border: 1px solid #ccc;
            border-collapse: collapse;
            margin: 0;
            padding: 0;
            width: 100%;
            table-layout: fixed;
            }

            table caption {
            font-size: 1.5em;
            margin: .5em 0 .75em;
            }

            table tr {
            border: 1px solid #ddd;
            padding: .35em;
            }

            table th,
            table td {
            padding: .625em;
            text-align: center;
            }

            table th {
            font-size: .85em;
            letter-spacing: .1em;
            text-transform: uppercase;
            }

            @media screen and (max-width: 600px) {
            table {
                border: 0;
            }

            table caption {
                font-size: 1.3em;
            }

            table thead {
                border: none;
                clip: rect(0 0 0 0);
                height: 1px;
                margin: -1px;
                overflow: hidden;
                padding: 0;
                position: absolute;
                width: 1px;
            }

            table tr {
                border-bottom: 3px solid #ddd;
                display: block;
                margin-bottom: .625em;
            }

            table td {
                border-bottom: 1px solid #ddd;
                display: block;
                font-size: .8em;
                text-align: right;
            }

            table td::before {
                /*
                * aria-label has no advantage, it won't be read inside a table
                content: attr(aria-label);
                */
                content: attr(data-label);
                float: left;
                font-weight: bold;
                text-transform: uppercase;
            }

            table td:last-child {
                border-bottom: 0;
            }
            }
        """


def send_approval_mail(
    request,
    createview_table_name,
    final_data_json,
    email_list,
    content,
    subject="",
    in_system_approval=True,
    to_cc=[],
    to_bcc=[],
    attachments_config={},
    approver_token="",
    smtpConfigKey="default",
    user_name_mapper={},
):
    if in_system_approval:
        try:
            domain = request.build_absolute_uri("/")[:-1]
        except Exception:
            domain = f"{request.headers.get('X-Forwarded-Proto', 'http')}://{request.host}"
    tenant = tenant_schema_from_request(request)
    app_code, db_connection_name = current_app_db_extractor(request)
    table_head = ""
    table_rows = ""

    drop_cols_list = [
        "created_by",
        "modified_by",
        "created_date",
        "modified_date",
        "active_to",
        "active_from",
        "transaction_id",
        "approved_by",
        "approval_status",
    ]

    if in_system_approval:
        head_flag = True
        for key in final_data_json:
            ijson = json.loads(final_data_json[key])[0]
            table_rows += "<tr>"
            for key2 in ijson.keys():
                if key2 not in drop_cols_list:
                    table_rows += f"<td>{ijson[key2]}</td>"
                    if head_flag:
                        table_head += f'<th scope="col">{key2}</th>'
            table_rows += f"""<td>
                            <a href="{domain}/users/{app_code}/User/approval_table-ima/?token={approver_token}&app_code={app_code}&type=approvals&approve={key}">Approve</a>
                            <a href="{domain}/users/{app_code}/User/approval_table-ima/?token={approver_token}&app_code={app_code}&type=approvals&reject={key}">Reject</a>
                            </td></tr>"""
            head_flag = False
            table_rows += "<tr>"

        message = f"""{content}
                    <style>
                    {email_table_style()}
                    </style>
                    <br>
                        <table class="table text-center" style="max-width:100vw; overflow-y: auto;">
                            <thead class="thead-dark">
                                <tr>
                                {table_head}
                                <th scope="col">Actions</th>
                                </tr>
                            </thead>
                            <tbody>
                                {table_rows}
                            </tbody>
                            </table>
                    """
    else:
        message = content

    if not subject:
        subject = f"Approval for table '{createview_table_name}' from '{request.user.username}'"
    else:
        pass
    attachments = {}
    if attachments_config:
        if attachments_config.get("attachment_type") and attachments_config.get("parameter"):
            if attachments_config["attachment_type"] == "static":
                file_names = attachments_config["parameter"]
                path = f"{MEDIA_ROOT}/{tenant}/{app_code}/assets"
                for f in file_names:
                    with open(f"{path}/{f}", "rb") as file:
                        attachments[f] = file.read()
            elif attachments_config["attachment_type"] == "dynamic" and final_data_json:
                if attachments_config["parameter"] == "csv":
                    data = json.loads(list(final_data_json.values())[0])
                    path = f"{MEDIA_ROOT}/{tenant}/{app_code}/uploaded_files"
                    data = pd.DataFrame(data)
                    data.to_csv(f"{path}/TransactionData_{createview_table_name}{request.user.username}.csv")
                    if not os.path.exists(f"{MEDIA_ROOT}/{tenant}/{app_code}"):
                        os.mkdir(f"{MEDIA_ROOT}/{tenant}/{app_code}")
                        os.mkdir(path)
                    else:
                        pass
                    if not os.path.exists(path):
                        os.mkdir(path)
                    else:
                        pass
                    with open(
                        f"{path}/TransactionData_{createview_table_name}{request.user.username}.csv", "rb"
                    ) as file:
                        attachments["Transaction Data.csv"] = file.read()
                    os.remove(f"{path}/TransactionData_{createview_table_name}{request.user.username}.csv")
                elif attachments_config["parameter"] == "pdf":
                    path = f"{MEDIA_ROOT}/{tenant}/{app_code}/uploaded_files"
                    asset_path = f"{MEDIA_ROOT}/{tenant}/{app_code}/assets"
                    if not os.path.exists(f"{MEDIA_ROOT}/{tenant}/{app_code}"):
                        os.mkdir(f"{MEDIA_ROOT}/{tenant}/{app_code}")
                        os.mkdir(path)
                        os.mkdir(asset_path)
                    else:
                        pass
                    if not os.path.exists(path):
                        os.mkdir(path)
                    else:
                        pass
                    if not os.path.exists(asset_path):
                        os.mkdir(asset_path)
                    else:
                        pass

                    pdf_file_name = f"{path}/TransactionData_{request.user.username}.pdf"
                    data = json.loads(list(final_data_json.values())[0])
                    data = pd.DataFrame(data)
                    logo_config = {}
                    row_height = 40
                    header_bg_color = "#000000"
                    header_text_color = "#FFFFFF"
                    cell_bg_color = "#FFFFFF"
                    cell_text_color = "#000000"
                    column_width = {}
                    layout = "horizontal"
                    column_alignment_config = {}
                    if attachments_config.get("additional_config"):
                        additional_config = attachments_config["additional_config"]
                        if additional_config.get("layoutOption"):
                            layout = additional_config["layoutOption"]
                        else:
                            pass
                        if additional_config.get("logoConfig"):
                            logo_config = additional_config["logoConfig"]
                            logo_config["file_name"] = f"{asset_path}/{logo_config['parameter']}"
                        else:
                            pass
                        if additional_config.get("dropcolumns"):
                            dropcolumns = additional_config.get("dropcolumns")
                            data = data[data.columns[~data.columns.isin(dropcolumns)]]
                        if additional_config.get("styleConfig"):
                            style_config = additional_config["styleConfig"]
                            if style_config["customize_style"] == "yes":
                                if style_config["row_height"]:
                                    row_height = int(style_config["row_height"])
                                else:
                                    row_height = 40
                                header_bg_color = style_config["header_bg_color"]
                                header_text_color = style_config["header_text_color"]
                                cell_bg_color = style_config["cell_bg_color"]
                                cell_text_color = style_config["cell_text_color"]
                                customize_column_width = style_config["customize_column_width"]
                                if customize_column_width == "manual":
                                    column_width["static_column_width"] = style_config["static_column_width"]
                                    column_width["field_level_config"] = style_config[
                                        "custom_column_field_level_config"
                                    ]["field_config"]
                                else:
                                    pass
                                if style_config.get("column_alignment"):
                                    column_alignment_config = style_config["column_alignment"]
                                else:
                                    pass
                            else:
                                pass
                        else:
                            pass
                    else:
                        pass

                    if "audit_log" in data.columns:
                        audit_trail_data = data["audit_log"].iloc[0]
                        if audit_trail_data and audit_trail_data.startswith("[{"):
                            audit_trail_data = json.loads(
                                audit_trail_data.replace("'", '"').replace(r'\\"', "'")
                            )
                            level_data = []
                            for act_idx, action in enumerate(audit_trail_data):
                                if action["action"] == "Edited By":
                                    audit_value = action["value"]
                                    from_index = audit_value.index(" from ")
                                    to_index = audit_value.index(" to ")
                                    pre_from_content = audit_value[:from_index]
                                    from_content = audit_value[from_index + 6 : to_index]
                                    to_content = audit_value[to_index + 4 :]
                                    if pre_from_content.startswith("approval_level_config"):
                                        if from_content.startswith("{"):
                                            from_content = json.loads(from_content.replace("'", '"'))
                                            updated_from_content = ""
                                            for (
                                                from_c_approval_level_idx,
                                                from_c_approval_levels,
                                            ) in enumerate(from_content["level_config"]):
                                                if user_name_mapper:
                                                    updated_from_content += f"{str([user_name_mapper[i] for i in from_c_approval_levels['user_list']])}"
                                                else:
                                                    updated_from_content += (
                                                        f"{str(from_c_approval_levels['user_list'])}"
                                                    )
                                                if (
                                                    from_c_approval_level_idx
                                                    != len(from_content["level_config"]) - 1
                                                ):
                                                    updated_from_content += " <> "
                                                else:
                                                    pass
                                            from_content = updated_from_content
                                        else:
                                            pass
                                        if to_content.startswith("{"):
                                            to_content = json.loads(to_content.replace("'", '"'))
                                            updated_to_content = ""
                                            for to_c_approval_level_idx, to_c_approval_levels in enumerate(
                                                to_content["level_config"]
                                            ):
                                                if user_name_mapper:
                                                    updated_to_content += f"{str([user_name_mapper[i] for i in to_c_approval_levels['user_list']])}"
                                                else:
                                                    updated_to_content += (
                                                        f"{str(to_c_approval_levels['user_list'])}"
                                                    )
                                                if (
                                                    to_c_approval_level_idx
                                                    != len(to_content["level_config"]) - 1
                                                ):
                                                    updated_to_content += " <> "
                                                else:
                                                    pass
                                            to_content = updated_to_content
                                        else:
                                            pass
                                    else:
                                        pass
                                    action["value"] = (
                                        f"<p>{pre_from_content}</p><p>From</p><p>{from_content}</p><p>To</p><p>{to_content}</p>"
                                    )
                                else:
                                    pass
                                level_data.append(action)
                            data["audit_log"] = json.dumps(level_data)
                        else:
                            pass
                    else:
                        pass
                    data_to_pdf_converter.generate_pdf_from_data(
                        data,
                        file_name=pdf_file_name,
                        col_width=column_width,
                        rowHeights=row_height,
                        header_bg_color=header_bg_color,
                        header_font_color=header_text_color,
                        cell_bg_color=cell_bg_color,
                        cell_font_color=cell_text_color,
                        logo=logo_config,
                        layout=layout,
                        column_alignment=column_alignment_config,
                    )
                    if os.path.exists(pdf_file_name):
                        with open(pdf_file_name, "rb") as file:
                            attachments["Transaction.pdf"] = file.read()
                        os.remove(pdf_file_name)
                    else:
                        pass
                else:
                    pass
            else:
                pass
        else:
            pass
        if attachments_config.get("additional_attachments"):
            for file_name, file_path in attachments_config["additional_attachments"].items():
                if os.path.exists(file_path):
                    with open(file_path, "rb") as file:
                        attachments[file_name] = file.read()
                else:
                    continue
        else:
            pass
    else:
        pass

    send_Emails(
        request,
        "",
        email_list,
        subject,
        message,
        username=None,
        approval=1,
        to_cc=to_cc,
        to_bcc=to_bcc,
        attachments=attachments,
        smtpConfigKey=smtpConfigKey,
    )


def HierarchyListCreateFunc(request, app_code, mode, dic=None):
    if dic not in [None]:
        hierarchy_data = dic
        parent_name = hierarchy_data["hierarchy_parent_name"]
        hierarchy_level = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Hierarchy_table",
                    "Columns": ["hierarchy_level", "hierarchy_level_name"],
                },
                "condition": [
                    {
                        "column_name": "hierarchy_name",
                        "condition": "Equal to",
                        "input_value": parent_name,
                        "and_or": "",
                    }
                ],
            },
        )
        if hierarchy_level.empty:
            hierarchy_level = 0
        else:
            hierarchy_level = int(hierarchy_level.loc[0, "hierarchy_level"]) + 1
        hierarchy_data["hierarchy_level"] = hierarchy_level
    else:
        hierarchy_data = json.loads(request.body)
        hierarchy_data["hierarchy_level"] = int(hierarchy_data["hierarchy_level"])
    hierarchy_data["configuration_date"] = pd.to_datetime(
        hierarchy_data["configuration_date"]
    ).date()
    if hierarchy_data["hierarchy_parent_name"] in ["", "NULL"]:
        hierarchy_data["hierarchy_parent_name"] = None
    mandatory_fields = []
    for key, val in hierarchy_data.items():
        if val == "":
            mandatory_fields.append(key)
    if len(mandatory_fields) == 0:
        hierarchy_data = pd.DataFrame([hierarchy_data])
        hierarchy_data["created_date"] = datetime.now()
        hierarchy_data["modified_date"] = datetime.now()
        hierarchy_data["created_by"] = request.user.username
        hierarchy_data["modified_by"] = request.user.username
        data_handling(request, hierarchy_data, "Hierarchy_table")
        return {"status": 201}
    else:
        return {"status": 401, "mandatory_fields": mandatory_fields}


def decisionBox(
    element_id,
    entity_name,
    FinalData,
    request,
    transaction_id="NULL",
    type="create",
    identifier_column=[],
    update_column=[],
    current_decision_box_id="#",
    action_performed_by="",
):
    start_time = time.time()
    element_id = [element_id]
    item_code = getPrCodeFromElementId(element_id[0], request)
    app_code, __ = current_app_db_extractor(request)
    model_name1 = dynamic_model_create.get_model_class(entity_name, request)
    options = model_name1
    date_field = []
    num_field = []
    fields = {}
    status = "pass"
    FinalData["transaction_id"] = transaction_id
    FinalData_ = FinalData
    dataFrame = pd.DataFrame(
        columns=[
            "tablename",
            "json_data",
            "approval_status",
            "create_view_element_id",
            "approval_type",
            "created_by",
            "created_date",
            "modified_by",
            "modified_date",
            "approver_group",
            "transaction_id",
            "modify_column",
            "approval_decision_mailer_config",
        ]
    )

    identifier_column = json.dumps(identifier_column)
    update_column = json.dumps(update_column)

    for field in options.concrete_fields + options.many_to_many:
        fields[field.name] = field
    for field in fields.values():
        if field.get_internal_type() == "ManyToManyField":
            pass
        elif field.get_internal_type() in ["DateField", "DateTimeField"]:
            date_field.append(field.name)
        elif field.get_internal_type() in ["IntField", "FloatField"]:
            num_field.append(field.name)

    related_item_flowchart = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "Process_subprocess_flowchart",
                "Columns": ["flowchart_elements"],
            },
            "condition": [
                {
                    "column_name": "related_item_code",
                    "condition": "Equal to",
                    "input_value": item_code,
                    "and_or": "",
                }
            ],
        },
    )
    related_item_flowchart = related_item_flowchart.to_dict()
    flowchart_element = json.loads(related_item_flowchart["flowchart_elements"][0])

    child_element_id = "#"
    if current_decision_box_id == "#":
        for i in flowchart_element:
            if i["shapeID"] == element_id[0]:
                for child in i["child"]:
                    if child.startswith("decision"):
                        child_element_id = child
    else:
        for i in flowchart_element:
            if i["shapeID"] == current_decision_box_id:
                for child in i["child"]:
                    if child.startswith("decision"):
                        child_element_id = child
    if action_performed_by == "":
        action_performed_by = request.user.username
    else:
        pass
    # extracting condition object for the child element id if the child element is decision box
    if child_element_id != "#":
        condition_data = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "TabScreens",
                    "Columns": ["tab_body_content"],
                },
                "condition": [
                    {
                        "column_name": "element_id",
                        "condition": "Equal to",
                        "input_value": child_element_id,
                        "and_or": "and",
                    },
                    {
                        "column_name": "tab_type",
                        "condition": "Equal to",
                        "input_value": "decision_box",
                        "and_or": "",
                    },
                ],
            },
        )
        condition_data_check = condition_data.to_dict("records")
        is_aug = False
        aug_ = {}

        message_db_data = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "TabScreens",
                    "Columns": ["tab_body_content", "element_id"],
                },
                "condition": [
                    {
                        "column_name": "related_item_code",
                        "condition": "Equal to",
                        "input_value": item_code,
                        "and_or": "and",
                    },
                    {
                        "column_name": "tab_type",
                        "condition": "Equal to",
                        "input_value": "message",
                        "and_or": "",
                    },
                ],
            },
        )

        recurr_cond_flag = False
        recurr_cond_actions = []
        recurr_cond_action_config = {}
        message_ele_id = ""
        message_db_data_content = message_db_data["tab_body_content"].tolist()
        message_db_data_ele_id = message_db_data["element_id"].tolist()

        for indx, mess_config in enumerate(message_db_data_content):
            temp_config = json.loads(mess_config)
            if (
                temp_config["action_type"] == "RecurrenceBasedAction"
                and temp_config["config"]["recurrence_action"]["element_id"] == child_element_id
            ):
                recurr_cond_flag = True
                recurr_cond_actions = temp_config["config"]["recurrence_action"]["action"]
                recurr_cond_action_config = temp_config
                message_ele_id = message_db_data_ele_id[indx]
                break

        if len(condition_data) > 0:
            if condition_data_check[0]["tab_body_content"] not in ["NULL", None]:
                aug_ = json.loads(condition_data_check[0]["tab_body_content"])
                if aug_.get("type") == "augmentation":
                    is_aug = True
        if len(condition_data) > 0 and not is_aug:
            condition_data_check = json.loads(condition_data_check[0]["tab_body_content"])
            createview_decision_type = condition_data_check["Category_sub_elements"][0][
                "Category_sub_element_attributes"
            ][1]["value"]["decision_type"]
            if createview_decision_type == "Approval":
                decision_check = condition_data_check["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][1]["value"]["decisionCheck"]
                user_group = condition_data_check["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][1]["value"]["groups"]
                condition_data = condition_data.to_dict()
                condition_data = json.loads(condition_data["tab_body_content"][0])
                decision_action = condition_data["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][1]["value"]["actions"]
                if condition_data["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("smtpConfigKey"):
                    smtpConfigKey = condition_data["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["smtpConfigKey"]
                else:
                    smtpConfigKey = "default"

                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_type"):
                    approval_type = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approval_type"]
                else:
                    approval_type = "static"
                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_config"):
                    approval_config = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approval_config"]
                else:
                    approval_config = {}
                if condition_data["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("message"):
                    message = condition_data["Category_sub_elements"][0]["Category_sub_element_attributes"][
                        1
                    ]["value"].get("message")
                else:
                    message = ""

                if condition_data["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_notification_subject"):
                    approval_notification_subject = condition_data["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"].get("approval_notification_subject")
                else:
                    approval_notification_subject = ""
                modify_column_data = "NULL"

                if approval_type == "static":
                    user_group = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["groups"]
                    approval_config = {"group_list": user_group}
                else:
                    pass

                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approver_mailer_type"):
                    approver_mailer_type = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approver_mailer_type"]
                else:
                    approver_mailer_type = "static"

                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approver_decision_mailer_type"):
                    approver_decision_mailer_type = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approver_decision_mailer_type"]
                else:
                    approver_decision_mailer_type = "static"

                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_email_list"):
                    approval_email_list = json.loads(
                        condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][
                            1
                        ]["value"]["approval_email_list"]
                    )
                else:
                    approval_email_list = []

                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_decision_email_list"):
                    approval_decision_email_list = json.loads(
                        condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][
                            1
                        ]["value"]["approval_decision_email_list"]
                    )
                else:
                    approval_decision_email_list = []

                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approvalInMailApprovalOption"):
                    approvalInMailApprovalOption = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"].get("approvalInMailApprovalOption")
                else:
                    approvalInMailApprovalOption = False

                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_mail_additional_config"):
                    approval_mail_additional_config = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approval_mail_additional_config"]
                else:
                    approval_mail_additional_config = {}

                if condition_data["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("modifyColumnAttr") not in [None]:
                    modify_column_data = condition_data["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["modifyColumnAttr"]
                condition_data = condition_data["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][1]["value"]["condition"]
                transDataCols = []
                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_notification_attachment_config"):
                    approval_notification_attachment_config = condition_data_check["Category_sub_elements"][
                        0
                    ]["Category_sub_element_attributes"][1]["value"][
                        "approval_notification_attachment_config"
                    ]
                    if approval_notification_attachment_config.get("additional_config"):
                        if approval_notification_attachment_config["additional_config"].get("transDataCols"):
                            transDataCols = approval_notification_attachment_config["additional_config"][
                                "transDataCols"
                            ]
                        else:
                            pass
                    else:
                        pass
                else:
                    approval_notification_attachment_config = {}
                if len(condition_data) > 0:
                    final_data_json_email = {}
                    for i in date_field:
                        try:
                            if i in ["modified_date", "created_date"]:
                                FinalData[i] = pd.to_datetime(FinalData[i]).dt.strftime("%Y-%m-%d %H:%M:%S")
                            else:
                                FinalData[i] = pd.to_datetime(FinalData[i]).dt.strftime("%Y-%m-%d")
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                    for i in num_field:
                        FinalData[i] = pd.to_numeric(FinalData[i], errors="coerce").fillna(0)
                    data = flowValidation(element_id[0], item_code, request, transaction_id)
                    result = validation_result(
                        FinalData,
                        data,
                        {},
                        entity_name,
                        transaction_id=transaction_id,
                        request=request,
                        element_id=element_id[0],
                    )

                    for i in range(len(FinalData)):
                        tdata = FinalData.iloc[i]
                        condition_satisfied = True
                        for j in condition_data.values():
                            if len(j) > 0:
                                if j[0]["table_name"] in entity_name:
                                    if not condition_validator(j, tdata):
                                        condition_satisfied = False
                                        break
                                    else:
                                        pass
                            else:
                                condition_satisfied = False
                                if decision_check == "check":
                                    condition_satisfied = True
                                else:
                                    pass
                        tdata = pd.DataFrame(tdata)
                        if condition_satisfied is True:
                            if not FinalData_.empty:
                                FinalData_ = FinalData_.drop(i)
                            for i in date_field:
                                if i in tdata.columns:
                                    try:
                                        if i in ["modified_date", "created_date"]:
                                            tdata[i] = pd.to_datetime(tdata[i]).dt.strftime(
                                                "%Y-%m-%d %H:%M:%S"
                                            )
                                        else:
                                            tdata[i] = pd.to_datetime(tdata[i]).dt.strftime("%Y-%m-%d")
                                    except Exception as e:
                                        logging.warning(f"Following exception occured - {e}")

                            for i in num_field:
                                if i in tdata.columns:
                                    try:
                                        tdata[i] = pd.to_numeric(tdata[i], errors="coerce").fillna(0)
                                    except Exception as e:
                                        logging.warning(f"Following exception occured - {e}")

                            tdata = tdata.T
                            approval_type_ = "create"

                            if type == "update":
                                tdata["identifier_column"] = identifier_column
                                tdata["update_column"] = update_column
                                tdata["modified_by"] = action_performed_by
                                approval_type_ = "edit"
                            final_data_json = tdata.to_json(orient="records")
                            approval_code = random_generator("alphanum", 32)
                            ConditionalData = {
                                "tablename": [entity_name],
                                "json_data": [final_data_json],
                                "approval_status": ["Pending"],
                                "create_view_element_id": [element_id[0]],
                                "approval_type": [approval_type_],
                                "created_by": [action_performed_by],
                                "created_date": [datetime.now()],
                                "modified_by": [action_performed_by],
                                "modified_date": [datetime.now()],
                                "transaction_id": transaction_id,
                                "modify_column": json.dumps(modify_column_data),
                                "current_decision_box_id": [child_element_id],
                            }
                            (
                                approver_group,
                                approver_user,
                                hierarchy_approval_config,
                                approval_recipient_list,
                                approval_decision_recipient_list,
                                approval_level_config,
                                approver_type,
                                additional_recipients,
                                skipFinalLevel,
                            ) = approvals_information_extractor(
                                request,
                                tdata,
                                approval_type,
                                approval_config,
                                decision_action,
                                approver_mailer_type,
                                approver_decision_mailer_type,
                                approval_email_list,
                                approval_decision_email_list,
                                model_name1,
                                approval_mail_additional_config,
                            )
                            ConditionalData["approver_group"] = json.dumps(approver_group)
                            ConditionalData["approver_user"] = json.dumps(approver_user)
                            ConditionalData["approver_type"] = approver_type
                            if approval_type in ["hierarchical", "hierarchical_user"]:
                                ConditionalData["hierarchy_group"] = json.dumps(hierarchy_approval_config)
                            elif approval_type == "multi_level":
                                ConditionalData["approval_level_config"] = json.dumps(approval_level_config)
                            else:
                                pass

                            if transDataCols:
                                if "approver_type" in transDataCols:
                                    tdata["approver_type"] = approver_type

                                if "approval_level_config" in transDataCols:
                                    if approval_type == "multi_level":
                                        if "approval_level_config" in ConditionalData:
                                            ddata = json.loads(ConditionalData["approval_level_config"])
                                            tdata["approver_details"] = json.dumps(ddata["level_config"])
                                        else:
                                            tdata["approver_details"] = "-"
                                    else:
                                        if approver_group:
                                            tdata["approver_details"] = json.dumps(
                                                [{"group_list": approver_group}]
                                            )
                                        else:
                                            tdata["approver_details"] = json.dumps(
                                                [{"user_list": approver_user}]
                                            )
                                else:
                                    tdata["approver_details"] = "-"

                                if "audit_log" in transDataCols:
                                    tdata["audit_log"] = "-"

                            if decision_action == "Set Approval and Email":
                                approval_decision_mailer_config = {
                                    "recipient_to": approval_decision_recipient_list,
                                    "recipient_cc": additional_recipients[
                                        "approval_decision_recipient_list_cc"
                                    ],
                                    "recipient_bcc": additional_recipients[
                                        "approval_decision_recipient_list_bcc"
                                    ],
                                }
                                ConditionalData["approval_decision_mailer_config"] = json.dumps(
                                    approval_decision_mailer_config
                                )
                                for field in model_name1.concrete_fields:
                                    if (
                                        field.name in tdata.columns
                                        and field.internal_type == "MultiselectField"
                                    ):
                                        tdata = multi_select_id_to_value_converter(
                                            request, tdata, field.name, json.loads(field.mulsel_config)
                                        )
                                    else:
                                        continue
                                final_data_json_email[approval_code] = tdata.to_json(orient="records")
                            else:
                                pass
                            ConditionalData = pd.DataFrame(ConditionalData)
                            if True in list(result.values()):
                                dataFrame = pd.concat([dataFrame, ConditionalData], ignore_index=True)
                                if decision_action == "Set Approval and Email":
                                    ## Email code starts here
                                    to_list = approval_recipient_list
                                    approver_tokens = {}

                                    if recurr_cond_flag:
                                        if approver_group:
                                            groups_user_app = approver_group

                                        if approver_user:
                                            groups_user_app = approver_user

                                        try:
                                            emailBox_functions.trigger_recurring_action_emailbox(
                                                request,
                                                recurr_cond_actions,
                                                recurr_cond_action_config,
                                                child_element_id,
                                                groups_user_app,
                                                approval_code,
                                                entity_name,
                                                message_ele_id,
                                                json.loads(final_data_json_email[approval_code])[0],
                                            )
                                        except Exception as e:
                                            logging.warning(f"Following exception occured - {e}")

                                    if message == "":
                                        content = f"{len(dataFrame)} new row of {entity_name} has been submitted for approval by {request.user.username}."
                                    else:
                                        if "{TransactionApprovers}" in message:
                                            approver_string = ""
                                            if approver_group:
                                                approver_string = ", ".join(approver_group)
                                            if approver_user:
                                                approver_string = ", ".join(approver_user)
                                            message = message.replace(
                                                "{TransactionApprovers}", approver_string
                                            )
                                        else:
                                            pass
                                        if "{TransactionCreatedBy}" in message:
                                            message = message.replace(
                                                "{TransactionCreatedBy}", request.user.username
                                            )
                                        else:
                                            pass
                                        if "{TransactionTime}" in message:
                                            message = message.replace(
                                                "{TransactionTime}", f"{datetime.now()}"
                                            )
                                        else:
                                            pass
                                        if "{ApproveButton}" in message or "{RejectButton}" in message:

                                            class UserObject:
                                                def __init__(self, i_dict):
                                                    for key, value in i_dict.items():
                                                        if key not in [
                                                            "password",
                                                            "last_login",
                                                            "date_joined",
                                                        ]:
                                                            setattr(self, key, value)
                                                        else:
                                                            continue

                                            if approver_user:
                                                approver_user_data = read_data_func(
                                                    request,
                                                    {
                                                        "inputs": {
                                                            "Data_source": "Database",
                                                            "Table": "User",
                                                            "Columns": ["id", "username", "email"],
                                                        },
                                                        "condition": [
                                                            {
                                                                "column_name": "username",
                                                                "condition": "IN",
                                                                "input_value": str(
                                                                    tuple(approver_user)
                                                                ).replace(",)", ")"),
                                                                "and_or": "",
                                                            }
                                                        ],
                                                    },
                                                ).to_dict("records")
                                            else:
                                                group_id = (
                                                    read_data_func(
                                                        request,
                                                        {
                                                            "inputs": {
                                                                "Data_source": "Database",
                                                                "Table": "auth_group",
                                                                "Columns": ["id"],
                                                            },
                                                            "condition": [
                                                                {
                                                                    "column_name": "name",
                                                                    "condition": "IN",
                                                                    "input_value": str(
                                                                        tuple(approver_group)
                                                                    ).replace(",)", ")"),
                                                                    "and_or": "",
                                                                }
                                                            ],
                                                        },
                                                    )
                                                ).id.tolist()
                                                if group_id:
                                                    user_ids = (
                                                        read_data_func(
                                                            request,
                                                            {
                                                                "inputs": {
                                                                    "Data_source": "Database",
                                                                    "Table": "user_groups",
                                                                    "Columns": ["user_id"],
                                                                },
                                                                "condition": [
                                                                    {
                                                                        "column_name": "group_id",
                                                                        "condition": "IN",
                                                                        "input_value": str(
                                                                            tuple(group_id)
                                                                        ).replace(",)", ")"),
                                                                        "and_or": "",
                                                                    }
                                                                ],
                                                            },
                                                        )
                                                    ).user_id.tolist()
                                                    if user_ids:
                                                        approver_user_data = (
                                                            read_data_func(
                                                                request,
                                                                {
                                                                    "inputs": {
                                                                        "Data_source": "Database",
                                                                        "Table": "User",
                                                                        "Columns": [
                                                                            "id",
                                                                            "username",
                                                                            "email",
                                                                        ],
                                                                    },
                                                                    "condition": [
                                                                        {
                                                                            "column_name": "id",
                                                                            "condition": "IN",
                                                                            "input_value": str(
                                                                                tuple(user_ids)
                                                                            ).replace(",)", ")"),
                                                                            "and_or": "",
                                                                        }
                                                                    ],
                                                                },
                                                            )
                                                        ).to_dict("records")
                                                    else:
                                                        approver_user_data = []
                                                else:
                                                    approver_user_data = []
                                            from rest_framework_simplejwt.tokens import RefreshToken

                                            for approver in approver_user_data:
                                                approver_object = UserObject(approver)
                                                refresh = RefreshToken.for_user(approver_object)
                                                approver_tokens[approver["email"]] = str(refresh.access_token)
                                        else:
                                            pass
                                        if "{ApproveButton}" in message:
                                            approve_link = f"{request.build_absolute_uri('/')[:-1]}/users/{app_code}/User/approval_table-ima/?token={{approver_token}}&app_code={app_code}&type=approvals&approve={approval_code}"
                                            if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                                approve_link = approve_link.replace("http", "https")
                                            else:
                                                pass
                                            message = message.replace("{ApproveButton}", approve_link)
                                        else:
                                            pass
                                        if "{InAppApproveButton}" in message:
                                            approve_link = f"{request.build_absolute_uri('/')[:-1]}/users/{app_code}/User/in-app-approve/{approval_code}/Approve"
                                            if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                                approve_link = approve_link.replace("http", "https")
                                            else:
                                                pass
                                            message = message.replace("{InAppApproveButton}", approve_link)
                                        else:
                                            pass
                                        if "{InRejectButton}" in message:
                                            approve_link = f"{request.build_absolute_uri('/')[:-1]}/users/{app_code}/User/in-app-approve/{approval_code}/Reject"
                                            if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                                approve_link = approve_link.replace("http", "https")
                                            else:
                                                pass
                                            message = message.replace("{InRejectButton}", approve_link)
                                        else:
                                            pass
                                        
                                        if "{domain}" in message:
                                            domain = request.build_absolute_uri("/")[:-1]
                                            if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                                domain = domain.replace("http", "https")
                                            else:
                                                pass
                                            message = message.replace("{domain}", f"{domain}")
                                        else:
                                            pass
                                        if "{app_code}" in message:
                                            url_string = request.path
                                            f_occ = url_string.find("/", url_string.find("/") + 1)
                                            s_occ = url_string.find("/", url_string.find("/") + f_occ + 1)
                                            app_code = url_string[f_occ + 1 : s_occ]
                                            message = message.replace("{app_code}", f"{app_code}")
                                        else:
                                            pass
                                        if "{RejectButton}" in message:
                                            approve_link = f"{request.build_absolute_uri('/')[:-1]}/users/{app_code}/User/approval_table-ima/?token={{approver_token}}&app_code={app_code}&type=approvals&reject={approval_code}"
                                            if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                                approve_link = approve_link.replace("http", "https")
                                            else:
                                                pass
                                            message = message.replace("{RejectButton}", approve_link)
                                        else:
                                            pass
                                        transaction_data_dict = json.loads(
                                            final_data_json_email[approval_code]
                                        )[0]
                                        for field in model_name1.concrete_fields:
                                            if f"VerboseName-{field.name}" in message:
                                                message = message.replace(
                                                    f"{{VerboseName-{field.name}}}", field.verbose_name
                                                )
                                            else:
                                                pass
                                            if f"Value-{field.name}" in message:
                                                if field.name in transaction_data_dict:
                                                    message = message.replace(
                                                        f"{{Value-{field.name}}}",
                                                        str(
                                                            replace_escape_chr_decode(
                                                                transaction_data_dict[field.name]
                                                            )
                                                        ),
                                                    )
                                                else:
                                                    message = message.replace(
                                                        f"{{Value-{field.name}}}", " - "
                                                    )
                                            else:
                                                continue
                                        content = message
                                    if approval_notification_subject:
                                        if "{TransactionApprovers}" in approval_notification_subject:
                                            approver_string = ""
                                            if approver_group:
                                                approver_string = ", ".join(approver_group)
                                            if approver_user:
                                                approver_string = ", ".join(approver_user)
                                            approval_notification_subject = (
                                                approval_notification_subject.replace(
                                                    "{TransactionApprovers}", approver_string
                                                )
                                            )
                                        else:
                                            pass
                                        if "{TransactionCreatedBy}" in approval_notification_subject:
                                            approval_notification_subject = (
                                                approval_notification_subject.replace(
                                                    "{TransactionCreatedBy}", request.user.username
                                                )
                                            )
                                        else:
                                            pass
                                        if "{TransactionTime}" in approval_notification_subject:
                                            approval_notification_subject = (
                                                approval_notification_subject.replace(
                                                    "{TransactionTime}", f"{datetime.now()}"
                                                )
                                            )
                                        else:
                                            pass
                                    else:
                                        approval_notification_subject = "Approval Notification"
                                    try:
                                        if "{approver_token}" in content:
                                            for i in to_list:
                                                approver_token = approver_tokens[i]
                                                email_content = content.replace(
                                                    "{approver_token}", approver_token
                                                )
                                                send_approval_mail(
                                                    request,
                                                    entity_name,
                                                    final_data_json_email,
                                                    [i],
                                                    email_content,
                                                    subject=approval_notification_subject,
                                                    in_system_approval=approvalInMailApprovalOption,
                                                    to_cc=additional_recipients["approval_recipient_list_cc"],
                                                    to_bcc=additional_recipients[
                                                        "approval_recipient_list_bcc"
                                                    ],
                                                    smtpConfigKey=smtpConfigKey,
                                                )
                                        else:
                                            send_approval_mail(
                                                request,
                                                entity_name,
                                                final_data_json_email,
                                                to_list,
                                                content,
                                                subject=approval_notification_subject,
                                                in_system_approval=approvalInMailApprovalOption,
                                                to_cc=additional_recipients["approval_recipient_list_cc"],
                                                to_bcc=additional_recipients["approval_recipient_list_bcc"],
                                                smtpConfigKey=smtpConfigKey,
                                            )
                                    except Exception as e:
                                        logging.warning(f"Following exception occured - {e}")
                                else:
                                    pass
                            else:
                                status = "fail"
                                end_time = time.time() - start_time
                                process_flow_monitor(
                                    element_id[0],
                                    item_code,
                                    app_code,
                                    request,
                                    FinalData,
                                    transaction_id,
                                    current_element_status="fail",
                                    current_element_message=f"{result[transaction_id]}",
                                    total_data="1",
                                    passed_data="0",
                                    run_time=round(end_time / 60, 2),
                                )
                        else:
                            data = flowValidation(element_id[0], item_code, request, transaction_id)
                            result = validation_result(
                                FinalData,
                                data,
                                {},
                                entity_name,
                                transaction_id=transaction_id,
                                request=request,
                                element_id=element_id[0],
                            )
                            if True in list(result.values()):
                                pass
                            else:
                                end_time = time.time() - start_time
                                process_flow_monitor(
                                    element_id[0],
                                    item_code,
                                    app_code,
                                    request,
                                    FinalData,
                                    transaction_id,
                                    current_element_status="fail",
                                    current_element_message=f"{result[transaction_id]}",
                                    total_data="1",
                                    passed_data="0",
                                    run_time=round(end_time / 60, 2),
                                )
                    if not dataFrame.empty:
                        data_handling(
                            request,
                            dataFrame,
                            "ApprovalTable",
                        )

    return FinalData_, len(FinalData) - len(FinalData_), status


def updateComp(sql_data, table_name, identifier_column, update_column, request):

    actmodelName = dynamic_model_create.get_model_class(table_name, request)
    fieldList = {field.verbose_name.title(): field.name for field in actmodelName.concrete_fields}
    for field in actmodelName.concrete_fields:
        fieldList[field.verbose_name] = field.name
    fieldList["Approval Status"] = "approval_status"
    fieldList["Approved By"] = "approved_by"

    status = "fail"
    for t_row in range(len(sql_data)):
        row_data = sql_data.iloc[t_row]
        update_config_dict = {
            "inputs": {
                "Data_source": "Database",
                "Table": table_name,
                "Columns": [],
            },
            "condition": [],
        }
        for id_index, id_col in enumerate(identifier_column):
            try:
                condition_dict = {
                    "column_name": id_col,
                    "condition": "Equal to",
                    "input_value": str(row_data[id_col]),
                    "and_or": "",
                }
            except Exception as e:
                logging.warning(f"Following exception occured - {e}")
                condition_dict = {
                    "column_name": fieldList[id_col],
                    "condition": "Equal to",
                    "input_value": str(row_data[fieldList[id_col]]),
                    "and_or": "",
                }
            if len(identifier_column) > 0 and (id_index != (len(identifier_column) - 1)):
                condition_dict["and_or"] = "AND"
            update_config_dict["condition"].append(condition_dict)

        for up_index, up_col in enumerate(update_column):
            try:
                column_dict = {
                    "column_name": up_col,
                    "input_value": str(row_data[up_col]),
                    "separator": ",",
                }
            except Exception as e:
                logging.warning(f"Following exception occured - {e}")
                column_dict = {
                    "column_name": fieldList[up_col],
                    "input_value": str(row_data[fieldList[up_col]]),
                    "separator": ",",
                }
            update_config_dict["inputs"]["Columns"].append(column_dict)

        update_config_dict["inputs"]["Columns"].append(
            {
                "column_name": "modified_date",
                "input_value": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "separator": ",",
            }
        )
        update_config_dict["inputs"]["Columns"].append(
            {
                "column_name": "modified_by",
                "input_value": request.user.username,
                "separator": "",
            }
        )

        data_val = sql_data.copy()
        f_data = data_preprocessing(
            data_val,
            table_name,
            request,
            customvalidation={},
            message_show="no",
            user_operation="update",
            export_data="yes",
            export_update_column=update_column,
        )
        FinalData_val = f_data.data_validation(message_out=False)

        if isinstance(FinalData_val, list):
            status = f"Failed to export data to {table_name} table as following validations failed - {FinalData_val[0][0]['error_description'].replace('Error while uploading:','')}"
        elif isinstance(FinalData_val, pd.DataFrame):

            update_data_func(request, update_config_dict, if_app_db=True)
            status = "pass"

    return status


def checkAug(child_element_id, request):
    is_aug = False
    aug_ = {}
    condition_data_ = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["tab_body_content"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": child_element_id,
                    "and_or": "and",
                },
                {
                    "column_name": "tab_type",
                    "condition": "Equal to",
                    "input_value": "flowController",
                    "and_or": "",
                },
            ],
        },
    )

    condition_data_check = condition_data_.to_dict("records")
    if len(condition_data_) > 0:
        if condition_data_check[0]["tab_body_content"] not in ["NULL", None]:
            aug_ = json.loads(condition_data_check[0]["tab_body_content"])
            if aug_.get("type") == "augmentation":
                is_aug = True

    return is_aug, aug_


def append_event_all(request, schema, usergroup_list, app_code, alert_type, events, alert_options):
    if isinstance(request, dict):

        class AttrDict:
            def __init__(self, i_dict):
                for key, value in i_dict.items():
                    if key not in ["password", "last_login", "date_joined"]:
                        setattr(self, key, value)
                if i_dict.get("username"):
                    setattr(self, "is_anonymous", False)
                else:
                    setattr(self, "is_anonymous", True)

            def get_host(self):
                return self.host

        request["user"] = AttrDict(request["user"])
        request = AttrDict(request)

    db_type = ""
    db_connection_name = None
    if os.path.exists(f"{PLATFORM_FILE_PATH}app_database_mapping.json"):
        with open(f"{PLATFORM_FILE_PATH}app_database_mapping.json") as json_file:
            db_connection_name = json.load(json_file).get(schema)
            json_file.close()
    user_db_engine, db_type = db_engine_extractor(db_connection_name)

    if alert_type != "Unauthorized alerts":
        check_exists = read_data_func(
            request="",
            config_dict={
                "inputs": {
                    "Data_source": "Database",
                    "Table": "alerts",
                    "Columns": ["*"],
                },
                "condition": [
                    {
                        "column_name": "app_code",
                        "condition": "Equal to",
                        "input_value": app_code,
                        "and_or": "and",
                    },
                    {
                        "column_name": "usergroup",
                        "condition": "IN",
                        "input_value": usergroup_list,
                        "and_or": "and",
                    },
                    {
                        "column_name": "alert_type",
                        "condition": "Equal to",
                        "input_value": alert_type,
                        "and_or": "and",
                    },
                    {
                        "column_name": "approval_status",
                        "condition": "Equal to",
                        "input_value": "approved",
                        "and_or": "and",
                    },
                    {
                        "column_name": "alert_owner",
                        "condition": "Not Equal to",
                        "input_value": "admin",
                        "and_or": "",
                    },
                ],
            },
            engine2=user_db_engine,
            db_type=db_type,
            engine_override=True,
        )
        if len(check_exists) > 0:
            for row in range(len(check_exists)):
                id_row = check_exists.iloc[row]["id"]
                existing = json.loads(check_exists.iloc[row]["events"])
                existing_alert = json.loads(check_exists.iloc[row]["alert_options"])

                if alert_type == "Application":
                    events_dict = {}
                    for e_id in events.keys():
                        if e_id not in existing.keys():
                            events_dict = existing
                            events_dict[e_id] = events[e_id]
                        else:
                            events_dict[e_id] = existing[e_id]
                            events_dict[e_id]["event"] = list(
                                set(events[e_id]["event"] + existing[e_id]["event"])
                            )
                    events = events_dict

                    for e_id in alert_options.keys():
                        if e_id not in existing_alert.keys():
                            existing_alert[e_id] = alert_options[e_id]
                    alert_options = existing_alert

                    update_data_func(
                        request="",
                        config_dict={
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "alerts",
                                "Columns": [
                                    {
                                        "column_name": "events",
                                        "input_value": json.dumps(events),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "alert_options",
                                        "input_value": json.dumps(alert_options),
                                        "separator": "",
                                    },
                                ],
                            },
                            "condition": [
                                {
                                    "column_name": "id",
                                    "condition": "Equal to",
                                    "input_value": str(id_row),
                                    "and_or": "",
                                },
                            ],
                        },
                        engine2=user_db_engine,
                        db_type=db_type,
                        engine_override=True,
                    )
                elif alert_type == "Access alerts":
                    existing_events = json.loads(check_exists.loc[0]["events"])
                    existing_alert = json.loads(check_exists.loc[0]["alert_options"])
                    events = list(set(existing_events + events))

                    for evt in alert_options.keys():
                        if evt not in existing_alert.keys():
                            existing_alert[evt] = alert_options[evt]
                    alert_options = existing_alert

                    update_data_func(
                        request="",
                        config_dict={
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "alerts",
                                "Columns": [
                                    {
                                        "column_name": "events",
                                        "input_value": json.dumps(events),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "alert_options",
                                        "input_value": json.dumps(alert_options),
                                        "separator": "",
                                    },
                                ],
                            },
                            "condition": [
                                {
                                    "column_name": "id",
                                    "condition": "Equal to",
                                    "input_value": str(id_row),
                                    "and_or": "",
                                },
                            ],
                        },
                        engine2=user_db_engine,
                        db_type=db_type,
                        engine_override=True,
                    )


def reject_all_approval(
    tablename,
    type_of_query,
    exceptions,
    ele_id,
    edited_data,
    approval_comment,
    request,
    t_id="",
    approval_id="",
    request2={},
):
    start_time = time.time()
    app_code, db_connection_name = current_app_db_extractor(request)

    ele_id = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "ApprovalTable",
                "Columns": [
                    "create_view_element_id",
                    "json_data",
                    "created_date",
                    "created_by",
                    "modified_date",
                    "modified_by",
                    "transaction_id",
                    "approval_decision_mailer_config",
                    "approval_audit_log",
                    "type_of_approval",
                    "approval_level_config",
                    "approver_type",
                    "current_decision_box_id",
                    "approval_code",
                    "approver_user",
                    "approval_information",
                ],
            },
            "condition": [
                {
                    "column_name": "id",
                    "condition": "Equal to",
                    "input_value": str(approval_id),
                    "and_or": "",
                }
            ],
        },
    )
    pd_data = ele_id
    modified_date = ele_id.iloc[0]["modified_date"]
    modified_by = ele_id.iloc[0]["modified_by"]
    transaction_id = ele_id.iloc[0]["transaction_id"]
    action_performed_by = ele_id.iloc[0]["created_by"]
    action_performed_on = ele_id.iloc[0]["created_date"]
    transaction_data_dict = json.loads(ele_id.iloc[0]["json_data"])[0]
    approval_decision_mailer_config = ele_id.iloc[0]["approval_decision_mailer_config"]
    approval_audit_log = ele_id.iloc[0]["approval_audit_log"]
    type_of_approval = ele_id.iloc[0]["type_of_approval"]
    approver_type = ele_id.iloc[0]["approver_type"]
    current_decision_box_id = ele_id.iloc[0]["current_decision_box_id"]
    approval_code = ele_id.iloc[0]["approval_code"]
    approver_user = ele_id.iloc[0]["approver_user"]
    approval_level_config = ele_id.approval_level_config.iloc[0]
    approval_information = ele_id.approval_information.iloc[0]

    current_approval_level = 0

    if approval_comment:
        approval_comment = replace_escape_chr_decode(approval_comment)

    if type_of_approval == "multi_level":
        approval_level_config = json.loads(ele_id.iloc[0]["approval_level_config"])
        current_approval_level = approval_level_config["current_level"]

    if approval_information:
        approval_information = json.loads(approval_information)
        if approval_information.get("approval_details"):
            if type_of_approval == "multi_level":
                approval_information["approval_details"]["level_config"][int(current_approval_level)][
                    "rejected_by"
                ] = [request.user.username]
            else:
                approval_information["approval_details"]["rejected_by"] = [request.user.username]
        else:
            pass
        approval_information = json.dumps(approval_information)
    else:
        approval_information = "NULL"

    current_code_id = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["related_item_code"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": ele_id["create_view_element_id"].iloc[0],
                    "and_or": "",
                }
            ],
        },
    )
    if not current_code_id.empty:
        pr_code = current_code_id["related_item_code"].iloc[0]
        condition_data = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "TabScreens",
                    "Columns": ["tab_body_content", "element_id"],
                },
                "condition": [
                    {
                        "column_name": "element_id",
                        "condition": "Equal to",
                        "input_value": current_decision_box_id,
                        "and_or": "",
                    }
                ],
            },
        )
        condition_data_check = condition_data.to_dict("records")
        if len(condition_data) > 0:
            condition_data_check = json.loads(condition_data_check[0]["tab_body_content"])

            createview_decision_type = condition_data_check["Category_sub_elements"][0][
                "Category_sub_element_attributes"
            ][1]["value"]["decision_type"]
            if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                "value"
            ].get("smtpConfigKey"):
                smtpConfigKey = condition_data_check["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][1]["value"]["smtpConfigKey"]
            else:
                smtpConfigKey = "default"
            if createview_decision_type == "Approval":
                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_decision_message_reject"):
                    reject_msg = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approval_decision_message_reject"]
                else:
                    reject_msg = ""
                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_decision_message_reject_subject"):
                    reject_msg_subject = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approval_decision_message_reject_subject"]
                else:
                    reject_msg_subject = ""
                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_notification_attachment_config"):
                    approval_notification_attachment_config = condition_data_check["Category_sub_elements"][
                        0
                    ]["Category_sub_element_attributes"][1]["value"][
                        "approval_notification_attachment_config"
                    ]
                else:
                    approval_notification_attachment_config = {}

        element_id = current_decision_box_id
        date_str = str(modified_date).split(":")
        date_str = str(date_str[0]) + ":" + str(date_str[1])
        if transaction_id not in [None, "NULL"]:
            is_match = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "Process_flow_model",
                        "Columns": ["modified_date", "flow", "total_batch_data", "pass_batch_data"],
                    },
                    "condition": [
                        {
                            "column_name": "transaction_id",
                            "condition": "Equal to",
                            "input_value": transaction_id,
                            "and_or": "and",
                        },
                        {
                            "column_name": "modified_by",
                            "condition": "Equal to",
                            "input_value": modified_by,
                            "and_or": "and",
                        },
                        {
                            "column_name": "element_id",
                            "condition": "Equal to",
                            "input_value": ele_id["create_view_element_id"].iloc[0],
                            "and_or": "and",
                        },
                        {
                            "column_name": "flow",
                            "condition": "Contains",
                            "input_value": element_id,
                            "and_or": "and",
                        },
                        {
                            "column_name": "current_status",
                            "condition": "Equal to",
                            "input_value": "Pass",
                            "and_or": "",
                        },
                    ],
                },
            )

        if approval_audit_log and approval_audit_log is not None:
            approval_audit_log_temp = json.loads(approval_audit_log)
            if type_of_approval != "multi_level":
                current_approval_level = 0
            temp_app_log_dict = {}
            temp_all_log = []
            if approval_comment:
                temp_all_log.append(
                    {
                        "action": "Comment",
                        "user": request.user.username,
                        "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "value": approval_comment,
                    }
                )
            temp_all_log.append(
                {
                    "action": "Rejected By",
                    "user": request.user.username,
                    "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "value": "",
                }
            )

            temp_app_log_dict[f"Level {current_approval_level}"] = temp_all_log
            approval_audit_log_temp.append(temp_app_log_dict)
            approval_audit_log = approval_audit_log_temp
        else:
            temp_app_log_dict = {}
            temp_all_log = []
            if approval_comment:
                temp_all_log.append(
                    {
                        "action": "Comment",
                        "user": request.user.username,
                        "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "value": approval_comment,
                    }
                )
            temp_all_log.append(
                {
                    "action": "Rejected By",
                    "user": request.user.username,
                    "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "value": "",
                }
            )

            temp_app_log_dict[f"Level {current_approval_level}"] = temp_all_log
            approval_audit_log = [temp_app_log_dict]

        final_approval_data = [
            {
                "column_name": "approval_status",
                "input_value": "Rejected",
                "separator": ",",
            },
            {
                "column_name": "modified_by",
                "input_value": request.user.username,
                "separator": ",",
            },
            {
                "column_name": "modified_date",
                "input_value": datetime.now(),
                "separator": ",",
            },
            {
                "column_name": "approval_audit_log",
                "input_value": json.dumps(approval_audit_log),
                "separator": ",",
            },
            {
                "column_name": "approval_information",
                "input_value": approval_information,
                "separator": "",
            },
        ]
        if approval_comment:
            final_approval_data = [
                {
                    "column_name": "approval_status",
                    "input_value": "Rejected",
                    "separator": ",",
                },
                {
                    "column_name": "modified_by",
                    "input_value": request.user.username,
                    "separator": ",",
                },
                {
                    "column_name": "modified_date",
                    "input_value": datetime.now(),
                    "separator": ",",
                },
                {
                    "column_name": "approval_comments",
                    "input_value": approval_comment,
                    "separator": ",",
                },
                {
                    "column_name": "approval_audit_log",
                    "input_value": json.dumps(approval_audit_log),
                    "separator": ",",
                },
                {
                    "column_name": "approval_information",
                    "input_value": approval_information,
                    "separator": "",
                },
            ]

        update_data_func(
            request,
            config_dict={
                "inputs": {
                    "Data_source": "Database",
                    "Table": "ApprovalTable",
                    "Columns": final_approval_data,
                },
                "condition": [
                    {
                        "column_name": "tablename",
                        "condition": "Equal to",
                        "input_value": tablename,
                        "and_or": "AND",
                    },
                    {
                        "column_name": "approval_status",
                        "condition": "Equal to",
                        "input_value": "Pending",
                        "and_or": "AND",
                    },
                    {
                        "column_name": "id",
                        "condition": "Equal to",
                        "input_value": str(approval_id),
                        "and_or": "",
                    },
                ],
            },
        )

        check_event_data = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "event_master",
                    "Columns": ["event", "action_config"],
                },
                "condition": [
                    {
                        "column_name": "approval_code",
                        "condition": "Equal to",
                        "input_value": approval_code,
                        "and_or": "",
                    }
                ],
            },
        )

        if len(check_event_data) > 0:
            action_config = json.loads(check_event_data.loc[0, "action_config"])
            message_job_id = action_config["job_id"]
            event_message = json.loads(check_event_data.loc[0, "event"])

            if "Rejected" in event_message:
                scheduler = Scheduler(connection=redis_instance_scheduler)
                scheduler.cancel(message_job_id)

                update_data_func(
                    request,
                    config_dict={
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "event_master",
                            "Columns": [
                                {
                                    "column_name": "event_triggered_by",
                                    "input_value": request.user.username,
                                    "separator": ",",
                                },
                                {
                                    "column_name": "event_triggered_date",
                                    "input_value": datetime.now(),
                                    "separator": "",
                                },
                            ],
                        },
                        "condition": [
                            {
                                "column_name": "approval_code",
                                "condition": "Equal to",
                                "input_value": approval_code,
                                "and_or": "",
                            }
                        ],
                    },
                )

        ## Email code starts here
        try:
            to_list = json.loads(approval_decision_mailer_config)
        except Exception as e:
            logging.warning(f"Following exception occured - {e}")
            to_list = []
        email_success = True
        if len(to_list) > 0:
            modelName = dynamic_model_create.get_model_class(tablename, request)
            content = ""
            if reject_msg:
                html_audit_log_table_notif = "<table border='1'><thead><tr><th>Level</th><th>Action</th><th>User</th><th>Time</th><th>Value</th></tr></thead>"

                for entry in approval_audit_log:
                    for level, log_entries in entry.items():
                        for log_entry in log_entries:
                            action = log_entry["action"]
                            user = log_entry["user"]
                            creation_time = log_entry["time"]
                            value = log_entry["value"]

                            html_audit_log_table_notif += f"<tbody><tr><td>{level}</td><td>{action}</td><td>{user}</td><td>{creation_time}</td><td>{value}</td></tr>"

                html_audit_log_table_notif += "</tbody></table>"

                if "{ApprovalLevelConfig}" in reject_msg:
                    user_table_data = (
                        read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "User",
                                    "Columns": [
                                        "username",
                                        "first_name",
                                        "last_name",
                                        "department",
                                        "contact_number",
                                    ],
                                },
                                "condition": [],
                            },
                        )
                    ).to_dict("records")
                    user_name_mapper = {}

                    for user_row in user_table_data:
                        user_name = user_row["username"]
                        user_name_mapper[user_name] = user_row

                    ApprovalLevelConfig_string = ""
                    approval_level_config_string = approval_level_config
                    approver_user_string_notif = approver_user
                    if approval_level_config_string is None:
                        if isinstance(approver_user_string_notif, str):
                            approver_user_string_notif = json.loads(approver_user_string_notif)
                        else:
                            pass
                        ApprovalLevelConfig_string = ", ".join(
                            [
                                f"{user_name_mapper[user]['username']} ({user_name_mapper[user]['first_name']} {user_name_mapper[user]['last_name']} {user_name_mapper[user]['department']} {user_name_mapper[user]['contact_number']})"
                                for user in approver_user_string_notif
                            ]
                        )
                    else:
                        approver_level_html = "<table style='width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;'>"
                        approver_level_html += "<thead><tr>"
                        approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Users List</th>"
                        approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Approval Type</th>"
                        approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Approver Type</th>"
                        approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Rejected By</th>"
                        approver_level_html += "</tr></thead>"
                        table_body_html = "<tbody>"
                        current_level = approval_level_config_string["current_level"]

                        for lvl_idx, data_dict in enumerate(approval_level_config_string["level_config"]):
                            row_html = "<tr>"
                            user_list = data_dict["user_list"]
                            user_info_str = " ".join(
                                [
                                    f"{user_name_mapper[user]['username']} ({user_name_mapper[user]['first_name']} {user_name_mapper[user]['last_name']} {user_name_mapper[user]['department']} {user_name_mapper[user]['contact_number']})"
                                    for user in user_list
                                ]
                            )
                            row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{user_info_str}</td>"

                            approval_type = data_dict.get("approval_type", "N/A")
                            approver_type = data_dict.get("approver_type", "N/A")
                            row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approval_type}</td>"
                            row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approver_type}</td>"
                            if str(lvl_idx) == str(current_level):
                                lvl_approved_by_users = [request.user.username]
                                approved_by_string = ", ".join(
                                    [
                                        f"{user_name_mapper[user]['username']} ({user_name_mapper[user]['first_name']} {user_name_mapper[user]['last_name']} {user_name_mapper[user]['department']} {user_name_mapper[user]['contact_number']})"
                                        for user in lvl_approved_by_users
                                    ]
                                )
                                row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approved_by_string}</td>"
                            else:
                                row_html += "<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'></td>"
                            row_html += "</tr>"
                            table_body_html += row_html

                        table_body_html += "</tbody>"
                        approver_level_html += table_body_html
                        approver_level_html += "</table>"

                        ApprovalLevelConfig_string = approver_level_html

                    reject_msg = reject_msg.replace("{ApprovalLevelConfig}", ApprovalLevelConfig_string)
                if "{ApprovalType}" in reject_msg:
                    ApprovalType_string = approver_type
                    reject_msg = reject_msg.replace("{ApprovalType}", ApprovalType_string)
                else:
                    pass
                if "{ApproverAuditLog}" in reject_msg:
                    reject_msg = reject_msg.replace("{ApproverAuditLog}", html_audit_log_table_notif)
                else:
                    pass
                if "{TransactionRejectedBy}" in reject_msg:
                    reject_msg = reject_msg.replace("{TransactionRejectedBy}", request.user.username)
                else:
                    pass
                if "{TransactionRejectedBy-Name}" in reject_msg:
                    reject_msg = reject_msg.replace(
                        "{TransactionRejectedBy-Name}", f"{request.user.first_name} {request.user.last_name}"
                    )
                else:
                    pass
                if "{TransactionCreatedBy}" in reject_msg:
                    reject_msg = reject_msg.replace("{TransactionCreatedBy}", action_performed_by)
                else:
                    pass
                if "{TransactionTime}" in reject_msg:
                    reject_msg = reject_msg.replace("{TransactionTime}", f"{action_performed_on}")
                else:
                    pass
                if "{TransactionRejectionTime}" in reject_msg:
                    reject_msg = reject_msg.replace("{TransactionRejectionTime}", f"{datetime.now()}")
                else:
                    pass
                if "{TransactionApproverComment}" in reject_msg:
                    reject_msg = reject_msg.replace("{TransactionApproverComment}", approval_comment)
                else:
                    pass
                if "{TransactionCreatedBy-Name}" in reject_msg:
                    user_names = read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "User",
                                "Columns": ["first_name", "last_name"],
                            },
                            "condition": [
                                {
                                    "column_name": "username",
                                    "condition": "Equal to",
                                    "input_value": action_performed_by,
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                    user_names["name"] = user_names["first_name"] + " " + user_names["last_name"]
                    approver_string = user_names["name"].tolist()[0]
                    reject_msg = reject_msg.replace("{TransactionCreatedBy-Name}", approver_string)
                else:
                    pass
                for field in modelName.concrete_fields:
                    if f"VerboseName-{field.name}" in reject_msg:
                        reject_msg = reject_msg.replace(f"{{VerboseName-{field.name}}}", field.verbose_name)
                    else:
                        pass
                    if f"Value-{field.name}" in reject_msg:
                        if field.name in transaction_data_dict:
                            if (
                                modelName.get_field(field.name).internal_type == "ForeignKey"
                                and transaction_data_dict[field.name]
                            ):
                                actual_values_for_idx = read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": modelName.get_field(field.name).parent,
                                            "Columns": [field.name],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "id",
                                                "condition": "Equal to",
                                                "input_value": str(transaction_data_dict[field.name]),
                                                "and_or": "",
                                            },
                                        ],
                                    },
                                    access_controller=False,
                                )[field.name].to_list()
                                if actual_values_for_idx:
                                    transaction_data_dict[field.name] = actual_values_for_idx[0]
                                else:
                                    pass
                            reject_msg = reject_msg.replace(
                                f"{{Value-{field.name}}}",
                                str(replace_escape_chr_decode(transaction_data_dict[field.name])),
                            )
                        else:
                            reject_msg = reject_msg.replace(f"{{Value-{field.name}}}", " - ")
                    else:
                        continue
                content = reject_msg
            else:
                content = f"1 row of {tablename} has been rejected by {request.user.username}."
                if approval_comment:
                    content = content + f"\nComment: {approval_comment}"
            if reject_msg_subject:
                if "{TransactionRejectedBy}" in reject_msg_subject:
                    reject_msg_subject = reject_msg_subject.replace(
                        "{TransactionRejectedBy}", request.user.username
                    )
                else:
                    pass
                if "{TransactionRejectedBy-Name}" in reject_msg_subject:
                    reject_msg_subject = reject_msg_subject.replace(
                        "{TransactionRejectedBy-Name}", f"{request.user.first_name} {request.user.last_name}"
                    )
                else:
                    pass
                if "{TransactionCreatedBy}" in reject_msg_subject:
                    reject_msg_subject = reject_msg_subject.replace(
                        "{TransactionCreatedBy}", action_performed_by
                    )
                else:
                    pass
                if "{TransactionTime}" in reject_msg_subject:
                    reject_msg_subject = reject_msg_subject.replace(
                        "{TransactionTime}", f"{action_performed_on}"
                    )
                else:
                    pass
                if "{TransactionCreatedBy-Name}" in reject_msg_subject:
                    user_names = read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "User",
                                "Columns": ["first_name", "last_name"],
                            },
                            "condition": [
                                {
                                    "column_name": "username",
                                    "condition": "Equal to",
                                    "input_value": action_performed_by,
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                    user_names["name"] = user_names["first_name"] + " " + user_names["last_name"]
                    approver_string = user_names["name"].tolist()[0]
                    reject_msg_subject = reject_msg_subject.replace(
                        "{TransactionCreatedBy-Name}", approver_string
                    )
                else:
                    pass

                for field in modelName.concrete_fields:
                    if f"VerboseName-{field.name}" in reject_msg_subject:
                        reject_msg_subject = reject_msg_subject.replace(
                            f"{{VerboseName-{field.name}}}", field.verbose_name
                        )
                    else:
                        pass
                    if f"Value-{field.name}" in reject_msg_subject:
                        if field.name in transaction_data_dict:
                            if (
                                modelName.get_field(field.name).internal_type == "ForeignKey"
                                and transaction_data_dict[field.name]
                            ):
                                actual_values_for_idx = read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": modelName.get_field(field.name).parent,
                                            "Columns": [field.name],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "id",
                                                "condition": "Equal to",
                                                "input_value": str(transaction_data_dict[field.name]),
                                                "and_or": "",
                                            },
                                        ],
                                    },
                                    access_controller=False,
                                )[field.name].to_list()
                                if actual_values_for_idx:
                                    transaction_data_dict[field.name] = actual_values_for_idx[0]
                                else:
                                    pass
                            reject_msg_subject = reject_msg_subject.replace(
                                f"{{Value-{field.name}}}",
                                str(replace_escape_chr_decode(transaction_data_dict[field.name])),
                            )
                        else:
                            reject_msg_subject = reject_msg_subject.replace(f"{{Value-{field.name}}}", " - ")
                    else:
                        continue

            else:
                reject_msg_subject = "Approval Decision Notification"
            for field in modelName.concrete_fields:
                if (
                    field.name in transaction_data_dict
                    and field.internal_type == "FileField"
                    and transaction_data_dict[field.name]
                    and str(transaction_data_dict[field.name]) != "nan"
                    and approval_notification_attachment_config.get("addUploadedFilesAsAttachment") == "Yes"
                ):
                    file_names = transaction_data_dict[field.name]
                    additional_attachment_file_names = {
                        i: f"{MEDIA_ROOT}/uploaded_files/{i}" for i in file_names.split(", ")
                    }
                    approval_notification_attachment_config["additional_attachments"] = (
                        additional_attachment_file_names
                    )
                else:
                    continue
            try:
                if type(to_list) == list:
                    recipients_to = to_list
                    recipients_cc = []
                    recipients_bcc = []
                else:
                    recipients_to = to_list["recipient_to"]
                    recipients_cc = to_list["recipient_cc"]
                    recipients_bcc = to_list["recipient_bcc"]
                send_approval_mail(
                    request,
                    tablename,
                    {approval_code: json.dumps([transaction_data_dict])},
                    recipients_to,
                    content,
                    subject=reject_msg_subject,
                    in_system_approval=False,
                    to_cc=recipients_cc,
                    to_bcc=recipients_bcc,
                    attachments_config=approval_notification_attachment_config,
                    smtpConfigKey=smtpConfigKey,
                    user_name_mapper=[],
                )
            except Exception as e:
                logging.warning(f"Following exception occured - {e}")
                messages.error(
                    request,
                    "Error while sending approval email notification. Kindly check the SMTP configuration in management console or contact your administrator.",
                )
                email_success = False
        if transaction_id not in [None, "NULL"]:
            if not is_match.empty:
                pass_batch_data = is_match.iloc[0]["pass_batch_data"]
                if not is_match.empty:
                    transaction_id_ = [transaction_id]
                    for transaction_id in transaction_id_:
                        transaction_id = json.dumps([transaction_id])
                        data = flowValidation(
                            element_id,
                            getPrCodeFromElementId(element_id, request),
                            request,
                            transaction_id=transaction_id,
                        )
                        result = validation_result(
                            [[]],
                            data,
                            {},
                            tablename,
                            email_success,
                            transaction_id=transaction_id,
                            request=request,
                            element_id=element_id,
                        )
                        exception = ""
                        exception = exception + f"1 out of {pass_batch_data} rejected by approver"
                        if True in list(result.values()):
                            pass
                        else:
                            exception = exception + str(result)
                        info_data = checkLatestData(
                            pd_data,
                            element_id,
                            "table",
                            request,
                            json.loads(transaction_id),
                            "pass_batch",
                        )
                        update_data_func(
                            request,
                            config_dict={
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Process_flow_model",
                                    "Columns": [
                                        {
                                            "column_name": "pass_batch_data",
                                            "input_value": info_data[(json.loads(transaction_id))[0]][
                                                "data_left"
                                            ],
                                            "separator": "",
                                        },
                                    ],
                                },
                                "condition": [
                                    {
                                        "column_name": "transaction_id",
                                        "condition": "IN",
                                        "input_value": json.loads(transaction_id),
                                        "and_or": "and",
                                    },
                                    {
                                        "column_name": "flow",
                                        "condition": "Contains",
                                        "input_value": element_id,
                                        "and_or": "and",
                                    },
                                    {
                                        "column_name": "(element_id",
                                        "condition": "Equal to",
                                        "input_value": element_id,
                                        "and_or": "or",
                                    },
                                    {
                                        "column_name": "element_id",
                                        "condition": "Equal to",
                                        "input_value": ele_id["create_view_element_id"].iloc[0],
                                        "and_or": ")",
                                    },
                                ],
                            },
                        )
                        end_time = time.time() - start_time
                        process_flow_monitor(
                            element_id,
                            getPrCodeFromElementId(element_id, request),
                            app_code,
                            request,
                            None,
                            json.loads(transaction_id)[0],
                            current_element_status="fail",
                            current_element_message=str(exception),
                            total_data="1",
                            passed_data="0",
                            run_time=round(end_time / 60, 2),
                        )

            else:
                pr_code = ""
        else:
            pr_code = ""
        redirect_config, status = active_flow_element(request, "approval")
        pr_code_redirect = ""
        if status:
            pr_code_redirect = redirect_config["subprocess"]
        return {"response": "success", "pr_code": pr_code, "pr_code_redirect": pr_code_redirect}

    else:
        return {"response": "fail", "pr_code": ""}


def approve_all_approval(
    tablename,
    type_of_query,
    exceptions,
    ele_id,
    edited_data,
    approval_comment,
    request,
    t_id="",
    approval_id="",
    request2={},
):
    def request_to_dict(request):
        user_dict = request.user.__class__.objects.filter(pk=request.user.id).values().first()
        request2 = {"path": request.path, "host": request.get_host(), "user": user_dict}
        return request2

    start_time = time.time()
    app_code, db_connection_name = current_app_db_extractor(request)

    ele_id = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "ApprovalTable",
                "Columns": ["*"],
            },
            "condition": [
                {
                    "column_name": "id",
                    "condition": "Equal to",
                    "input_value": str(approval_id),
                    "and_or": "",
                }
            ],
        },
    )
    approval_data = ele_id.copy()
    modified_date = ele_id.iloc[0]["modified_date"]
    modified_by = ele_id.iloc[0]["modified_by"]
    transaction_id = ele_id.iloc[0]["transaction_id"]
    current_decision_box_id = ele_id.iloc[0]["current_decision_box_id"]
    action_performed_by = ele_id.iloc[0]["created_by"]
    action_performed_on = ele_id.iloc[0]["created_date"]
    approver_type = ele_id.iloc[0]["approver_type"]
    approver_group = ele_id.iloc[0]["approver_group"]
    approver_user = ele_id.iloc[0]["approver_user"]
    approved_by = ele_id.iloc[0]["approved_by"]
    approval_comments_pr = ele_id.iloc[0]["approval_comments"]
    approval_audit_log = ele_id.iloc[0]["approval_audit_log"]
    approval_code = ele_id.iloc[0]["approval_code"]
    data_sent_for_approval = json.loads(ele_id.iloc[0]["json_data"])
    type_of_approval = ele_id.type_of_approval.iloc[0]
    approval_level_config = ele_id.approval_level_config.iloc[0]
    approval_information = ele_id.approval_information.iloc[0]
    temp_app_dict = {}

    if approval_comment:
        approval_comment = replace_escape_chr_decode(approval_comment)

    if approval_comments_pr is not None and approval_comments_pr:
        if approval_comments_pr.startswith("{") and approval_comments_pr.endswith("}"):
            old_message = json.loads(approval_comments_pr)
            if old_message:
                last_level = int(list(old_message.keys())[-1].split("___")[1]) + 1
            else:
                last_level = "1"
            if approval_comment:
                old_message[request.user.username + "___" + str(last_level)] = approval_comment
            else:
                old_message[request.user.username + "___" + str(last_level)] = "No approval comments"
            temp_app_dict = old_message
    else:
        if approval_comment:
            temp_app_dict[request.user.username + "___1"] = approval_comment
        else:
            temp_app_dict[request.user.username + "___1"] = "No approval comments"
    # Joint Approval Check
    if approved_by:
        approved_by_dict = json.loads(approved_by)
    else:
        approved_by_dict = {}
    approved_by_users = []
    if approval_information:
        approval_information = json.loads(approval_information)
    else:
        pass
    if type_of_approval == "multi_level":
        if approval_level_config:
            approval_level_config = json.loads(approval_level_config)
            current_approval_level = str(approval_level_config["current_level"])
            if approved_by_dict.get(current_approval_level):
                if request.user.username not in approved_by_dict[current_approval_level]:
                    approved_by_dict[current_approval_level].append(request.user.username)
                else:
                    pass
            else:
                approved_by_dict[current_approval_level] = [request.user.username]
            approved_by_users = approved_by_dict[current_approval_level]
            if approval_information:
                approval_information["approval_details"]["level_config"][int(current_approval_level)][
                    "approved_by"
                ] = approved_by_users
            else:
                pass
        else:
            pass
    else:
        if approved_by_dict.get("0"):
            if request.user.username not in approved_by_dict["0"]:
                approved_by_dict["0"].append(request.user.username)
            else:
                pass
        else:
            approved_by_dict["0"] = [request.user.username]
        approved_by_users = approved_by_dict["0"]
        if approval_information:
            approval_information["approval_details"]["approved_by"] = approved_by_users
        else:
            pass

    if approval_information:
        approval_information = json.dumps(approval_information)
    else:
        approval_information = "NULL"
    if approver_type == "joint":
        if approver_group:
            approver_group = json.loads(approver_group)
            if approver_group:
                group_ids = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "auth_group",
                            "Columns": ["id"],
                        },
                        "condition": [
                            {
                                "column_name": "name",
                                "condition": "IN",
                                "input_value": str(tuple(approver_group)).replace(",)", ")"),
                                "and_or": "",
                            }
                        ],
                    },
                ).id.tolist()
                user_in_the_group = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "user_groups",
                            "Columns": ["user_id"],
                        },
                        "condition": [
                            {
                                "column_name": "group_id",
                                "condition": "IN",
                                "input_value": str(tuple(group_ids)).replace(",)", ")"),
                                "and_or": "",
                            }
                        ],
                    },
                ).user_id.tolist()
                user_lists = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "user",
                            "Columns": ["username"],
                        },
                        "condition": [
                            {
                                "column_name": "id",
                                "condition": "IN",
                                "input_value": str(tuple(user_in_the_group)).replace(",)", ")"),
                                "and_or": "",
                            }
                        ],
                    },
                ).username.tolist()
                if set(user_lists) - set(approved_by_users):

                    if approval_audit_log and approval_audit_log is not None:
                        approval_audit_log_temp = json.loads(approval_audit_log)
                        temp_app_log_dict = {}
                        temp_all_log = []
                        if approval_comment:
                            temp_all_log.append(
                                {
                                    "action": "Comment",
                                    "user": request.user.username,
                                    "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "value": approval_comment,
                                }
                            )
                        temp_all_log.append(
                            {
                                "action": "Approved By",
                                "user": request.user.username,
                                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "value": "",
                            }
                        )

                        temp_app_log_dict["Level 0"] = temp_all_log
                        approval_audit_log_temp.append(temp_app_log_dict)
                        approval_audit_log = approval_audit_log_temp
                    else:
                        temp_app_log_dict = {}
                        temp_all_log = []
                        if approval_comment:
                            temp_all_log.append(
                                {
                                    "action": "Comment",
                                    "user": request.user.username,
                                    "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "value": approval_comment,
                                }
                            )
                        temp_all_log.append(
                            {
                                "action": "Approved By",
                                "user": request.user.username,
                                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "value": "",
                            }
                        )

                        temp_app_log_dict["Level 0"] = temp_all_log
                        approval_audit_log = [temp_app_log_dict]

                    update_data_func(
                        request=request,
                        config_dict={
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "ApprovalTable",
                                "Columns": [
                                    {
                                        "column_name": "approved_by",
                                        "input_value": json.dumps(approved_by_dict),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "approval_audit_log",
                                        "input_value": json.dumps(approval_audit_log),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "approval_information",
                                        "input_value": approval_information,
                                        "separator": "",
                                    },
                                ],
                            },
                            "condition": [
                                {
                                    "column_name": "id",
                                    "condition": "Equal to",
                                    "input_value": str(approval_id),
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                    return {"response": "success", "pr_code": "", "pr_code_redirect": ""}
                else:
                    pass
            else:
                pass
        else:
            pass
        if approver_user:
            approver_user = json.loads(approver_user)
            if set(approver_user) - set(approved_by_users):

                if approval_audit_log and approval_audit_log is not None:
                    approval_audit_log_temp = json.loads(approval_audit_log)
                    temp_app_log_dict = {}
                    temp_all_log = []
                    if approval_comment:
                        temp_all_log.append(
                            {
                                "action": "Comment",
                                "user": request.user.username,
                                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "value": approval_comment,
                            }
                        )
                    temp_all_log.append(
                        {
                            "action": "Approved By",
                            "user": request.user.username,
                            "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "value": "",
                        }
                    )

                    temp_app_log_dict["Level 0"] = temp_all_log
                    approval_audit_log_temp.append(temp_app_log_dict)
                    approval_audit_log = approval_audit_log_temp
                else:
                    temp_app_log_dict = {}
                    temp_all_log = []
                    if approval_comment:
                        temp_all_log.append(
                            {
                                "action": "Comment",
                                "user": request.user.username,
                                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "value": approval_comment,
                            }
                        )
                    temp_all_log.append(
                        {
                            "action": "Approved By",
                            "user": request.user.username,
                            "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "value": "",
                        }
                    )

                    temp_app_log_dict["Level 0"] = temp_all_log
                    approval_audit_log = [temp_app_log_dict]

                update_data_func(
                    request=request,
                    config_dict={
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "ApprovalTable",
                            "Columns": [
                                {
                                    "column_name": "approved_by",
                                    "input_value": json.dumps(approved_by_dict),
                                    "separator": ",",
                                },
                                {
                                    "column_name": "approval_audit_log",
                                    "input_value": json.dumps(approval_audit_log),
                                    "separator": ",",
                                },
                                {
                                    "column_name": "approval_information",
                                    "input_value": approval_information,
                                    "separator": "",
                                },
                            ],
                        },
                        "condition": [
                            {
                                "column_name": "id",
                                "condition": "Equal to",
                                "input_value": str(approval_id),
                                "and_or": "",
                            }
                        ],
                    },
                )
                return {"response": "success", "pr_code": "", "pr_code_redirect": ""}
            else:
                pass
        else:
            pass
    else:
        pass

    current_code_id = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["related_item_code"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": ele_id["create_view_element_id"].iloc[0],
                    "and_or": "",
                }
            ],
        },
    )
    if not current_code_id.empty:
        pr_code = current_code_id.iloc[0]["related_item_code"]
        condition_data = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "TabScreens",
                    "Columns": ["tab_body_content"],
                },
                "condition": [
                    {
                        "column_name": "element_id",
                        "condition": "Equal to",
                        "input_value": current_decision_box_id,
                        "and_or": "",
                    }
                ],
            },
        )
        condition_data_check = condition_data.to_dict("records")
        decision_action = "Approval"
        approver_mailer_type = "static"
        approve_msg = ""
        approve_msg_subject = ""
        approver_mailer_type = "static"
        approval_mail_additional_config = {}
        approversDispFields = ["username"]
        approversDispFormat = ","
        if len(condition_data) > 0:
            condition_data_check = json.loads(condition_data_check[0]["tab_body_content"])

            createview_decision_type = condition_data_check["Category_sub_elements"][0][
                "Category_sub_element_attributes"
            ][1]["value"]["decision_type"]
            if createview_decision_type == "Approval":
                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_decision_message_approve"):
                    approve_msg = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approval_decision_message_approve"]
                else:
                    approve_msg = ""
                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_decision_message_approve_subject"):
                    approve_msg_subject = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approval_decision_message_approve_subject"]
                else:
                    approve_msg_subject = ""
                decision_action = condition_data_check["Category_sub_elements"][0][
                    "Category_sub_element_attributes"
                ][1]["value"]["actions"]
                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approver_mailer_type"):
                    approver_mailer_type = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approver_mailer_type"]
                else:
                    approver_mailer_type = "static"
                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approval_mail_additional_config"):
                    approval_mail_additional_config = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approval_mail_additional_config"]
                else:
                    approval_mail_additional_config = {}

                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approversDispFields"):
                    approversDispFields = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approversDispFields"]
                else:
                    approversDispFields = ["username"]

                if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                    "value"
                ].get("approversDispFormat"):
                    approversDispFormat = condition_data_check["Category_sub_elements"][0][
                        "Category_sub_element_attributes"
                    ][1]["value"]["approversDispFormat"]
                    if approversDispFormat == "space_sep":
                        approversDispFormat = " "
                    else:
                        approversDispFormat = ","
                else:
                    approversDispFormat = ","

        modelName = dynamic_model_create.get_model_class(tablename, request)

        columns = [field.name for field in modelName.concrete_fields]
        approval_decision_mailer_config = approval_data.approval_decision_mailer_config.iloc[0]
        hierarchy_approval_config = approval_data.hierarchy_group.iloc[0]
        approval_type = approval_data.approval_type.iloc[0]
        if edited_data.get(approval_id) not in [None, '"NULL"', "NULL", "None", "N"]:
            data_ = json.loads(approval_data["json_data"].iloc[0])[0]
            for key, value in edited_data[approval_id].items():
                if value.get("value") not in [None]:
                    data_[key] = value["value"]
            approval_data = [json.dumps([data_])]
            approval_data_edit = [json.dumps([data_])]
        else:
            approval_data_edit = approval_data["json_data"].to_list()
            approval_data = approval_data["json_data"].tolist()
        exceptions = ""

        if type_of_approval in ["hierarchical", "hierarchical_user"]:
            if hierarchy_approval_config:
                hierarchy_approval_config = json.loads(hierarchy_approval_config)
            else:
                pass
            if type_of_approval == "hierarchical":
                user_or_group = "group"
                approver_field = "approver_group"
            else:
                user_or_group = "user"
                approver_field = "approver_user"
            hierarchy_check_status, hierarchy_next_level = hierarchy_approval_group_extractor(
                request, hierarchy_approval_config, user_or_group
            )
            if hierarchy_check_status == "Success" and hierarchy_next_level:
                next_level_approver_group = [hierarchy_next_level]
                hierarchy_approval_config["current_level_name"] = hierarchy_next_level
                hierarchy_approval_config["current_level"] = (
                    f"{int(hierarchy_approval_config['current_level']) - 1}"
                )
                update_data_func(
                    request,
                    config_dict={
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "ApprovalTable",
                            "Columns": [
                                {
                                    "column_name": approver_field,
                                    "input_value": json.dumps(next_level_approver_group),
                                    "separator": ",",
                                },
                                {
                                    "column_name": "hierarchy_group",
                                    "input_value": json.dumps(hierarchy_approval_config),
                                    "separator": ",",
                                },
                                {
                                    "column_name": "modified_by",
                                    "input_value": request.user.username,
                                    "separator": ",",
                                },
                                {
                                    "column_name": "modified_date",
                                    "input_value": datetime.now(),
                                    "separator": ",",
                                },
                                {
                                    "column_name": "approved_by",
                                    "input_value": json.dumps(approved_by_dict),
                                    "separator": ",",
                                },
                                {
                                    "column_name": "approval_comments",
                                    "input_value": approval_comment,
                                    "separator": "",
                                },
                            ],
                        },
                        "condition": [
                            {
                                "column_name": "tablename",
                                "condition": "Equal to",
                                "input_value": tablename,
                                "and_or": "AND",
                            },
                            {
                                "column_name": "id",
                                "condition": "Equal to",
                                "input_value": str(approval_id),
                                "and_or": "",
                            },
                        ],
                    },
                )
                return {"response": "success", "pr_code": pr_code, "pr_code_redirect": ""}
        elif type_of_approval == "multi_level":
            if approval_level_config:
                current_approval_level = approval_level_config["current_level"]
                level_configs = approval_level_config["level_config"]
                if current_approval_level < len(level_configs) and (
                    current_approval_level != len(level_configs) - 1
                ):
                    if approval_audit_log and approval_audit_log is not None:
                        approval_audit_log_temp = json.loads(approval_audit_log)
                        temp_app_log_dict = {}
                        temp_all_log = []
                        if approval_comment:
                            temp_all_log.append(
                                {
                                    "action": "Comment",
                                    "user": request.user.username,
                                    "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "value": approval_comment,
                                }
                            )
                        temp_all_log.append(
                            {
                                "action": "Approved By",
                                "user": request.user.username,
                                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "value": "",
                            }
                        )

                        temp_app_log_dict[f"Level {current_approval_level}"] = temp_all_log
                        approval_audit_log_temp.append(temp_app_log_dict)
                        approval_audit_log = approval_audit_log_temp
                    else:
                        temp_app_log_dict = {}
                        temp_all_log = []
                        if approval_comment:
                            temp_all_log.append(
                                {
                                    "action": "Comment",
                                    "user": request.user.username,
                                    "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "value": approval_comment,
                                }
                            )
                        temp_all_log.append(
                            {
                                "action": "Approved By",
                                "user": request.user.username,
                                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "value": "",
                            }
                        )

                        temp_app_log_dict[f"Level {current_approval_level}"] = temp_all_log
                        approval_audit_log = [temp_app_log_dict]

                    approval_level_config["current_level"] = current_approval_level + 1
                    (
                        approver_group,
                        approver_user,
                        __hac__,
                        approval_recipient_list,
                        __adrl__,
                        approval_level_config,
                        approver_type,
                        additional_recipients,
                        skipFinalLevel,
                    ) = approvals_information_extractor(
                        request,
                        pd.DataFrame(json.loads(approval_data[0])),
                        type_of_approval,
                        approval_level_config,
                        decision_action,
                        approver_mailer_type,
                        "static",
                        [],
                        [],
                        modelName,
                        approval_mail_additional_config,
                    )
                    update_data_func(
                        request,
                        config_dict={
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "ApprovalTable",
                                "Columns": [
                                    {
                                        "column_name": "approver_group",
                                        "input_value": json.dumps(approver_group),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "approver_user",
                                        "input_value": json.dumps(approver_user),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "approval_level_config",
                                        "input_value": json.dumps(approval_level_config),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "modified_by",
                                        "input_value": request.user.username,
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "modified_date",
                                        "input_value": datetime.now(),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "approved_by",
                                        "input_value": json.dumps(approved_by_dict),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "approver_type",
                                        "input_value": approver_type,
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "approval_comments",
                                        "input_value": json.dumps(temp_app_dict),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "approval_audit_log",
                                        "input_value": json.dumps(approval_audit_log),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "approval_information",
                                        "input_value": approval_information,
                                        "separator": "",
                                    },
                                ],
                            },
                            "condition": [
                                {
                                    "column_name": "tablename",
                                    "condition": "Equal to",
                                    "input_value": tablename,
                                    "and_or": "AND",
                                },
                                {
                                    "column_name": "id",
                                    "condition": "Equal to",
                                    "input_value": str(approval_id),
                                    "and_or": "",
                                },
                            ],
                        },
                    )
                    if approval_recipient_list:
                        approver_tokens = {}
                        if condition_data_check["Category_sub_elements"][0][
                            "Category_sub_element_attributes"
                        ][1]["value"].get("message"):
                            notification_msg = condition_data_check["Category_sub_elements"][0][
                                "Category_sub_element_attributes"
                            ][1]["value"]["message"]
                            if "{TransactionApprovers}" in notification_msg:
                                approver_string = ""
                                if approver_group:
                                    approver_string = ", ".join(approver_group)
                                if approver_user:
                                    approver_string = ", ".join(approver_user)
                                notification_msg = notification_msg.replace(
                                    "{TransactionApprovers}", approver_string
                                )
                            else:
                                pass
                            if "{ApprovalLevelConfig}" in notification_msg:
                                user_table_data = (
                                    read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": [
                                                    "username",
                                                    "first_name",
                                                    "last_name",
                                                    "department",
                                                    "contact_number",
                                                ],
                                            },
                                            "condition": [],
                                        },
                                    )
                                ).fillna(" ")
                                user_table_data = user_table_data.to_dict("records")
                                user_name_mapper = {}

                                for user_row in user_table_data:
                                    user_name = user_row["username"]
                                    user_name_mapper[user_name] = user_row

                                ApprovalLevelConfig_string = ""
                                approval_level_config_string = approval_level_config
                                approver_user_string = approver_user
                                if approval_level_config_string is None:
                                    ApprovalLevelConfig_string = ", ".join(approver_user_string)
                                else:
                                    approver_level_html = "<table style='width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;'>"
                                    approver_level_html += "<thead><tr>"
                                    approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Users List</th>"
                                    approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Approval Type</th>"
                                    approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Approver Type</th>"
                                    approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Approved By</th>"
                                    approver_level_html += "</tr></thead>"
                                    table_body_html = "<tbody>"

                                    for lvl_idx, data_dict in enumerate(
                                        approval_level_config_string["level_config"]
                                    ):
                                        row_html = "<tr>"
                                        if data_dict.get("user_list"):
                                            user_list = data_dict["user_list"]
                                            user_info_str = " ".join(
                                                [
                                                    f"{user_name_mapper[user]['username']} ({user_name_mapper[user]['first_name']} {user_name_mapper[user]['last_name']} {user_name_mapper[user]['department']} {user_name_mapper[user]['contact_number']})"
                                                    for user in user_list
                                                ]
                                            )
                                            row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{user_info_str}</td>"
                                        elif data_dict.get("group_list"):
                                            group_list = data_dict["group_list"]
                                            group_info_str = " ,".join(group_list)
                                            row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{group_info_str}</td>"
                                        else:
                                            approval_info_str = f"{data_dict['approval_type']}"
                                            row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approval_info_str}</td>"

                                        approval_type = data_dict.get("approval_type", "N/A")
                                        approver_type = data_dict.get("approver_type", "N/A")
                                        row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approval_type}</td>"
                                        row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approver_type}</td>"

                                        if approved_by_dict.get(f"{lvl_idx}"):
                                            lvl_approved_by_users = approved_by_dict[str(lvl_idx)]
                                            approved_by_string = ", ".join(
                                                [
                                                    f"{user_name_mapper[user]['username']} ({user_name_mapper[user]['first_name']} {user_name_mapper[user]['last_name']} {user_name_mapper[user]['department']} {user_name_mapper[user]['contact_number']})"
                                                    for user in lvl_approved_by_users
                                                ]
                                            )
                                        else:
                                            approved_by_string = ""
                                        row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approved_by_string}</td>"
                                        row_html += "</tr>"
                                        table_body_html += row_html

                                    table_body_html += "</tbody>"
                                    approver_level_html += table_body_html
                                    approver_level_html += "</table>"

                                    ApprovalLevelConfig_string = approver_level_html

                                notification_msg = notification_msg.replace(
                                    "{ApprovalLevelConfig}", ApprovalLevelConfig_string
                                )
                            else:
                                pass
                            if "{ApproverAuditLog}" in notification_msg:
                                user_table_data = (
                                    read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": [
                                                    "username",
                                                    "first_name",
                                                    "last_name",
                                                    "department",
                                                    "contact_number",
                                                ],
                                            },
                                            "condition": [],
                                        },
                                    )
                                ).to_dict("records")
                                user_name_mapper = {}

                                for user_row in user_table_data:
                                    user_name = user_row["username"]
                                    user_name_mapper[user_name] = user_row

                                auditLog_List = approval_audit_log
                                approval_audit_log_html = ""
                                if auditLog_List is not None:

                                    header = "<tr style='background-color: #f2f2f2;'><th style='padding: 8px; border: 1px solid #ddd;'>Level</th><th style='padding: 8px; border: 1px solid #ddd;'>Action</th><th style='padding: 8px; border: 1px solid #ddd;'>Time</th><th style='padding: 8px; border: 1px solid #ddd;'>User</th><th style='padding: 8px; border: 1px solid #ddd;'>Value</th></tr>"

                                    table_content = ""

                                    for entry in auditLog_List:
                                        for level, entries in entry.items():
                                            for log in entries:
                                                auditLog_action = log.get("action", "")
                                                auditLog_time = log.get("time", "")
                                                auditLog_user = log.get("user", "")
                                                auditLog_value = log.get("value", "")
                                                auditLog_value_formatted = ""
                                                if auditLog_value.startswith("approval_level_config"):
                                                    pre_from_content = (
                                                        "approval_level_config column was updated"
                                                    )
                                                    from_to_content = auditLog_value.split(" from ")[1].split(
                                                        " to "
                                                    )
                                                    from_content = from_to_content[0]
                                                    to_content = from_to_content[1]

                                                    from_content_dict = json.loads(from_content)
                                                    to_content_dict = json.loads(to_content)
                                                    from_users = [
                                                        user_name_mapper[user_info["user_list"][0]]
                                                        for user_info in from_content_dict["level_config"]
                                                    ]
                                                    to_users = [
                                                        user_name_mapper[user_info["user_list"][0]]
                                                        for user_info in to_content_dict["level_config"]
                                                    ]

                                                    from_users_str = " <> ".join(
                                                        [
                                                            f"['{user['username']} ({user['first_name']} {user['last_name']} {user['department']} {user['contact_number']})']"
                                                            for user in from_users
                                                        ]
                                                    )
                                                    to_users_str = " <> ".join(
                                                        [
                                                            f"['{user['username']} ({user['first_name']} {user['last_name']} {user['department']} {user['contact_number']})']"
                                                            for user in to_users
                                                        ]
                                                    )

                                                    auditLog_value_formatted = f"<p>{pre_from_content}</p><p>From</p><p>{from_users_str}</p><p>To</p><p>{to_users_str}</p>"
                                                elif auditLog_value.startswith("json_data"):
                                                    json_data_pattern = r"from (\[.*?\]) to (\[.*?\])"
                                                    pre_from_content = "json_data column was updated"
                                                    json_data_match = re.search(
                                                        json_data_pattern, auditLog_value
                                                    )
                                                    if json_data_match:
                                                        from_data = json_data_match.group(1)
                                                        to_data = json_data_match.group(2)
                                                        from_data = from_data.replace("'", '"')
                                                        to_data = to_data.replace("'", '"')

                                                    auditLog_value_formatted = f"<p>{pre_from_content}</p><p>From</p><p>{from_data}</p><p>To</p><p>{to_data}</p>"
                                                else:
                                                    auditLog_value_formatted = auditLog_value

                                                row = f"<tr><td style='padding: 8px; border: 1px solid #ddd;'>{level}</td><td style='padding: 8px; border: 1px solid #ddd;'>{auditLog_action}</td><td style='padding: 8px; border: 1px solid #ddd;'>{auditLog_time}</td><td style='padding: 8px; border: 1px solid #ddd;'>{auditLog_user}</td><td style='padding: 8px; border: 1px solid #ddd;'>{auditLog_value_formatted}</td></tr>"
                                                table_content += row

                                    html_table = f"<table style='border-collapse: collapse; width: 100%;'>{header}{table_content}</table>"
                                    approval_audit_log_html = html_table
                                else:
                                    pass
                                notification_msg = notification_msg.replace(
                                    "{ApproverAuditLog}", approval_audit_log_html
                                )
                            else:
                                pass
                            if "{ApprovalType}" in notification_msg:
                                ApprovalType_string = approver_type
                                notification_msg = notification_msg.replace(
                                    "{ApprovalType}", ApprovalType_string
                                )
                            else:
                                pass
                            if "{TransactionApprovers-Name}" in notification_msg:
                                approver_string = ""
                                if approver_group:
                                    approver_string = ", ".join(approver_group)
                                if approver_user:
                                    user_names = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": ["first_name", "last_name"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "username",
                                                    "condition": "IN",
                                                    "input_value": str(tuple(approver_user)).replace(
                                                        ",)", ")"
                                                    ),
                                                    "and_or": "",
                                                }
                                            ],
                                        },
                                    )
                                    user_names["name"] = (
                                        user_names["first_name"] + " " + user_names["last_name"]
                                    )
                                    approver_string = ", ".join(user_names["name"].tolist())
                                notification_msg = notification_msg.replace(
                                    "{TransactionApprovers-Name}", approver_string
                                )
                            else:
                                pass
                            if "{TransactionCreatedBy}" in notification_msg:
                                notification_msg = notification_msg.replace(
                                    "{TransactionCreatedBy}", action_performed_by
                                )
                            else:
                                pass
                            if "{TransactionCreatedBy-Name}" in notification_msg:
                                user_names = read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": "User",
                                            "Columns": ["first_name", "last_name"],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "username",
                                                "condition": "Equal to",
                                                "input_value": action_performed_by,
                                                "and_or": "",
                                            }
                                        ],
                                    },
                                )
                                user_names["name"] = user_names["first_name"] + " " + user_names["last_name"]
                                approver_string = user_names["name"].tolist()[0]
                                notification_msg = notification_msg.replace(
                                    "{TransactionCreatedBy-Name}", approver_string
                                )
                            else:
                                pass
                            if "{TransactionTime}" in notification_msg:
                                notification_msg = notification_msg.replace(
                                    "{TransactionTime}", f"{datetime.now()}"
                                )
                            else:
                                pass
                            if "{ApproveButton}" in notification_msg or "{RejectButton}" in notification_msg:

                                class UserObject:
                                    def __init__(self, i_dict):
                                        for key, value in i_dict.items():
                                            if key not in ["password", "last_login", "date_joined"]:
                                                setattr(self, key, value)
                                            else:
                                                continue

                                if approver_user:
                                    approver_user_data = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": ["id", "username", "email"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "username",
                                                    "condition": "IN",
                                                    "input_value": str(tuple(approver_user)).replace(
                                                        ",)", ")"
                                                    ),
                                                    "and_or": "",
                                                }
                                            ],
                                        },
                                    ).to_dict("records")
                                else:
                                    group_id = (
                                        read_data_func(
                                            request,
                                            {
                                                "inputs": {
                                                    "Data_source": "Database",
                                                    "Table": "auth_group",
                                                    "Columns": ["id"],
                                                },
                                                "condition": [
                                                    {
                                                        "column_name": "name",
                                                        "condition": "IN",
                                                        "input_value": str(tuple(approver_group)).replace(
                                                            ",)", ")"
                                                        ),
                                                        "and_or": "",
                                                    }
                                                ],
                                            },
                                        )
                                    ).id.tolist()
                                    if group_id:
                                        user_ids = (
                                            read_data_func(
                                                request,
                                                {
                                                    "inputs": {
                                                        "Data_source": "Database",
                                                        "Table": "user_groups",
                                                        "Columns": ["user_id"],
                                                    },
                                                    "condition": [
                                                        {
                                                            "column_name": "group_id",
                                                            "condition": "IN",
                                                            "input_value": str(tuple(group_id)).replace(
                                                                ",)", ")"
                                                            ),
                                                            "and_or": "",
                                                        }
                                                    ],
                                                },
                                            )
                                        ).user_id.tolist()
                                        if user_ids:
                                            approver_user_data = (
                                                read_data_func(
                                                    request,
                                                    {
                                                        "inputs": {
                                                            "Data_source": "Database",
                                                            "Table": "User",
                                                            "Columns": ["id", "username", "email"],
                                                        },
                                                        "condition": [
                                                            {
                                                                "column_name": "id",
                                                                "condition": "IN",
                                                                "input_value": str(tuple(user_ids)).replace(
                                                                    ",)", ")"
                                                                ),
                                                                "and_or": "",
                                                            }
                                                        ],
                                                    },
                                                )
                                            ).to_dict("records")
                                        else:
                                            approver_user_data = []
                                    else:
                                        approver_user_data = []
                                from rest_framework_simplejwt.tokens import RefreshToken

                                for approver in approver_user_data:
                                    approver_object = UserObject(approver)
                                    refresh = RefreshToken.for_user(approver_object)
                                    approver_tokens[approver["email"]] = str(refresh.access_token)
                            else:
                                pass
                            if "{ApproveButton}" in notification_msg:
                                approve_link = f"{request.build_absolute_uri('/')[:-1]}/users/{app_code}/User/approval_table-ima/?token={{approver_token}}&app_code={app_code}&type=approvals&approve={approval_code}"
                                if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                    approve_link = approve_link.replace("http", "https")
                                else:
                                    pass
                                notification_msg = notification_msg.replace("{ApproveButton}", approve_link)
                            else:
                                pass
                            if "{InAppApproveButton}" in notification_msg:
                                approve_link = f"{request.build_absolute_uri('/')[:-1]}/users/{app_code}/User/in-app-approve/{approval_code}/Approve"
                                if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                    approve_link = approve_link.replace("http", "https")
                                else:
                                    pass
                                notification_msg = notification_msg.replace("{InAppApproveButton}", approve_link)
                            else:
                                pass
                            if "{InRejectButton}" in notification_msg:
                                approve_link = f"{request.build_absolute_uri('/')[:-1]}/users/{app_code}/User/in-app-approve/{approval_code}/Reject"
                                if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                    approve_link = approve_link.replace("http", "https")
                                else:
                                    pass
                                notification_msg = notification_msg.replace("{InRejectButton}", approve_link)
                            else:
                                pass
                            
                            if "{domain}" in notification_msg:
                                domain = request.build_absolute_uri("/")[:-1]
                                if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                    domain = domain.replace("http", "https")
                                else:
                                    pass
                                notification_msg = notification_msg.replace("{domain}", f"{domain}")
                            else:
                                pass
                            if "{app_code}" in notification_msg:
                                url_string = request.path
                                f_occ = url_string.find("/", url_string.find("/") + 1)
                                s_occ = url_string.find("/", url_string.find("/") + f_occ + 1)
                                app_code = url_string[f_occ + 1 : s_occ]
                                notification_msg = notification_msg.replace("{app_code}", f"{app_code}")
                            else:
                                pass
                            if "{RejectButton}" in notification_msg:
                                approve_link = f"{request.build_absolute_uri('/')[:-1]}/users/{app_code}/User/approval_table-ima/?token={{approver_token}}&app_code={app_code}&type=approvals&reject={approval_code}"
                                if request.headers.get("X-Forwarded-Proto", "http") == "https":
                                    approve_link = approve_link.replace("http", "https")
                                else:
                                    pass
                                notification_msg = notification_msg.replace("{RejectButton}", approve_link)
                            else:
                                pass
                            transaction_data_dict = data_sent_for_approval[0]
                            for field in modelName.concrete_fields:
                                if f"VerboseName-{field.name}" in notification_msg:
                                    notification_msg = notification_msg.replace(
                                        f"{{VerboseName-{field.name}}}", field.verbose_name
                                    )
                                else:
                                    pass
                                if f"Value-{field.name}" in notification_msg:
                                    if field.name in transaction_data_dict:
                                        notification_msg = notification_msg.replace(
                                            f"{{Value-{field.name}}}",
                                            str(replace_escape_chr_decode(transaction_data_dict[field.name])),
                                        )
                                    else:
                                        notification_msg = notification_msg.replace(
                                            f"{{Value-{field.name}}}", " - "
                                        )
                                else:
                                    continue
                        else:
                            notification_msg = f"{len(data_sent_for_approval)} new rows of {tablename} have been submitted for approval by {action_performed_by}."
                        if condition_data_check["Category_sub_elements"][0][
                            "Category_sub_element_attributes"
                        ][1]["value"].get("approval_notification_subject"):
                            approval_notification_subject = condition_data_check["Category_sub_elements"][0][
                                "Category_sub_element_attributes"
                            ][1]["value"].get("approval_notification_subject")
                            if "{TransactionApprovers}" in approval_notification_subject:
                                approver_string = ""
                                if approver_group:
                                    approver_string = ", ".join(approver_group)
                                if approver_user:
                                    approver_string = ", ".join(approver_user)
                                approval_notification_subject = approval_notification_subject.replace(
                                    "{TransactionApprovers}", approver_string
                                )
                            else:
                                pass
                            if "{TransactionApprovers-Name}" in approval_notification_subject:
                                approver_string = ""
                                if approver_group:
                                    approver_string = ", ".join(approver_group)
                                if approver_user:
                                    user_names = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": ["first_name", "last_name"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "username",
                                                    "condition": "IN",
                                                    "input_value": str(tuple(approver_user)).replace(
                                                        ",)", ")"
                                                    ),
                                                    "and_or": "",
                                                }
                                            ],
                                        },
                                    )
                                    user_names["name"] = (
                                        user_names["first_name"] + " " + user_names["last_name"]
                                    )
                                    approver_string = ", ".join(user_names["name"].tolist())
                                approval_notification_subject = approval_notification_subject.replace(
                                    "{TransactionApprovers-Name}", approver_string
                                )
                            else:
                                pass
                            if "{TransactionCreatedBy}" in approval_notification_subject:
                                approval_notification_subject = approval_notification_subject.replace(
                                    "{TransactionCreatedBy}", action_performed_by
                                )
                            else:
                                pass
                            if "{TransactionCreatedBy-Name}" in approval_notification_subject:
                                user_names = read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": "User",
                                            "Columns": ["first_name", "last_name"],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "username",
                                                "condition": "Equal to",
                                                "input_value": action_performed_by,
                                                "and_or": "",
                                            }
                                        ],
                                    },
                                )
                                user_names["name"] = user_names["first_name"] + " " + user_names["last_name"]
                                approver_string = user_names["name"].tolist()[0]
                                approval_notification_subject = approval_notification_subject.replace(
                                    "{TransactionCreatedBy-Name}", approver_string
                                )
                            else:
                                pass
                            if "{TransactionTime}" in approval_notification_subject:
                                approval_notification_subject = approval_notification_subject.replace(
                                    "{TransactionTime}", f"{datetime.now()}"
                                )
                            else:
                                pass
                            transaction_data_dict = data_sent_for_approval[0]
                            for field in modelName.concrete_fields:
                                if f"VerboseName-{field.name}" in approval_notification_subject:
                                    approval_notification_subject = approval_notification_subject.replace(
                                        f"{{VerboseName-{field.name}}}", field.verbose_name
                                    )
                                else:
                                    pass
                                if f"Value-{field.name}" in approval_notification_subject:
                                    if field.name in transaction_data_dict:
                                        approval_notification_subject = approval_notification_subject.replace(
                                            f"{{Value-{field.name}}}",
                                            str(replace_escape_chr_decode(transaction_data_dict[field.name])),
                                        )
                                    else:
                                        approval_notification_subject = approval_notification_subject.replace(
                                            f"{{Value-{field.name}}}", " - "
                                        )
                                else:
                                    continue
                        else:
                            approval_notification_subject = "Approval Notification"
                        try:
                            if condition_data_check["Category_sub_elements"][0][
                                "Category_sub_element_attributes"
                            ][1]["value"].get("approvalInMailApprovalOption"):
                                approvalInMailApprovalOption = condition_data_check["Category_sub_elements"][
                                    0
                                ]["Category_sub_element_attributes"][1]["value"].get(
                                    "approvalInMailApprovalOption"
                                )
                            else:
                                approvalInMailApprovalOption = False
                            if condition_data_check["Category_sub_elements"][0][
                                "Category_sub_element_attributes"
                            ][1]["value"].get("smtpConfigKey"):
                                smtpConfigKey = condition_data_check["Category_sub_elements"][0][
                                    "Category_sub_element_attributes"
                                ][1]["value"]["smtpConfigKey"]
                            else:
                                smtpConfigKey = "default"
                            transDataCols = []
                            if condition_data_check["Category_sub_elements"][0][
                                "Category_sub_element_attributes"
                            ][1]["value"].get("approval_notification_attachment_config"):
                                approval_notification_attachment_config = condition_data_check[
                                    "Category_sub_elements"
                                ][0]["Category_sub_element_attributes"][1]["value"][
                                    "approval_notification_attachment_config"
                                ]
                                if approval_notification_attachment_config.get("additional_config"):
                                    if approval_notification_attachment_config["additional_config"].get(
                                        "transDataCols"
                                    ):
                                        transDataCols = approval_notification_attachment_config[
                                            "additional_config"
                                        ]["transDataCols"]
                                    else:
                                        pass
                                else:
                                    pass
                            else:
                                approval_notification_attachment_config = {}

                            user_list = {}
                            if transDataCols:
                                if approversDispFields and approversDispFields != ["username"]:
                                    user_list = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": approversDispFields,
                                            },
                                            "condition": [],
                                        },
                                    )
                                    if "username" in approversDispFields:
                                        approversDispFields.remove("username")
                                    user_list["temp_name"] = user_list[approversDispFields].apply(
                                        lambda row: approversDispFormat.join(row.values.astype(str)), axis=1
                                    )
                                    user_list["full_name"] = (
                                        user_list["username"] + " (" + user_list["temp_name"] + ")"
                                    )
                                    user_list = user_list.set_index("username")["full_name"].to_dict()
                                else:
                                    user_list = {}
                                if "approver_type" in transDataCols:
                                    data_sent_for_approval[0]["approver_type"] = approver_type

                                if "approval_level_config" in transDataCols:
                                    if approversDispFields and approversDispFields != ["username"]:
                                        for lvl_idx, lvl in enumerate(approval_level_config["level_config"]):
                                            if lvl.get("user_list"):
                                                lvl_user_list = [user_list[i] for i in lvl["user_list"]]
                                                approval_level_config["level_config"][lvl_idx][
                                                    "user_list"
                                                ] = lvl_user_list
                                            else:
                                                continue
                                    else:
                                        pass
                                    data_sent_for_approval[0]["approval_details"] = json.dumps(
                                        approval_level_config["level_config"]
                                    )
                                else:
                                    data_sent_for_approval[0]["approval_details"] = "-"

                                if "audit_log" in transDataCols:
                                    level_data = []
                                    for event in approval_audit_log:
                                        level, actions = list(event.items())[0]
                                        for act in actions:
                                            act["Level"] = level
                                            if approversDispFields and approversDispFields != ["username"]:
                                                act["user"] = user_list[act["user"]]
                                            else:
                                                pass
                                            level_data.append(act)
                                    data_sent_for_approval[0]["audit_log"] = json.dumps(level_data)

                            for field in modelName.concrete_fields:
                                if (
                                    field.name in data_sent_for_approval[0]
                                    and field.internal_type == "FileField"
                                    and data_sent_for_approval[0][field.name]
                                    and str(data_sent_for_approval[0][field.name])
                                    not in ["nan", "None", "null"]
                                    and data_sent_for_approval[0][field.name]
                                    and approval_notification_attachment_config.get(
                                        "addUploadedFilesAsAttachment"
                                    )
                                    == "Yes"
                                ):
                                    file_names = data_sent_for_approval[0][field.name]
                                    additional_attachment_file_names = {
                                        i: f"{MEDIA_ROOT}/uploaded_files/{i}" for i in file_names.split(", ")
                                    }
                                    approval_notification_attachment_config["additional_attachments"] = (
                                        additional_attachment_file_names
                                    )
                                else:
                                    continue
                            if "{approver_token}" in notification_msg:
                                for i in approval_recipient_list:
                                    approver_token = approver_tokens[i]
                                    email_content = notification_msg.replace(
                                        "{approver_token}", approver_token
                                    )
                                    send_approval_mail(
                                        request,
                                        tablename,
                                        {approval_code: json.dumps(data_sent_for_approval)},
                                        [i],
                                        email_content,
                                        subject=approval_notification_subject,
                                        in_system_approval=approvalInMailApprovalOption,
                                        to_cc=additional_recipients["approval_recipient_list_cc"],
                                        to_bcc=additional_recipients["approval_recipient_list_bcc"],
                                        attachments_config=approval_notification_attachment_config,
                                        smtpConfigKey=smtpConfigKey,
                                        user_name_mapper=user_list,
                                    )
                            else:
                                send_approval_mail(
                                    request,
                                    tablename,
                                    {approval_code: json.dumps(data_sent_for_approval)},
                                    approval_recipient_list,
                                    notification_msg,
                                    subject=approval_notification_subject,
                                    in_system_approval=approvalInMailApprovalOption,
                                    to_cc=additional_recipients["approval_recipient_list_cc"],
                                    to_bcc=additional_recipients["approval_recipient_list_bcc"],
                                    attachments_config=approval_notification_attachment_config,
                                    smtpConfigKey=smtpConfigKey,
                                    user_name_mapper=user_list,
                                )
                        except Exception as e:
                            logging.warning(f"Following exception occured - {e}")
                            messages.error(
                                request,
                                f"Error while sending approval email notification. Following exception ocurred - {str(e)}",
                            )
                        else:
                            check_event_data = read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "event_master",
                                        "Columns": ["event", "action_config"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "approval_code",
                                            "condition": "Equal to",
                                            "input_value": approval_code,
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )

                            if not check_event_data.empty:
                                action_config = json.loads(check_event_data.loc[0, "action_config"])
                                message_job_id = action_config["job_id"]
                                event_message = json.loads(check_event_data.loc[0, "event"])
                                if "Approved" in event_message:
                                    update_data_func(
                                        request,
                                        config_dict={
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "event_master",
                                                "Columns": [
                                                    {
                                                        "column_name": "recipients_list",
                                                        "input_value": json.dumps(approval_recipient_list),
                                                        "separator": "",
                                                    }
                                                ],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "approval_code",
                                                    "condition": "Equal to",
                                                    "input_value": approval_code,
                                                    "and_or": "",
                                                }
                                            ],
                                        },
                                    )
                                else:
                                    pass
                            else:
                                pass
                    return {"response": "success", "pr_code": pr_code, "pr_code_redirect": ""}
                else:
                    pass
            else:
                pass
        else:
            pass

        if approval_type == "create":

            for i, v in enumerate(approval_data):
                data = json.loads(v)
                data_approved = pd.DataFrame(data)
                data_approved = data_approved[[i for i in columns if i in data_approved.columns]]
                FinalData_, len__, status__ = decisionBox(
                    ele_id["create_view_element_id"].iloc[0],
                    tablename,
                    data_approved,
                    request,
                    transaction_id=transaction_id,
                    type=approval_type,
                    current_decision_box_id=current_decision_box_id,
                    action_performed_by=action_performed_by,
                )
                rtf_data_list = []
                rtf_data_dict = {}
                rtf_data_field_list = []
                chr_text_fields = []
                multi_select_field_dict = {}
                is_multi_select_field = False
                for field in modelName.concrete_fields:
                    if field.get_internal_type() == "ConcatenationField":
                        divider = field.divider
                        concat_columns = json.loads(field.columns)
                        FinalData_[field.name] = ""
                        for col_idx, col in enumerate(concat_columns):
                            if col in FinalData_.columns:
                                if modelName.get_field(col).internal_type == "ForeignKey":
                                    __pt, new_converted_data, __table_h = nestedForeignKey(
                                        modelName.get_field(col),
                                        request,
                                        db_connection_name,
                                        FinalData_.copy(deep=True),
                                        col,
                                    )
                                    FinalData_[field.name] += (
                                        new_converted_data[col].astype(object).fillna("").astype(str)
                                    )
                                else:
                                    FinalData_[field.name] += (
                                        FinalData_[col].astype(object).fillna("").astype(str)
                                    )
                                if col_idx != len(concat_columns) - 1:
                                    FinalData_[field.name] += divider
                                else:
                                    continue
                            else:
                                continue
                    elif field.get_internal_type() == "RTFField":
                        if field.name in FinalData_.columns:
                            rtf_data = FinalData_[field.name][0]
                            rtf_data_list.append(rtf_data)
                            rtf_data_dict[field.name] = rtf_data
                            rtf_data_field_list.append(field.name)
                            FinalData_[field.name] = np.nan
                        else:
                            pass
                    elif field.get_internal_type() in ["MultiselectField"]:
                        is_multi_select_field = True
                        temp_mul_config = json.loads(field.mulsel_config)
                        for attri, conf_val in temp_mul_config.items():
                            if (
                                attri == "value"
                                or attri == "masterColumn"
                                or attri == "master"
                                or attri == "add"
                                or attri == "def_MulVal"
                                or attri == "checkBox"
                                or attri == "condition"
                            ):
                                if attri in multi_select_field_dict:
                                    multi_select_field_dict[attri].append(conf_val[0])
                                else:
                                    multi_select_field_dict[attri] = conf_val
                            elif attri == "plusBtn" or attri == "popUpOption":
                                if attri in multi_select_field_dict:
                                    multi_select_field_dict[attri].update(conf_val)
                                else:
                                    multi_select_field_dict[attri] = conf_val
                            else:
                                multi_select_field_dict[attri] = conf_val
                    elif field.get_internal_type() in ["CharField", "TextField", "URLField"]:
                        chr_text_fields.append(field.name)
                    else:
                        continue

                if chr_text_fields:
                    for i in chr_text_fields:
                        if i in FinalData_.columns:
                            FinalData_[i] = FinalData_[i].apply(replace_escape_chr_decode)

                if not FinalData_.empty and status__ == "pass":
                    try:
                        data_handling(request, FinalData_, tablename)

                        if is_multi_select_field:
                            table_name_replica = tablename
                            multi_select_tables = multi_select_field_dict["value"]
                            mutli_select_cols = multi_select_field_dict["masterColumn"]
                            mutli_select_attr = multi_select_field_dict["master"]

                            replica = read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "Tables",
                                        "Columns": ["linked_table"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "model_type",
                                            "condition": "Equal to",
                                            "input_value": "user defined",
                                            "and_or": "and",
                                        },
                                        {
                                            "column_name": "tablename",
                                            "condition": "Equal to",
                                            "input_value": tablename,
                                            "and_or": "",
                                        },
                                    ],
                                },
                            )

                            if replica.empty:
                                replica = None
                            else:
                                replica = replica.loc[0, "linked_table"]

                            if replica is not None:
                                mt = read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": "Tables",
                                            "Columns": ["id"],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "model_type",
                                                "condition": "Equal to",
                                                "input_value": "user defined",
                                                "and_or": "and",
                                            },
                                            {
                                                "column_name": "tablename",
                                                "condition": "Equal to",
                                                "input_value": table_name_replica + "_mul",
                                                "and_or": "",
                                            },
                                        ],
                                    },
                                )
                                if len(mt) > 0:
                                    request2 = request_to_dict(request)
                                    records = len(FinalData_)
                                    recent_record_ids = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": table_name_replica,
                                                "Agg_Type": f"TOP({records})",
                                                "Order_Type": "ORDER BY id DESC",
                                                "Columns": ["id"],
                                            },
                                            "condition": [],
                                        },
                                    )["id"].tolist()
                                    FinalData_["id"] = recent_record_ids

                                    Data_replica_utilities.insert_delimited_data(
                                        elementID="",
                                        request=request2,
                                        table_name_replica=table_name_replica,
                                        multi_select_tables=multi_select_tables,
                                        mutli_select_cols=mutli_select_cols,
                                        mutli_select_attr=mutli_select_attr,
                                        existingData=FinalData_,
                                    )

                        if rtf_data_list:
                            records = len(FinalData_)
                            recent_record_ids = read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": tablename,
                                        "Agg_Type": f"TOP({records})",
                                        "Order_Type": "ORDER BY id DESC",
                                        "Columns": ["id"],
                                    },
                                    "condition": [],
                                },
                            )["id"].tolist()

                            db_name = db_name_extractor(request, app_code)
                            tenant = tenant_schema_from_request(request)

                            if not os.path.exists(f"{MEDIA_ROOT}/rtf_files_master"):
                                os.makedirs(f"{MEDIA_ROOT}/rtf_files_master")

                            if not os.path.exists(f"{MEDIA_ROOT}/rtf_files_master/{db_name}"):
                                os.makedirs(f"{MEDIA_ROOT}/rtf_files_master/{db_name}")

                            if not os.path.exists(f"{MEDIA_ROOT}/rtf_files_master/{db_name}/rtf_data.json"):
                                with open(
                                    f"{MEDIA_ROOT}/rtf_files_master/{db_name}/rtf_data.json", "w"
                                ) as fp:
                                    fp.write("{}")
                                    fp.close()

                            temp = {}
                            with open(f"{MEDIA_ROOT}/rtf_files_master/{db_name}/rtf_data.json") as f:
                                temp = json.load(f)
                                f.close()
                            if tablename not in temp:
                                temp[tablename] = {}
                            else:
                                pass
                            for i in recent_record_ids:
                                for col, rtfd in rtf_data_dict.items():
                                    temp[tablename].update({f"{i}_{col}": rtfd})
                            with open(f"{MEDIA_ROOT}/rtf_files_master/{db_name}/rtf_data.json", "w") as f:
                                json.dump(temp, f, indent=4)
                                f.close()

                            if not os.path.exists(f"{MEDIA_ROOT}/{tenant}"):
                                os.makedirs(f"{MEDIA_ROOT}/{tenant}")

                            if not os.path.exists(f"{MEDIA_ROOT}/{tenant}/{app_code}"):
                                os.makedirs(f"{MEDIA_ROOT}/{tenant}/{app_code}")

                            if not os.path.exists(f"{MEDIA_ROOT}/{tenant}/{app_code}/rtf_files"):
                                os.makedirs(f"{MEDIA_ROOT}/{tenant}/{app_code}/rtf_files")

                            if not os.path.exists(f"{MEDIA_ROOT}/{tenant}/{app_code}/rtf_files/{db_name}"):
                                os.makedirs(f"{MEDIA_ROOT}/{tenant}/{app_code}/rtf_files/{db_name}")

                            if not os.path.exists(
                                f"{MEDIA_ROOT}/{tenant}/{app_code}/rtf_files/{db_name}/rtf_data.json"
                            ):
                                with open(
                                    f"{MEDIA_ROOT}/{tenant}/{app_code}/rtf_files/{db_name}/rtf_data.json", "w"
                                ) as fp:
                                    fp.write("{}")
                                    fp.close()

                            temp = {}
                            with open(f"{MEDIA_ROOT}/rtf_files_master/{db_name}/rtf_data.json") as f:
                                temp = json.load(f)
                                f.close()

                            with open(
                                f"{MEDIA_ROOT}/{tenant}/{app_code}/rtf_files/{db_name}/rtf_data.json", "w"
                            ) as f:
                                json.dump(temp, f, indent=4)
                                f.close()

                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")
                        exceptions = str("Fail," + str(e))
                else:
                    pass
        elif approval_type == "edit":
            approval_data_edit = json.loads(approval_data_edit[0])
            data_approved = pd.DataFrame(approval_data_edit)
            FinalData_, len__, status__ = decisionBox(
                ele_id["create_view_element_id"].iloc[0],
                tablename,
                data_approved,
                request,
                transaction_id=transaction_id,
                type=approval_type,
                current_decision_box_id=current_decision_box_id,
                action_performed_by=action_performed_by,
            )

            multi_select_field_dict = {}
            chr_text_fields = []
            is_multi_select_field = False
            for field in modelName.concrete_fields:
                if field.get_internal_type() == "ConcatenationField":
                    divider = field.divider
                    concat_columns = json.loads(field.columns)
                    FinalData_[field.name] = ""
                    for col_idx, col in enumerate(concat_columns):
                        if col in FinalData_.columns:
                            if modelName.get_field(col).internal_type == "ForeignKey":
                                __pt, new_converted_data, __table_h = nestedForeignKey(
                                    modelName.get_field(col), request, db_connection_name, FinalData_, col
                                )
                                FinalData_[field.name] += (
                                    new_converted_data[col].astype(object).fillna("").astype(str)
                                )
                            else:
                                FinalData_[field.name] += (
                                    FinalData_[col].astype(object).fillna("").astype(str)
                                )
                            if col_idx != len(concat_columns) - 1:
                                FinalData_[field.name] += divider
                            else:
                                continue
                        else:
                            continue
                if field.get_internal_type() in ["MultiselectField"]:
                    is_multi_select_field = True
                    temp_mul_config = json.loads(field.mulsel_config)
                    for attri, conf_val in temp_mul_config.items():
                        if (
                            attri == "value"
                            or attri == "masterColumn"
                            or attri == "master"
                            or attri == "add"
                            or attri == "def_MulVal"
                            or attri == "checkBox"
                            or attri == "condition"
                        ):
                            if attri in multi_select_field_dict:
                                multi_select_field_dict[attri].append(conf_val[0])
                            else:
                                multi_select_field_dict[attri] = conf_val
                        elif attri == "plusBtn" or attri == "popUpOption":
                            if attri in multi_select_field_dict:
                                multi_select_field_dict[attri].update(conf_val)
                            else:
                                multi_select_field_dict[attri] = conf_val
                        else:
                            multi_select_field_dict[attri] = conf_val
                if field.get_internal_type() in ["CharField", "TextField", "URLField"]:
                    chr_text_fields.append(field.name)

            if not FinalData_.empty and status__ == "pass":
                if chr_text_fields:
                    for i in chr_text_fields:
                        if i in FinalData_.columns:
                            FinalData_[i] = FinalData_[i].apply(replace_escape_chr_decode)

                approval_data_edit = FinalData_.to_dict("records")
                if ele_id["create_view_element_id"].iloc[0].__contains__("paral"):
                    sql_data = FinalData_
                    stat = updateComp(
                        sql_data,
                        tablename,
                        json.loads(sql_data.iloc[0]["identifier_column"]),
                        json.loads(sql_data.iloc[0]["update_column"]),
                        request,
                    )
                    if stat != "pass":
                        exceptions = stat

                view_history = ""
                if not ele_id["create_view_element_id"].iloc[0].__contains__("paral"):
                    column_string = ""
                    pk_id = int(approval_data_edit[0]["id"])
                    try:
                        view_history = approval_data_edit[0]["view"]
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")
                    if view_history == "history":
                        approval_data_edit[0].pop("view")
                    else:
                        pass

                    approval_data_edit[0].pop("id")
                    data_list = []
                    for k, v in approval_data_edit[0].items():
                        if view_history == "history":
                            if k == "active_to":
                                column_string += f"{k}='{approval_data_edit[0][k]}',"
                                data_dict = {}
                                data_dict["column_name"] = k
                                data_dict["input_value"] = str(approval_data_edit[0][k])
                                data_dict["separator"] = ","
                                data_list.append(data_dict)
                        elif k == "created_date" or k == "created_by":
                            pass
                        else:
                            if str(approval_data_edit[0][k]) in [
                                "nan",
                                "NaT",
                                pd.NaT,
                                np.nan,
                                "None",
                                None,
                                " ",
                                "",
                            ]:
                                column_string += f"{k}='{approval_data_edit[0][k]}',"
                                data_dict = {}
                                data_dict["column_name"] = k
                                data_dict["input_value"] = "NULL"
                                data_dict["separator"] = ","
                                data_list.append(data_dict)
                            else:
                                column_string += f"{k}='{approval_data_edit[0][k]}',"
                                data_dict = {}
                                data_dict["column_name"] = k
                                data_dict["input_value"] = str(approval_data_edit[0][k])
                                data_dict["separator"] = ","
                                data_list.append(data_dict)
                    data_list[len(data_list) - 1]["separator"] = ""
                    try:
                        update_data_func(
                            request,
                            config_dict={
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": tablename,
                                    "Columns": data_list,
                                },
                                "condition": [
                                    {
                                        "column_name": "id",
                                        "condition": "Equal to",
                                        "input_value": str(pk_id),
                                        "and_or": "",
                                    }
                                ],
                            },
                        )

                        if is_multi_select_field:
                            table_name_replica = tablename
                            multi_select_tables = multi_select_field_dict["value"]
                            mutli_select_cols = multi_select_field_dict["masterColumn"]
                            mutli_select_attr = multi_select_field_dict["master"]

                            replica = read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "Tables",
                                        "Columns": ["linked_table"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "model_type",
                                            "condition": "Equal to",
                                            "input_value": "user defined",
                                            "and_or": "and",
                                        },
                                        {
                                            "column_name": "tablename",
                                            "condition": "Equal to",
                                            "input_value": tablename,
                                            "and_or": "",
                                        },
                                    ],
                                },
                            )

                            if replica.empty:
                                replica = None
                            else:
                                replica = replica.loc[0, "linked_table"]

                            if replica is not None:
                                mt = read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": "Tables",
                                            "Columns": ["id"],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "model_type",
                                                "condition": "Equal to",
                                                "input_value": "user defined",
                                                "and_or": "and",
                                            },
                                            {
                                                "column_name": "tablename",
                                                "condition": "Equal to",
                                                "input_value": table_name_replica + "_mul",
                                                "and_or": "",
                                            },
                                        ],
                                    },
                                )

                                if len(mt) > 0:
                                    request2 = request_to_dict(request)

                                    existing_data = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": tablename,
                                                "Columns": ["*"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "id",
                                                    "condition": "Equal to",
                                                    "input_value": str(pk_id),
                                                    "and_or": "",
                                                }
                                            ],
                                        },
                                    )

                                    Data_replica_utilities.insert_delimited_data(
                                        elementID="",
                                        request=request2,
                                        table_name_replica=table_name_replica,
                                        multi_select_tables=multi_select_tables,
                                        mutli_select_cols=mutli_select_cols,
                                        mutli_select_attr=mutli_select_attr,
                                        existingData=existing_data,
                                    )
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")
                        exceptions = "Fail, " + str(e)

                if view_history == "history":
                    if "active_to" or "active_from" in approval_data_edit[0]:
                        approval_data_edit[0]["active_to"] = datetime(2099, 7, 5).strftime(
                            "%Y-%m-%d %H:%M:%S"
                        )
                        approval_data_edit[0]["active_from"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                    else:
                        pass
                    approval_data_edit = pd.DataFrame(approval_data_edit)
                    data_handling(request, approval_data_edit, tablename)
                else:
                    pass
            else:
                pass
        if exceptions == "" or not exceptions.startswith("Fail"):
            ## Email code starts here
            try:
                to_list = json.loads(approval_decision_mailer_config)
            except Exception as e:
                logging.warning(f"Following exception occured - {e}")
                to_list = []
            email_success = True
            if len(to_list) > 0:
                content = ""
                if approve_msg:

                    if approval_audit_log and approval_audit_log is not None:
                        if type_of_approval != "multi_level":
                            current_approval_level = 0
                        approval_audit_log_temp = json.loads(approval_audit_log)
                        temp_app_log_dict = {}
                        temp_all_log = []
                        if approval_comment:
                            temp_all_log.append(
                                {
                                    "action": "Comment",
                                    "user": request.user.username,
                                    "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "value": approval_comment,
                                }
                            )
                        temp_all_log.append(
                            {
                                "action": "Approved By",
                                "user": request.user.username,
                                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "value": "",
                            }
                        )

                        temp_app_log_dict[f"Level {current_approval_level}"] = temp_all_log
                        approval_audit_log_temp.append(temp_app_log_dict)
                        approval_audit_log_inmail = approval_audit_log_temp
                    else:
                        temp_app_log_dict = {}
                        temp_all_log = []
                        if approval_comment:
                            temp_all_log.append(
                                {
                                    "action": "Comment",
                                    "user": request.user.username,
                                    "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                    "value": approval_comment,
                                }
                            )
                        temp_all_log.append(
                            {
                                "action": "Approved By",
                                "user": request.user.username,
                                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "value": "",
                            }
                        )

                        temp_app_log_dict["Level 0"] = temp_all_log
                        approval_audit_log_inmail = [temp_app_log_dict]

                    html_table_notif = "<table border='1'><thead><tr><th>Level</th><th>Action</th><th>User</th><th>Time</th><th>Value</th></tr></thead>"

                    for entry in approval_audit_log_inmail:
                        for level, log_entries in entry.items():
                            for log_entry in log_entries:
                                action = log_entry["action"]
                                user = log_entry["user"]
                                creation_time = log_entry["time"]
                                value = log_entry["value"]

                                html_table_notif += f"<tbody><tr><td>{level}</td><td>{action}</td><td>{user}</td><td>{creation_time}</td><td>{value}</td></tr>"

                    html_table_notif += "</tbody></table>"

                    transaction_data_dict = json.loads(approval_data[0])[0]
                    if "{ApprovalType}" in approve_msg:
                        ApprovalType_string = approver_type
                        approve_msg = approve_msg.replace("{ApprovalType}", ApprovalType_string)
                    else:
                        pass
                    if "{ApproverAuditLog}" in approve_msg:
                        approve_msg = approve_msg.replace("{ApproverAuditLog}", html_table_notif)
                    else:
                        pass
                    if "{TransactionApprovedBy}" in approve_msg:
                        approve_msg = approve_msg.replace("{TransactionApprovedBy}", request.user.username)
                    else:
                        pass
                    if "{TransactionApprovedBy-Name}" in approve_msg:
                        approve_msg = approve_msg.replace(
                            "{TransactionApprovedBy-Name}",
                            f"{request.user.first_name} {request.user.last_name}",
                        )
                    else:
                        pass
                    if "{TransactionCreatedBy-Name}" in approve_msg:
                        user_names = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "User",
                                    "Columns": ["first_name", "last_name"],
                                },
                                "condition": [
                                    {
                                        "column_name": "username",
                                        "condition": "Equal to",
                                        "input_value": action_performed_by,
                                        "and_or": "",
                                    }
                                ],
                            },
                        )
                        user_names["name"] = user_names["first_name"] + " " + user_names["last_name"]
                        approver_string = user_names["name"].tolist()[0]
                        approve_msg = approve_msg.replace("{TransactionCreatedBy-Name}", f"{approver_string}")
                    else:
                        pass
                    if "{TransactionCreatedBy}" in approve_msg:
                        approve_msg = approve_msg.replace("{TransactionCreatedBy}", action_performed_by)
                    else:
                        pass
                    if "{ApprovalLevelConfig}" in approve_msg:
                        user_table_data = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "User",
                                        "Columns": [
                                            "username",
                                            "first_name",
                                            "last_name",
                                            "department",
                                            "contact_number",
                                        ],
                                    },
                                    "condition": [],
                                },
                            )
                        ).to_dict("records")
                        user_name_mapper = {}

                        for user_row in user_table_data:
                            user_name = user_row["username"]
                            user_name_mapper[user_name] = user_row

                        ApprovalLevelConfig_string = ""
                        approval_level_config_string = approval_level_config
                        approver_user_string_notif = approver_user
                        if approval_level_config_string is None:
                            if isinstance(approver_user_string_notif, str):
                                approver_user_string_notif = json.loads(approver_user_string_notif)
                            else:
                                pass
                            ApprovalLevelConfig_string = ", ".join(
                                [
                                    f"{user_name_mapper[user]['username']} ({user_name_mapper[user]['first_name']} {user_name_mapper[user]['last_name']} {user_name_mapper[user]['department']} {user_name_mapper[user]['contact_number']})"
                                    for user in approver_user_string_notif
                                ]
                            )
                        else:
                            approver_level_html = "<table style='width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;'>"
                            approver_level_html += "<thead><tr>"
                            approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Users List</th>"
                            approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Approval Type</th>"
                            approver_level_html += "<th style='border: 1px solid #dddddd; background-color: #f2f2f2; padding: 8px; text-align: left;'>Approver Type</th>"
                            approver_level_html += "</tr></thead>"
                            table_body_html = "<tbody>"

                            for data_dict in approval_level_config_string["level_config"]:
                                row_html = "<tr>"
                                if data_dict.get("user_list"):
                                    user_list = data_dict["user_list"]
                                    user_info_str = " ".join(
                                        [
                                            f"{user_name_mapper[user]['username']} ({user_name_mapper[user]['first_name']} {user_name_mapper[user]['last_name']} {user_name_mapper[user]['department']} {user_name_mapper[user]['contact_number']})"
                                            for user in user_list
                                        ]
                                    )
                                    row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{user_info_str}</td>"
                                elif data_dict.get("group_list"):
                                    group_list = data_dict["group_list"]
                                    group_info_str = " ,".join(group_list)
                                    row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{group_info_str}</td>"
                                else:
                                    approval_info_str = f"{data_dict['approval_type']}"
                                    row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approval_info_str}</td>"

                                approval_type = data_dict.get("approval_type", "N/A")
                                approver_type = data_dict.get("approver_type", "N/A")
                                row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approval_type}</td>"
                                row_html += f"<td style='border: 1px solid #dddddd; padding: 8px; text-align: left;'>{approver_type}</td>"

                                row_html += "</tr>"
                                table_body_html += row_html

                            table_body_html += "</tbody>"
                            approver_level_html += table_body_html
                            approver_level_html += "</table>"

                            ApprovalLevelConfig_string = approver_level_html

                        approve_msg = approve_msg.replace("{ApprovalLevelConfig}", ApprovalLevelConfig_string)
                    if "{TransactionTime}" in approve_msg:
                        approve_msg = approve_msg.replace("{TransactionTime}", f"{action_performed_on}")
                    else:
                        pass
                    if "{TransactionApprovalTime}" in approve_msg:
                        approve_msg = approve_msg.replace("{TransactionApprovalTime}", f"{datetime.now()}")
                    else:
                        pass
                    if "{TransactionApproverComment}" in approve_msg:
                        approve_msg = approve_msg.replace("{TransactionApproverComment}", approval_comment)
                    else:
                        pass
                    for field in modelName.concrete_fields:
                        if f"VerboseName-{field.name}" in approve_msg:
                            approve_msg = approve_msg.replace(
                                f"{{VerboseName-{field.name}}}", field.verbose_name
                            )
                        else:
                            pass
                        if f"Value-{field.name}" in approve_msg:
                            if field.name in transaction_data_dict:
                                if (
                                    modelName.get_field(field.name).internal_type == "ForeignKey"
                                    and transaction_data_dict[field.name]
                                ):
                                    actual_values_for_idx = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": modelName.get_field(field.name).parent,
                                                "Columns": [field.name],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "id",
                                                    "condition": "Equal to",
                                                    "input_value": str(transaction_data_dict[field.name]),
                                                    "and_or": "",
                                                },
                                            ],
                                        },
                                        access_controller=False,
                                    )[field.name].to_list()
                                    if actual_values_for_idx:
                                        transaction_data_dict[field.name] = actual_values_for_idx[0]
                                    else:
                                        pass
                                approve_msg = approve_msg.replace(
                                    f"{{Value-{field.name}}}",
                                    str(replace_escape_chr_decode(transaction_data_dict[field.name])),
                                )
                            else:
                                approve_msg = approve_msg.replace(f"{{Value-{field.name}}}", " - ")
                        else:
                            continue
                    content = approve_msg
                else:
                    content = f"1 row of {tablename} has been approved by {request.user.username}."
                    if approval_comment:
                        content = content + f"\nComment: {approval_comment}"
                if approve_msg_subject:
                    if "{TransactionApprovedBy}" in approve_msg_subject:
                        approve_msg_subject = approve_msg_subject.replace(
                            "{TransactionApprovedBy}", request.user.username
                        )
                    else:
                        pass
                    if "{TransactionCreatedBy}" in approve_msg_subject:
                        approve_msg_subject = approve_msg_subject.replace(
                            "{TransactionCreatedBy}", action_performed_by
                        )
                    else:
                        pass
                    if "{TransactionCreatedBy-Name}" in approve_msg_subject:
                        user_names = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "User",
                                    "Columns": ["first_name", "last_name"],
                                },
                                "condition": [
                                    {
                                        "column_name": "username",
                                        "condition": "Equal to",
                                        "input_value": action_performed_by,
                                        "and_or": "",
                                    }
                                ],
                            },
                        )
                        user_names["name"] = user_names["first_name"] + " " + user_names["last_name"]
                        approver_string = user_names["name"].tolist()[0]
                        approve_msg_subject = approve_msg_subject.replace(
                            "{TransactionCreatedBy-Name}", f"{approver_string}"
                        )
                    else:
                        pass
                    if "{TransactionApprovedBy-Name}" in approve_msg_subject:
                        approve_msg_subject = approve_msg_subject.replace(
                            "{TransactionApprovedBy-Name}",
                            f"{request.user.first_name} {request.user.last_name}",
                        )
                    else:
                        pass
                    if "{TransactionTime}" in approve_msg_subject:
                        approve_msg_subject = approve_msg_subject.replace(
                            "{TransactionTime}", f"{action_performed_on}"
                        )
                    else:
                        pass
                    for field in modelName.concrete_fields:
                        if f"VerboseName-{field.name}" in approve_msg_subject:
                            approve_msg_subject = approve_msg_subject.replace(
                                f"{{VerboseName-{field.name}}}", field.verbose_name
                            )
                        else:
                            pass
                        if f"Value-{field.name}" in approve_msg_subject:
                            if field.name in transaction_data_dict:
                                if (
                                    modelName.get_field(field.name).internal_type == "ForeignKey"
                                    and transaction_data_dict[field.name]
                                ):
                                    actual_values_for_idx = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": modelName.get_field(field.name).parent,
                                                "Columns": [field.name],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "id",
                                                    "condition": "Equal to",
                                                    "input_value": str(transaction_data_dict[field.name]),
                                                    "and_or": "",
                                                },
                                            ],
                                        },
                                        access_controller=False,
                                    )[field.name].to_list()
                                    if actual_values_for_idx:
                                        transaction_data_dict[field.name] = actual_values_for_idx[0]
                                    else:
                                        pass
                                approve_msg_subject = approve_msg_subject.replace(
                                    f"{{Value-{field.name}}}",
                                    str(replace_escape_chr_decode(transaction_data_dict[field.name])),
                                )
                            else:
                                approve_msg_subject = approve_msg_subject.replace(
                                    f"{{Value-{field.name}}}", " - "
                                )
                        else:
                            continue

                else:
                    approve_msg_subject = "Approval Decision Notification"
                try:
                    if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                        "value"
                    ].get("smtpConfigKey"):
                        smtpConfigKey = condition_data_check["Category_sub_elements"][0][
                            "Category_sub_element_attributes"
                        ][1]["value"]["smtpConfigKey"]
                    else:
                        smtpConfigKey = "default"
                    transDataCols = []
                    if condition_data_check["Category_sub_elements"][0]["Category_sub_element_attributes"][1][
                        "value"
                    ].get("approval_notification_attachment_config"):
                        approval_notification_attachment_config = condition_data_check[
                            "Category_sub_elements"
                        ][0]["Category_sub_element_attributes"][1]["value"][
                            "approval_notification_attachment_config"
                        ]
                        if approval_notification_attachment_config.get("additional_config"):
                            if approval_notification_attachment_config["additional_config"].get(
                                "transDataCols"
                            ):
                                transDataCols = approval_notification_attachment_config["additional_config"][
                                    "transDataCols"
                                ]
                            else:
                                pass
                        else:
                            pass
                    else:
                        approval_notification_attachment_config = {}
                    user_list = {}
                    if transDataCols:
                        if approversDispFields and approversDispFields != ["username"]:
                            user_list = read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "User",
                                        "Columns": approversDispFields,
                                    },
                                    "condition": [],
                                },
                            )
                            if "username" in approversDispFields:
                                approversDispFields.remove("username")
                            user_list["temp_name"] = user_list[approversDispFields].apply(
                                lambda row: approversDispFormat.join(row.values.astype(str)), axis=1
                            )
                            user_list["full_name"] = (
                                user_list["username"] + " (" + user_list["temp_name"] + ")"
                            )
                            user_list = user_list.set_index("username")["full_name"].to_dict()
                        else:
                            user_list = {}
                        if "approver_type" in transDataCols:
                            data_sent_for_approval[0]["approver_type"] = approver_type

                        if "approval_level_config" in transDataCols and approval_level_config:
                            if approversDispFields and approversDispFields != ["username"]:
                                for lvl_idx, lvl in enumerate(approval_level_config["level_config"]):
                                    if lvl.get("user_list"):
                                        lvl_user_list = [user_list[i] for i in lvl["user_list"]]
                                        approval_level_config["level_config"][lvl_idx][
                                            "user_list"
                                        ] = lvl_user_list
                                    else:
                                        continue
                            else:
                                pass
                            data_sent_for_approval[0]["approval_details"] = json.dumps(
                                approval_level_config["level_config"]
                            )
                        else:
                            data_sent_for_approval[0]["approval_details"] = "-"

                        if "audit_log" in transDataCols and approval_audit_log:
                            level_data = []
                            for event in approval_audit_log:
                                if isinstance(event, dict):
                                    level, actions = list(event.items())[0]
                                    for act in actions:
                                        act["Level"] = level
                                        if approversDispFields and approversDispFields != ["username"]:
                                            act["user"] = user_list[act["user"]]
                                        else:
                                            pass
                                        level_data.append(act)
                                else:
                                    pass
                            data_sent_for_approval[0]["audit_log"] = json.dumps(level_data)

                    for field in modelName.concrete_fields:
                        if (
                            field.name in data_sent_for_approval[0]
                            and field.internal_type == "FileField"
                            and data_sent_for_approval[0][field.name]
                            and str(data_sent_for_approval[0][field.name]) not in ["nan", "None", "null"]
                            and data_sent_for_approval[0][field.name]
                            and approval_notification_attachment_config.get("addUploadedFilesAsAttachment")
                            == "Yes"
                        ):
                            file_names = data_sent_for_approval[0][field.name]
                            additional_attachment_file_names = {
                                i: f"{MEDIA_ROOT}/uploaded_files/{i}" for i in file_names.split(", ")
                            }
                            approval_notification_attachment_config["additional_attachments"] = (
                                additional_attachment_file_names
                            )
                        else:
                            continue
                    if type(to_list) == list:
                        recipients_to = to_list
                        recipients_cc = []
                        recipients_bcc = []
                    else:
                        recipients_to = to_list["recipient_to"]
                        recipients_cc = to_list["recipient_cc"]
                        recipients_bcc = to_list["recipient_bcc"]
                    send_approval_mail(
                        request,
                        tablename,
                        {approval_code: json.dumps(data_sent_for_approval)},
                        recipients_to,
                        content,
                        subject=approve_msg_subject,
                        in_system_approval=False,
                        to_cc=recipients_cc,
                        to_bcc=recipients_bcc,
                        attachments_config=approval_notification_attachment_config,
                        smtpConfigKey=smtpConfigKey,
                        user_name_mapper=[],
                    )
                except Exception as e:
                    logging.warning(f"Following exception occured - {e}")
                    messages.error(
                        request,
                        "Error while sending approval email notification. Kindly check the SMTP configuration in management console or contact your administrator.",
                    )
                    email_success = False

            date_str = str(modified_date).split(":")
            date_str = str(date_str[0]) + ":" + str(date_str[1])
            if transaction_id not in [None, "NULL"]:
                is_match = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "Process_flow_model",
                            "Columns": ["modified_date", "flow", "pass_batch_data", "total_batch_data"],
                        },
                        "condition": [
                            {
                                "column_name": "transaction_id",
                                "condition": "Equal to",
                                "input_value": transaction_id,
                                "and_or": "and",
                            },
                            {
                                "column_name": "modified_by",
                                "condition": "Equal to",
                                "input_value": modified_by,
                                "and_or": "and",
                            },
                            {
                                "column_name": "element_id",
                                "condition": "Equal to",
                                "input_value": ele_id["create_view_element_id"].iloc[0],
                                "and_or": "and",
                            },
                            {
                                "column_name": "flow",
                                "condition": "Contains",
                                "input_value": current_decision_box_id,
                                "and_or": "and",
                            },
                            {
                                "column_name": "current_status",
                                "condition": "Equal to",
                                "input_value": "Pass",
                                "and_or": "",
                            },
                        ],
                    },
                )
                if not is_match.empty:
                    transaction_id_ = [transaction_id]
                    for transaction_id in transaction_id_:
                        transaction_id = json.dumps([transaction_id])
                        pass_batch_data = is_match.iloc[0]["pass_batch_data"]
                        update_data_func(
                            request,
                            config_dict={
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Process_flow_model",
                                    "Columns": [
                                        {
                                            "column_name": "pass_batch_data",
                                            "input_value": str(pass_batch_data),
                                            "separator": "",
                                        },
                                    ],
                                },
                                "condition": [
                                    {
                                        "column_name": "transaction_id",
                                        "condition": "IN",
                                        "input_value": json.loads(
                                            transaction_id
                                        ),  # modified_date.strftime("%Y-%m-%d %H:%M:%S"),
                                        "and_or": "and",
                                    },
                                    {
                                        "column_name": "flow",
                                        "condition": "Contains",
                                        "input_value": str(current_decision_box_id),
                                        "and_or": "and",
                                    },
                                    {
                                        "column_name": "(element_id",
                                        "condition": "Equal to",
                                        "input_value": str(current_decision_box_id),
                                        "and_or": "or",
                                    },
                                    {
                                        "column_name": "element_id",
                                        "condition": "Equal to",
                                        "input_value": ele_id["create_view_element_id"].iloc[0],
                                        "and_or": ")",
                                    },
                                ],
                            },
                        )
                        data = flowValidation(
                            current_decision_box_id,
                            getPrCodeFromElementId(current_decision_box_id, request),
                            request,
                            transaction_id=transaction_id,
                        )
                        result = validation_result(
                            [[]],
                            data,
                            {},
                            tablename,
                            email_success,
                            transaction_id=transaction_id,
                            request=request,
                            element_id=current_decision_box_id,
                        )
                        if True in list(result.values()):
                            exceptions = ""
                        else:
                            exceptions = exceptions + result[transaction_id]
                        if exceptions == "":
                            end_time = time.time() - start_time
                            process_flow_monitor(
                                current_decision_box_id,
                                getPrCodeFromElementId(current_decision_box_id, request),
                                app_code,
                                request,
                                None,
                                json.loads(transaction_id)[0],
                                current_element_status="pass",
                                current_element_message="Success",
                                total_data="1",
                                passed_data="1",
                                run_time=round(end_time / 60, 2),
                            )
                        else:
                            end_time = time.time() - start_time
                            process_flow_monitor(
                                current_decision_box_id,
                                getPrCodeFromElementId(current_decision_box_id, request),
                                app_code,
                                request,
                                None,
                                json.loads(transaction_id)[0],
                                current_element_status="fail",
                                current_element_message=exceptions,
                                total_data="1",
                                passed_data="0",
                                run_time=round(end_time / 60, 2),
                            )
                else:
                    pr_code = ""
            else:
                pr_code = ""

            if approval_audit_log and approval_audit_log is not None:
                if type_of_approval != "multi_level":
                    current_approval_level = 0
                else:
                    pass
                approval_audit_log_temp = json.loads(approval_audit_log)
                temp_app_log_dict = {}
                temp_all_log = []
                if approval_comment:
                    temp_all_log.append(
                        {
                            "action": "Comment",
                            "user": request.user.username,
                            "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "value": approval_comment,
                        }
                    )
                temp_all_log.append(
                    {
                        "action": "Approved By",
                        "user": request.user.username,
                        "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "value": "",
                    }
                )

                temp_app_log_dict[f"Level {current_approval_level}"] = temp_all_log
                approval_audit_log_temp.append(temp_app_log_dict)
                approval_audit_log = approval_audit_log_temp
            else:
                temp_app_log_dict = {}
                temp_all_log = []
                if approval_comment:
                    temp_all_log.append(
                        {
                            "action": "Comment",
                            "user": request.user.username,
                            "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "value": approval_comment,
                        }
                    )
                temp_all_log.append(
                    {
                        "action": "Approved By",
                        "user": request.user.username,
                        "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "value": "",
                    }
                )

                temp_app_log_dict["Level 0"] = temp_all_log
                approval_audit_log = [temp_app_log_dict]

            final_approval_data = [
                {
                    "column_name": "approval_status",
                    "input_value": "Approved",
                    "separator": ",",
                },
                {
                    "column_name": "modified_by",
                    "input_value": request.user.username,
                    "separator": ",",
                },
                {
                    "column_name": "modified_date",
                    "input_value": datetime.now(),
                    "separator": ",",
                },
                {
                    "column_name": "approved_by",
                    "input_value": json.dumps(approved_by_dict),
                    "separator": ",",
                },
                {
                    "column_name": "approval_audit_log",
                    "input_value": json.dumps(approval_audit_log),
                    "separator": "",
                },
            ]
            if approval_comment:
                if approval_comments_pr is not None:
                    if approval_comments_pr.startswith("{") and approval_comments_pr.endswith("}"):
                        approval_comment = json.dumps(temp_app_dict)
                elif type_of_approval == "multi_level":
                    approval_comment = json.dumps(temp_app_dict)
                final_approval_data = [
                    {
                        "column_name": "approval_status",
                        "input_value": "Approved",
                        "separator": ",",
                    },
                    {
                        "column_name": "modified_by",
                        "input_value": request.user.username,
                        "separator": ",",
                    },
                    {
                        "column_name": "modified_date",
                        "input_value": datetime.now(),
                        "separator": ",",
                    },
                    {
                        "column_name": "approval_comments",
                        "input_value": approval_comment,
                        "separator": ",",
                    },
                    {
                        "column_name": "approved_by",
                        "input_value": json.dumps(approved_by_dict),
                        "separator": ",",
                    },
                    {
                        "column_name": "approval_audit_log",
                        "input_value": json.dumps(approval_audit_log),
                        "separator": ",",
                    },
                    {
                        "column_name": "approval_information",
                        "input_value": approval_information,
                        "separator": "",
                    },
                ]
            elif type_of_approval == "multi_level":
                if approval_comments_pr is not None:
                    if (
                        approval_comments_pr.startswith("{")
                        and approval_comments_pr.endswith("}")
                        and not approval_comment
                    ):
                        approval_comment = json.dumps(temp_app_dict)
                        final_approval_data = [
                            {
                                "column_name": "approval_status",
                                "input_value": "Approved",
                                "separator": ",",
                            },
                            {
                                "column_name": "modified_by",
                                "input_value": request.user.username,
                                "separator": ",",
                            },
                            {
                                "column_name": "modified_date",
                                "input_value": datetime.now(),
                                "separator": ",",
                            },
                            {
                                "column_name": "approval_comments",
                                "input_value": approval_comment,
                                "separator": ",",
                            },
                            {
                                "column_name": "approved_by",
                                "input_value": json.dumps(approved_by_dict),
                                "separator": ",",
                            },
                            {
                                "column_name": "approver_user",
                                "input_value": "[]",
                                "separator": ",",
                            },
                            {
                                "column_name": "approver_group",
                                "input_value": "[]",
                                "separator": ",",
                            },
                            {
                                "column_name": "approval_audit_log",
                                "input_value": json.dumps(approval_audit_log),
                                "separator": ",",
                            },
                            {
                                "column_name": "approval_information",
                                "input_value": approval_information,
                                "separator": "",
                            },
                        ]
                else:
                    approval_comment = json.dumps(temp_app_dict)
                    final_approval_data = [
                        {
                            "column_name": "approval_status",
                            "input_value": "Approved",
                            "separator": ",",
                        },
                        {
                            "column_name": "modified_by",
                            "input_value": request.user.username,
                            "separator": ",",
                        },
                        {
                            "column_name": "modified_date",
                            "input_value": datetime.now(),
                            "separator": ",",
                        },
                        {
                            "column_name": "approval_comments",
                            "input_value": approval_comment,
                            "separator": ",",
                        },
                        {
                            "column_name": "approved_by",
                            "input_value": json.dumps(approved_by_dict),
                            "separator": ",",
                        },
                        {
                            "column_name": "approver_user",
                            "input_value": "[]",
                            "separator": ",",
                        },
                        {
                            "column_name": "approver_group",
                            "input_value": "[]",
                            "separator": ",",
                        },
                        {
                            "column_name": "approval_audit_log",
                            "input_value": json.dumps(approval_audit_log),
                            "separator": ",",
                        },
                        {
                            "column_name": "approval_information",
                            "input_value": approval_information,
                            "separator": "",
                        },
                    ]

            update_data_func(
                request,
                config_dict={
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "ApprovalTable",
                        "Columns": final_approval_data,
                    },
                    "condition": [
                        {
                            "column_name": "tablename",
                            "condition": "Equal to",
                            "input_value": tablename,
                            "and_or": "AND",
                        },
                        {
                            "column_name": "id",
                            "condition": "Equal to",
                            "input_value": str(approval_id),
                            "and_or": "",
                        },
                    ],
                },
            )

            check_event_data = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "event_master",
                        "Columns": ["event", "action_config"],
                    },
                    "condition": [
                        {
                            "column_name": "approval_code",
                            "condition": "Equal to",
                            "input_value": approval_code,
                            "and_or": "",
                        }
                    ],
                },
            )

            if len(check_event_data) > 0:
                action_config = json.loads(check_event_data.loc[0, "action_config"])
                message_job_id = action_config["job_id"]
                event_message = json.loads(check_event_data.loc[0, "event"])

                if "Approved" in event_message:
                    scheduler = Scheduler(connection=redis_instance_scheduler)
                    scheduler.cancel(message_job_id)

                    update_data_func(
                        request,
                        config_dict={
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "event_master",
                                "Columns": [
                                    {
                                        "column_name": "event_triggered_by",
                                        "input_value": request.user.username,
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "status",
                                        "input_value": "closed",
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "event_triggered_date",
                                        "input_value": datetime.now(),
                                        "separator": "",
                                    },
                                ],
                            },
                            "condition": [
                                {
                                    "column_name": "approval_code",
                                    "condition": "Equal to",
                                    "input_value": approval_code,
                                    "and_or": "",
                                }
                            ],
                        },
                    )

            redis_instance.set("pr_code_t", pickle.dumps(pr_code))
            redirect_config, status = active_flow_element(request, "approval")
            pr_code_redirect = ""
            if status:
                pr_code_redirect = redirect_config["subprocess"]
            return {
                "response": "success",
                "pr_code": pr_code,
                "pr_code_redirect": pr_code_redirect,
                "error": "",
            }
        else:
            return {
                "response": "fail",
                "pr_code": "",
                "error": "Validation failed! Please check the data and try again",
            }
    else:
        return {"response": "fail", "pr_code": "", "error": ""}


def server_side_content_func(request, elementTabID, model_name="", view_name="", request2={}):
    return_dic = False
    if view_name == "viewname":
        view_name = None
    if redis_instance.exists(elementTabID + "MulView_Table") == 1:
        temp_data = pickle.loads(redis_instance.get(elementTabID + "MulView_Table"))
        if temp_data.get("fetch_on_select"):
            del temp_data["fetch_on_select"]
            redis_instance.set(elementTabID + "MulView_Table", pickle.dumps(temp_data))

    read_func_col_1 = [
        "id",
        "tab_header_name",
        "tab_icon",
        "tab_type",
        "tab_body_content",
        "level",
        "related_item_code",
        "element_id",
        "shape",
        "user_name",
        "table_name",
        "computation_name",
        "fields",
    ]
    tabscreendata = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": read_func_col_1,
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": elementTabID,
                    "and_or": "",
                }
            ],
        },
    ).loc[0]
    createviewname = json.loads(tabscreendata.tab_body_content)
    if model_name == "":
        model_name = createviewname
        model_name = model_name["Category_attributes"]["Mandatory"]["Table_name"]
        return_dic = True

    modelName = dynamic_model_create.get_model_class(model_name, request)
    columns = [field.name for field in modelName.concrete_fields]

    request_start = "0"
    request_length = "-1"
    rawData, r_len = data_chunking(model_name, request, request_start, request_length, [], columns)
    results = rawData
    results = results.fillna("-").astype(str).to_dict("records")

    if return_dic:
        return results, model_name
    return results, columns, r_len


def check_approval_condition(condition, request, action, request2={}, approval_condition=[]):

    approval_condition.append(
        {
            "column_name": "approvaL_status",
            "condition": "Equal to",
            "input_value": "Pending",
            "and_or": "AND",
            "constraintName": "ApprovalStatus",
            "ruleSet": "ApprovalStatus",
        }
    )
    for i in range(len(approval_condition)):
        approval_condition[i]["and_or"] = "AND"
    data = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "ApprovalTable",
                "Columns": ["json_data", "tablename", "id", "create_view_element_id", "approval_type"],
            },
            "condition": approval_condition,
        },
    )
    if not data.empty:
        if condition:
            condition_dict = {}
            for cond in condition:
                input_val = cond["input_value"]
                if cond["condition"] == "Starts with":
                    cond_str = (
                        f"transaction_data.{cond['column_name']}.astype('str').startswith('{input_val}')"
                    )
                elif cond["condition"] == "Ends with":
                    cond_str = f"transaction_data.{cond['column_name']}.astype('str').endswith('{input_val}')"
                elif cond["condition"] == "Equal to":
                    if input_val == "True":
                        cond_str = f"transaction_data.{cond['column_name']}"
                    else:
                        if cond.get("type") and cond.get("type") != "text":
                            cond_str = f"transaction_data.{cond['column_name']} == {input_val}"
                        else:
                            cond_str = f"""transaction_data.{cond['column_name']} == '{input_val}'"""
                elif cond["condition"] == "Not Equal to":
                    if input_val == "True":
                        cond_str = f"~transaction_data.{cond['column_name']}"
                    else:
                        if cond.get("type") and cond.get("type") != "text":
                            cond_str = f"transaction_data.{cond['column_name']} != {input_val}"
                        else:
                            cond_str = f"""transaction_data.{cond['column_name']} != '{input_val}'"""
                elif cond["condition"] == "Greater than":
                    cond_str = f"transaction_data.{cond['column_name']} > {input_val}"
                elif cond["condition"] == "Smaller than":
                    cond_str = f"transaction_data.{cond['column_name']} < {input_val}"
                elif cond["condition"] == "IN":
                    cond_str = f"transaction_data.{cond['column_name']}.isin({input_val})"
                elif cond["condition"] == "NOT IN":
                    cond_str = f"~transaction_data.{cond['column_name']}.isin({input_val})"
                else:
                    pass
                if condition_dict.get(cond["constraintName"]):
                    if condition_dict[cond["constraintName"]].get(cond["ruleSet"]):
                        condition_dict[cond["constraintName"]][cond["ruleSet"]] += " & "
                        condition_dict[cond["constraintName"]][cond["ruleSet"]] += cond_str
                    else:
                        condition_dict[cond["constraintName"]][cond["ruleSet"]] = cond_str
                else:
                    condition_dict[cond["constraintName"]] = {cond["ruleSet"]: cond_str}
            for const, rule in condition_dict.items():
                cont_str = "("
                for rule_config in rule.values():
                    cont_str += "(" + rule_config + ")"
                    cont_str += " | "
                cont_str = cont_str.rstrip(" | ")
                cont_str += ") & "
            cont_str = cont_str.rstrip(" & ")
            transaction_data_list = [json.loads(i)[0] for i in data["json_data"].tolist()]
            transaction_data = pd.DataFrame(transaction_data_list)
            data = data[pd.eval(cont_str).fillna(False)]
        else:
            pass
        data.drop(columns=["json_data"], inplace=True)
        for idx, row in data.iterrows():
            approval_id = row["id"]
            tablename = row["tablename"]
            element_id = row["create_view_element_id"]
            type_of_query = row["approval_type"]
            if action in ["approve", "approve_with_condition"]:
                approve_all_approval(
                    tablename=tablename,
                    type_of_query=type_of_query,
                    exceptions="",
                    ele_id=element_id,
                    edited_data={},
                    approval_comment="",
                    request=request,
                    t_id="",
                    approval_id=approval_id,
                    request2=request2,
                )
            else:
                reject_all_approval(
                    tablename=tablename,
                    type_of_query=type_of_query,
                    exceptions="",
                    ele_id=element_id,
                    edited_data={},
                    approval_comment="",
                    request=request,
                    t_id="",
                    approval_id=approval_id,
                    request2=request2,
                )
    else:
        pass
    return True


def get_condition(column, cond, input_val, daterange, cus_d1="", cus_d2=""):
    Agg_Type = ""
    Order_Type = ""
    condition = []

    if daterange == "Latest":
        Agg_Type = "TOP(1)"
        Order_Type = f"ORDER BY {column} DESC"
    elif daterange == "Today":
        Agg_Type = ""
        Order_Type = ""
        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": datetime.now().strftime("%Y-%m-%d 00:00:00"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "Yesterday":
        Agg_Type = ""
        Order_Type = ""
        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": (datetime.now() + pd.DateOffset(days=-1)).strftime("%Y-%m-%d 00:00:00"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "This Week":
        Agg_Type = ""
        Order_Type = ""
        current_date = datetime.now()
        start_of_week = current_date - timedelta(days=current_date.weekday())
        start_of_week = start_of_week.replace(hour=0, minute=0, second=0)
        end_of_week = start_of_week + timedelta(days=6)
        end_of_week = end_of_week.replace(hour=23, minute=59, second=59)
        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": start_of_week.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
        condition.append(
            {
                "column_name": column,
                "condition": "Smaller than equal to",
                "input_value": end_of_week.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "This Month":
        Agg_Type = ""
        Order_Type = ""
        current_date = datetime.now()
        currMonth = current_date.month
        dtFirstDay = datetime(current_date.year, currMonth, 1)
        next_month = current_date.replace(day=28) + timedelta(days=4)
        next_month = next_month - timedelta(days=next_month.day)
        next_month = next_month.replace(hour=23, minute=59, second=59)
        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": dtFirstDay.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
        condition.append(
            {
                "column_name": column,
                "condition": "Smaller than equal to",
                "input_value": next_month.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "This Quarter":
        Agg_Type = ""
        Order_Type = ""
        current_date = datetime.now()
        currQuarter = (current_date.month - 1) // 3 + 1
        dtFirstDay = datetime(current_date.year, 3 * currQuarter - 2, 1)
        dtLastDay = datetime(current_date.year, (3 * currQuarter) % 12 + 1, 1) + timedelta(days=-1)
        dtLastDay = dtLastDay.replace(hour=23, minute=59, second=59)
        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": dtFirstDay.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
        condition.append(
            {
                "column_name": column,
                "condition": "Smaller than equal to",
                "input_value": dtLastDay.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "This Year":
        Agg_Type = ""
        Order_Type = ""
        current_date = datetime.now()
        dtFirstDay = datetime(current_date.year, 1, 1)
        dtLastDay = datetime(current_date.year, 12, 31)
        dtLastDay = dtLastDay.replace(hour=23, minute=59, second=59)
        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": dtFirstDay.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
        condition.append(
            {
                "column_name": column,
                "condition": "Smaller than equal to",
                "input_value": dtLastDay.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "Previous Week":
        Agg_Type = ""
        Order_Type = ""
        current_date = datetime.now()
        start_date = current_date + timedelta(-current_date.weekday(), weeks=-1)
        end_date = current_date + timedelta(-current_date.weekday() - 1)
        start_date = start_date.replace(hour=0, minute=0, second=0)
        end_date = end_date.replace(hour=23, minute=59, second=59)

        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": start_date.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
        condition.append(
            {
                "column_name": column,
                "condition": "Smaller than equal to",
                "input_value": end_date.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "Previous Month":
        Agg_Type = ""
        Order_Type = ""
        current_date = datetime.now()
        last_day_of_prev_month = current_date.replace(day=1) - timedelta(days=1)
        start_day_of_prev_month = current_date.replace(day=1) - timedelta(days=last_day_of_prev_month.day)
        start_day_of_prev_month = start_day_of_prev_month.replace(hour=0, minute=0, second=0)
        last_day_of_prev_month = last_day_of_prev_month.replace(hour=23, minute=59, second=59)

        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": start_day_of_prev_month.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
        condition.append(
            {
                "column_name": column,
                "condition": "Smaller than equal to",
                "input_value": last_day_of_prev_month.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "Previous Quarter":
        Agg_Type = ""
        Order_Type = ""
        current_date = datetime.now()
        if current_date.month < 4:
            end_date = datetime(current_date.year - 1, 12, 31)
        elif current_date.month < 7:
            end_date = datetime(current_date.year, 3, 31)
        elif current_date.month < 10:
            end_date = datetime(current_date.year, 6, 30)
        else:
            end_date = datetime(current_date.year, 9, 30)

        start_date = (end_date + pd.DateOffset(months=-3)).replace(day=1)
        start_date = start_date.replace(hour=0, minute=0, second=0)
        end_date = end_date.replace(hour=23, minute=59, second=59)

        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": start_date.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
        condition.append(
            {
                "column_name": column,
                "condition": "Smaller than equal to",
                "input_value": end_date.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "Previous Year":
        Agg_Type = ""
        Order_Type = ""
        current_date = datetime.now()
        dtFirstDay = datetime(current_date.year - 1, 1, 1)
        dtLastDay = datetime(current_date.year - 1, 12, 31)
        dtFirstDay = dtFirstDay.replace(hour=0, minute=0, second=0)
        dtLastDay = dtLastDay.replace(hour=23, minute=59, second=59)

        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": dtFirstDay.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": dtFirstDay.strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    elif daterange == "Custom":
        start_date = cus_d1
        end_date = cus_d2
        Agg_Type = ""
        Order_Type = ""

        condition.append(
            {
                "column_name": column,
                "condition": "Greater than equal to",
                "input_value": pd.to_datetime(start_date).strftime("%Y-%m-%d %H:%M:%S"),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
        condition.append(
            {
                "column_name": column,
                "condition": "Smaller than equal to",
                "input_value": (pd.to_datetime(end_date) + pd.DateOffset(days=1)).strftime(
                    "%Y-%m-%d %H:%M:%S"
                ),
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )

    if cond in [
        "Starts with",
        "Ends with",
        "Contains",
        "Equal to",
        "Not Starts with",
        "Not Ends with",
        "Not Contains",
        "Not Equal to",
        "Greater than",
        "Greater than equal to",
        "Smaller than",
        "Smaller than equal to",
        "IN",
        "NOT IN",
    ]:
        condition.append(
            {
                "column_name": column,
                "condition": cond,
                "input_value": input_val,
                "and_or": "",
                "constraintName": "LV_Filter",
                "ruleSet": "LV_Filter",
            }
        )
    else:
        pass
    return Agg_Type, Order_Type, condition


def approvals_information_extractor(
    request,
    data,
    approval_type,
    approval_config,
    decision_action_type,
    approval_emailer_type,
    approval_decision_emailer_type,
    approval_emailer_list,
    approval_decision_emailer_list,
    model_class,
    approval_mail_additional_config,
    approvalSkipLevelOption=False,
):
    approver_group = []
    approver_user = []
    hierarchy_approval_config = None
    approval_level_config = None
    skipFinalLevel = False
    approver_type = "several"
    if approval_type != "multi_level":
        if approval_config.get("approver_type"):
            approver_type = approval_config["approver_type"]
        else:
            pass
    else:
        pass
    if approval_type == "static":
        approver_group = approval_config["group_list"]
    elif approval_type == "static_user":
        approver_user = approval_config["user_list"]
    elif approval_type == "dynamic_group":
        interim_value = data[approval_config["field"]].values[0]
        if model_class.get_field(approval_config["field"]).get_internal_type() == "MultiselectField":
            if interim_value:
                field_multiselect_config = json.loads(
                    model_class.get_field(approval_config["field"]).mulsel_config
                )
                multi_select_table = field_multiselect_config["value"][0]
                multi_select_master_column = field_multiselect_config["masterColumn"][0]
                interim_value = list(json.loads(interim_value).keys())
                converted_value = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": multi_select_table,
                            "Columns": [multi_select_master_column],
                        },
                        "condition": [
                            {
                                "column_name": "id",
                                "condition": "IN",
                                "input_value": interim_value,
                                "and_or": "",
                            }
                        ],
                    },
                )[multi_select_master_column].tolist()
                approver_group = converted_value
            else:
                approver_group = []
        else:
            approver_group = [interim_value]
    elif approval_type == "dynamic_user":
        interim_value = data[approval_config["field"]].values[0]
        if model_class.get_field(approval_config["field"]).get_internal_type() == "MultiselectField":
            if interim_value:
                field_multiselect_config = json.loads(
                    model_class.get_field(approval_config["field"]).mulsel_config
                )
                multi_select_table = field_multiselect_config["value"][0]
                multi_select_master_column = field_multiselect_config["masterColumn"][0]
                interim_value = list(json.loads(interim_value).keys())
                converted_value = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": multi_select_table,
                            "Columns": [multi_select_master_column],
                        },
                        "condition": [
                            {
                                "column_name": "id",
                                "condition": "IN",
                                "input_value": interim_value,
                                "and_or": "",
                            }
                        ],
                    },
                )[multi_select_master_column].tolist()
                approver_user = converted_value
            else:
                approver_user = []
        elif model_class.get_field(approval_config["field"]).get_internal_type() == "ForeignKey":
            if interim_value:
                parent_df = (
                    read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": model_class.get_field(approval_config["field"]).parent,
                                "Columns": [
                                    "id",
                                    approval_config["field"],
                                ],
                            },
                            "condition": [],
                        },
                        access_controller=False,
                    )
                    .astype("str")
                    .set_index("id")[approval_config["field"]]
                    .to_dict()
                )
                if str(interim_value) in parent_df:
                    interim_value = parent_df[str(interim_value)]
                else:
                    pass
            approver_user = [interim_value]
        else:
            approver_user = [interim_value]
    elif approval_type in ["dynamic_master_group", "dynamic_master_user"]:
        parameter = approval_config["parameter"]
        if parameter == "user_username":
            parameter_value = [request.user.username]
        elif parameter == "user_email":
            parameter_value = [request.user.email]
        else:
            parameter_value = data[approval_config["parameter_field"]].values[0]
            if (
                model_class.get_field(approval_config["parameter_field"]).get_internal_type()
                == "MultiselectField"
            ):
                if parameter_value:
                    field_multiselect_config = json.loads(
                        model_class.get_field(approval_config["parameter_field"]).mulsel_config
                    )
                    multi_select_table = field_multiselect_config["value"][0]
                    multi_select_master_column = field_multiselect_config["masterColumn"][0]
                    parameter_value = list(json.loads(parameter_value).keys())
                    if parameter_value:
                        converted_value = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": multi_select_table,
                                    "Columns": [multi_select_master_column],
                                },
                                "condition": [
                                    {
                                        "column_name": "id",
                                        "condition": "IN",
                                        "input_value": parameter_value,
                                        "and_or": "",
                                    }
                                ],
                            },
                        )[multi_select_master_column].tolist()
                        parameter_value = converted_value
                    else:
                        pass
                else:
                    parameter_value = []
            elif (
                model_class.get_field(approval_config["parameter_field"]).get_internal_type() == "ForeignKey"
            ):
                if parameter_value:
                    parent_df = (
                        read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": model_class.get_field(approval_config["parameter_field"]).parent,
                                    "Columns": [
                                        "id",
                                        approval_config["parameter_field"],
                                    ],
                                },
                                "condition": [],
                            },
                            access_controller=False,
                        )
                        .astype("str")
                        .set_index("id")[approval_config["parameter_field"]]
                        .to_dict()
                    )
                    if str(parameter_value) in parent_df:
                        parameter_value = parent_df[str(parameter_value)]
                    else:
                        pass
                parameter_value = [parameter_value]
            else:
                parameter_value = [parameter_value]

        # Master Mapping
        for level in approval_config["master_level_config"]:
            if parameter_value:
                approver_value = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": level["table_name"],
                            "Columns": [level["approver_field"]],
                        },
                        "condition": [
                            {
                                "column_name": level["mapping_field"],
                                "condition": "IN",
                                "input_value": parameter_value,
                                "and_or": "",
                            },
                        ],
                    },
                )
                if not approver_value.empty:
                    parameter_value = approver_value[level["approver_field"]].tolist()
                else:
                    break
            else:
                break
        if approval_type == "dynamic_master_group":
            approver_group = parameter_value
        else:
            approver_user = parameter_value
    elif approval_type == "hierarchical":
        status, next_level_in_hierarchy = hierarchy_approval_group_extractor(
            request, approval_config, user_or_group="group"
        )
        hierarchy_approval_config = approval_config.copy()
        if status == "Success":
            approver_group = [next_level_in_hierarchy]
            hierarchy_approval_config["current_level_name"] = next_level_in_hierarchy
            hierarchy_approval_config["current_level"] = (
                f'{int(hierarchy_approval_config["starting_level"]) - 1}'
            )
        else:
            approver_group = []
    elif approval_type == "hierarchical_user":
        status, next_level_in_hierarchy = hierarchy_approval_group_extractor(
            request, approval_config, user_or_group="user"
        )
        hierarchy_approval_config = approval_config.copy()
        if status == "Success":
            approver_user = [next_level_in_hierarchy]
            hierarchy_approval_config["current_level_name"] = next_level_in_hierarchy
            hierarchy_approval_config["current_level"] = (
                f'{int(hierarchy_approval_config["starting_level"]) - 1}'
            )
        else:
            approver_user = []
    elif approval_type == "multi_level":
        if approval_config.get("current_level"):
            current_level = approval_config["current_level"]
        else:
            current_level = 0
        approval_level_config = approval_config.copy()
        approval_level_config["current_level"] = current_level
        level_config = approval_config["level_config"]
        current_level_config = level_config[current_level]
        if current_level_config.get("approver_type"):
            approver_type = current_level_config["approver_type"]
        else:
            pass
        approver_user, approver_group, approver_type = approval_info_extractor(
            request, current_level_config, data, model_class, approver_type
        )
    else:
        pass

    if approvalSkipLevelOption:
        if approval_type != "multi_level":
            if approver_group:
                current_user_group = list(request.user.groups.values_list("name", flat=True))
                if any(i for i in approver_group if i in current_user_group):
                    skipFinalLevel = True
                else:
                    pass
            elif approver_user:
                current_user_name = request.user.username
                if current_user_name in approver_user:
                    skipFinalLevel = True
                else:
                    pass
            else:
                pass
        else:
            current_approval_level = approval_level_config["current_level"]
            if current_approval_level == 0:
                multi_level_approval_details = {}
                for lvl_idx, lvl_conf in enumerate(approval_level_config["level_config"]):
                    if lvl_conf.get("approver_type"):
                        lvl_approver_type = lvl_conf["approver_type"]
                    else:
                        lvl_approver_type = approver_type
                    if lvl_idx == 0:
                        multi_level_approval_details[lvl_idx] = (
                            approver_user,
                            approver_group,
                            lvl_approver_type,
                        )
                    else:
                        multi_level_approval_details[lvl_idx] = approval_info_extractor(
                            request, lvl_conf, data, model_class, lvl_approver_type
                        )

                for key, value in multi_level_approval_details.items():
                    lvl_approver_user, lvl_approver_group, lvl_approver_type = value
                    if lvl_approver_group:
                        current_user_group = list(request.user.groups.values_list("name", flat=True))
                        if any(i for i in lvl_approver_group if i in current_user_group):
                            approval_level_config["current_level"] = key + 1
                        else:
                            pass
                    elif lvl_approver_user:
                        current_user_name = request.user.username
                        if current_user_name in lvl_approver_user:
                            approval_level_config["current_level"] = key + 1
                        else:
                            continue
                    else:
                        continue
                new_approval_level = approval_level_config["current_level"]
                if new_approval_level == len(approval_level_config["level_config"]):
                    skipFinalLevel = True
                    new_approval_level -= 1
                else:
                    pass
                approver_user, approver_group, approver_type = multi_level_approval_details[
                    new_approval_level
                ]
            else:
                pass
    else:
        pass

    # Email information
    approval_recipient_list = []
    approval_decision_recipient_list = []
    approval_recipient_list_cc = []
    approval_decision_recipient_list_cc = []
    approval_recipient_list_bcc = []
    approval_decision_recipient_list_bcc = []
    if decision_action_type == "Set Approval and Email":
        # Entry Email Recipients (Approvers)
        if approval_emailer_type == "static":
            approval_recipient_list = approval_emailer_list
        elif approval_emailer_type == "dynamic_user":
            approval_recipient_list = [request.user.email]
        else:
            user_emails = []
            if approver_group:
                group_id = (
                    read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "auth_group",
                                "Columns": ["id"],
                            },
                            "condition": [
                                {
                                    "column_name": "name",
                                    "condition": "IN",
                                    "input_value": str(tuple(approver_group)).replace(",)", ")"),
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                ).id.tolist()
                if group_id:
                    user_ids = (
                        read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "user_groups",
                                    "Columns": ["user_id"],
                                },
                                "condition": [
                                    {
                                        "column_name": "group_id",
                                        "condition": "IN",
                                        "input_value": str(tuple(group_id)).replace(",)", ")"),
                                        "and_or": "",
                                    }
                                ],
                            },
                        )
                    ).user_id.tolist()
                    if user_ids:
                        user_emails = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "User",
                                        "Columns": ["email"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "id",
                                            "condition": "IN",
                                            "input_value": str(tuple(user_ids)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).email.tolist()
                    else:
                        user_emails = []
                else:
                    user_emails = []
            else:
                pass
            if approver_user:
                user_emails = (
                    read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "User",
                                "Columns": ["email"],
                            },
                            "condition": [
                                {
                                    "column_name": "username",
                                    "condition": "IN",
                                    "input_value": str(tuple(approver_user)).replace(",)", ")"),
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                ).email.tolist()
            else:
                pass
            approval_recipient_list = user_emails

        # Decision Email Recipients
        if approval_decision_emailer_type == "static":
            approval_decision_recipient_list = approval_decision_emailer_list
        elif approval_decision_emailer_type == "dynamic_user":
            approval_decision_recipient_list = [request.user.email]
        else:
            user_emails = []
            if approver_group:
                group_id = (
                    read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "auth_group",
                                "Columns": ["id"],
                            },
                            "condition": [
                                {
                                    "column_name": "name",
                                    "condition": "IN",
                                    "input_value": str(tuple(approver_group)).replace(",)", ")"),
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                ).id.tolist()
                if group_id:
                    user_ids = (
                        read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "user_groups",
                                    "Columns": ["user_id"],
                                },
                                "condition": [
                                    {
                                        "column_name": "group_id",
                                        "condition": "IN",
                                        "input_value": str(tuple(group_id)).replace(",)", ")"),
                                        "and_or": "",
                                    }
                                ],
                            },
                        )
                    ).user_id.tolist()
                    if user_ids:
                        user_emails = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "User",
                                        "Columns": ["email"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "id",
                                            "condition": "IN",
                                            "input_value": str(tuple(user_ids)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).email.tolist()
                    else:
                        user_emails = []
                else:
                    user_emails = []
            else:
                pass
            if approver_user:
                user_emails = (
                    read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "User",
                                "Columns": ["email"],
                            },
                            "condition": [
                                {
                                    "column_name": "username",
                                    "condition": "IN",
                                    "input_value": str(tuple(approver_user)).replace(",)", ")"),
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                ).email.tolist()
            else:
                pass
            approval_decision_recipient_list = user_emails

        if approval_mail_additional_config:
            # CC
            if approval_mail_additional_config.get("approver_mailer_typeCC"):
                if approval_mail_additional_config["approver_mailer_typeCC"] == "static":
                    if approval_mail_additional_config.get("approval_email_listCC"):
                        approval_recipient_list_cc = approval_mail_additional_config["approval_email_listCC"]
                    else:
                        pass
                elif approval_mail_additional_config["approver_mailer_typeCC"] == "dynamic_user":
                    approval_recipient_list_cc = [request.user.email]
                else:
                    user_emails = []
                    if approver_group:
                        group_id = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "auth_group",
                                        "Columns": ["id"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "name",
                                            "condition": "IN",
                                            "input_value": str(tuple(approver_group)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).id.tolist()
                        if group_id:
                            user_ids = (
                                read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": "user_groups",
                                            "Columns": ["user_id"],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "group_id",
                                                "condition": "IN",
                                                "input_value": str(tuple(group_id)).replace(",)", ")"),
                                                "and_or": "",
                                            }
                                        ],
                                    },
                                )
                            ).user_id.tolist()
                            if user_ids:
                                user_emails = (
                                    read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": ["email"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "id",
                                                    "condition": "IN",
                                                    "input_value": str(tuple(user_ids)).replace(",)", ")"),
                                                    "and_or": "",
                                                }
                                            ],
                                        },
                                    )
                                ).email.tolist()
                            else:
                                user_emails = []
                        else:
                            user_emails = []
                    else:
                        pass
                    if approver_user:
                        user_emails = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "User",
                                        "Columns": ["email"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "username",
                                            "condition": "IN",
                                            "input_value": str(tuple(approver_user)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).email.tolist()
                    else:
                        user_emails = []
                    approval_recipient_list_cc = user_emails

                # Decision Email Recipients
                if approval_mail_additional_config["approver_decision_mailer_typeCC"] == "static":
                    if approval_mail_additional_config["approval_decision_email_listCC"]:
                        approval_decision_recipient_list_cc = approval_mail_additional_config[
                            "approval_decision_email_listCC"
                        ]
                    else:
                        pass
                elif approval_mail_additional_config["approver_decision_mailer_typeCC"] == "dynamic_user":
                    approval_decision_recipient_list_cc = [request.user.email]
                else:
                    user_emails = []
                    if approver_group:
                        group_id = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "auth_group",
                                        "Columns": ["id"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "name",
                                            "condition": "IN",
                                            "input_value": str(tuple(approver_group)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).id.tolist()
                        if group_id:
                            user_ids = (
                                read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": "user_groups",
                                            "Columns": ["user_id"],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "group_id",
                                                "condition": "IN",
                                                "input_value": str(tuple(group_id)).replace(",)", ")"),
                                                "and_or": "",
                                            }
                                        ],
                                    },
                                )
                            ).user_id.tolist()
                            if user_ids:
                                user_emails = (
                                    read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": ["email"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "id",
                                                    "condition": "IN",
                                                    "input_value": str(tuple(user_ids)).replace(",)", ")"),
                                                    "and_or": "",
                                                }
                                            ],
                                        },
                                    )
                                ).email.tolist()
                            else:
                                user_emails = []
                        else:
                            user_emails = []
                    else:
                        pass
                    if approver_user:
                        user_emails = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "User",
                                        "Columns": ["email"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "username",
                                            "condition": "IN",
                                            "input_value": str(tuple(approver_user)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).email.tolist()
                    else:
                        pass
                    approval_decision_recipient_list_cc = user_emails
            else:
                pass

            # BCC
            if approval_mail_additional_config.get("approver_mailer_typeBCC"):
                if approval_mail_additional_config["approver_mailer_typeBCC"] == "static":
                    if approval_mail_additional_config.get("approval_email_listBCC"):
                        approval_recipient_list_bcc = approval_mail_additional_config[
                            "approval_email_listBCC"
                        ]
                    else:
                        pass
                elif approval_mail_additional_config["approver_mailer_typeBCC"] == "dynamic_user":
                    approval_recipient_list_bcc = [request.user.email]
                else:
                    user_emails = []
                    if approver_group:
                        group_id = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "auth_group",
                                        "Columns": ["id"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "name",
                                            "condition": "IN",
                                            "input_value": str(tuple(approver_group)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).id.tolist()
                        if group_id:
                            user_ids = (
                                read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": "user_groups",
                                            "Columns": ["user_id"],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "group_id",
                                                "condition": "IN",
                                                "input_value": str(tuple(group_id)).replace(",)", ")"),
                                                "and_or": "",
                                            }
                                        ],
                                    },
                                )
                            ).user_id.tolist()
                            if user_ids:
                                user_emails = (
                                    read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": ["email"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "id",
                                                    "condition": "IN",
                                                    "input_value": str(tuple(user_ids)).replace(",)", ")"),
                                                    "and_or": "",
                                                }
                                            ],
                                        },
                                    )
                                ).email.tolist()
                            else:
                                user_emails = []
                        else:
                            user_emails = []
                    else:
                        pass
                    if approver_user:
                        user_emails = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "User",
                                        "Columns": ["email"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "username",
                                            "condition": "IN",
                                            "input_value": str(tuple(approver_user)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).email.tolist()
                    else:
                        pass
                    approval_recipient_list_bcc = user_emails

                # Decision Email Recipients
                if approval_mail_additional_config["approver_decision_mailer_typeBCC"] == "static":
                    if approval_mail_additional_config.get("approval_decision_email_listBCC"):
                        approval_decision_recipient_list_bcc = approval_mail_additional_config[
                            "approval_decision_email_listBCC"
                        ]
                    else:
                        pass
                elif approval_mail_additional_config["approver_decision_mailer_typeBCC"] == "dynamic_user":
                    approval_decision_recipient_list_bcc = [request.user.email]
                else:
                    user_emails = []
                    if approver_group:
                        group_id = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "auth_group",
                                        "Columns": ["id"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "name",
                                            "condition": "IN",
                                            "input_value": str(tuple(approver_group)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).id.tolist()
                        if group_id:
                            user_ids = (
                                read_data_func(
                                    request,
                                    {
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": "user_groups",
                                            "Columns": ["user_id"],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "group_id",
                                                "condition": "IN",
                                                "input_value": str(tuple(group_id)).replace(",)", ")"),
                                                "and_or": "",
                                            }
                                        ],
                                    },
                                )
                            ).user_id.tolist()
                            if user_ids:
                                user_emails = (
                                    read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "User",
                                                "Columns": ["email"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "id",
                                                    "condition": "IN",
                                                    "input_value": str(tuple(user_ids)).replace(",)", ")"),
                                                    "and_or": "",
                                                }
                                            ],
                                        },
                                    )
                                ).email.tolist()
                            else:
                                user_emails = []
                        else:
                            user_emails = []
                    else:
                        pass
                    if approver_user:
                        user_emails = (
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "User",
                                        "Columns": ["email"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "username",
                                            "condition": "IN",
                                            "input_value": str(tuple(approver_user)).replace(",)", ")"),
                                            "and_or": "",
                                        }
                                    ],
                                },
                            )
                        ).email.tolist()
                    else:
                        pass
                    approval_decision_recipient_list_bcc = user_emails
            else:
                pass
        else:
            pass
    else:
        pass
    additional_recipients = {
        "approval_recipient_list_cc": approval_recipient_list_cc,
        "approval_decision_recipient_list_cc": approval_decision_recipient_list_cc,
        "approval_recipient_list_bcc": approval_recipient_list_bcc,
        "approval_decision_recipient_list_bcc": approval_decision_recipient_list_bcc,
    }
    return (
        approver_group,
        approver_user,
        hierarchy_approval_config,
        approval_recipient_list,
        approval_decision_recipient_list,
        approval_level_config,
        approver_type,
        additional_recipients,
        skipFinalLevel,
    )


def approval_info_extractor(request, current_level_config, data, model_class, current_level_approver_type):
    level_approver_user = []
    level_approver_group = []
    current_level_approval_type = current_level_config["approval_type"]
    if current_level_approval_type == "static":
        level_approver_group = current_level_config["group_list"]
    elif current_level_approval_type == "static_user":
        level_approver_user = current_level_config["user_list"]
    elif current_level_approval_type == "dynamic_group":
        interim_value = data[current_level_config["field"]].values[0]
        if model_class.get_field(current_level_config["field"]).get_internal_type() == "MultiselectField":
            if interim_value:
                field_multiselect_config = json.loads(
                    model_class.get_field(current_level_config["field"]).mulsel_config
                )
                multi_select_table = field_multiselect_config["value"][0]
                multi_select_master_column = field_multiselect_config["masterColumn"][0]
                interim_value = list(json.loads(interim_value).keys())
                converted_value = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": multi_select_table,
                            "Columns": [multi_select_master_column],
                        },
                        "condition": [
                            {
                                "column_name": "id",
                                "condition": "IN",
                                "input_value": interim_value,
                                "and_or": "",
                            }
                        ],
                    },
                )[multi_select_master_column].tolist()
                level_approver_group = converted_value
            else:
                level_approver_group = []
        else:
            level_approver_group = [interim_value]
    elif current_level_approval_type == "dynamic_user":
        interim_value = data[current_level_config["field"]].values[0]
        if model_class.get_field(current_level_config["field"]).get_internal_type() == "MultiselectField":
            if interim_value:
                field_multiselect_config = json.loads(
                    model_class.get_field(current_level_config["field"]).mulsel_config
                )
                multi_select_table = field_multiselect_config["value"][0]
                multi_select_master_column = field_multiselect_config["masterColumn"][0]
                interim_value = list(json.loads(interim_value).keys())
                converted_value = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": multi_select_table,
                            "Columns": [multi_select_master_column],
                        },
                        "condition": [
                            {
                                "column_name": "id",
                                "condition": "IN",
                                "input_value": interim_value,
                                "and_or": "",
                            }
                        ],
                    },
                )[multi_select_master_column].tolist()
                level_approver_user = converted_value
            else:
                level_approver_user = []
        else:
            level_approver_user = [interim_value]
    elif current_level_approval_type in ["dynamic_master_group", "dynamic_master_user"]:
        parameter = current_level_config["parameter"]
        if parameter == "user_username":
            parameter_value = [request.user.username]
        elif parameter == "user_email":
            parameter_value = [request.user.email]
        else:
            parameter_value = data[current_level_config["parameter_field"]].values[0]
            if (
                model_class.get_field(current_level_config["parameter_field"]).get_internal_type()
                == "MultiselectField"
            ):
                if parameter_value:
                    field_multiselect_config = json.loads(
                        model_class.get_field(current_level_config["parameter_field"]).mulsel_config
                    )
                    multi_select_table = field_multiselect_config["value"][0]
                    multi_select_master_column = field_multiselect_config["masterColumn"][0]
                    parameter_value = list(json.loads(parameter_value).keys())
                    converted_value = read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": multi_select_table,
                                "Columns": [multi_select_master_column],
                            },
                            "condition": [
                                {
                                    "column_name": "id",
                                    "condition": "IN",
                                    "input_value": parameter_value,
                                    "and_or": "",
                                }
                            ],
                        },
                    )[multi_select_master_column].tolist()
                    parameter_value = converted_value
                else:
                    parameter_value = []
            else:
                parameter_value = [parameter_value]

        # Master Mapping
        for level in current_level_config["master_level_config"]:
            approver_value = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": level["table_name"],
                        "Columns": [level["approver_field"]],
                    },
                    "condition": [
                        {
                            "column_name": level["mapping_field"],
                            "condition": "IN",
                            "input_value": parameter_value,
                            "and_or": "",
                        },
                    ],
                },
            )
            if not approver_value.empty:
                parameter_value = approver_value[level["approver_field"]].tolist()
            else:
                break
        if current_level_approval_type == "dynamic_master_group":
            level_approver_group = parameter_value
        else:
            level_approver_user = parameter_value
    else:
        pass
    return level_approver_user, level_approver_group, current_level_approver_type


def hierarchy_approval_group_extractor(
    request, hierarchy_approval_config, user_or_group="group", overwrite_user=""
):
    hierarchy_group = hierarchy_approval_config["hierarchy_group"]
    starting_level = hierarchy_approval_config["starting_level"]
    ending_level = hierarchy_approval_config["ending_level"]
    if hierarchy_approval_config.get("current_level"):
        current_level = hierarchy_approval_config["current_level"]
    else:
        current_level = None
    if hierarchy_approval_config.get("current_level_name"):
        current_level_name = hierarchy_approval_config["current_level_name"]
    else:
        current_level_name = None

    status = "Success"
    if current_level != ending_level:
        if not current_level:
            current_level_name = None
            if user_or_group == "group":
                user_groups_list = list(request.user.groups.values_list("name", flat=True))
                current_level_name = str(tuple(user_groups_list)).replace(",)", ")")
                condition = "IN"
            else:
                if overwrite_user:
                    current_level_name = overwrite_user
                else:
                    current_level_name = request.user.username
                condition = "Equal to"
            if current_level_name and current_level_name != "()":
                next_level_in_hierarchy = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "Hierarchy_table",
                            "Columns": ["hierarchy_parent_name"],
                        },
                        "condition": [
                            {
                                "column_name": "hierarchy_name",
                                "condition": condition,
                                "input_value": current_level_name,
                                "and_or": "AND",
                            },
                            {
                                "column_name": "hierarchy_group",
                                "condition": "Equal to",
                                "input_value": hierarchy_group,
                                "and_or": "AND",
                            },
                            {
                                "column_name": "hierarchy_level",
                                "condition": "Equal to",
                                "input_value": starting_level,
                                "and_or": "",
                            },
                        ],
                    },
                )
                if not next_level_in_hierarchy.empty:
                    next_level_in_hierarchy = next_level_in_hierarchy["hierarchy_parent_name"].iloc[0]
                else:
                    status = "User_not_part_of_hierarchy"
                    next_level_in_hierarchy = None
            else:
                status = "User_not_part_of_hierarchy"
                next_level_in_hierarchy = None
        else:
            next_level_in_hierarchy = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "Hierarchy_table",
                        "Columns": ["hierarchy_parent_name"],
                    },
                    "condition": [
                        {
                            "column_name": "hierarchy_name",
                            "condition": "Equal to",
                            "input_value": current_level_name,
                            "and_or": "AND",
                        },
                        {
                            "column_name": "hierarchy_group",
                            "condition": "Equal to",
                            "input_value": hierarchy_group,
                            "and_or": "AND",
                        },
                        {
                            "column_name": "hierarchy_level",
                            "condition": "Equal to",
                            "input_value": current_level,
                            "and_or": "",
                        },
                    ],
                },
            )
            if not next_level_in_hierarchy.empty:
                next_level_in_hierarchy = next_level_in_hierarchy["hierarchy_parent_name"].iloc[0]
                if not next_level_in_hierarchy:
                    status = "Final_level"
                    next_level_in_hierarchy = None
                else:
                    pass
            else:
                status = "Final_level"
                next_level_in_hierarchy = None
    else:
        status = "Final_level"
        next_level_in_hierarchy = None
    return status, next_level_in_hierarchy


def recently_visited(request, config):
    tenant = tenant_schema_from_request(request)
    user_name_tenant = request.user.username + tenant

    if os.path.exists(f"{PLATFORM_FILE_PATH}recently_used_dashboard.json"):
        with open(f"{PLATFORM_FILE_PATH}recently_used_dashboard.json") as json_file:
            recently_used_data = json.load(json_file)
            if recently_used_data == {}:
                recently_used_data = {
                    user_name_tenant: [
                        {
                            "app_code": config["app_code"],
                            "pr_code": config["pr_code"],
                            "dashboard_type": config["dashboard_type"],
                            "element_id": config["element_id"],
                            "shared_type": config["shared_type"],
                            "tab_id": config["tab_id"],
                            "name": config["name"],
                            "dashboard_config_id": config["dashboard_config_id"],
                        }
                    ]
                }
                with open(f"{PLATFORM_FILE_PATH}recently_used_dashboard.json", "w") as outfile:
                    json.dump(recently_used_data, outfile, indent=4)
                    outfile.close()
            elif user_name_tenant in recently_used_data:
                with open(f"{PLATFORM_FILE_PATH}recently_used_dashboard.json", "w") as outfile:
                    data_list = recently_used_data[user_name_tenant]
                    if len(data_list) == 5:
                        data_list.pop()
                    for i in data_list:
                        if (
                            i["app_code"] == config["app_code"]
                            and i["pr_code"] == config["pr_code"]
                            and i["dashboard_type"] == config["dashboard_type"]
                            and i["element_id"] == config["element_id"]
                            and i["shared_type"] == config["shared_type"]
                            and i["tab_id"] == config["tab_id"]
                            and i["dashboard_config_id"] == config["dashboard_config_id"]
                        ):
                            data_list.remove(i)
                    data_list.insert(
                        0,
                        {
                            "app_code": config["app_code"],
                            "pr_code": config["pr_code"],
                            "dashboard_type": config["dashboard_type"],
                            "element_id": config["element_id"],
                            "shared_type": config["shared_type"],
                            "tab_id": config["tab_id"],
                            "name": config["name"],
                            "dashboard_config_id": config["dashboard_config_id"],
                        },
                    )
                    recently_used_data[user_name_tenant] = data_list
                    json.dump(recently_used_data, outfile, indent=4)
                    outfile.close()
            else:
                recently_used_data[user_name_tenant] = [
                    {
                        "app_code": config["app_code"],
                        "pr_code": config["pr_code"],
                        "dashboard_type": config["dashboard_type"],
                        "element_id": config["element_id"],
                        "shared_type": config["shared_type"],
                        "tab_id": config["tab_id"],
                        "name": config["name"],
                        "dashboard_config_id": config["dashboard_config_id"],
                    }
                ]

                with open(f"{PLATFORM_FILE_PATH}recently_used_dashboard.json", "w") as outfile:
                    json.dump(recently_used_data, outfile, indent=4)
                    outfile.close()
            json_file.close()
    else:
        recently_used_data = {
            user_name_tenant: [
                {
                    "app_code": config["app_code"],
                    "pr_code": config["pr_code"],
                    "dashboard_type": config["dashboard_type"],
                    "element_id": config["element_id"],
                    "shared_type": config["shared_type"],
                    "tab_id": config["tab_id"],
                    "name": config["name"],
                    "dashboard_config_id": config["dashboard_config_id"],
                }
            ]
        }
        with open(f"{PLATFORM_FILE_PATH}recently_used_dashboard.json", "w") as outfile:
            json.dump(recently_used_data, outfile, indent=4)
            outfile.close()
    return True


def get_key(password):
    kdf = PBKDF2HMAC(
        algorithm=hashes.SHA256(),
        length=32,
        salt=bytes(PASSCODE_KEY, "utf-8"),
        iterations=100,
        backend=default_backend(),
    )
    key = base64.urlsafe_b64encode(kdf.derive(password))
    return key


def encrypt_col(request_user, tablename, db_connection_name, fieldname, datakey):
    if isinstance(request_user, dict):

        class AttrDict:
            def __init__(self, i_dict):
                for key, value in i_dict.items():
                    if key not in ["password", "last_login", "date_joined"]:
                        setattr(self, key, value)
                if i_dict.get("username"):
                    setattr(self, "is_anonymous", False)
                else:
                    setattr(self, "is_anonymous", True)

            def get_host(self):
                return self.host

        request_user["user"] = AttrDict(request_user["user"])
        request_user = AttrDict(request_user)
    new_table_data = read_data_func(
        request_user,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": tablename,
                "Columns": ["*"],
            },
            "condition": [],
        },
    )
    key = get_key(bytes(datakey, "utf-8"))

    def encrypt_data(x):
        if x not in ["", None]:
            try:
                f = Fernet(key)
                token = f.encrypt(bytes(x.encode("utf-8")))
                if isinstance(token, bytes):
                    token = token.decode()
                return token
            except Exception as e:
                logging.warning(f"Following exception occured - {e}")
                return x

    new_table_data[fieldname] = new_table_data[fieldname].apply(encrypt_data)
    for ind, row in new_table_data.iterrows():
        update_data_func(
            request=request_user,
            config_dict={
                "inputs": {
                    "Data_source": "Database",
                    "Table": tablename,
                    "Columns": [
                        {
                            "column_name": fieldname,
                            "input_value": row[fieldname].decode(),
                            "separator": "",
                        },
                    ],
                },
                "condition": [
                    {
                        "column_name": "id",
                        "condition": "Equal to",
                        "input_value": str(row["id"]),
                        "and_or": "",
                    }
                ],
            },
        )
    return True


def data_hierarchy_access_list(request, hierarchy_mapping):
    user = request.user
    schema = user.instance.name
    if hasattr(user, "groups"):
        usergroup_list = list(user.groups.values_list("name", flat=True))
    else:
        user_group_ids = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "user_groups",
                    "Columns": ["group_id"],
                },
                "condition": [
                    {
                        "column_name": "user_id",
                        "condition": "Equal to",
                        "input_value": str(user.id),
                        "and_or": "",
                    }
                ],
            },
        ).group_id.tolist()
        if user_group_ids:
            usergroup_list = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "auth_group",
                        "Columns": ["name"],
                    },
                    "condition": [
                        {
                            "column_name": "id",
                            "condition": "IN",
                            "input_value": str(tuple(user_group_ids)).replace(",)", ")"),
                            "and_or": "",
                        }
                    ],
                },
            ).name.tolist()
        else:
            usergroup_list = []
    if usergroup_list == []:
        placeholders = ""
    else:
        placeholders = ", ".join("'" + i + "'" for i in usergroup_list)
    # Extract user group permissions
    if not placeholders.startswith("("):
        placeholders = "(" + placeholders
    if not placeholders.endswith(")"):
        placeholders = placeholders + ")"

    user_perm = read_data_func(
        request,
        config_dict={
            "inputs": {
                "Data_source": "Database",
                "Table": "UserPermission_Master",
                "Columns": ["permission_level", "permission_name"],
            },
            "condition": [
                {"column_name": "usergroup", "condition": "IN", "input_value": placeholders, "and_or": "AND"},
                {
                    "column_name": "permission_type",
                    "condition": "Equal to",
                    "input_value": "Data hierarchy",
                    "and_or": "",
                },
            ],
        },
        schema=schema,
    )
    user_perm_list = user_perm["permission_name"].to_list()
    data_access_list = []
    for i in user_perm_list:
        ll_1 = ast.literal_eval(i)
        data_access_list = data_access_list + ll_1

    hierarchy_groups = []
    for key in hierarchy_mapping:
        hierarchy_groups.append(key)

    if hierarchy_groups == []:
        placeholders1 = ""
    else:
        placeholders1 = ", ".join("'" + i + "'" for i in hierarchy_groups)
    if not placeholders1.startswith("("):
        placeholders1 = "(" + placeholders1
    if not placeholders1.endswith(")"):
        placeholders1 = placeholders1 + ")"
    Hierarchy_df = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "Hierarchy_table",
                "Columns": ["hierarchy_group", "hierarchy_name", "hierarchy_parent_name"],
            },
            "condition": [
                {
                    "column_name": "hierarchy_group",
                    "condition": "IN",
                    "input_value": placeholders1,
                    "and_or": "",
                }
            ],
        },
        schema=schema,
    )
    hierarchy_dict = {}
    for data_access in data_access_list:
        ll1 = data_access.split("__")[0]
        ll2 = data_access.split("__")[1]
        access_list = []
        loop_list = []
        access_list.append(ll2)
        loop_list.append(ll2)

        while (
            len(Hierarchy_df[Hierarchy_df["hierarchy_parent_name"].isin(loop_list)].hierarchy_name.to_list())
            > 0
        ):
            for hierarchy_name in Hierarchy_df[
                Hierarchy_df["hierarchy_parent_name"].isin(loop_list)
            ].hierarchy_name.to_list():
                access_list.append(hierarchy_name)
            loop_list = Hierarchy_df[
                Hierarchy_df["hierarchy_parent_name"].isin(loop_list)
            ].hierarchy_name.to_list()
        [hierarchy_dict.setdefault(ll1, []).append(item) for item in access_list]
    return hierarchy_dict


def getNavPoints(current_dev_mode, request, curr_app_code, tenant):
    process = {}
    subprocess = {}
    tenant = "antares"
    logging.warning("here get nav") 
    identifier = tenant + request.user.username + "navbar"
    if redis_instance.exists(identifier) == 1:
        user_config = pickle.loads(redis_instance.get(identifier))
        if user_config.get(curr_app_code):
            app_config = user_config[curr_app_code]
            process = app_config[tenant]["existing"]["process"]
            subprocess = app_config[tenant]["existing"]["subprocess"]
            new = app_config[tenant]["new"]
            config_navbar = {
                "process": process,
                "subprocess": subprocess,
                "new": new,
                "processList": list(process.keys()),
                "subprocessList": list(subprocess.keys()),
            }
            return config_navbar

    app_config = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "static_page_config",
                "Columns": ["config"],
            },
            "condition": [
                {
                    "column_name": "app_code",
                    "condition": "Equal to",
                    "input_value": curr_app_code,
                    "and_or": "AND",
                },
                {
                    "column_name": "display_type",
                    "condition": "Equal to",
                    "input_value": "navbar",
                    "and_or": "",
                },
            ],
        },
    )
    if app_config.empty:
        app_process_codes = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Application",
                    "Columns": [
                        "process_group_codes",
                    ],
                },
                "condition": [
                    {
                        "column_name": "application_code",
                        "condition": "Equal to",
                        "input_value": curr_app_code,
                        "and_or": "",
                    }
                ],
            },
        )
        if not app_process_codes.empty:
            if app_process_codes.process_group_codes.iloc[0]:
                app_process_codes = json.loads(app_process_codes.process_group_codes.iloc[0])
            else:
                app_process_codes = []
        else:
            app_process_codes = []
        if len(app_process_codes):
            if len(app_process_codes) == 1:
                process_data = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "NavigationSideBar",
                            "Columns": ["item_name"],
                        },
                        "condition": [
                            {
                                "column_name": "item_code",
                                "condition": "Equal to",
                                "input_value": app_process_codes[0],
                                "and_or": "",
                            }
                        ],
                    },
                )
                process_data = process_data.item_name.iloc[0]
                process_data = {app_process_codes[0]: process_data}
                sub_process_data = (
                    read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "NavigationSideBar",
                                "Columns": ["item_code", "item_name"],
                            },
                            "condition": [
                                {
                                    "column_name": "item_group_code",
                                    "condition": "Equal to",
                                    "input_value": app_process_codes[0],
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                    .set_index("item_code")["item_name"]
                    .to_dict()
                )
            else:
                process_tuple = (
                    json.dumps(app_process_codes).replace('"', "'").replace("[", "(").replace("]", ")")
                )
                process_data = (
                    read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "NavigationSideBar",
                                "Columns": ["item_code", "item_name"],
                            },
                            "condition": [
                                {
                                    "column_name": "item_code",
                                    "condition": "IN",
                                    "input_value": process_tuple,
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                    .set_index("item_code")["item_name"]
                    .to_dict()
                )
                sub_process_data = (
                    read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "NavigationSideBar",
                                "Columns": ["item_code", "item_name"],
                            },
                            "condition": [
                                {
                                    "column_name": "item_group_code",
                                    "condition": "IN",
                                    "input_value": process_tuple,
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                    .set_index("item_code")["item_name"]
                    .to_dict()
                )
        else:
            process_data = {}
            sub_process_data = {}
        config_navbar = {
            "process": process_data,
            "subprocess": sub_process_data,
            "new": {"Build": {}, f"{request.user.username}": {}},
            "processList": list(process_data.keys()),
            "subprocessList": list(sub_process_data.keys()),
        }
        dic = {
            f"{curr_app_code}": {
                f"{tenant}": {
                    "existing": {"process": process_data, "subprocess": sub_process_data},
                    "new": {"Build": {}, f"{request.user.username}": {}, "User": {}},
                }
            }
        }
        redis_instance.set(identifier, pickle.dumps(dic))
        query_add = pd.DataFrame(
            [
                {
                    "app_code": curr_app_code,
                    "config": json.dumps(dic),
                    "display_type": "navbar",
                    "created_by": request.user.username,
                    "created_date": datetime.now(),
                    "modified_by": request.user.username,
                    "modified_date": datetime.now(),
                }
            ]
        )
        data_handling(request, query_add, "static_page_config")
    else:
        config = app_config.iloc[0]["config"]
        config = json.loads(config)
        if config[curr_app_code][tenant]["new"].get(request.user.username) in [None]:
            config[curr_app_code][tenant]["new"][request.user.username] = {}
            update_data_func(
                request,
                config_dict={
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "static_page_config",
                        "Columns": [
                            {
                                "column_name": "config",
                                "input_value": json.dumps(config),
                                "separator": "",
                            }
                        ],
                    },
                    "condition": [
                        {
                            "column_name": "app_code",
                            "condition": "Equal to",
                            "input_value": curr_app_code,
                            "and_or": "AND",
                        },
                        {
                            "column_name": "display_type",
                            "condition": "Equal to",
                            "input_value": "navbar",
                            "and_or": "",
                        },
                    ],
                },
            )
        redis_instance.set(identifier, pickle.dumps(config))
        process = config[curr_app_code][tenant]["existing"]["process"]
        subprocess = config[curr_app_code][tenant]["existing"]["subprocess"]
        new = config[curr_app_code][tenant]["new"]
        config_navbar = {
            "process": process,
            "subprocess": subprocess,
            "new": new,
            "processList": list(process.keys()),
            "subprocessList": list(subprocess.keys()),
        }
    return config_navbar


def getAllApps(request, tenant):
    connected_database = {}
    if os.path.exists(f"{PLATFORM_FILE_PATH}user_databases.json"):
        with open(f"{PLATFORM_FILE_PATH}user_databases.json") as json_file:
            db_data = json.load(json_file)
            connected_database = {k: v for k, v in db_data.items() if v.get("tenant") == tenant}
            json_file.close()
    sql_query_app = pd.DataFrame(
        columns=[
            "application_code",
            "application_name",
        ]
    )
    if len(connected_database) > 0:
        db_type = "MSSQL"
        for k, config in connected_database.items():
            if k != "default":
                user_db_engine, db_type = db_engine_extractor(k)
                if user_db_engine != ["", None]:
                    try:
                        sql_query_app = sql_query_app.append(
                            read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "Application",
                                        "Columns": [
                                            "application_code",
                                            "application_name",
                                            "description",
                                            "app_icon",
                                            "app_icon_color",
                                            "app_card_color",
                                            "app_text_color",
                                        ],
                                    },
                                    "condition": [],
                                },
                                engine2=user_db_engine,
                                engine_override=True,
                                db_type=db_type,
                            )
                        )
                        sql_query_app.fillna("", inplace=True)
                    except Exception as e:
                        logging.warning(f"Following exception occured - {e}")
                        continue
        sql_query_app.drop_duplicates(
            subset=["application_code"], keep="last", inplace=True, ignore_index=True
        )
        return sql_query_app.to_dict("records")


def fetchGlobalTheme(tenant, app_code):
    global_css = ""
    if os.path.exists(
        f"kore_investment/templates/user_defined_template/{tenant}/{app_code}/theme/Global/style.css"
    ):
        with open(
            f"kore_investment/templates/user_defined_template/{tenant}/{app_code}/theme/Global/style.css"
        ) as f:
            global_css = global_css + f.read()
            f.close()
    return global_css


def getTabIndexVisibility(request, element_id, app_code=""):
    db_type = ""
    db_connection_name = ""
    engine_override = False
    user_db_engine = ["", None]
    if app_code != "":
        engine_override = True
        schema = tenant_schema_from_request(request) + "_" + app_code
        if os.path.exists(f"{PLATFORM_FILE_PATH}app_database_mapping.json"):
            with open(f"{PLATFORM_FILE_PATH}app_database_mapping.json") as json_file:
                db_connection_name = json.load(json_file).get(schema)
                json_file.close()
        user_db_engine, db_type = db_engine_extractor(db_connection_name)

    tab_body_content = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["tab_body_content"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": element_id,
                    "and_or": "",
                }
            ],
        },
        engine2=user_db_engine,
        db_type=db_type,
        engine_override=engine_override,
    ).iloc[0]["tab_body_content"]
    tab_body_content = json.loads(tab_body_content)
    dashboardIndex = tab_body_content.get("dashboardIndex")
    publishDashboardIndex = tab_body_content.get("publishDashboardIndex")
    dashboardIndexTemplate = tab_body_content.get("dashboardIndexTemplate")

    if dashboardIndex in [None]:
        dashboardIndex = "Required"
    if publishDashboardIndex in [None]:
        publishDashboardIndex = "Required"
    if dashboardIndexTemplate in [None]:
        dashboardIndexTemplate = "Template1"
    return dashboardIndex, publishDashboardIndex, dashboardIndexTemplate


def execute_auto_run_computation(
    element_id,
    subprocess_code,
    request,
    computation_data_pass_on={},
    attempt=1,
    transaction_id="NULL",
    subprocess_linkto_dict_main={},
):
    """
    Executes computation configured on auto run

    Parameters:
        element_id (str): Element id of the computation block to be executed.
        subprocess_code (str): Id of the sub-process where this element is in.
        request (AsgiRequest): Django request object.
        computation_data_pass_on (dict): Data to be passed on to the computation model (default is {}).
    """
    model_name = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["tab_body_content", "computation_name"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": element_id,
                    "and_or": "",
                },
            ],
        },
    ).iloc[0]["computation_name"]
    model_config = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_flowchart",
                "Columns": ["flowchart_elements", "scenario_comparative_config"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": model_name,
                    "and_or": "",
                },
            ],
        },
    )
    flowchart_elements = model_config.flowchart_elements.iloc[0]
    flowchart_elements = json.loads(flowchart_elements)
    global_variable_list = []
    global_dict = {"inputs": {}}
    global_element_id = "###"
    global_config = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_configuration",
                "Columns": ["element_config", "element_id"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": model_name,
                    "and_or": "and",
                },
                {
                    "column_name": "element_id",
                    "condition": "Contains",
                    "input_value": "globalVariable",
                    "and_or": "",
                },
            ],
        },
    )
    if len(global_config) > 0:
        global_dict = global_config.element_config.iloc[-1]
        global_element_id = global_config.element_id.iloc[-1]
        global_dict = json.loads(global_dict)
    else:
        pass

    if global_dict["inputs"].get("variables"):
        for gvar in global_dict["inputs"]["variables"]:
            config = {
                "varName": gvar["varName"],
                "inputValue": gvar["defaultValue"],
            }
    else:
        pass

    data_pass_on_config = {}
    if computation_data_pass_on.get("computationInputConfig"):
        if computation_data_pass_on["computationInputConfig"].get("globalVariableMapper"):
            g_var_mapper = computation_data_pass_on["computationInputConfig"]["globalVariableMapper"]
            source_global_var_list = computation_data_pass_on["global_config"]
            if global_dict.get("inputs"):
                global_variable_list = []
                for gvar in global_dict["inputs"]["variables"]:
                    config = {
                        "varName": gvar["varName"],
                        "inputValue": gvar["defaultValue"],
                    }
                    if gvar["varName"] in g_var_mapper:
                        for i in source_global_var_list:
                            if gvar["varName"] == i["varName"]:
                                config["inputValue"] = i["inputValue"]
                            else:
                                continue
                    else:
                        pass
                    global_variable_list.append(config)
            else:
                pass
        else:
            pass
        if computation_data_pass_on["computationInputConfig"].get("passPrecedingOutputTo"):
            pass_preceding_output_to = computation_data_pass_on["computationInputConfig"][
                "passPrecedingOutputTo"
            ]
            data_pass_on_config[pass_preceding_output_to] = computation_data_pass_on["output"]
        else:
            pass
    else:
        if global_dict["inputs"].get("variables"):
            for gvar in global_dict["inputs"]["variables"]:
                config = {
                    "varName": gvar["varName"],
                    "inputValue": gvar["defaultValue"],
                }
                global_variable_list.append(config)
        else:
            pass
    config = {
        "model": model_name,
        "configGlobalDict": global_variable_list,
        "configGlobalFunc": [],
    }
    related_item_flowchart = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "Process_subprocess_flowchart",
                "Columns": ["flowchart_elements"],
            },
            "condition": [
                {
                    "column_name": "related_item_code",
                    "condition": "Equal to",
                    "input_value": str(subprocess_code),
                    "and_or": "",
                }
            ],
        },
    )
    related_item_flowchart = related_item_flowchart.to_dict()
    flowchart_element = json.loads(related_item_flowchart["flowchart_elements"][0])

    child_element_id_email_box = []
    for i in flowchart_element:
        if (i["shapeID"] == element_id) and (i["shape"] == "parallelogram"):
            for child in i["child"]:
                if child.startswith("message"):
                    child_element_id_email_box.append(child)
                else:
                    continue
        else:
            continue

    result = execute_computation_model(
        request,
        flowchart_elements,
        config,
        global_dict,
        global_element_id,
        element_id,
        subprocess_code,
        pd.DataFrame(),
        pd.DataFrame(),
        is_trigger_event=False,
        request2=request,
        data_pass_on_config=data_pass_on_config,
        attempt=1,
        transaction_id=transaction_id,
        child_element_id_email_box=child_element_id_email_box,
        subprocess_linkto_dict_main=subprocess_linkto_dict_main,
    )
    return result


def process_flow_monitor(
    element_id,
    subprocess_code,
    app_code,
    request,
    data=None,
    transaction_id=None,
    current_element_status="pass",
    current_element_message="Success",
    total_data="0",
    passed_data="0",
    computation_data_pass_on={},
    run_time=None,
    subprocess_linkto_dict_main={},
):
    """
    Records the status of user actions on the elements in configured process flow

    Parameters:
        element_id (str): Element id of the process tab/ block.
        subprocess_code (str): Id of the sub-process where this element is in.
        app_code (str): Id of the application where this sub-process is in.
        request (AsgiRequest): Django request object.
        data (pandas Dataframe): Data pertaining to the current element (default is None).
        transaction_id (str): Id of the existing transaction (default is None).
        current_element_status (str): Status of the action on the current element (default is Pass).
        current_element_message (str): Status message of the current element's execution (default is Success).
        computation_data_pass_on (dict): Data from current element to be passed to subsequent element (default is {}).
        run_time (str): run time of specific transaction is recorded
    """
    try:
        transaction_details = read_data_func(
            request,
            {
                "inputs": {
                    "Data_source": "Database",
                    "Table": "Process_flow_model",
                    "Columns": ["flow", "transaction_id", "current_status"],
                },
                "condition": [
                    {
                        "column_name": "subprocess",
                        "condition": "Equal to",
                        "input_value": subprocess_code,
                        "and_or": "AND",
                    },
                    {
                        "column_name": "app_code",
                        "condition": "Equal to",
                        "input_value": app_code,
                        "and_or": "AND",
                    },
                    {
                        "column_name": "element_id",
                        "condition": "Equal to",
                        "input_value": element_id,
                        "and_or": "AND",
                    },
                    {
                        "column_name": "transaction_id",
                        "condition": "Equal to",
                        "input_value": transaction_id,
                        "and_or": "",
                    },
                ],
            },
        )
        subprocess_linkto = []
        subprocess_linkto_dict = {}
        username = request.user.username
        if not transaction_details.empty:
            # Existing Transaction: update transaction details
            if not transaction_details[
                transaction_details["current_status"].isin(["Not started", "Ongoing"])
            ].empty:
                if current_element_status == "pass":
                    if total_data != passed_data:
                        # All records in the transaction passed
                        update_data_func(
                            request,
                            config_dict={
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "Process_flow_model",
                                    "Columns": [
                                        {
                                            "column_name": "current_status",
                                            "input_value": "Ongoing",
                                            "separator": ",",
                                        },
                                        {
                                            "column_name": "modified_date",
                                            "input_value": datetime.now(),
                                            "separator": ",",
                                        },
                                        {
                                            "column_name": "total_batch_data",
                                            "input_value": str(total_data),
                                            "separator": ",",
                                        },
                                        {
                                            "column_name": "pass_batch_data",
                                            "input_value": str(passed_data),
                                            "separator": ",",
                                        },
                                        {
                                            "column_name": "detailed_status",
                                            "input_value": f"{total_data - passed_data} record(s) is pending out of {total_data}",
                                            "separator": ",",
                                        },
                                        {
                                            "column_name": "modified_by",
                                            "input_value": username,
                                            "separator": ",",
                                        },
                                        {
                                            "column_name": "run_time",
                                            "input_value": str(run_time),
                                            "separator": "",
                                        },
                                    ],
                                },
                                "condition": [
                                    {
                                        "column_name": "element_id",
                                        "condition": "Equal to",
                                        "input_value": element_id,
                                        "and_or": "AND",
                                    },
                                    {
                                        "column_name": "transaction_id",
                                        "condition": "Equal to",
                                        "input_value": transaction_id,
                                        "and_or": "AND",
                                    },
                                    {
                                        "column_name": "app_code",
                                        "condition": "Equal to",
                                        "input_value": app_code,
                                        "and_or": "AND",
                                    },
                                    {
                                        "column_name": "subprocess",
                                        "condition": "Equal to",
                                        "input_value": subprocess_code,
                                        "and_or": "",
                                    },
                                ],
                            },
                        )
                    else:
                        # All records in the transaction passed
                        transaction_flow = json.loads(transaction_details.flow.iloc[0])
                        flow_from_current_element = transaction_flow[transaction_flow.index(element_id) :]
                        last_element_status = current_element_status
                        for flow_index, flow_ele in enumerate(flow_from_current_element):
                            if flow_ele == element_id or (
                                last_element_status == "pass"
                                and (flow_ele.startswith("process") or flow_ele.startswith("ellipse"))
                            ):
                                if last_element_status == "pass":
                                    status = "Pass"
                                    detailed_status = "Success"
                                    redirect_status = "Active"
                                else:
                                    status = "Not started"
                                    detailed_status = "Not started"
                                    redirect_status = "Not active"
                                update_data_func(
                                    request,
                                    config_dict={
                                        "inputs": {
                                            "Data_source": "Database",
                                            "Table": "Process_flow_model",
                                            "Columns": [
                                                {
                                                    "column_name": "current_status",
                                                    "input_value": status,
                                                    "separator": ",",
                                                },
                                                {
                                                    "column_name": "modified_date",
                                                    "input_value": datetime.now(),
                                                    "separator": ",",
                                                },
                                                {
                                                    "column_name": "total_batch_data",
                                                    "input_value": str(total_data),
                                                    "separator": ",",
                                                },
                                                {
                                                    "column_name": "pass_batch_data",
                                                    "input_value": str(passed_data),
                                                    "separator": ",",
                                                },
                                                {
                                                    "column_name": "detailed_status",
                                                    "input_value": detailed_status,
                                                    "separator": ",",
                                                },
                                                {
                                                    "column_name": "redirect_status",
                                                    "input_value": redirect_status,
                                                    "separator": ",",
                                                },
                                                {
                                                    "column_name": "modified_by",
                                                    "input_value": username,
                                                    "separator": ",",
                                                },
                                                {
                                                    "column_name": "run_time",
                                                    "input_value": str(run_time),
                                                    "separator": "",
                                                },
                                            ],
                                        },
                                        "condition": [
                                            {
                                                "column_name": "element_id",
                                                "condition": "Equal to",
                                                "input_value": element_id,
                                                "and_or": "AND",
                                            },
                                            {
                                                "column_name": "transaction_id",
                                                "condition": "Equal to",
                                                "input_value": transaction_id,
                                                "and_or": "AND",
                                            },
                                            {
                                                "column_name": "app_code",
                                                "condition": "Equal to",
                                                "input_value": app_code,
                                                "and_or": "AND",
                                            },
                                            {
                                                "column_name": "subprocess",
                                                "condition": "Equal to",
                                                "input_value": subprocess_code,
                                                "and_or": "",
                                            },
                                        ],
                                    },
                                )
                                if len(flow_from_current_element) > flow_index + 1:
                                    next_element = flow_from_current_element[flow_index + 1]
                                    if (
                                        subprocess_linkto_dict_main
                                        and next_element in subprocess_linkto_dict_main
                                    ):
                                        subprocess_code = subprocess_linkto_dict_main[next_element]
                                    element_connector_detail = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "TabScreens",
                                                "Columns": ["tab_body_content"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "related_item_code",
                                                    "condition": "Equal to",
                                                    "input_value": subprocess_code,
                                                    "and_or": "AND",
                                                },
                                                {
                                                    "column_name": "tab_body_content",
                                                    "condition": "Contains",
                                                    "input_value": f'"child": "{next_element}"',
                                                    "and_or": "AND",
                                                },
                                                {
                                                    "column_name": "tab_body_content",
                                                    "condition": "Contains",
                                                    "input_value": '"autoRun": true',
                                                    "and_or": "AND",
                                                },
                                                {
                                                    "column_name": "tab_type",
                                                    "condition": "Equal to",
                                                    "input_value": "connector",
                                                    "and_or": "",
                                                },
                                            ],
                                        },
                                    )
                                    if not element_connector_detail.empty:
                                        connector_config = json.loads(
                                            element_connector_detail.tab_body_content.iloc[0]
                                        )
                                        if connector_config.get("computationInputConfig"):
                                            computation_data_pass_on["computationInputConfig"] = (
                                                connector_config.get("computationInputConfig")
                                            )
                                        else:
                                            pass
                                        next_element = connector_config["child"]
                                        execute_auto_run_computation(
                                            next_element,
                                            subprocess_code,
                                            request,
                                            computation_data_pass_on=computation_data_pass_on,
                                            transaction_id=transaction_id,
                                            subprocess_linkto_dict_main=subprocess_linkto_dict_main,
                                        )
                                    else:
                                        continue
                                    on_trigger_scheduler_config = read_data_func(
                                        request,
                                        {
                                            "inputs": {
                                                "Data_source": "Database",
                                                "Table": "ProcessScheduler",
                                                "Columns": ["element_id", "config"],
                                            },
                                            "condition": [
                                                {
                                                    "column_name": "item_code",
                                                    "condition": "Equal to",
                                                    "input_value": subprocess_code,
                                                    "and_or": "AND",
                                                },
                                                {
                                                    "column_name": "app_code",
                                                    "condition": "Equal to",
                                                    "input_value": app_code,
                                                    "and_or": "AND",
                                                },
                                                {
                                                    "column_name": "dependent_block",
                                                    "condition": "Equal to",
                                                    "input_value": flow_from_current_element[flow_index],
                                                    "and_or": "AND",
                                                },
                                                {
                                                    "column_name": "trigger_option",
                                                    "condition": "Equal to",
                                                    "input_value": "trigger",
                                                    "and_or": "",
                                                },
                                            ],
                                        },
                                    )
                                    if not on_trigger_scheduler_config.empty:
                                        element_to_run = on_trigger_scheduler_config["element_id"].iloc[0]
                                        computation_data_pass_on = {}
                                        execute_auto_run_computation(
                                            element_to_run,
                                            subprocess_code,
                                            request,
                                            computation_data_pass_on=computation_data_pass_on,
                                        )
                                    else:
                                        continue
                                else:
                                    break
                            else:
                                break
                else:
                    update_data_func(
                        request,
                        config_dict={
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "Process_flow_model",
                                "Columns": [
                                    {
                                        "column_name": "current_status",
                                        "input_value": "Fail",
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "modified_date",
                                        "input_value": datetime.now(),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "total_batch_data",
                                        "input_value": str(total_data),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "pass_batch_data",
                                        "input_value": str(passed_data),
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "detailed_status",
                                        "input_value": current_element_message,
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "modified_by",
                                        "input_value": username,
                                        "separator": ",",
                                    },
                                    {
                                        "column_name": "run_time",
                                        "input_value": str(run_time),
                                        "separator": "",
                                    },
                                ],
                            },
                            "condition": [
                                {
                                    "column_name": "element_id",
                                    "condition": "Equal to",
                                    "input_value": element_id,
                                    "and_or": "AND",
                                },
                                {
                                    "column_name": "transaction_id",
                                    "condition": "Equal to",
                                    "input_value": transaction_id,
                                    "and_or": "AND",
                                },
                                {
                                    "column_name": "app_code",
                                    "condition": "Equal to",
                                    "input_value": app_code,
                                    "and_or": "AND",
                                },
                                {
                                    "column_name": "subprocess",
                                    "condition": "Equal to",
                                    "input_value": subprocess_code,
                                    "and_or": "",
                                },
                            ],
                        },
                    )
            else:
                pass
        else:
            # New Transaction: create transaction details and record in Process flow model table
            flow_connector_details = read_data_func(
                request,
                {
                    "inputs": {
                        "Data_source": "Database",
                        "Table": "TabScreens",
                        "Columns": ["tab_body_content", "tab_type", "element_id"],
                    },
                    "condition": [
                        {
                            "column_name": "related_item_code",
                            "condition": "Equal to",
                            "input_value": subprocess_code,
                            "and_or": "AND",
                        },
                        {
                            "column_name": "tab_type",
                            "condition": "IN",
                            "input_value": ["connector", "flowlink"],
                            "and_or": "",
                        },
                    ],
                },
            )
            flow_connector_json = flow_connector_details.tab_body_content.apply(json.loads).tolist()
            flow_connector_tab_types = flow_connector_details.tab_type.tolist()
            del_indx = []
            if "flowlink" in flow_connector_tab_types:
                for indx, conn in enumerate(flow_connector_tab_types):
                    if conn == "flowlink":
                        del_indx.append(indx)
                        tab_data = flow_connector_json[indx]
                        flow_to_pr_code = tab_data["pr_code"]

                        temp_flow_det = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "TabScreens",
                                    "Columns": ["tab_body_content", "tab_type"],
                                },
                                "condition": [
                                    {
                                        "column_name": "related_item_code",
                                        "condition": "Equal to",
                                        "input_value": flow_to_pr_code,
                                        "and_or": "AND",
                                    },
                                    {
                                        "column_name": "tab_type",
                                        "condition": "IN",
                                        "input_value": ["connector"],
                                        "and_or": "",
                                    },
                                ],
                            },
                        )

                        temp_flow_det_json = temp_flow_det.tab_body_content.apply(json.loads).tolist()
                        for tcom in temp_flow_det_json:
                            tparent = tcom["parent"]
                            ldata = read_data_func(
                                request,
                                {
                                    "inputs": {
                                        "Data_source": "Database",
                                        "Table": "TabScreens",
                                        "Columns": ["tab_body_content"],
                                    },
                                    "condition": [
                                        {
                                            "column_name": "element_id",
                                            "condition": "Equal to",
                                            "input_value": tparent,
                                            "and_or": "",
                                        },
                                    ],
                                },
                            )

                            if len(ldata) > 0:
                                ldata_tab_data = ldata.tab_body_content.apply(json.loads).tolist()
                                for kj in ldata_tab_data:
                                    flow_connector_json.append(tcom)
                                    subprocess_linkto.append(flow_to_pr_code)
                                    subprocess_linkto_dict[tcom["child"]] = flow_to_pr_code
                for ll in del_indx:
                    del flow_connector_json[ll]
                flow_connector_details = flow_connector_json
            else:
                flow_connector_details = flow_connector_json
            flow_checker = [
                True if fdc["parent"] == element_id or fdc["child"] == element_id else False
                for fdc in flow_connector_details
            ]
            if flow_connector_details and any(flow_checker):
                subprocess_flow_data = read_data_func(
                    request,
                    {
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "process_subprocess_flowchart",
                            "Columns": ["flowchart_elements"],
                        },
                        "condition": [
                            {
                                "column_name": "related_item_code",
                                "condition": "Equal to",
                                "input_value": subprocess_code,
                                "and_or": "",
                            }
                        ],
                    },
                ).flowchart_elements.iloc[0]
                subprocess_flow_data = json.loads(subprocess_flow_data)
                if subprocess_linkto:
                    subprocess_linkto_flow_data = read_data_func(
                        request,
                        {
                            "inputs": {
                                "Data_source": "Database",
                                "Table": "process_subprocess_flowchart",
                                "Columns": ["flowchart_elements"],
                            },
                            "condition": [
                                {
                                    "column_name": "related_item_code",
                                    "condition": "IN",
                                    "input_value": subprocess_linkto,
                                    "and_or": "",
                                }
                            ],
                        },
                    )
                    subprocess_linkto_flow_data_json = subprocess_linkto_flow_data.flowchart_elements.apply(
                        json.loads
                    ).tolist()
                    for kk in subprocess_linkto_flow_data_json:
                        for mm in kk:
                            subprocess_flow_data.append(mm)
                subprocess_flow_data = {ele["shapeID"]: ele for ele in subprocess_flow_data}
                process_flow_path = [element_id]
                if current_element_status.title() == "Skip":
                    process_flow_status = {
                        element_id: {
                            "status": "Pass",
                            "detailed_status": current_element_message,
                            "total_data": total_data,
                            "passed_data": passed_data,
                        }
                    }
                else:
                    process_flow_status = {
                        element_id: {
                            "status": current_element_status.title(),
                            "detailed_status": current_element_message,
                            "total_data": total_data,
                            "passed_data": passed_data,
                        }
                    }
                flow_ended = False
                current_element = element_id
                last_element_status = current_element_status
                while not flow_ended:
                    for indx, conn in enumerate(flow_connector_details):
                        if current_element in subprocess_linkto_dict:
                            subprocess_code = subprocess_linkto_dict[current_element]
                        if conn["parent"] == current_element:
                            if current_element in subprocess_flow_data:
                                current_element_details = subprocess_flow_data[current_element]
                                if current_element_details["shape"] == "flowcontrol":
                                    if type(data) != type(None):
                                        next_elements = flow_controller_handler(
                                            current_element, request, data
                                        )
                                        if len(next_elements) != 0:
                                            if last_element_status == "pass":
                                                process_flow_status[current_element] = {
                                                    "status": "Pass",
                                                    "detailed_status": "Success",
                                                    "connector_config": conn,
                                                    "total_data": total_data,
                                                    "passed_data": passed_data,
                                                    "subprocess_code": subprocess_code,
                                                }
                                            else:
                                                last_element_status = "Not started"
                                                process_flow_status[current_element] = {
                                                    "status": last_element_status,
                                                    "detailed_status": last_element_status,
                                                    "connector_config": conn,
                                                    "total_data": total_data,
                                                    "passed_data": "0",
                                                    "subprocess_code": subprocess_code,
                                                }
                                            if len(next_elements) == 1:
                                                current_element = next_elements[0]
                                            else:
                                                pass
                                        else:
                                            last_element_status = "fail"
                                            if last_element_status == "pass":
                                                process_flow_status[current_element] = {
                                                    "status": "Pass",
                                                    "detailed_status": "Success",
                                                    "connector_config": conn,
                                                    "total_data": total_data,
                                                    "passed_data": passed_data,
                                                    "subprocess_code": subprocess_code,
                                                }
                                            else:
                                                last_element_status = "Not started"
                                                process_flow_status[current_element] = {
                                                    "status": last_element_status,
                                                    "detailed_status": last_element_status,
                                                    "connector_config": conn,
                                                    "total_data": total_data,
                                                    "passed_data": "0",
                                                    "subprocess_code": subprocess_code,
                                                }
                                    else:
                                        if last_element_status == "pass":
                                            last_element_status = "fail"
                                            process_flow_status[current_element] = {
                                                "status": "fail",
                                                "detailed_status": "None of the conditions satisfied by the data.",
                                                "connector_config": conn,
                                                "total_data": total_data,
                                                "passed_data": "0",
                                                "subprocess_code": subprocess_code,
                                            }
                                        else:
                                            last_element_status = "Not started"
                                            process_flow_status[current_element] = {
                                                "status": last_element_status,
                                                "detailed_status": last_element_status,
                                                "connector_config": conn,
                                                "total_data": total_data,
                                                "passed_data": "0",
                                                "subprocess_code": subprocess_code,
                                            }
                                        flow_ended = True
                                        break
                                else:
                                    if current_element != element_id:
                                        if last_element_status == "pass" and (
                                            current_element_details["shape"] == "process"
                                            or current_element.startswith("ellipse")
                                        ):
                                            process_flow_status[current_element] = {
                                                "status": "Pass",
                                                "detailed_status": "Success",
                                                "connector_config": conn,
                                                "total_data": total_data,
                                                "passed_data": passed_data,
                                                "subprocess_code": subprocess_code,
                                            }
                                        elif last_element_status == "skip" and current_element.startswith(
                                            "decision"
                                        ):
                                            process_flow_status[current_element] = {
                                                "status": "Pass",
                                                "detailed_status": "Success",
                                                "connector_config": conn,
                                                "total_data": total_data,
                                                "passed_data": passed_data,
                                                "subprocess_code": subprocess_code,
                                            }
                                            last_element_status = "Pass"
                                        else:
                                            last_element_status = "Not started"
                                            process_flow_status[current_element] = {
                                                "status": last_element_status,
                                                "detailed_status": last_element_status,
                                                "connector_config": conn,
                                                "total_data": total_data,
                                                "passed_data": "0",
                                                "subprocess_code": subprocess_code,
                                            }
                                    else:
                                        process_flow_status[current_element]["connector_config"] = conn
                                    if conn["child"].startswith("link") and not conn["child"].startswith(
                                        "linkto"
                                    ):
                                        ii = 1
                                        while 1:
                                            if indx + ii <= len(flow_connector_details) - 1:
                                                if flow_connector_details[indx + ii]["parent"].startswith(
                                                    "linkto"
                                                ):
                                                    current_element = flow_connector_details[indx + ii][
                                                        "child"
                                                    ]
                                                    break
                                                else:
                                                    ii = ii + 1
                                            else:
                                                current_element = conn["child"]
                                                break
                                    else:
                                        current_element = conn["child"]
                                process_flow_path.append(current_element)

                                if subprocess_flow_data[current_element]["child"] == "#":
                                    if last_element_status == "pass" and (
                                        subprocess_flow_data[current_element]["shape"] == "process"
                                        or current_element.startswith("ellipse")
                                    ):
                                        process_flow_status[current_element] = {
                                            "status": "Pass",
                                            "detailed_status": "Success",
                                            "connector_config": {},
                                            "total_data": total_data,
                                            "passed_data": passed_data,
                                            "subprocess_code": subprocess_code,
                                        }
                                    else:
                                        last_element_status = "Not started"
                                        process_flow_status[current_element] = {
                                            "status": last_element_status,
                                            "detailed_status": last_element_status,
                                            "connector_config": {},
                                            "total_data": total_data,
                                            "passed_data": "0",
                                            "subprocess_code": subprocess_code,
                                        }
                                    flow_ended = True
                                    break
                                else:
                                    pass
                                break
                        else:
                            continue
                    if any(
                        [
                            True if con_cf["parent"] == current_element else False
                            for con_cf in flow_connector_details
                        ]
                    ):
                        continue
                    else:
                        flow_ended = True
                        break
                createTransactionRecords(
                    subprocess_code, process_flow_status, app_code, transaction_id, request, run_time
                )
                for ele, ele_details in process_flow_status.items():
                    if ele_details["status"] == "Pass" and ele_details.get("connector_config"):
                        if ele_details["connector_config"]["autoRun"]:
                            if ele_details["connector_config"].get("computationInputConfig"):
                                computation_data_pass_on["computationInputConfig"] = ele_details[
                                    "connector_config"
                                ].get("computationInputConfig")
                            else:
                                pass
                            next_element = ele_details["connector_config"]["child"]
                            if ele_details.get("subprocess_code"):
                                subprocess_code = ele_details["subprocess_code"]
                            execute_auto_run_computation(
                                next_element,
                                subprocess_code,
                                request,
                                computation_data_pass_on=computation_data_pass_on,
                                transaction_id=transaction_id,
                                subprocess_linkto_dict_main=subprocess_linkto_dict,
                            )
                        else:
                            pass
                        on_trigger_scheduler_config = read_data_func(
                            request,
                            {
                                "inputs": {
                                    "Data_source": "Database",
                                    "Table": "ProcessScheduler",
                                    "Columns": ["element_id", "config"],
                                },
                                "condition": [
                                    {
                                        "column_name": "item_code",
                                        "condition": "Equal to",
                                        "input_value": subprocess_code,
                                        "and_or": "AND",
                                    },
                                    {
                                        "column_name": "app_code",
                                        "condition": "Equal to",
                                        "input_value": app_code,
                                        "and_or": "AND",
                                    },
                                    {
                                        "column_name": "dependent_block",
                                        "condition": "Equal to",
                                        "input_value": ele,
                                        "and_or": "AND",
                                    },
                                    {
                                        "column_name": "trigger_option",
                                        "condition": "Equal to",
                                        "input_value": "trigger",
                                        "and_or": "",
                                    },
                                ],
                            },
                        )
                        if not on_trigger_scheduler_config.empty:
                            element_to_run = on_trigger_scheduler_config["element_id"].iloc[0]
                            trigger_scheduler_config = json.loads(
                                on_trigger_scheduler_config["config"].iloc[0]
                            )
                            computation_data_pass_on = {}
                            if element_to_run.startswith("decision"):
                                if trigger_scheduler_config["schedulerAction"] in [
                                    "approve_with_condition",
                                    "reject_with_condition",
                                ] and trigger_scheduler_config.get("schedulerActionCondition"):
                                    condition = trigger_scheduler_config["schedulerActionCondition"][
                                        "underlying_table_conditions"
                                    ]
                                    approval_condition = trigger_scheduler_config["schedulerActionCondition"][
                                        "approval_conditions"
                                    ]
                                    check_approval_condition(
                                        condition,
                                        request,
                                        trigger_scheduler_config["schedulerAction"],
                                        approval_condition=approval_condition,
                                    )
                                else:
                                    check_approval_condition(
                                        trigger_scheduler_config["blockTriggerConfig"]["previousElement"],
                                        subprocess_code,
                                        "create",
                                        [],
                                        request,
                                        trigger_scheduler_config["schedulerAction"],
                                    )
                            else:
                                execute_auto_run_computation(
                                    element_to_run,
                                    subprocess_code,
                                    request,
                                    computation_data_pass_on=computation_data_pass_on,
                                )
                        else:
                            continue
                    else:
                        continue
            else:
                pass
    except Exception as e:
        logging.warning(f"Following exception occured while recording process flows logs - {e}")
    return None


def flow_controller_handler(element_id, request, data):
    """
    Identifies the next element in the flow basis the scenarios configured in flow controller block

    Parameters:
        element_id (str): Element id of the subprocess tab/ block.
        request (AsgiRequest): Django request object.
        data (pandas DataFrame): Data pertaining to the parent element of the flow controller.
    """
    flow_controller_details = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["tab_body_content"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": element_id,
                    "and_or": "",
                }
            ],
        },
    ).tab_body_content.iloc[0]
    flow_controller_details = json.loads(flow_controller_details)
    flow_controller_details = flow_controller_details["Category_sub_elements"][0][
        "Category_sub_element_attributes"
    ][1]["value"]
    next_element = []
    for key, value in flow_controller_details.items():
        if value != "augmentation" and key not in ["decision_name", "decision_purpose"]:
            condition_value = value["value"]
            if value["type"] == "FloatField":
                condition_value = float(condition_value)
            elif value["type"] == "IntegerField":
                condition_value = int(condition_value)
            elif value["type"] == "BigIntegerField":
                condition_value = int(condition_value)
            elif value["type"] in ["DateField", "DateTimeField"]:
                condition_value = pd.to_datetime(condition_value)
            else:
                pass

            if value["condition"] == "Starts with":
                if not data[data[value["column"]].astype("str").startswith(condition_value)].empty:
                    next_element.append(key)
                else:
                    continue
            elif value["condition"] == "Ends with":
                if not data[data[value["column"]].str.endswith(condition_value)].empty:
                    next_element.append(key)
                else:
                    continue
            elif value["condition"] == "Equal to":
                if not data[data[value["column"]] == condition_value].empty:
                    next_element.append(key)
                else:
                    continue
            elif value["condition"] == "Not Equal to":
                if not data[data[value["column"]] != condition_value].empty:
                    next_element.append(key)
                else:
                    continue
            elif value["condition"] == "Greater than":
                if not data[data[value["column"]] > condition_value].empty:
                    next_element.append(key)
                else:
                    continue
            elif value["condition"] == "Smaller than":
                if not data[data[value["column"]] < condition_value].empty:
                    next_element.append(key)
                else:
                    continue
            elif value["condition"] == "IN":
                if not data[data[value["column"]].isin(condition_value)].empty:
                    next_element.append(key)
                else:
                    continue
            elif value["condition"] == "NOT IN":
                if not data[~data[value["column"]].isin(condition_value)].empty:
                    next_element.append(key)
                else:
                    continue
            else:
                continue
        else:
            continue
    return next_element


def createTransactionRecords(subprocess_code, subprocess_flow, app_code, transaction_id, request, run_time):
    """
    Creates transaction detail records in process flow model table

    Parameters:
        subprocess_code (str): Id of the sub-process where this element is in.
        subprocess_flow (dict): Dictionary of flow elements with details.
        transaction_id (str): Id of the existing transaction.
        app_code (str): Id of the application where this sub-process is in.
        request (AsgiRequest): Django request object.
        run_time (str): run time of specific transaction is recorded
    """
    username = request.user.username
    run_left = "0"
    process_code = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "NavigationSideBar",
                "Columns": ["item_group_code"],
            },
            "condition": [
                {
                    "column_name": "item_code",
                    "condition": "Equal to",
                    "input_value": subprocess_code,
                    "and_or": "",
                }
            ],
        },
    ).item_group_code.iloc[0]
    element_details = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "TabScreens",
                "Columns": ["element_id", "tab_header_name", "tab_type"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "IN",
                    "input_value": list(subprocess_flow.keys()),
                    "and_or": "",
                },
            ],
        },
    )
    flow_data = pd.DataFrame(
        columns=[
            "app_code",
            "process",
            "subprocess",
            "transaction_id",
            "flow",
            "flow_id",
            "current_status",
            "element_id",
            "created_by",
            "created_date",
            "modified_by",
            "modified_date",
            "element_name",
            "data_id",
            "tab_type",
            "detailed_status",
            "total_batch_data",
            "pass_batch_data",
            "redirect_status",
            "run_left",
            "run_time",
        ]
    )
    for ele in subprocess_flow:
        connector_config = subprocess_flow[ele].get("connector_config")
        flow_id = "NULL"
        if connector_config:
            if connector_config.get("nextElement"):
                flow_id = json.dumps(connector_config.get("nextElement"))
            else:
                pass
        else:
            pass
        if subprocess_flow[ele]["status"] == "Pass":
            redirect_status = "Active"
        else:
            redirect_status = "Not active"

        if subprocess_flow[ele].get("subprocess_code"):
            subprocess_code = subprocess_flow[ele].get("subprocess_code")
        transaction_element_detail = pd.DataFrame(
            [
                {
                    "app_code": app_code,
                    "process": process_code,
                    "subprocess": subprocess_code,
                    "transaction_id": transaction_id,
                    "flow": json.dumps(list(subprocess_flow.keys())),
                    "flow_id": flow_id,
                    "current_status": subprocess_flow[ele]["status"],
                    "element_id": ele,
                    "created_by": username,
                    "created_date": datetime.now(),
                    "modified_by": username,
                    "modified_date": datetime.now(),
                    "element_name": element_details.loc[
                        element_details.element_id == ele, "tab_header_name"
                    ].values[0],
                    "data_id": "",
                    "tab_type": element_details.loc[element_details.element_id == ele, "tab_type"].values[0],
                    "detailed_status": subprocess_flow[ele]["detailed_status"],
                    "total_batch_data": subprocess_flow[ele]["total_data"],
                    "pass_batch_data": subprocess_flow[ele]["passed_data"],
                    "redirect_status": redirect_status,
                    "run_left": run_left,
                    "run_time": str(run_time),
                }
            ]
        )
        flow_data = pd.concat([flow_data, transaction_element_detail], ignore_index=True)
    data_handling(request, flow_data, "Process_flow_model")
    return None


def paginationNum():
    return ["1", "5", "10", "25", "50", "75", "100", "All"]


class HTMLStripper(HTMLParser):
    def __init__(self):
        super().__init__()
        self.reset()
        self.strict = False
        self.convert_charrefs = True
        self.text = StringIO()

    def handle_data(self, d):
        self.text.write(d)

    def get_data(self):
        return self.text.getvalue()


def strip_tags(html):
    s = HTMLStripper()
    try:
        if type(html) != str:
            html = str(html)
        else:
            pass
        s.feed(html)
        return s.get_data()
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        return "-"


def strip_quotes(str):
    return str.replace('"', "").replace("'", "")


def replace_escape_chr_encode(data):
    try:
        return (
            data.replace("’", "&rsquo;")
            .replace("”", "&rdquo;")
            .replace("‘", "&lsquo;")
            .replace("“", "&ldquo;")
            .replace("'", "&rsquo;")
            .replace('"', "&rdquo;")
        )
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        return data


def replace_escape_chr_decode(data):
    try:
        return (
            data.replace("&rsquo;", "'")
            .replace("&rdquo;", '"')
            .replace("&rsquo;", "’")
            .replace("&rdquo;", "”")
            .replace("&lsquo;", "‘")
            .replace("&ldquo;", "“")
        )
    except Exception as e:
        logging.warning(f"Following exception occured - {e}")
        return data


def reorder_js(js_attr):
    act_order = []
    for i in js_attr:
        if i["parentvalue"] == "Show-hide":
            act_order.append(i)
    for i in js_attr:
        if i["parentvalue"] == "Cascading":
            act_order.append(i)
    for i in js_attr:
        if (
            i["parentvalue"] == "Auto-populate"
            or i["parentvalue"] == "Auto-populate Constant"
            or i["parentvalue"] == "Foreign-key-relation"
        ):
            act_order.append(i)
    for i in js_attr:
        if i["parentvalue"] not in [
            "Show-hide",
            "Cascading",
            "Auto-populate",
            "Auto-populate Constant",
            "Foreign-key-relation",
        ]:
            act_order.append(i)
    return act_order


def get_time_spent(df):
    mask = df["url_from"].notnull()
    df["prev_time"] = df["logged_time"].shift(1)
    df.reset_index(drop=True)
    if len(df) != 1:
        df.loc[0, "prev_time"] = df.loc[1, "prev_time"]
    else:
        df.loc[0, "prev_time"] = df.loc[0, "logged_time"]
    df["logged_time"] = df["logged_date"].astype("str") + " " + df["logged_time"].fillna("").astype("str")
    df["prev_time"] = df["logged_date"].astype("str") + " " + df["prev_time"].fillna("").astype("str")
    df["logged_time"] = pd.to_datetime(df["logged_time"]).dt.floor("S")
    df["prev_time"] = pd.to_datetime(df["prev_time"], format="mixed").dt.floor("S")
    df.loc[mask, "time_spent1"] = df.loc[mask, "logged_time"] - df.loc[mask, "prev_time"]
    df.loc[mask, "time_spent"] = df.loc[mask, "time_spent1"].apply(format_time_spent)
    df.drop(["prev_time", "time_spent1"], axis=1, inplace=True)
    return df


def format_time_spent(inpt_date):
    act_val = inpt_date.components
    hours = act_val.hours
    minutes = act_val.minutes
    seconds = act_val.seconds
    output_str = 0
    if hours > 0:
        output_str = output_str + hours * 60 * 60
    if minutes > 0:
        output_str = output_str + minutes * 60
    if seconds > 0:
        output_str = output_str + seconds
    if hours == 0 and minutes == 0 and seconds == 0:
        output_str = 0
    output_str = round(float(output_str / 3600), 2)
    return output_str


def check_multi_import_id(element_id, request):
    element_config = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_configuration",
                "Columns": ["element_config", "element_name"],
            },
            "condition": [
                {
                    "column_name": "element_id",
                    "condition": "Equal to",
                    "input_value": element_id,
                    "and_or": "",
                },
            ],
        },
    )
    if len(element_config) > 0:
        elecon_dict = element_config.element_config.iloc[0]
        config_dict = json.loads(elecon_dict)
        if config_dict.get("function"):
            function = config_dict["function"]
        else:
            function = ""
        if function and function == "Import Data":
            if config_dict["inputs"]["Data_source"] in ["SFTP", "FTP", "AWS_S3", "AZURE"]:
                return True, config_dict
            else:
                return False, {}
        else:
            return False, {}
    else:
        return False, {}


def add_scripts_grapesjs(tab_name, plotInd=False, compute_list=[], compute_prev_list=[]):
    script = """<script src="{% static 'js/Kore_TI_js/create_view_form.js/create_view_save_form.min.js' %}" defer></script>
    <script type="text/javascript" src="{% static 'js/Kore_TI_js/htmlGeneratorScript.min.js' %}"></script>"""
    if "create_view" in tab_name:
        script = (
            script
            + """
        <script type="module" src="{% static 'js/Kore_TI_js/embeded_computation.min.js' %}" defer></script>"""
        )
    if "list_view" in tab_name:
        script = (
            script
            + """<script src="{% static 'js/Kore_TI_js/datatables/base_datatable_filter.min.js' %}"></script>
            <script type="module" src="{% static 'js/Kore_TI_js/embeded_computation_list_view.min.js' %}" defer></script>
            <link rel="stylesheet" href="{% static 'vendor/Base_theme/ion-range-slider/css/ion.rangeSlider.min.css' %}"/>
            <script src="{% static 'vendor/Base_theme/ion-range-slider/js/ion.rangeSlider.min.js' %}"></script>
            <script type="module" src="{% static 'js/Kore_TI_js/embeded_computation.min.js' %}" defer></script>
        """
        )
    if "computation" in tab_name:
        script += """
        <script type="text/javascript" src="{% static 'js/Kore_TI_js/computation/computation.min.js' %}"></script>
        <script>
        """
        for i in compute_list:
            script += f"computationElementIdsArray.push('{i}');\n"
        for i in compute_prev_list:
            script += f"previousRunComputeElementIdArray.push('{i}');\n"
        script += """
            var globalVariableID = []
            $('.gVarDropDown').each(function() {
            var id = $(this).closest('.form-row').attr('data-parent_element_id');
            globalVariableID.push(id);
            })
            if (globalVariableID.length) {
            $.ajax({
                url:`/users/${urlPath}/dynamicVal/`,
                data: {
                'operation':'popuplateGlobalVariable',
                'element_id_list': JSON.stringify(globalVariableID),
                },
                type: 'POST',
                dataType: "json",
                success: function (data) {
                $('.gVarDropDown').each(function() {
                    var idGV = $(this).attr('name').split('gVar_')[1];
                    var listGV = data[idGV]
                    $(this).find('select').empty();
                    for(let i = 0; i < listGV.length; i++) {
                    $(this).find('select').append(`<option value="${listGV[i]}">${listGV[i]}</option>`);
                    }
                })
                },
                error: ()=>{
                Swal.fire({icon: 'error',text: 'Error! Please try again.'});
                }
            });
            }
        </script>
        <script>populateCascades()</script>
        <script>masterComputeExecutionHandler(computationElementIdsArray)</script>
        <script>masterComputePreviousRunDisplayHandler(previousRunComputeElementIdArray)</script>
        """
    if ("list_view" in tab_name and plotInd) or ("analysis" in tab_name):
        script = (
            script
            + """<script src="{% static 'js/Kore_TI_js/plot_charts/plotly_chartsAnalysisUtilites.min.js' %}"></script>"""
        )
        script = (
            script
            + """<script src="{% static 'js/Kore_TI_js/plot_charts/plotly_chartsAnalysis.min.js' %}" ></script>"""
        )
        script = (
            script
            + """<script src="{% static 'js/Kore_TI_js/plot_charts/plotly_chartsAnalysis_modal.min.js' %}"></script>
      <script defer>masterPlotly(analysiselementIDList)</script>
      """
        )
    return script


def add_html_grapesjs(tab_name):
    html = ""
    if "data_connector" == tab_name:
        html += """<script src="{% static 'js/Kore_TI_js/Standardized_JS/upload_block.min.js' %}" defer></script>"""
    if "analysis" == tab_name or "list_view" == tab_name:
        html = (
            html
            + """
        <style>
            /* Dropdown Button */


            /* .modal-dialog {
                max-width: 1300px;
                margin: 0.75rem auto;
            } */

            .analysisDashboardmove {
                background-color: var(--font-hover-color);
            }

            .tabulator .tabulator-header .tabulator-col {
                background-color: var(--primary-color);
                color: var(--font-hover-color);
                text-align: center;

            }


            .dropbtn {
                background-color: var(--font-hover-color);
                color: var(--font-color);
                padding: 1px;
                font-size: 30px;
                border: none;
            }

            .xaxislayer-above {
                /* cursor: pointer; */
                pointer-events: all;
            }

            .yaxislayer-above {
                /* cursor: pointer; */
                pointer-events: all;
            }

            /* The container <div> - needed to position the dropdown content */
            .dropdown {
                position: relative;
                display: inline-block;
            }

            /* Dropdown Content (Hidden by Default) */
            .dropdown-content {
                display: none;
                position: absolute;
                background-color: var(--font-hover-color);
                min-width: 110px;
                box-shadow: 0px 8px 16px 0px rgba(0, 0, 0, 0.2);
                z-index: 1000;
            }

            .dropdown2-tab {
                position: relative;
                display: inline-block;
            }

            /* Dropdown Content (Hidden by Default) */
            .dropdown2-content-tab {
                display: none;
                position: absolute;
                background-color: var(--font-hover-color);
                min-width: 110px;
                box-shadow: 0px 8px 16px 0px rgba(0, 0, 0, 0.2);
                z-index: 1000;
            }

            /* Links inside the dropdown */
            .dropdown-content div {
                color: var(--font-color);
                padding: 2px 1px;
                text-decoration: none;
                display: block;
            }

            /* Change color of dropdown links on hover */
            .dropdown-content a:hover {
                background-color: #ddd;
            }

            /* Show the dropdown menu on hover */
            .dropdown:hover .dropdown-content {
                display: block;
            }

            .dropdown2-content-tab div {
                color: var(--font-color);
                padding: 2px 1px;
                text-decoration: none;
                display: block;
            }

            /* Change color of dropdown links on hover */
            .dropdown2-content-tab a:hover {
                background-color: #ddd;
            }
            /* Give grid like background to chart parent container */
        </style>
        <script>
            if ($('textarea[name="text_editor"]').length > 0) {
              var form_rtf = ['CreateDiv,Anchor,Language,About,PasteText,PasteFromWord,Find,Replace,SelectAll,Scayt,Blockquote,Outdent,Indent,BulletedList,NumberedList,CopyFormatting,RemoveFormat,Bold,Italic,Underline,Strike,Subscript,Superscript,TextColor,BidiLtr,BidiRtl,Templates,Link,Unlink,Source,Save,NewPage,ExportPdf,Preview,Print,Styles,Format,Font,FontSize,BGColor,ShowBlocks,Maximize,JustifyLeft,JustifyCenter,JustifyRight,JustifyBlock,HorizontalRule,SpecialChar,PageBreak,Iframe,Flash,Table,Image,Smiley'];
              var home_rtf =['Source,Save,Templates,CreateDiv,Unlink,Anchor,Language,Link,Image,Flash,Table,HorizontalRule,SpecialChar,PageBreak,Iframe,ShowBlocks,Maximize,About,Print,Preview,ExportPdf,NewPage,Form,Checkbox,Radio,TextField,Textarea,Select,Button,ImageButton,HiddenField,Smiley'];
              var tools_rtf =['Flash,About,Templates,Cut,Copy,Paste,PasteText,PasteFromWord,Redo,Undo,Find,Replace,SelectAll,Scayt,Form,Checkbox,Radio,TextField,Textarea,Select,Button,ImageButton,HiddenField,Bold,Italic,Underline,Strike,Subscript,Superscript,CopyFormatting,RemoveFormat,Outdent,NumberedList,BulletedList,Indent,Blockquote,JustifyLeft,CreateDiv,JustifyCenter,JustifyRight,JustifyBlock,Language,BidiRtl,BidiLtr,Link,Unlink,Anchor,Image,Table,HorizontalRule,Smiley,SpecialChar,PageBreak,Iframe,Styles,Format,Font,FontSize,TextColor,BGColor'];
              var insert_rtf2 =['Source,Save,NewPage,ExportPdf,Preview,Print,Templates,PasteText,PasteFromWord,Replace,Find,SelectAll,Scayt,Form,Checkbox,Radio,TextField,Textarea,Select,Button,ImageButton,HiddenField,Bold,BidiLtr,BidiRtl,Language,JustifyRight,JustifyBlock,JustifyCenter,CreateDiv,Indent,BulletedList,NumberedList,Outdent,Blockquote,JustifyLeft,CopyFormatting,RemoveFormat,Styles,Format,Font,FontSize,TextColor,BGColor,ShowBlocks,Maximize,About,Italic,Underline,Strike,Subscript,Superscript'];
              CKEDITOR.replace(`text_editor`,{height: 60, removeButtons:home_rtf[0]});
              CKEDITOR.config.removePlugins = 'exportpdf';
              CKEDITOR.config.extraPlugins = 'autocorrect';
              $(".rtf_action_tab").find('button').each(function(){
                $(this).on('click',function(){
                  $(".rtf_action_tab").find('button').removeClass('active')
                  $(this).addClass('active')
                  if($(this).attr('data-bs-target') == "Form"){
                    var editor = CKEDITOR.instances[`text_editor`];
                    var editor_data = CKEDITOR.instances[`text_editor`].getData()
                    if (editor) { editor.destroy(true); }
                    CKEDITOR.replace(`text_editor`,{height: 60,removeButtons:form_rtf[0] });
                    CKEDITOR.instances[`text_editor`].setData(editor_data)
                  }
                  else if ($(this).attr('data-bs-target') == "Text"){
                    var editor = CKEDITOR.instances[`text_editor`];
                    var editor_data = CKEDITOR.instances[`text_editor`].getData()
                    if (editor) { editor.destroy(true); }
                    CKEDITOR.replace(`text_editor`,{height: 60,removeButtons:home_rtf[0] });
                    CKEDITOR.instances[`text_editor`].setData(editor_data)
                  }
                  else if ($(this).attr('data-bs-target') == "Insert"){
                    var editor = CKEDITOR.instances[`text_editor`];
                    var editor_data = CKEDITOR.instances[`text_editor`].getData()
                    if (editor) { editor.destroy(true); }
                    CKEDITOR.replace(`text_editor`,{height: 60,removeButtons:insert_rtf2[0] });
                    CKEDITOR.instances[`text_editor`].setData(editor_data)
                  }
                  else if ($(this).attr('data-bs-target') == "Page Layout"){
                    var editor = CKEDITOR.instances[`text_editor`];
                    var editor_data = CKEDITOR.instances[`text_editor`].getData()
                    if (editor) { editor.destroy(true); }
                    CKEDITOR.replace(`text_editor`,{height: 60,removeButtons:tools_rtf[0] });
                    CKEDITOR.instances[`text_editor`].setData(editor_data)
                  }
                });
              });
              function ckEditorFunc () { // eslint-disable-line no-unused-vars
                const data = $(this).parent().parent().find('.commentbox').html()
                const id_ = $(this).parent().parent().attr('data-id')
                if (typeof (data) !== 'undefined') {
                  CKEDITOR.instances.text_editor.setData(`${data}`)
                }
                $('#ckEditorModal').attr('data-id', id_)
                $('#ckEditorModal').modal('show')
              }
              function saveCkEditor () { // eslint-disable-line no-unused-vars
                const editorData = CKEDITOR.instances.text_editor.getData()
                const id_ = $('#ckEditorModal').attr('data-id')
                $('#' + id_).find('.commentbox').html(editorData)
                $('#ckEditorModal').modal('hide')
              }
            }
        </script>
        """
        )

    return html


def update_navbar_order_configs(request, user_db_engine, db_type):
    updated_data_list = []

    if os.path.exists(f"{PLATFORM_FILE_PATH}user_databases_updation.json"):
        with open(f"{PLATFORM_FILE_PATH}user_databases_updation.json") as json_file:
            updated_data_list = json.load(json_file)
            json_file.close()

    subprocessname_to_code_dict = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "NavigationSideBar",
                "Columns": ["item_code", "item_name"],
            },
            "condition": [
                {
                    "column_name": "item_group_code",
                    "condition": "Not Equal to",
                    "input_value": "NULL",
                    "and_or": "",
                }
            ],
        },
        engine2=user_db_engine,
        db_type=db_type,
        engine_override=True,
    )
    subprocessname_to_code_dict = subprocessname_to_code_dict.set_index("item_name")["item_code"].to_dict()

    processname_to_code_dict = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "NavigationSideBar",
                "Columns": ["item_code", "item_name"],
            },
            "condition": [
                {
                    "column_name": "item_group_code",
                    "condition": "Equal to",
                    "input_value": "NULL",
                    "and_or": "",
                }
            ],
        },
        engine2=user_db_engine,
        db_type=db_type,
        engine_override=True,
    )
    processname_to_code_dict = processname_to_code_dict.set_index("item_name")["item_code"].to_dict()

    app_config = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "Application",
                "Columns": ["application_code", "navbar_order"],
            },
            "condition": [],
        },
        engine2=user_db_engine,
        db_type=db_type,
        engine_override=True,
    )

    app_config = app_config.to_dict("records")
    for conf in app_config:
        if conf["application_code"] not in updated_data_list:
            old_navbar_order = conf["navbar_order"]
            if old_navbar_order and old_navbar_order is not None:
                old_navbar_order = json.loads(old_navbar_order)
            else:
                old_navbar_order = None

            new_navbar_order = {}
            issue_flag = False
            if old_navbar_order:
                for process_name, process_config in old_navbar_order.items():
                    try:
                        new_navbar_order[processname_to_code_dict[process_name]] = {}
                        for order, subprocess_name_conf in process_config.items():
                            new_navbar_order[processname_to_code_dict[process_name]][order] = {}
                            for order_inner, subprocess_names in subprocess_name_conf.items():
                                new_navbar_order[processname_to_code_dict[process_name]][order][
                                    order_inner
                                ] = subprocessname_to_code_dict[subprocess_names]
                    except Exception as e:
                        logging.warning(
                            f"Following exception occured in update_navbar_order_configs for app_code {conf['application_code']} - {e}"
                        )
                        issue_flag = True
                        new_navbar_order = {}
                        break

            if not issue_flag and old_navbar_order:
                update_data_func(
                    request="",
                    config_dict={
                        "inputs": {
                            "Data_source": "Database",
                            "Table": "Application",
                            "Columns": [
                                {
                                    "column_name": "navbar_order",
                                    "input_value": json.dumps(new_navbar_order),
                                    "separator": "",
                                },
                            ],
                        },
                        "condition": [
                            {
                                "column_name": "application_code",
                                "condition": "Equal to",
                                "input_value": conf["application_code"],
                                "and_or": "",
                            }
                        ],
                    },
                    engine2=user_db_engine,
                    db_type=db_type,
                    engine_override=True,
                )

                updated_data_list.append(conf["application_code"])

    if os.path.exists(f"{PLATFORM_FILE_PATH}user_databases_updation.json"):
        with open(f"{PLATFORM_FILE_PATH}user_databases_updation.json", "w") as outfile:
            json.dump(updated_data_list, outfile, indent=4)
            outfile.close()


def cal_upload_computation(request, tablename, comp_model, import_element_id, data_csv):

    flowchart_elements = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_flowchart",
                "Columns": ["flowchart_elements"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": comp_model,
                    "and_or": "",
                },
            ],
        },
    )
    flowchart_elements = flowchart_elements.iloc[0, 0]
    flowchart_elements = json.loads(flowchart_elements)
    global_config = read_data_func(
        request,
        {
            "inputs": {
                "Data_source": "Database",
                "Table": "computation_model_configuration",
                "Columns": ["element_config", "element_id"],
            },
            "condition": [
                {
                    "column_name": "model_name",
                    "condition": "Equal to",
                    "input_value": comp_model,
                    "and_or": "and",
                },
                {
                    "column_name": "element_id",
                    "condition": "Contains",
                    "input_value": "globalVariable",
                    "and_or": "",
                },
            ],
        },
    )
    if len(global_config) > 0:
        global_dict = global_config.element_config.iloc[-1]
        global_element_id = global_config.element_id.iloc[-1]
        global_dict = json.loads(global_dict)
    else:
        global_dict = {}
        global_element_id = ""

    data_csv1 = run_process_model_run_handler(
        request,
        flowchart_elements=flowchart_elements,
        model_name=comp_model,
        global_dict=global_dict,
        global_element_id=global_element_id,
        data_csv=data_csv,
        upload_then_compute=True,
        upload_import_ele=import_element_id,
    )
    if data_csv1["element_error_message"] == "Success":
        if isinstance(data_csv1["content"], pd.DataFrame):
            final_data = data_csv1["content"]
        else:
            final_data = None
    else:
        final_data = None

    return final_data
